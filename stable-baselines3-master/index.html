<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Stable Baselines3 2.2.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
      <link rel="stylesheet" type="text/css" href="_static/css/baselines_theme.css" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="#" class="icon icon-home">
            Stable Baselines3
              <img src="_static/logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                master
              </div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/install">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/quickstart">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/rl_tips">Reinforcement Learning Tips and Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/rl">Reinforcement Learning Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/algos">RL Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/examples">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/vec_envs">Vectorized Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/custom_policy">Policy Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/custom_env">Using Custom Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/callbacks">Callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/tensorboard">Tensorboard Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/integrations">Integrations</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/rl_zoo">RL Baselines3 Zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/sb3_contrib">SB3 Contrib</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/sbx">Stable Baselines Jax (SBX)</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/imitation">Imitation Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/migration">Migrating from Stable-Baselines</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/checking_nan">Dealing with NaNs and infs</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/developer">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/save_format">On saving and loading</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-guide/export">Exporting models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RL Algorithms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-modules/base">Base RL Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-modules/a2c">A2C</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-modules/ddpg">DDPG</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-modules/dqn">DQN</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-modules/her">HER</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-modules/ppo">PPO</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-modules/sac">SAC</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-modules/td3">TD3</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Common</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-common/atari_wrappers">Atari Wrappers</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-common/env_util">Environments Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-common/envs">Custom Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-common/distributions">Probability Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-common/evaluation">Evaluation Helper</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-common/env_checker">Gym Environment Checker</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-common/monitor">Monitor Wrapper</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-common/logger">Logger</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-common/noise">Action Noise</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-common/utils">Utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-misc/changelog">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-misc/projects">Projects</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">Stable Baselines3</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Stable Baselines3 2.2.1 documentation</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/DLR-RM/stable-baselines3/blob/master/docs/index" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="stable-baselines3-docs-reliable-reinforcement-learning-implementations">
<h1>Stable-Baselines3 Docs - Reliable Reinforcement Learning Implementations<a class="headerlink" href="#stable-baselines3-docs-reliable-reinforcement-learning-implementations" title="Permalink to this heading"></a></h1>
<p><a class="reference external" href="https://github.com/DLR-RM/stable-baselines3">Stable Baselines3 (SB3)</a> is a set of reliable implementations of reinforcement learning algorithms in PyTorch.
It is the next major version of <a class="reference external" href="https://github.com/hill-a/stable-baselines">Stable Baselines</a>.</p>
<p>Github repository: <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3">https://github.com/DLR-RM/stable-baselines3</a></p>
<p>Paper: <a class="reference external" href="https://jmlr.org/papers/volume22/20-1364/20-1364.pdf">https://jmlr.org/papers/volume22/20-1364/20-1364.pdf</a></p>
<p>RL Baselines3 Zoo (training framework for SB3): <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">https://github.com/DLR-RM/rl-baselines3-zoo</a></p>
<p>RL Baselines3 Zoo provides a collection of pre-trained agents, scripts for training, evaluating agents, tuning hyperparameters, plotting results and recording videos.</p>
<p>SB3 Contrib (experimental RL code, latest algorithms): <a class="reference external" href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib">https://github.com/Stable-Baselines-Team/stable-baselines3-contrib</a></p>
<section id="main-features">
<h2>Main Features<a class="headerlink" href="#main-features" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p>Unified structure for all algorithms</p></li>
<li><p>PEP8 compliant (unified code style)</p></li>
<li><p>Documented functions and classes</p></li>
<li><p>Tests, high code coverage and type hints</p></li>
<li><p>Clean code</p></li>
<li><p>Tensorboard support</p></li>
<li><p><strong>The performance of each algorithm was tested</strong> (see <em>Results</em> section in their respective page)</p></li>
</ul>
<div class="toctree-wrapper compound">
<span id="document-guide/install"></span><section id="installation">
<span id="install"></span><h3>Installation<a class="headerlink" href="#installation" title="Permalink to this heading"></a></h3>
<section id="prerequisites">
<h4>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this heading"></a></h4>
<p>Stable-Baselines3 requires python 3.8+ and PyTorch &gt;= 1.13</p>
<section id="windows">
<h5>Windows<a class="headerlink" href="#windows" title="Permalink to this heading"></a></h5>
<p>We recommend using <a class="reference external" href="https://conda.io/docs/user-guide/install/windows.html">Anaconda</a> for Windows users for easier installation of Python packages and required libraries. You need an environment with Python version 3.8 or above.</p>
<p>For a quick start you can move straight to installing Stable-Baselines3 in the next step.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Trying to create Atari environments may result to vague errors related to missing DLL files and modules. This is an
issue with atari-py package. <a class="reference external" href="https://github.com/openai/atari-py/issues/65">See this discussion for more information</a>.</p>
</div>
</section>
<section id="stable-release">
<h5>Stable Release<a class="headerlink" href="#stable-release" title="Permalink to this heading"></a></h5>
<p>To install Stable Baselines3 with pip, execute:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>stable-baselines3<span class="o">[</span>extra<span class="o">]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Some shells such as Zsh require quotation marks around brackets, i.e. <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">'stable-baselines3[extra]'</span></code> <a class="reference external" href="https://stackoverflow.com/a/30539963">More information</a>.</p>
</div>
<p>This includes an optional dependencies like Tensorboard, OpenCV or <code class="docutils literal notranslate"><span class="pre">ale-py</span></code> to train on Atari games. If you do not need those, you can use:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>stable-baselines3
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you need to work with OpenCV on a machine without a X-server (for instance inside a docker image),
you will need to install <code class="docutils literal notranslate"><span class="pre">opencv-python-headless</span></code>, see <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/298">issue #298</a>.</p>
</div>
</section>
</section>
<section id="bleeding-edge-version">
<h4>Bleeding-edge version<a class="headerlink" href="#bleeding-edge-version" title="Permalink to this heading"></a></h4>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/DLR-RM/stable-baselines3
</pre></div>
</div>
<p>with extras:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;stable_baselines3[extra,tests,docs] @ git+https://github.com/DLR-RM/stable-baselines3&quot;</span>
</pre></div>
</div>
</section>
<section id="development-version">
<h4>Development version<a class="headerlink" href="#development-version" title="Permalink to this heading"></a></h4>
<p>To contribute to Stable-Baselines3, with support for running tests and building the documentation.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/DLR-RM/stable-baselines3<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>stable-baselines3
pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span>.<span class="o">[</span>docs,tests,extra<span class="o">]</span>
</pre></div>
</div>
</section>
<section id="using-docker-images">
<h4>Using Docker Images<a class="headerlink" href="#using-docker-images" title="Permalink to this heading"></a></h4>
<p>If you are looking for docker images with stable-baselines already installed in it,
we recommend using images from <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">RL Baselines3 Zoo</a>.</p>
<p>Otherwise, the following images contained all the dependencies for stable-baselines3 but not the stable-baselines3 package itself.
They are made for development.</p>
<section id="use-built-images">
<h5>Use Built Images<a class="headerlink" href="#use-built-images" title="Permalink to this heading"></a></h5>
<p>GPU image (requires <a class="reference external" href="https://github.com/NVIDIA/nvidia-docker">nvidia-docker</a>):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>pull<span class="w"> </span>stablebaselines/stable-baselines3
</pre></div>
</div>
<p>CPU only:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>pull<span class="w"> </span>stablebaselines/stable-baselines3-cpu
</pre></div>
</div>
</section>
<section id="build-the-docker-images">
<h5>Build the Docker Images<a class="headerlink" href="#build-the-docker-images" title="Permalink to this heading"></a></h5>
<p>Build GPU image (with nvidia-docker):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>make<span class="w"> </span>docker-gpu
</pre></div>
</div>
<p>Build CPU image:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>make<span class="w"> </span>docker-cpu
</pre></div>
</div>
<p>Note: if you are using a proxy, you need to pass extra params during
build and do some <a class="reference external" href="https://stackoverflow.com/questions/23111631/cannot-download-docker-images-behind-a-proxy">tweaks</a>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>--network<span class="o">=</span>host<span class="w"> </span>--build-arg<span class="w"> </span><span class="nv">HTTP_PROXY</span><span class="o">=</span>http://your.proxy.fr:8080/<span class="w"> </span>--build-arg<span class="w"> </span><span class="nv">http_proxy</span><span class="o">=</span>http://your.proxy.fr:8080/<span class="w"> </span>--build-arg<span class="w"> </span><span class="nv">HTTPS_PROXY</span><span class="o">=</span>https://your.proxy.fr:8080/<span class="w"> </span>--build-arg<span class="w"> </span><span class="nv">https_proxy</span><span class="o">=</span>https://your.proxy.fr:8080/
</pre></div>
</div>
</section>
<section id="run-the-images-cpu-gpu">
<h5>Run the images (CPU/GPU)<a class="headerlink" href="#run-the-images-cpu-gpu" title="Permalink to this heading"></a></h5>
<p>Run the nvidia-docker GPU image</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>run<span class="w"> </span>-it<span class="w"> </span>--runtime<span class="o">=</span>nvidia<span class="w"> </span>--rm<span class="w"> </span>--network<span class="w"> </span>host<span class="w"> </span>--ipc<span class="o">=</span>host<span class="w"> </span>--name<span class="w"> </span><span class="nb">test</span><span class="w"> </span>--mount<span class="w"> </span><span class="nv">src</span><span class="o">=</span><span class="s2">&quot;</span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span><span class="s2">&quot;</span>,target<span class="o">=</span>/home/mamba/stable-baselines3,type<span class="o">=</span><span class="nb">bind</span><span class="w"> </span>stablebaselines/stable-baselines3<span class="w"> </span>bash<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;cd /home/mamba/stable-baselines3/ &amp;&amp; pytest tests/&#39;</span>
</pre></div>
</div>
<p>Or, with the shell file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./scripts/run_docker_gpu.sh<span class="w"> </span>pytest<span class="w"> </span>tests/
</pre></div>
</div>
<p>Run the docker CPU image</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>run<span class="w"> </span>-it<span class="w"> </span>--rm<span class="w"> </span>--network<span class="w"> </span>host<span class="w"> </span>--ipc<span class="o">=</span>host<span class="w"> </span>--name<span class="w"> </span><span class="nb">test</span><span class="w"> </span>--mount<span class="w"> </span><span class="nv">src</span><span class="o">=</span><span class="s2">&quot;</span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span><span class="s2">&quot;</span>,target<span class="o">=</span>/home/mamba/stable-baselines3,type<span class="o">=</span><span class="nb">bind</span><span class="w"> </span>stablebaselines/stable-baselines3-cpu<span class="w"> </span>bash<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;cd /home/mamba/stable-baselines3/ &amp;&amp; pytest tests/&#39;</span>
</pre></div>
</div>
<p>Or, with the shell file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./scripts/run_docker_cpu.sh<span class="w"> </span>pytest<span class="w"> </span>tests/
</pre></div>
</div>
<p>Explanation of the docker command:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">run</span> <span class="pre">-it</span></code> create an instance of an image (=container), and
run it interactively (so ctrl+c will work)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--rm</span></code> option means to remove the container once it exits/stops
(otherwise, you will have to use <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">rm</span></code>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--network</span> <span class="pre">host</span></code> don’t use network isolation, this allow to use
tensorboard/visdom on host machine</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--ipc=host</span></code> Use the host system’s IPC namespace. IPC (POSIX/SysV IPC) namespace provides
separation of named shared memory segments, semaphores and message
queues.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--name</span> <span class="pre">test</span></code> give explicitly the name <code class="docutils literal notranslate"><span class="pre">test</span></code> to the container,
otherwise it will be assigned a random name</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--mount</span> <span class="pre">src=...</span></code> give access of the local directory (<code class="docutils literal notranslate"><span class="pre">pwd</span></code>
command) to the container (it will be map to <code class="docutils literal notranslate"><span class="pre">/home/mamba/stable-baselines</span></code>), so
all the logs created in the container in this folder will be kept</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bash</span> <span class="pre">-c</span> <span class="pre">'...'</span></code> Run command inside the docker image, here run the tests
(<code class="docutils literal notranslate"><span class="pre">pytest</span> <span class="pre">tests/</span></code>)</p></li>
</ul>
</section>
</section>
</section>
<span id="document-guide/quickstart"></span><section id="getting-started">
<span id="quickstart"></span><h3>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this heading"></a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Stable-Baselines3 (SB3) uses <a class="reference internal" href="index.html#vec-env"><span class="std std-ref">vectorized environments (VecEnv)</span></a> internally.
Please read the associated section to learn more about its features and differences compared to a single Gym environment.</p>
</div>
<p>Most of the library tries to follow a sklearn-like syntax for the Reinforcement Learning algorithms.</p>
<p>Here is a quick example of how to train and run A2C on a CartPole environment:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">A2C</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">A2C</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">10_000</span><span class="p">)</span>

<span class="n">vec_env</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_env</span><span class="p">()</span>
<span class="n">obs</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">_state</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="n">vec_env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">)</span>
    <span class="c1"># VecEnv resets automatically</span>
    <span class="c1"># if done:</span>
    <span class="c1">#   obs = vec_env.reset()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can find explanations about the logger output and names in the <a class="reference internal" href="index.html#logger"><span class="std std-ref">Logger</span></a> section.</p>
</div>
<p>Or just train a model with a one line if
<a class="reference external" href="https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/#registering-envs">the environment is registered in Gymnasium</a> and if
the policy is registered:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">A2C</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">A2C</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;CartPole-v1&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
</pre></div>
</div>
</section>
<span id="document-guide/rl_tips"></span><section id="reinforcement-learning-tips-and-tricks">
<span id="rl-tips"></span><h3>Reinforcement Learning Tips and Tricks<a class="headerlink" href="#reinforcement-learning-tips-and-tricks" title="Permalink to this heading"></a></h3>
<p>The aim of this section is to help you do reinforcement learning experiments.
It covers general advice about RL (where to start, which algorithm to choose, how to evaluate an algorithm, …),
as well as tips and tricks when using a custom environment or implementing an RL algorithm.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We have a <a class="reference external" href="https://www.youtube.com/watch?v=Ikngt0_DXJg">video on YouTube</a> that covers
this section in more details. You can also find the <a class="reference external" href="https://araffin.github.io/slides/rlvs-tips-tricks/">slides here</a>.</p>
</div>
<section id="general-advice-when-using-reinforcement-learning">
<h4>General advice when using Reinforcement Learning<a class="headerlink" href="#general-advice-when-using-reinforcement-learning" title="Permalink to this heading"></a></h4>
<section id="tl-dr">
<h5>TL;DR<a class="headerlink" href="#tl-dr" title="Permalink to this heading"></a></h5>
<ol class="arabic simple">
<li><p>Read about RL and Stable Baselines3</p></li>
<li><p>Do quantitative experiments and hyperparameter tuning if needed</p></li>
<li><p>Evaluate the performance using a separate test environment (remember to check wrappers!)</p></li>
<li><p>For better performance, increase the training budget</p></li>
</ol>
<p>Like any other subject, if you want to work with RL, you should first read about it (we have a dedicated <a class="reference external" href="rl.html">resource page</a> to get you started)
to understand what you are using. We also recommend you read Stable Baselines3 (SB3) documentation and do the <a class="reference external" href="https://github.com/araffin/rl-tutorial-jnrr19">tutorial</a>.
It covers basic usage and guide you towards more advanced concepts of the library (e.g. callbacks and wrappers).</p>
<p>Reinforcement Learning differs from other machine learning methods in several ways. The data used to train the agent is collected
through interactions with the environment by the agent itself (compared to supervised learning where you have a fixed dataset for instance).
This dependence can lead to vicious circle: if the agent collects poor quality data (e.g., trajectories with no rewards), then it will not improve and continue to amass
bad trajectories.</p>
<p>This factor, among others, explains that results in RL may vary from one run to another (i.e., when only the seed of the pseudo-random generator changes).
For this reason, you should always do several runs to have quantitative results.</p>
<p>Good results in RL are generally dependent on finding appropriate hyperparameters. Recent algorithms (PPO, SAC, TD3, DroQ) normally require little hyperparameter tuning,
however, <em>don’t expect the default ones to work</em> on any environment.</p>
<p>Therefore, we <em>highly recommend you</em> to take a look at the <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">RL zoo</a> (or the original papers) for tuned hyperparameters.
A best practice when you apply RL to a new problem is to do automatic hyperparameter optimization. Again, this is included in the <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">RL zoo</a>.</p>
<p>When applying RL to a custom problem, you should always normalize the input to the agent (e.g. using <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> for PPO/A2C)
and look at common preprocessing done on other environments (e.g. for <a class="reference external" href="https://danieltakeshi.github.io/2016/11/25/frame-skipping-and-preprocessing-for-deep-q-networks-on-atari-2600-games/">Atari</a>, frame-stack, …).
Please refer to <em>Tips and Tricks when creating a custom environment</em> paragraph below for more advice related to custom environments.</p>
</section>
<section id="current-limitations-of-rl">
<h5>Current Limitations of RL<a class="headerlink" href="#current-limitations-of-rl" title="Permalink to this heading"></a></h5>
<p>You have to be aware of the current <a class="reference external" href="https://www.alexirpan.com/2018/02/14/rl-hard.html">limitations</a> of reinforcement learning.</p>
<p>Model-free RL algorithms (i.e. all the algorithms implemented in SB) are usually <em>sample inefficient</em>. They require a lot of samples (sometimes millions of interactions) to learn something useful.
That’s why most of the successes in RL were achieved on games or in simulation only. For instance, in this <a class="reference external" href="https://www.youtube.com/watch?v=aTDkYFZFWug">work</a> by ETH Zurich, the ANYmal robot was trained in simulation only, and then tested in the real world.</p>
<p>As a general advice, to obtain better performances, you should augment the budget of the agent (number of training timesteps).</p>
<p>In order to achieve the desired behavior, expert knowledge is often required to design an adequate reward function.
This <em>reward engineering</em> (or <em>RewArt</em> as coined by <a class="reference external" href="http://www.freekstulp.net/">Freek Stulp</a>), necessitates several iterations. As a good example of reward shaping,
you can take a look at <a class="reference external" href="https://xbpeng.github.io/projects/DeepMimic/index.html">Deep Mimic paper</a> which combines imitation learning and reinforcement learning to do acrobatic moves.</p>
<p>One last limitation of RL is the instability of training. That is to say, you can observe during training a huge drop in performance.
This behavior is particularly present in <code class="docutils literal notranslate"><span class="pre">DDPG</span></code>, that’s why its extension <code class="docutils literal notranslate"><span class="pre">TD3</span></code> tries to tackle that issue.
Other method, like <code class="docutils literal notranslate"><span class="pre">TRPO</span></code> or <code class="docutils literal notranslate"><span class="pre">PPO</span></code> make use of a <em>trust region</em> to minimize that problem by avoiding too large update.</p>
</section>
<section id="how-to-evaluate-an-rl-algorithm">
<h5>How to evaluate an RL algorithm?<a class="headerlink" href="#how-to-evaluate-an-rl-algorithm" title="Permalink to this heading"></a></h5>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Pay attention to environment wrappers when evaluating your agent and comparing results to others’ results. Modifications to episode rewards
or lengths may also affect evaluation results which may not be desirable. Check <code class="docutils literal notranslate"><span class="pre">evaluate_policy</span></code> helper function in <a class="reference internal" href="index.html#eval"><span class="std std-ref">Evaluation Helper</span></a> section.</p>
</div>
<p>Because most algorithms use exploration noise during training, you need a separate test environment to evaluate the performance
of your agent at a given time. It is recommended to periodically evaluate your agent for <code class="docutils literal notranslate"><span class="pre">n</span></code> test episodes (<code class="docutils literal notranslate"><span class="pre">n</span></code> is usually between 5 and 20)
and average the reward per episode to have a good estimate.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We provide an <code class="docutils literal notranslate"><span class="pre">EvalCallback</span></code> for doing such evaluation. You can read more about it in the <a class="reference internal" href="index.html#callbacks"><span class="std std-ref">Callbacks</span></a> section.</p>
</div>
<p>As some policies are stochastic by default (e.g. A2C or PPO), you should also try to set <cite>deterministic=True</cite> when calling the <cite>.predict()</cite> method,
this frequently leads to better performance.
Looking at the training curve (episode reward function of the timesteps) is a good proxy but underestimates the agent true performance.</p>
<p>We highly recommend reading <a class="reference external" href="https://arxiv.org/abs/2304.01315">Empirical Design in Reinforcement Learning</a>, as it provides valuable insights for best practices when running RL experiments.</p>
<p>We also suggest reading <a class="reference external" href="https://arxiv.org/abs/1709.06560">Deep Reinforcement Learning that Matters</a> for a good discussion about RL evaluation,
and <a class="reference external" href="https://araffin.github.io/post/rliable/">Rliable: Better Evaluation for Reinforcement Learning</a> for comparing results.</p>
<p>You can also take a look at this <a class="reference external" href="https://openlab-flowers.inria.fr/t/how-many-random-seeds-should-i-use-statistical-power-analysis-in-deep-reinforcement-learning-experiments/457">blog post</a>
and this <a class="reference external" href="https://github.com/hill-a/stable-baselines/issues/199">issue</a> by Cédric Colas.</p>
</section>
</section>
<section id="which-algorithm-should-i-use">
<h4>Which algorithm should I use?<a class="headerlink" href="#which-algorithm-should-i-use" title="Permalink to this heading"></a></h4>
<p>There is no silver bullet in RL, depending on your needs and problem, you may choose one or the other.
The first distinction comes from your action space, i.e., do you have discrete (e.g. LEFT, RIGHT, …)
or continuous actions (ex: go to a certain speed)?</p>
<p>Some algorithms are only tailored for one or the other domain: <code class="docutils literal notranslate"><span class="pre">DQN</span></code> only supports discrete actions, where <code class="docutils literal notranslate"><span class="pre">SAC</span></code> is restricted to continuous actions.</p>
<p>The second difference that will help you choose is whether you can parallelize your training or not.
If what matters is the wall clock training time, then you should lean towards <code class="docutils literal notranslate"><span class="pre">A2C</span></code> and its derivatives (PPO, …).
Take a look at the <a class="reference external" href="vec_envs.html">Vectorized Environments</a> to learn more about training with multiple workers.</p>
<p>To accelerate training, you can also take a look at <a class="reference external" href="https://github.com/araffin/sbx">SBX</a>, which is SB3 + Jax, it has fewer features than SB3 but can be up to 20x faster than SB3 PyTorch thanks to JIT compilation of the gradient update.</p>
<p>In sparse reward settings, we either recommend to use dedicated methods like HER (see below) or population-based algorithms like ARS (available in our <a class="reference internal" href="index.html#sb3-contrib"><span class="std std-ref">contrib repo</span></a>).</p>
<p>To sum it up:</p>
<section id="discrete-actions">
<h5>Discrete Actions<a class="headerlink" href="#discrete-actions" title="Permalink to this heading"></a></h5>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This covers <code class="docutils literal notranslate"><span class="pre">Discrete</span></code>, <code class="docutils literal notranslate"><span class="pre">MultiDiscrete</span></code>, <code class="docutils literal notranslate"><span class="pre">Binary</span></code> and <code class="docutils literal notranslate"><span class="pre">MultiBinary</span></code> spaces</p>
</div>
<section id="discrete-actions-single-process">
<h6>Discrete Actions - Single Process<a class="headerlink" href="#discrete-actions-single-process" title="Permalink to this heading"></a></h6>
<p><code class="docutils literal notranslate"><span class="pre">DQN</span></code> with extensions (double DQN, prioritized replay, …) are the recommended algorithms.
We notably provide <code class="docutils literal notranslate"><span class="pre">QR-DQN</span></code> in our <a class="reference internal" href="index.html#sb3-contrib"><span class="std std-ref">contrib repo</span></a>.
<code class="docutils literal notranslate"><span class="pre">DQN</span></code> is usually slower to train (regarding wall clock time) but is the most sample efficient (because of its replay buffer).</p>
</section>
<section id="discrete-actions-multiprocessed">
<h6>Discrete Actions - Multiprocessed<a class="headerlink" href="#discrete-actions-multiprocessed" title="Permalink to this heading"></a></h6>
<p>You should give a try to <code class="docutils literal notranslate"><span class="pre">PPO</span></code> or <code class="docutils literal notranslate"><span class="pre">A2C</span></code>.</p>
</section>
</section>
<section id="continuous-actions">
<h5>Continuous Actions<a class="headerlink" href="#continuous-actions" title="Permalink to this heading"></a></h5>
<section id="continuous-actions-single-process">
<h6>Continuous Actions - Single Process<a class="headerlink" href="#continuous-actions-single-process" title="Permalink to this heading"></a></h6>
<p>Current State Of The Art (SOTA) algorithms are <code class="docutils literal notranslate"><span class="pre">SAC</span></code>, <code class="docutils literal notranslate"><span class="pre">TD3</span></code> and <code class="docutils literal notranslate"><span class="pre">TQC</span></code> (available in our <a class="reference internal" href="index.html#sb3-contrib"><span class="std std-ref">contrib repo</span></a>).
Please use the hyperparameters in the <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">RL zoo</a> for best results.</p>
<p>If you want an extremely sample-efficient algorithm, we recommend using the <a class="reference external" href="https://twitter.com/araffin2/status/1575439865222660098">DroQ configuration</a> in <a class="reference external" href="https://github.com/araffin/sbx">SBX</a> (it does many gradient steps per step in the environment).</p>
</section>
<section id="continuous-actions-multiprocessed">
<h6>Continuous Actions - Multiprocessed<a class="headerlink" href="#continuous-actions-multiprocessed" title="Permalink to this heading"></a></h6>
<p>Take a look at <code class="docutils literal notranslate"><span class="pre">PPO</span></code>, <code class="docutils literal notranslate"><span class="pre">TRPO</span></code> (available in our <a class="reference internal" href="index.html#sb3-contrib"><span class="std std-ref">contrib repo</span></a>) or <code class="docutils literal notranslate"><span class="pre">A2C</span></code>. Again, don’t forget to take the hyperparameters from the <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">RL zoo</a>
for continuous actions problems (cf <em>Bullet</em> envs).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Normalization is critical for those algorithms</p>
</div>
</section>
</section>
<section id="goal-environment">
<h5>Goal Environment<a class="headerlink" href="#goal-environment" title="Permalink to this heading"></a></h5>
<p>If your environment follows the <code class="docutils literal notranslate"><span class="pre">GoalEnv</span></code> interface (cf <a class="reference internal" href="index.html#her"><span class="std std-ref">HER</span></a>), then you should use
HER + (SAC/TD3/DDPG/DQN/QR-DQN/TQC) depending on the action space.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> is an important hyperparameter for experiments with <a class="reference internal" href="index.html#her"><span class="std std-ref">HER</span></a></p>
</div>
</section>
</section>
<section id="tips-and-tricks-when-creating-a-custom-environment">
<h4>Tips and Tricks when creating a custom environment<a class="headerlink" href="#tips-and-tricks-when-creating-a-custom-environment" title="Permalink to this heading"></a></h4>
<p>If you want to learn about how to create a custom environment, we recommend you read this <a class="reference external" href="custom_env.html">page</a>.
We also provide a <a class="reference external" href="https://colab.research.google.com/github/araffin/rl-tutorial-jnrr19/blob/master/5_custom_gym_env.ipynb">colab notebook</a> for
a concrete example of creating a custom gym environment.</p>
<p>Some basic advice:</p>
<ul class="simple">
<li><p>always normalize your observation space when you can, i.e., when you know the boundaries</p></li>
<li><p>normalize your action space and make it symmetric when continuous (cf potential issue below) A good practice is to rescale your actions to lie in [-1, 1]. This does not limit you as you can easily rescale the action inside the environment</p></li>
<li><p>start with shaped reward (i.e. informative reward) and simplified version of your problem</p></li>
<li><p>debug with random actions to check that your environment works and follows the gym interface:</p></li>
</ul>
<p>Two important things to keep in mind when creating a custom environment is to avoid breaking Markov assumption
and properly handle termination due to a timeout (maximum number of steps in an episode).
For instance, if there is some time delay between action and observation (e.g. due to wifi communication), you should give a history of observations
as input.</p>
<p>Termination due to timeout (max number of steps per episode) needs to be handled separately.
You should return <code class="docutils literal notranslate"><span class="pre">truncated</span> <span class="pre">=</span> <span class="pre">True</span></code>.
If you are using the gym <code class="docutils literal notranslate"><span class="pre">TimeLimit</span></code> wrapper, this will be done automatically.
You can read <a class="reference external" href="https://arxiv.org/abs/1712.00378">Time Limit in RL</a> or take a look at the <a class="reference external" href="https://www.youtube.com/watch?v=Ikngt0_DXJg">RL Tips and Tricks video</a>
for more details.</p>
<p>We provide a helper to check that your environment runs without error:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3.common.env_checker</span> <span class="kn">import</span> <span class="n">check_env</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">CustomEnv</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="c1"># It will check your custom environment and output additional warnings if needed</span>
<span class="n">check_env</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
<p>If you want to quickly try a random agent on your environment, you can also do:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">YourEnv</span><span class="p">()</span>
<span class="n">obs</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">n_steps</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
    <span class="c1"># Random action</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</pre></div>
</div>
<p><strong>Why should I normalize the action space?</strong></p>
<p>Most reinforcement learning algorithms rely on a Gaussian distribution (initially centered at 0 with std 1) for continuous actions.
So, if you forget to normalize the action space when using a custom environment,
this can harm learning and be difficult to debug (cf attached image and <a class="reference external" href="https://github.com/hill-a/stable-baselines/issues/473">issue #473</a>).</p>
<figure class="align-default">
<img alt="_images/mistake.png" src="_images/mistake.png" />
</figure>
<p>Another consequence of using a Gaussian distribution is that the action range is not bounded.
That’s why clipping is usually used as a bandage to stay in a valid interval.
A better solution would be to use a squashing function (cf <code class="docutils literal notranslate"><span class="pre">SAC</span></code>) or a Beta distribution (cf <a class="reference external" href="https://github.com/hill-a/stable-baselines/issues/112">issue #112</a>).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This statement is not true for <code class="docutils literal notranslate"><span class="pre">DDPG</span></code> or <code class="docutils literal notranslate"><span class="pre">TD3</span></code> because they don’t rely on any probability distribution.</p>
</div>
</section>
<section id="tips-and-tricks-when-implementing-an-rl-algorithm">
<h4>Tips and Tricks when implementing an RL algorithm<a class="headerlink" href="#tips-and-tricks-when-implementing-an-rl-algorithm" title="Permalink to this heading"></a></h4>
<p>When you try to reproduce a RL paper by implementing the algorithm, the <a class="reference external" href="http://joschu.net/docs/nuts-and-bolts.pdf">nuts and bolts of RL research</a>
by John Schulman are quite useful (<a class="reference external" href="https://www.youtube.com/watch?v=8EcdaCk9KaQ">video</a>).</p>
<p>We <em>recommend following those steps to have a working RL algorithm</em>:</p>
<ol class="arabic simple">
<li><p>Read the original paper several times</p></li>
<li><p>Read existing implementations (if available)</p></li>
<li><p>Try to have some “sign of life” on toy problems</p></li>
<li><p>Validate the implementation by making it run on harder and harder envs (you can compare results against the RL zoo).
You usually need to run hyperparameter optimization for that step.</p></li>
</ol>
<p>You need to be particularly careful on the shape of the different objects you are manipulating (a broadcast mistake will fail silently cf. <a class="reference external" href="https://github.com/hill-a/stable-baselines/pull/76">issue #75</a>)
and when to stop the gradient propagation.</p>
<p>Don’t forget to handle termination due to timeout separately (see remark in the custom environment section above),
you can also take a look at <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/284">Issue #284</a> and <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/633">Issue #633</a>.</p>
<p>A personal pick (by &#64;araffin) for environments with gradual difficulty in RL with continuous actions:</p>
<ol class="arabic simple">
<li><p>Pendulum (easy to solve)</p></li>
<li><p>HalfCheetahBullet (medium difficulty with local minima and shaped reward)</p></li>
<li><p>BipedalWalkerHardcore (if it works on that one, then you can have a cookie)</p></li>
</ol>
<p>in RL with discrete actions:</p>
<ol class="arabic simple">
<li><p>CartPole-v1 (easy to be better than random agent, harder to achieve maximal performance)</p></li>
<li><p>LunarLander</p></li>
<li><p>Pong (one of the easiest Atari game)</p></li>
<li><p>other Atari games (e.g. Breakout)</p></li>
</ol>
</section>
</section>
<span id="document-guide/rl"></span><section id="reinforcement-learning-resources">
<span id="rl"></span><h3>Reinforcement Learning Resources<a class="headerlink" href="#reinforcement-learning-resources" title="Permalink to this heading"></a></h3>
<p>Stable-Baselines3 assumes that you already understand the basic concepts of Reinforcement Learning (RL).</p>
<p>However, if you want to learn about RL, there are several good resources to get started:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spinningup.openai.com/en/latest/">OpenAI Spinning Up</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/learn/deep-rl-course/unit0/introduction">The Deep Reinforcement Learning Course</a></p></li>
<li><p><a class="reference external" href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html">David Silver’s course</a></p></li>
<li><p><a class="reference external" href="https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html">Lilian Weng’s blog</a></p></li>
<li><p><a class="reference external" href="https://sites.google.com/view/deep-rl-bootcamp/lectures">Berkeley’s Deep RL Bootcamp</a></p></li>
<li><p><a class="reference external" href="http://rail.eecs.berkeley.edu/deeprlcourse/">Berkeley’s Deep Reinforcement Learning course</a></p></li>
<li><p><a class="reference external" href="https://github.com/araffin/rlss23-dqn-tutorial">DQN tutorial</a></p></li>
<li><p><a class="reference external" href="https://github.com/dennybritz/reinforcement-learning">More resources</a></p></li>
</ul>
</section>
<span id="document-guide/algos"></span><section id="rl-algorithms">
<h3>RL Algorithms<a class="headerlink" href="#rl-algorithms" title="Permalink to this heading"></a></h3>
<p>This table displays the rl algorithms that are implemented in the Stable Baselines3 project,
along with some useful characteristics: support for discrete/continuous actions, multiprocessing.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">Box</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">Discrete</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">MultiDiscrete</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">MultiBinary</span></code></p></th>
<th class="head"><p>Multi Processing</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ARS <a class="footnote-reference brackets" href="#f1" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>A2C</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>DDPG</p></td>
<td><p>✔️</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>DQN</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>HER</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>PPO</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>QR-DQN <a class="footnote-reference brackets" href="#f1" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></p></td>
<td><p>❌</p></td>
<td><p>️ ✔️</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>RecurrentPPO <a class="footnote-reference brackets" href="#f1" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>SAC</p></td>
<td><p>✔️</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>TD3</p></td>
<td><p>✔️</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>TQC <a class="footnote-reference brackets" href="#f1" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></p></td>
<td><p>✔️</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>TRPO  <a class="footnote-reference brackets" href="#f1" id="id5" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>Maskable PPO <a class="footnote-reference brackets" href="#f1" id="id6" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
</tbody>
</table>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="f1" role="note">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id2">2</a>,<a role="doc-backlink" href="#id3">3</a>,<a role="doc-backlink" href="#id4">4</a>,<a role="doc-backlink" href="#id5">5</a>,<a role="doc-backlink" href="#id6">6</a>)</span>
<p>Implemented in <a class="reference external" href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib">SB3 Contrib</a></p>
</aside>
</aside>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">Tuple</span></code> observation spaces are not supported by any environment,
however, single-level <code class="docutils literal notranslate"><span class="pre">Dict</span></code> spaces are (cf. <a class="reference internal" href="index.html#examples"><span class="std std-ref">Examples</span></a>).</p>
</div>
<p>Actions <code class="docutils literal notranslate"><span class="pre">gym.spaces</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Box</span></code>: A N-dimensional box that contains every point in the action
space.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Discrete</span></code>: A list of possible actions, where each timestep only
one of the actions can be used.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MultiDiscrete</span></code>: A list of possible actions, where each timestep only one action of each discrete set can be used.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MultiBinary</span></code>: A list of possible actions, where each timestep any of the actions can be used in any combination.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>More algorithms (like QR-DQN or TQC) are implemented in our <a class="reference internal" href="index.html#sb3-contrib"><span class="std std-ref">contrib repo</span></a>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Some logging values (like <code class="docutils literal notranslate"><span class="pre">ep_rew_mean</span></code>, <code class="docutils literal notranslate"><span class="pre">ep_len_mean</span></code>) are only available when using a <code class="docutils literal notranslate"><span class="pre">Monitor</span></code> wrapper
See <a class="reference external" href="https://github.com/hill-a/stable-baselines/issues/339">Issue #339</a> for more info.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When using off-policy algorithms, <a class="reference external" href="https://arxiv.org/abs/1712.00378">Time Limits</a> (aka timeouts) are handled
properly (cf. <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/284">issue #284</a>).
You can revert to SB3 &lt; 2.1.0 behavior by passing <code class="docutils literal notranslate"><span class="pre">handle_timeout_termination=False</span></code>
via the <code class="docutils literal notranslate"><span class="pre">replay_buffer_kwargs</span></code> argument.</p>
</div>
<section id="reproducibility">
<h4>Reproducibility<a class="headerlink" href="#reproducibility" title="Permalink to this heading"></a></h4>
<p>Completely reproducible results are not guaranteed across PyTorch releases or different platforms.
Furthermore, results need not be reproducible between CPU and GPU executions, even when using identical seeds.</p>
<p>In order to make computations deterministics, on your specific problem on one specific platform,
you need to pass a <code class="docutils literal notranslate"><span class="pre">seed</span></code> argument at the creation of a model.
If you pass an environment to the model using <code class="docutils literal notranslate"><span class="pre">set_env()</span></code>, then you also need to seed the environment first.</p>
<p>Credit: part of the <em>Reproducibility</em> section comes from <a class="reference external" href="https://pytorch.org/docs/stable/notes/randomness.html">PyTorch Documentation</a></p>
</section>
</section>
<span id="document-guide/examples"></span><section id="examples">
<span id="id1"></span><h3>Examples<a class="headerlink" href="#examples" title="Permalink to this heading"></a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>These examples are only to demonstrate the use of the library and its functions, and the trained agents may not solve the environments. Optimized hyperparameters can be found in the RL Zoo <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">repository</a>.</p>
</div>
<section id="try-it-online-with-colab-notebooks">
<h4>Try it online with Colab Notebooks!<a class="headerlink" href="#try-it-online-with-colab-notebooks" title="Permalink to this heading"></a></h4>
<p>All the following examples can be executed online using Google colab <img alt="colab" src="_images/colab.svg" />
notebooks:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/araffin/rl-tutorial-jnrr19/tree/sb3">Full Tutorial</a></p></li>
<li><p><a class="reference external" href="https://github.com/Stable-Baselines-Team/rl-colab-notebooks/tree/sb3">All Notebooks</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/stable_baselines_getting_started.ipynb">Getting Started</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/saving_loading_dqn.ipynb">Training, Saving, Loading</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/multiprocessing_rl.ipynb">Multiprocessing</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/monitor_training.ipynb">Monitor Training and Plotting</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/atari_games.ipynb">Atari Games</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/rl-baselines-zoo.ipynb">RL Baselines zoo</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/pybullet.ipynb">PyBullet</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/stable_baselines_her.ipynb">Hindsight Experience Replay</a></p></li>
<li><p><a class="reference external" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/advanced_saving_loading.ipynb">Advanced Saving and Loading</a></p></li>
</ul>
</section>
<section id="basic-usage-training-saving-loading">
<h4>Basic Usage: Training, Saving, Loading<a class="headerlink" href="#basic-usage-training-saving-loading" title="Permalink to this heading"></a></h4>
<p>In the following example, we will train, save and load a DQN model on the Lunar Lander environment.</p>
<a class="reference external image-reference" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/saving_loading_dqn.ipynb"><img alt="_images/colab-badge.svg" src="_images/colab-badge.svg" /></a>
<figure class="align-default" id="id4">
<img alt="https://cdn-images-1.medium.com/max/960/1*f4VZPKOI0PYNWiwt0la0Rg.gif" src="https://cdn-images-1.medium.com/max/960/1*f4VZPKOI0PYNWiwt0la0Rg.gif" />
<figcaption>
<p><span class="caption-text">Lunar Lander Environment</span><a class="headerlink" href="#id4" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>LunarLander requires the python package <code class="docutils literal notranslate"><span class="pre">box2d</span></code>.
You can install it using <code class="docutils literal notranslate"><span class="pre">apt</span> <span class="pre">install</span> <span class="pre">swig</span></code> and then <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">box2d</span> <span class="pre">box2d-kengz</span></code></p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p><code class="docutils literal notranslate"><span class="pre">load</span></code> method re-creates the model from scratch and should be called on the Algorithm without instantiating it first,
e.g. <code class="docutils literal notranslate"><span class="pre">model</span> <span class="pre">=</span> <span class="pre">DQN.load(&quot;dqn_lunar&quot;,</span> <span class="pre">env=env)</span></code> instead of <code class="docutils literal notranslate"><span class="pre">model</span> <span class="pre">=</span> <span class="pre">DQN(env=env)</span></code> followed by  <code class="docutils literal notranslate"><span class="pre">model.load(&quot;dqn_lunar&quot;)</span></code>. The latter <strong>will not work</strong> as <code class="docutils literal notranslate"><span class="pre">load</span></code> is not an in-place operation.
If you want to load parameters without re-creating the model, e.g. to evaluate the same model
with multiple different sets of parameters, consider using <code class="docutils literal notranslate"><span class="pre">set_parameters</span></code> instead.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">DQN</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.evaluation</span> <span class="kn">import</span> <span class="n">evaluate_policy</span>


<span class="c1"># Create environment</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;LunarLander-v2&quot;</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">)</span>

<span class="c1"># Instantiate the agent</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DQN</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Train the agent and display a progress bar</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">2e5</span><span class="p">),</span> <span class="n">progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># Save the agent</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;dqn_lunar&quot;</span><span class="p">)</span>
<span class="k">del</span> <span class="n">model</span>  <span class="c1"># delete trained model to demonstrate loading</span>

<span class="c1"># Load the trained agent</span>
<span class="c1"># NOTE: if you have loading issue, you can pass `print_system_info=True`</span>
<span class="c1"># to compare the system on which the model was trained vs the current one</span>
<span class="c1"># model = DQN.load(&quot;dqn_lunar&quot;, env=env, print_system_info=True)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DQN</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;dqn_lunar&quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>

<span class="c1"># Evaluate the agent</span>
<span class="c1"># NOTE: If you use wrappers with your environment that modify rewards,</span>
<span class="c1">#       this will be reflected here. To evaluate with original rewards,</span>
<span class="c1">#       wrap environment in a &quot;Monitor&quot; wrapper before other wrappers.</span>
<span class="n">mean_reward</span><span class="p">,</span> <span class="n">std_reward</span> <span class="o">=</span> <span class="n">evaluate_policy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">get_env</span><span class="p">(),</span> <span class="n">n_eval_episodes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Enjoy trained agent</span>
<span class="n">vec_env</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_env</span><span class="p">()</span>
<span class="n">obs</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">_states</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">dones</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="n">vec_env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="multiprocessing-unleashing-the-power-of-vectorized-environments">
<h4>Multiprocessing: Unleashing the Power of Vectorized Environments<a class="headerlink" href="#multiprocessing-unleashing-the-power-of-vectorized-environments" title="Permalink to this heading"></a></h4>
<a class="reference external image-reference" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/multiprocessing_rl.ipynb"><img alt="_images/colab-badge.svg" src="_images/colab-badge.svg" /></a>
<figure class="align-default" id="id5">
<img alt="https://cdn-images-1.medium.com/max/960/1*h4WTQNVIsvMXJTCpXm_TAw.gif" src="https://cdn-images-1.medium.com/max/960/1*h4WTQNVIsvMXJTCpXm_TAw.gif" />
<figcaption>
<p><span class="caption-text">CartPole Environment</span><a class="headerlink" href="#id5" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.vec_env</span> <span class="kn">import</span> <span class="n">DummyVecEnv</span><span class="p">,</span> <span class="n">SubprocVecEnv</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.env_util</span> <span class="kn">import</span> <span class="n">make_vec_env</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.utils</span> <span class="kn">import</span> <span class="n">set_random_seed</span>

<span class="k">def</span> <span class="nf">make_env</span><span class="p">(</span><span class="n">env_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Utility function for multiprocessed env.</span>

<span class="sd">    :param env_id: the environment ID</span>
<span class="sd">    :param num_env: the number of environments you wish to have in subprocesses</span>
<span class="sd">    :param seed: the inital seed for RNG</span>
<span class="sd">    :param rank: index of the subprocess</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">_init</span><span class="p">():</span>
        <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env_id</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">&quot;human&quot;</span><span class="p">)</span>
        <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span> <span class="o">+</span> <span class="n">rank</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">env</span>
    <span class="n">set_random_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_init</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">env_id</span> <span class="o">=</span> <span class="s2">&quot;CartPole-v1&quot;</span>
    <span class="n">num_cpu</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c1"># Number of processes to use</span>
    <span class="c1"># Create the vectorized environment</span>
    <span class="n">vec_env</span> <span class="o">=</span> <span class="n">SubprocVecEnv</span><span class="p">([</span><span class="n">make_env</span><span class="p">(</span><span class="n">env_id</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_cpu</span><span class="p">)])</span>

    <span class="c1"># Stable Baselines provides you with make_vec_env() helper</span>
    <span class="c1"># which does exactly the previous steps for you.</span>
    <span class="c1"># You can choose between `DummyVecEnv` (usually faster) and `SubprocVecEnv`</span>
    <span class="c1"># env = make_vec_env(env_id, n_envs=num_cpu, seed=0, vec_env_cls=SubprocVecEnv)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">vec_env</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">25_000</span><span class="p">)</span>

    <span class="n">obs</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
        <span class="n">action</span><span class="p">,</span> <span class="n">_states</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">dones</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="n">vec_env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="multiprocessing-with-off-policy-algorithms">
<h4>Multiprocessing with off-policy algorithms<a class="headerlink" href="#multiprocessing-with-off-policy-algorithms" title="Permalink to this heading"></a></h4>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When using multiple environments with off-policy algorithms, you should update the <code class="docutils literal notranslate"><span class="pre">gradient_steps</span></code>
parameter too. Set it to <code class="docutils literal notranslate"><span class="pre">gradient_steps=-1</span></code> to perform as many gradient steps as transitions collected.
There is usually a compromise between wall-clock time and sample efficiency,
see this <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/pull/439#issuecomment-961796799">example in PR #439</a></p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">SAC</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.env_util</span> <span class="kn">import</span> <span class="n">make_vec_env</span>

<span class="n">vec_env</span> <span class="o">=</span> <span class="n">make_vec_env</span><span class="p">(</span><span class="s2">&quot;Pendulum-v0&quot;</span><span class="p">,</span> <span class="n">n_envs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># We collect 4 transitions per call to `ènv.step()`</span>
<span class="c1"># and performs 2 gradient steps per call to `ènv.step()`</span>
<span class="c1"># if gradient_steps=-1, then we would do 4 gradients steps per call to `ènv.step()`</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">vec_env</span><span class="p">,</span> <span class="n">train_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">gradient_steps</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">10_000</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="dict-observations">
<h4>Dict Observations<a class="headerlink" href="#dict-observations" title="Permalink to this heading"></a></h4>
<p>You can use environments with dictionary observation spaces. This is useful in the case where one can’t directly
concatenate observations such as an image from a camera combined with a vector of servo sensor data (e.g., rotation angles).
Stable Baselines3 provides <code class="docutils literal notranslate"><span class="pre">SimpleMultiObsEnv</span></code> as an example of this kind of setting.
The environment is a simple grid world, but the observations for each cell come in the form of dictionaries.
These dictionaries are randomly initialized on the creation of the environment and contain a vector observation and an image observation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.envs</span> <span class="kn">import</span> <span class="n">SimpleMultiObsEnv</span>


<span class="c1"># Stable Baselines provides SimpleMultiObsEnv as an example environment with Dict observations</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">SimpleMultiObsEnv</span><span class="p">(</span><span class="n">random_start</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span><span class="s2">&quot;MultiInputPolicy&quot;</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">100_000</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="callbacks-monitoring-training">
<h4>Callbacks: Monitoring Training<a class="headerlink" href="#callbacks-monitoring-training" title="Permalink to this heading"></a></h4>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We recommend reading the <a class="reference external" href="callbacks.html">Callback section</a></p>
</div>
<p>You can define a custom callback function that will be called inside the agent.
This could be useful when you want to monitor training, for instance display live
learning curves in Tensorboard or save the best agent.
If your callback returns False, training is aborted early.</p>
<a class="reference external image-reference" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/monitor_training.ipynb"><img alt="_images/colab-badge.svg" src="_images/colab-badge.svg" /></a>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">TD3</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common</span> <span class="kn">import</span> <span class="n">results_plotter</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.monitor</span> <span class="kn">import</span> <span class="n">Monitor</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.results_plotter</span> <span class="kn">import</span> <span class="n">load_results</span><span class="p">,</span> <span class="n">ts2xy</span><span class="p">,</span> <span class="n">plot_results</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.noise</span> <span class="kn">import</span> <span class="n">NormalActionNoise</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">BaseCallback</span>


<span class="k">class</span> <span class="nc">SaveOnBestTrainingRewardCallback</span><span class="p">(</span><span class="n">BaseCallback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Callback for saving a model (the check is done every ``check_freq`` steps)</span>
<span class="sd">    based on the training reward (in practice, we recommend using ``EvalCallback``).</span>

<span class="sd">    :param check_freq:</span>
<span class="sd">    :param log_dir: Path to the folder where the model will be saved.</span>
<span class="sd">      It must contains the file created by the ``Monitor`` wrapper.</span>
<span class="sd">    :param verbose: Verbosity level: 0 for no output, 1 for info messages, 2 for debug messages</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">check_freq</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">log_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">verbose</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_freq</span> <span class="o">=</span> <span class="n">check_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">=</span> <span class="n">log_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span> <span class="s2">&quot;best_model&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_mean_reward</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>

    <span class="k">def</span> <span class="nf">_init_callback</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Create folder if needed</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_path</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_on_step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_calls</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">check_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>

          <span class="c1"># Retrieve training reward</span>
          <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">ts2xy</span><span class="p">(</span><span class="n">load_results</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">),</span> <span class="s2">&quot;timesteps&quot;</span><span class="p">)</span>
          <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
              <span class="c1"># Mean training reward over the last 100 episodes</span>
              <span class="n">mean_reward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="o">-</span><span class="mi">100</span><span class="p">:])</span>
              <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Num timesteps: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_timesteps</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best mean reward: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">best_mean_reward</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> - Last mean reward per episode: </span><span class="si">{</span><span class="n">mean_reward</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

              <span class="c1"># New best model, you could save the agent here</span>
              <span class="k">if</span> <span class="n">mean_reward</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_mean_reward</span><span class="p">:</span>
                  <span class="bp">self</span><span class="o">.</span><span class="n">best_mean_reward</span> <span class="o">=</span> <span class="n">mean_reward</span>
                  <span class="c1"># Example for saving best model</span>
                  <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Saving new best model to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                  <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_path</span><span class="p">)</span>

        <span class="k">return</span> <span class="kc">True</span>

<span class="c1"># Create log dir</span>
<span class="n">log_dir</span> <span class="o">=</span> <span class="s2">&quot;tmp/&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Create and wrap the environment</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;LunarLanderContinuous-v2&quot;</span><span class="p">)</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">Monitor</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">log_dir</span><span class="p">)</span>

<span class="c1"># Add some action noise for exploration</span>
<span class="n">n_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">action_noise</span> <span class="o">=</span> <span class="n">NormalActionNoise</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_actions</span><span class="p">),</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_actions</span><span class="p">))</span>
<span class="c1"># Because we use parameter noise, we should use a MlpPolicy with layer normalization</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TD3</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">action_noise</span><span class="o">=</span><span class="n">action_noise</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Create the callback: check every 1000 steps</span>
<span class="n">callback</span> <span class="o">=</span> <span class="n">SaveOnBestTrainingRewardCallback</span><span class="p">(</span><span class="n">check_freq</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">log_dir</span><span class="o">=</span><span class="n">log_dir</span><span class="p">)</span>
<span class="c1"># Train the agent</span>
<span class="n">timesteps</span> <span class="o">=</span> <span class="mf">1e5</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">timesteps</span><span class="p">),</span> <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">)</span>

<span class="n">plot_results</span><span class="p">([</span><span class="n">log_dir</span><span class="p">],</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">results_plotter</span><span class="o">.</span><span class="n">X_TIMESTEPS</span><span class="p">,</span> <span class="s2">&quot;TD3 LunarLander&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="callbacks-evaluate-agent-performance">
<h4>Callbacks: Evaluate Agent Performance<a class="headerlink" href="#callbacks-evaluate-agent-performance" title="Permalink to this heading"></a></h4>
<p>To periodically evaluate an agent’s performance on a separate test environment, use <code class="docutils literal notranslate"><span class="pre">EvalCallback</span></code>.
You can control the evaluation frequency with <code class="docutils literal notranslate"><span class="pre">eval_freq</span></code> to monitor your agent’s progress during training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">SAC</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">EvalCallback</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.env_util</span> <span class="kn">import</span> <span class="n">make_vec_env</span>

<span class="n">env_id</span> <span class="o">=</span> <span class="s2">&quot;Pendulum-v1&quot;</span>
<span class="n">n_training_envs</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">n_eval_envs</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Create log dir where evaluation results will be saved</span>
<span class="n">eval_log_dir</span> <span class="o">=</span> <span class="s2">&quot;./eval_logs/&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">eval_log_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Initialize a vectorized training environment with default parameters</span>
<span class="n">train_env</span> <span class="o">=</span> <span class="n">make_vec_env</span><span class="p">(</span><span class="n">env_id</span><span class="p">,</span> <span class="n">n_envs</span><span class="o">=</span><span class="n">n_training_envs</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Separate evaluation env, with different parameters passed via env_kwargs</span>
<span class="c1"># Eval environments can be vectorized to speed up evaluation.</span>
<span class="n">eval_env</span> <span class="o">=</span> <span class="n">make_vec_env</span><span class="p">(</span><span class="n">env_id</span><span class="p">,</span> <span class="n">n_envs</span><span class="o">=</span><span class="n">n_eval_envs</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">env_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;g&#39;</span><span class="p">:</span><span class="mf">0.7</span><span class="p">})</span>

<span class="c1"># Create callback that evaluates agent for 5 episodes every 500 training environment steps.</span>
<span class="c1"># When using multiple training environments, agent will be evaluated every</span>
<span class="c1"># eval_freq calls to train_env.step(), thus it will be evaluated every</span>
<span class="c1"># (eval_freq * n_envs) training steps. See EvalCallback doc for more information.</span>
<span class="n">eval_callback</span> <span class="o">=</span> <span class="n">EvalCallback</span><span class="p">(</span><span class="n">eval_env</span><span class="p">,</span> <span class="n">best_model_save_path</span><span class="o">=</span><span class="n">eval_log_dir</span><span class="p">,</span>
                              <span class="n">log_path</span><span class="o">=</span><span class="n">eval_log_dir</span><span class="p">,</span> <span class="n">eval_freq</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="mi">500</span> <span class="o">//</span> <span class="n">n_training_envs</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                              <span class="n">n_eval_episodes</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                              <span class="n">render</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">train_env</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">eval_callback</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id2">
<h4>Atari Games<a class="headerlink" href="#id2" title="Permalink to this heading"></a></h4>
<figure class="align-default" id="id6">
<img alt="_images/breakout.gif" src="_images/breakout.gif" />
<figcaption>
<p><span class="caption-text">Trained A2C agent on Breakout</span><a class="headerlink" href="#id6" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<figure class="align-default" id="id7">
<img alt="https://cdn-images-1.medium.com/max/960/1*UHYJE7lF8IDZS_U5SsAFUQ.gif" src="https://cdn-images-1.medium.com/max/960/1*UHYJE7lF8IDZS_U5SsAFUQ.gif" />
<figcaption>
<p><span class="caption-text">Pong Environment</span><a class="headerlink" href="#id7" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>Training a RL agent on Atari games is straightforward thanks to <code class="docutils literal notranslate"><span class="pre">make_atari_env</span></code> helper function.
It will do <a class="reference external" href="https://danieltakeshi.github.io/2016/11/25/frame-skipping-and-preprocessing-for-deep-q-networks-on-atari-2600-games/">all the preprocessing</a>
and multiprocessing for you. To install the Atari environments, run the command <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">gymnasium[atari,accept-rom-license]</span></code> to install the Atari environments and ROMs, or install Stable Baselines3 with <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">stable-baselines3[extra]</span></code> to install this and other optional dependencies.</p>
<a class="reference external image-reference" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/atari_games.ipynb"><img alt="_images/colab-badge.svg" src="_images/colab-badge.svg" /></a>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3.common.env_util</span> <span class="kn">import</span> <span class="n">make_atari_env</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.vec_env</span> <span class="kn">import</span> <span class="n">VecFrameStack</span>
<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">A2C</span>

<span class="c1"># There already exists an environment generator</span>
<span class="c1"># that will make and wrap atari environments correctly.</span>
<span class="c1"># Here we are also multi-worker training (n_envs=4 =&gt; 4 environments)</span>
<span class="n">vec_env</span> <span class="o">=</span> <span class="n">make_atari_env</span><span class="p">(</span><span class="s2">&quot;PongNoFrameskip-v4&quot;</span><span class="p">,</span> <span class="n">n_envs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Frame-stacking with 4 frames</span>
<span class="n">vec_env</span> <span class="o">=</span> <span class="n">VecFrameStack</span><span class="p">(</span><span class="n">vec_env</span><span class="p">,</span> <span class="n">n_stack</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">A2C</span><span class="p">(</span><span class="s2">&quot;CnnPolicy&quot;</span><span class="p">,</span> <span class="n">vec_env</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">25_000</span><span class="p">)</span>

<span class="n">obs</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">_states</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">dones</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="n">vec_env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="pybullet-normalizing-input-features">
<h4>PyBullet: Normalizing input features<a class="headerlink" href="#pybullet-normalizing-input-features" title="Permalink to this heading"></a></h4>
<p>Normalizing input features may be essential to successful training of an RL agent
(by default, images are scaled but not other types of input),
for instance when training on <a class="reference external" href="https://github.com/bulletphysics/bullet3/">PyBullet</a> environments. For that, a wrapper exists and
will compute a running average and standard deviation of input features (it can do the same for rewards).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>you need to install pybullet with <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">pybullet</span></code></p>
</div>
<a class="reference external image-reference" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/pybullet.ipynb"><img alt="_images/colab-badge.svg" src="_images/colab-badge.svg" /></a>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">pybullet_envs</span>

<span class="kn">from</span> <span class="nn">stable_baselines3.common.vec_env</span> <span class="kn">import</span> <span class="n">DummyVecEnv</span><span class="p">,</span> <span class="n">VecNormalize</span>
<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>

<span class="c1"># Note: pybullet is not compatible yet with Gymnasium</span>
<span class="c1"># you might need to use `import rl_zoo3.gym_patches`</span>
<span class="c1"># and use gym (not Gymnasium) to instantiate the env</span>
<span class="c1"># Alternatively, you can use the MuJoCo equivalent &quot;HalfCheetah-v4&quot;</span>
<span class="n">vec_env</span> <span class="o">=</span> <span class="n">DummyVecEnv</span><span class="p">([</span><span class="k">lambda</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;HalfCheetahBulletEnv-v0&quot;</span><span class="p">)])</span>
<span class="c1"># Automatically normalize the input features and reward</span>
<span class="n">vec_env</span> <span class="o">=</span> <span class="n">VecNormalize</span><span class="p">(</span><span class="n">vec_env</span><span class="p">,</span> <span class="n">norm_obs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">norm_reward</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">clip_obs</span><span class="o">=</span><span class="mf">10.</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">vec_env</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>

<span class="c1"># Don&#39;t forget to save the VecNormalize statistics when saving the agent</span>
<span class="n">log_dir</span> <span class="o">=</span> <span class="s2">&quot;/tmp/&quot;</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">log_dir</span> <span class="o">+</span> <span class="s2">&quot;ppo_halfcheetah&quot;</span><span class="p">)</span>
<span class="n">stats_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span> <span class="s2">&quot;vec_normalize.pkl&quot;</span><span class="p">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">stats_path</span><span class="p">)</span>

<span class="c1"># To demonstrate loading</span>
<span class="k">del</span> <span class="n">model</span><span class="p">,</span> <span class="n">vec_env</span>

<span class="c1"># Load the saved statistics</span>
<span class="n">vec_env</span> <span class="o">=</span> <span class="n">DummyVecEnv</span><span class="p">([</span><span class="k">lambda</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;HalfCheetahBulletEnv-v0&quot;</span><span class="p">)])</span>
<span class="n">vec_env</span> <span class="o">=</span> <span class="n">VecNormalize</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">stats_path</span><span class="p">,</span> <span class="n">vec_env</span><span class="p">)</span>
<span class="c1">#  do not update them at test time</span>
<span class="n">vec_env</span><span class="o">.</span><span class="n">training</span> <span class="o">=</span> <span class="kc">False</span>
<span class="c1"># reward normalization is not needed at test time</span>
<span class="n">vec_env</span><span class="o">.</span><span class="n">norm_reward</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Load the agent</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">log_dir</span> <span class="o">+</span> <span class="s2">&quot;ppo_halfcheetah&quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">vec_env</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="hindsight-experience-replay-her">
<h4>Hindsight Experience Replay (HER)<a class="headerlink" href="#hindsight-experience-replay-her" title="Permalink to this heading"></a></h4>
<p>For this example, we are using <a class="reference external" href="https://github.com/eleurent/highway-env">Highway-Env</a> by <a class="reference external" href="https://github.com/eleurent">&#64;eleurent</a>.</p>
<a class="reference external image-reference" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/stable_baselines_her.ipynb"><img alt="_images/colab-badge.svg" src="_images/colab-badge.svg" /></a>
<figure class="align-default" id="id8">
<img alt="https://raw.githubusercontent.com/eleurent/highway-env/gh-media/docs/media/parking-env.gif" src="https://raw.githubusercontent.com/eleurent/highway-env/gh-media/docs/media/parking-env.gif" />
<figcaption>
<p><span class="caption-text">The highway-parking-v0 environment.</span><a class="headerlink" href="#id8" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>The parking env is a goal-conditioned continuous control task, in which the vehicle must park in a given space with the appropriate heading.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The hyperparameters in the following example were optimized for that environment.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">highway_env</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">HerReplayBuffer</span><span class="p">,</span> <span class="n">SAC</span><span class="p">,</span> <span class="n">DDPG</span><span class="p">,</span> <span class="n">TD3</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.noise</span> <span class="kn">import</span> <span class="n">NormalActionNoise</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;parking-v0&quot;</span><span class="p">)</span>

<span class="c1"># Create 4 artificial transitions per real transition</span>
<span class="n">n_sampled_goal</span> <span class="o">=</span> <span class="mi">4</span>

<span class="c1"># SAC hyperparams:</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span>
    <span class="s2">&quot;MultiInputPolicy&quot;</span><span class="p">,</span>
    <span class="n">env</span><span class="p">,</span>
    <span class="n">replay_buffer_class</span><span class="o">=</span><span class="n">HerReplayBuffer</span><span class="p">,</span>
    <span class="n">replay_buffer_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
      <span class="n">n_sampled_goal</span><span class="o">=</span><span class="n">n_sampled_goal</span><span class="p">,</span>
      <span class="n">goal_selection_strategy</span><span class="o">=</span><span class="s2">&quot;future&quot;</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">buffer_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e6</span><span class="p">),</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
    <span class="n">gamma</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="n">policy_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">net_arch</span><span class="o">=</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">]),</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">2e5</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;her_sac_highway&quot;</span><span class="p">)</span>

<span class="c1"># Load saved model</span>
<span class="c1"># Because it needs access to `env.compute_reward()`</span>
<span class="c1"># HER must be loaded with the env</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;parking-v0&quot;</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">&quot;human&quot;</span><span class="p">)</span> <span class="c1"># Change the render mode</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;her_sac_highway&quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>

<span class="n">obs</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

<span class="c1"># Evaluate the agent</span>
<span class="n">episode_reward</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="n">episode_reward</span> <span class="o">+=</span> <span class="n">reward</span>
    <span class="k">if</span> <span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span> <span class="ow">or</span> <span class="n">info</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;is_success&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reward:&quot;</span><span class="p">,</span> <span class="n">episode_reward</span><span class="p">,</span> <span class="s2">&quot;Success?&quot;</span><span class="p">,</span> <span class="n">info</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;is_success&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">))</span>
        <span class="n">episode_reward</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="learning-rate-schedule">
<h4>Learning Rate Schedule<a class="headerlink" href="#learning-rate-schedule" title="Permalink to this heading"></a></h4>
<p>All algorithms allow you to pass a learning rate schedule that takes as input the current progress remaining (from 1 to 0).
<code class="docutils literal notranslate"><span class="pre">PPO</span></code>’s <code class="docutils literal notranslate"><span class="pre">clip_range`</span></code> parameter also accepts such schedule.</p>
<p>The <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">RL Zoo</a> already includes
linear and constant schedules.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>


<span class="k">def</span> <span class="nf">linear_schedule</span><span class="p">(</span><span class="n">initial_value</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">float</span><span class="p">],</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Linear learning rate schedule.</span>

<span class="sd">    :param initial_value: Initial learning rate.</span>
<span class="sd">    :return: schedule that computes</span>
<span class="sd">      current learning rate depending on remaining progress</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">progress_remaining</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Progress will decrease from 1 (beginning) to 0.</span>

<span class="sd">        :param progress_remaining:</span>
<span class="sd">        :return: current learning rate</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">progress_remaining</span> <span class="o">*</span> <span class="n">initial_value</span>

    <span class="k">return</span> <span class="n">func</span>

<span class="c1"># Initial learning rate of 0.001</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">linear_schedule</span><span class="p">(</span><span class="mf">0.001</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">20_000</span><span class="p">)</span>
<span class="c1"># By default, `reset_num_timesteps` is True, in which case the learning rate schedule resets.</span>
<span class="c1"># progress_remaining = 1.0 - (num_timesteps / total_timesteps)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">10_000</span><span class="p">,</span> <span class="n">reset_num_timesteps</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id3">
<h4>Advanced Saving and Loading<a class="headerlink" href="#id3" title="Permalink to this heading"></a></h4>
<p>In this example, we show how to use a policy independently from a model (and how to save it, load it) and save/load a replay buffer.</p>
<p>By default, the replay buffer is not saved when calling <code class="docutils literal notranslate"><span class="pre">model.save()</span></code>, in order to save space on the disk (a replay buffer can be up to several GB when using images).
However, SB3 provides a <code class="docutils literal notranslate"><span class="pre">save_replay_buffer()</span></code> and <code class="docutils literal notranslate"><span class="pre">load_replay_buffer()</span></code> method to save it separately.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For training model after loading it, we recommend loading the replay buffer to ensure stable learning (for off-policy algorithms).
You also need to pass <code class="docutils literal notranslate"><span class="pre">reset_num_timesteps=True</span></code> to <code class="docutils literal notranslate"><span class="pre">learn</span></code> function which initializes the environment
and agent for training if a new environment was created since saving the model.</p>
</div>
<a class="reference external image-reference" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/advanced_saving_loading.ipynb"><img alt="_images/colab-badge.svg" src="_images/colab-badge.svg" /></a>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">SAC</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.evaluation</span> <span class="kn">import</span> <span class="n">evaluate_policy</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.sac.policies</span> <span class="kn">import</span> <span class="n">MlpPolicy</span>

<span class="c1"># Create the model and the training environment</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="c1"># train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">6000</span><span class="p">)</span>

<span class="c1"># save the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;sac_pendulum&quot;</span><span class="p">)</span>

<span class="c1"># the saved model does not contain the replay buffer</span>
<span class="n">loaded_model</span> <span class="o">=</span> <span class="n">SAC</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;sac_pendulum&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The loaded_model has </span><span class="si">{</span><span class="n">loaded_model</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s2"> transitions in its buffer&quot;</span><span class="p">)</span>

<span class="c1"># now save the replay buffer too</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_replay_buffer</span><span class="p">(</span><span class="s2">&quot;sac_replay_buffer&quot;</span><span class="p">)</span>

<span class="c1"># load it into the loaded_model</span>
<span class="n">loaded_model</span><span class="o">.</span><span class="n">load_replay_buffer</span><span class="p">(</span><span class="s2">&quot;sac_replay_buffer&quot;</span><span class="p">)</span>

<span class="c1"># now the loaded replay is not empty anymore</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The loaded_model has </span><span class="si">{</span><span class="n">loaded_model</span><span class="o">.</span><span class="n">replay_buffer</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s2"> transitions in its buffer&quot;</span><span class="p">)</span>

<span class="c1"># Save the policy independently from the model</span>
<span class="c1"># Note: if you don&#39;t save the complete model with `model.save()`</span>
<span class="c1"># you cannot continue training afterward</span>
<span class="n">policy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">policy</span>
<span class="n">policy</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;sac_policy_pendulum&quot;</span><span class="p">)</span>

<span class="c1"># Retrieve the environment</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_env</span><span class="p">()</span>

<span class="c1"># Evaluate the policy</span>
<span class="n">mean_reward</span><span class="p">,</span> <span class="n">std_reward</span> <span class="o">=</span> <span class="n">evaluate_policy</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">n_eval_episodes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mean_reward=</span><span class="si">{</span><span class="n">mean_reward</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> +/- </span><span class="si">{</span><span class="n">std_reward</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Load the policy independently from the model</span>
<span class="n">saved_policy</span> <span class="o">=</span> <span class="n">MlpPolicy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;sac_policy_pendulum&quot;</span><span class="p">)</span>

<span class="c1"># Evaluate the loaded policy</span>
<span class="n">mean_reward</span><span class="p">,</span> <span class="n">std_reward</span> <span class="o">=</span> <span class="n">evaluate_policy</span><span class="p">(</span><span class="n">saved_policy</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">n_eval_episodes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mean_reward=</span><span class="si">{</span><span class="n">mean_reward</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> +/- </span><span class="si">{</span><span class="n">std_reward</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="accessing-and-modifying-model-parameters">
<h4>Accessing and modifying model parameters<a class="headerlink" href="#accessing-and-modifying-model-parameters" title="Permalink to this heading"></a></h4>
<p>You can access model’s parameters via <code class="docutils literal notranslate"><span class="pre">set_parameters</span></code> and <code class="docutils literal notranslate"><span class="pre">get_parameters</span></code> functions,
or via <code class="docutils literal notranslate"><span class="pre">model.policy.state_dict()</span></code> (and <code class="docutils literal notranslate"><span class="pre">load_state_dict()</span></code>),
which use dictionaries that map variable names to PyTorch tensors.</p>
<p>These functions are useful when you need to e.g. evaluate large set of models with same network structure,
visualize different layers of the network or modify parameters manually.</p>
<p>Policies also offers a simple way to save/load weights as a NumPy vector, using <code class="docutils literal notranslate"><span class="pre">parameters_to_vector()</span></code>
and <code class="docutils literal notranslate"><span class="pre">load_from_vector()</span></code> method.</p>
<p>Following example demonstrates reading parameters, modifying some of them and loading them to model
by implementing <a class="reference external" href="http://blog.otoro.net/2017/10/29/visual-evolution-strategies/">evolution strategy (es)</a>
for solving the <code class="docutils literal notranslate"><span class="pre">CartPole-v1</span></code> environment. The initial guess for parameters is obtained by running
A2C policy gradient updates on the model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span>

<span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">A2C</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.evaluation</span> <span class="kn">import</span> <span class="n">evaluate_policy</span>


<span class="k">def</span> <span class="nf">mutate</span><span class="p">(</span><span class="n">params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">th</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">th</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mutate parameters by adding normal noise to them&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">((</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="o">+</span> <span class="n">th</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">param</span><span class="p">))</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>


<span class="c1"># Create policy with a small network</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">A2C</span><span class="p">(</span>
    <span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span>
    <span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span>
    <span class="n">ent_coef</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">policy_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;net_arch&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">32</span><span class="p">]},</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Use traditional actor-critic policy gradient updates to</span>
<span class="c1"># find good initial parameters</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">10_000</span><span class="p">)</span>

<span class="c1"># Include only variables with &quot;policy&quot;, &quot;action&quot; (policy) or &quot;shared_net&quot; (shared layers)</span>
<span class="c1"># in their name: only these ones affect the action.</span>
<span class="c1"># NOTE: you can retrieve those parameters using model.get_parameters() too</span>
<span class="n">mean_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
    <span class="k">if</span> <span class="p">(</span><span class="s2">&quot;policy&quot;</span> <span class="ow">in</span> <span class="n">key</span> <span class="ow">or</span> <span class="s2">&quot;shared_net&quot;</span> <span class="ow">in</span> <span class="n">key</span> <span class="ow">or</span> <span class="s2">&quot;action&quot;</span> <span class="ow">in</span> <span class="n">key</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># population size of 50 invdiduals</span>
<span class="n">pop_size</span> <span class="o">=</span> <span class="mi">50</span>
<span class="c1"># Keep top 10%</span>
<span class="n">n_elite</span> <span class="o">=</span> <span class="n">pop_size</span> <span class="o">//</span> <span class="mi">10</span>
<span class="c1"># Retrieve the environment</span>
<span class="n">vec_env</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_env</span><span class="p">()</span>

<span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="c1"># Create population of candidates and evaluate them</span>
    <span class="n">population</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">population_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pop_size</span><span class="p">):</span>
        <span class="n">candidate</span> <span class="o">=</span> <span class="n">mutate</span><span class="p">(</span><span class="n">mean_params</span><span class="p">)</span>
        <span class="c1"># Load new policy parameters to agent.</span>
        <span class="c1"># Tell function that it should only update parameters</span>
        <span class="c1"># we give it (policy parameters)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">candidate</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># Evaluate the candidate</span>
        <span class="n">fitness</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">evaluate_policy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">vec_env</span><span class="p">)</span>
        <span class="n">population</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">candidate</span><span class="p">,</span> <span class="n">fitness</span><span class="p">))</span>
    <span class="c1"># Take top 10% and use average over their parameters as next mean parameter</span>
    <span class="n">top_candidates</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">population</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)[:</span><span class="n">n_elite</span><span class="p">]</span>
    <span class="n">mean_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="p">(</span>
            <span class="n">name</span><span class="p">,</span>
            <span class="n">th</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">candidate</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">candidate</span> <span class="ow">in</span> <span class="n">top_candidates</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">mean_params</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">mean_fitness</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">top_candidate</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">top_candidate</span> <span class="ow">in</span> <span class="n">top_candidates</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_elite</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="n">iteration</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">:</span><span class="s2">&lt;3</span><span class="si">}</span><span class="s2"> Mean top fitness: </span><span class="si">{</span><span class="n">mean_fitness</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best fitness: </span><span class="si">{</span><span class="n">top_candidates</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="sb3-and-procgenenv">
<h4>SB3 and ProcgenEnv<a class="headerlink" href="#sb3-and-procgenenv" title="Permalink to this heading"></a></h4>
<p>Some environments like <a class="reference external" href="https://github.com/openai/procgen">Procgen</a> already produce a vectorized
environment (see discussion in <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/314">issue #314</a>). In order to use it with SB3, you must wrap it in a <code class="docutils literal notranslate"><span class="pre">VecMonitor</span></code> wrapper which will also allow
to keep track of the agent progress.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">procgen</span> <span class="kn">import</span> <span class="n">ProcgenEnv</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.vec_env</span> <span class="kn">import</span> <span class="n">VecExtractDictObs</span><span class="p">,</span> <span class="n">VecMonitor</span>

<span class="c1"># ProcgenEnv is already vectorized</span>
<span class="n">venv</span> <span class="o">=</span> <span class="n">ProcgenEnv</span><span class="p">(</span><span class="n">num_envs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">env_name</span><span class="o">=</span><span class="s2">&quot;starpilot&quot;</span><span class="p">)</span>

<span class="c1"># To use only part of the observation:</span>
<span class="c1"># venv = VecExtractDictObs(venv, &quot;rgb&quot;)</span>

<span class="c1"># Wrap with a VecMonitor to collect stats and avoid errors</span>
<span class="n">venv</span> <span class="o">=</span> <span class="n">VecMonitor</span><span class="p">(</span><span class="n">venv</span><span class="o">=</span><span class="n">venv</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span><span class="s2">&quot;MultiInputPolicy&quot;</span><span class="p">,</span> <span class="n">venv</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="mi">10_000</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="sb3-with-envpool-or-isaac-gym">
<h4>SB3 with EnvPool or Isaac Gym<a class="headerlink" href="#sb3-with-envpool-or-isaac-gym" title="Permalink to this heading"></a></h4>
<p>Just like Procgen (see above), <a class="reference external" href="https://github.com/sail-sg/envpool">EnvPool</a> and <a class="reference external" href="https://github.com/NVIDIA-Omniverse/IsaacGymEnvs">Isaac Gym</a> accelerate the environment by
already providing a vectorized implementation.</p>
<p>To use SB3 with those tools, you must wrap the env with tool’s specific <code class="docutils literal notranslate"><span class="pre">VecEnvWrapper</span></code> that will pre-process the data for SB3,
you can find links to those wrappers in <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/772#issuecomment-1048657002">issue #772</a>.</p>
</section>
<section id="record-a-video">
<h4>Record a Video<a class="headerlink" href="#record-a-video" title="Permalink to this heading"></a></h4>
<p>Record a mp4 video (here using a random agent).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It requires <code class="docutils literal notranslate"><span class="pre">ffmpeg</span></code> or <code class="docutils literal notranslate"><span class="pre">avconv</span></code> to be installed on the machine.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.vec_env</span> <span class="kn">import</span> <span class="n">VecVideoRecorder</span><span class="p">,</span> <span class="n">DummyVecEnv</span>

<span class="n">env_id</span> <span class="o">=</span> <span class="s2">&quot;CartPole-v1&quot;</span>
<span class="n">video_folder</span> <span class="o">=</span> <span class="s2">&quot;logs/videos/&quot;</span>
<span class="n">video_length</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">vec_env</span> <span class="o">=</span> <span class="n">DummyVecEnv</span><span class="p">([</span><span class="k">lambda</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env_id</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">)])</span>

<span class="n">obs</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

<span class="c1"># Record the video starting at the first step</span>
<span class="n">vec_env</span> <span class="o">=</span> <span class="n">VecVideoRecorder</span><span class="p">(</span><span class="n">vec_env</span><span class="p">,</span> <span class="n">video_folder</span><span class="p">,</span>
                       <span class="n">record_video_trigger</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">video_length</span><span class="o">=</span><span class="n">video_length</span><span class="p">,</span>
                       <span class="n">name_prefix</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;random-agent-</span><span class="si">{</span><span class="n">env_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">vec_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">video_length</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
  <span class="n">action</span> <span class="o">=</span> <span class="p">[</span><span class="n">vec_env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()]</span>
  <span class="n">obs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
<span class="c1"># Save the video</span>
<span class="n">vec_env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="bonus-make-a-gif-of-a-trained-agent">
<h4>Bonus: Make a GIF of a Trained Agent<a class="headerlink" href="#bonus-make-a-gif-of-a-trained-agent" title="Permalink to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">imageio</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">A2C</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">A2C</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;LunarLander-v2&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="mi">100_000</span><span class="p">)</span>

<span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">obs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">350</span><span class="p">):</span>
    <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">)</span>

<span class="n">imageio</span><span class="o">.</span><span class="n">mimsave</span><span class="p">(</span><span class="s2">&quot;lander_a2c.gif&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">img</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">images</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span><span class="o">%</span><span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">],</span> <span class="n">fps</span><span class="o">=</span><span class="mi">29</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<span id="document-guide/vec_envs"></span><span class="target" id="module-stable_baselines3.common.vec_env"><span id="vec-env"></span></span><section id="vectorized-environments">
<h3>Vectorized Environments<a class="headerlink" href="#vectorized-environments" title="Permalink to this heading"></a></h3>
<p>Vectorized Environments are a method for stacking multiple independent environments into a single environment.
Instead of training an RL agent on 1 environment per step, it allows us to train it on <code class="docutils literal notranslate"><span class="pre">n</span></code> environments per step.
Because of this, <code class="docutils literal notranslate"><span class="pre">actions</span></code> passed to the environment are now a vector (of dimension <code class="docutils literal notranslate"><span class="pre">n</span></code>).
It is the same for <code class="docutils literal notranslate"><span class="pre">observations</span></code>, <code class="docutils literal notranslate"><span class="pre">rewards</span></code> and end of episode signals (<code class="docutils literal notranslate"><span class="pre">dones</span></code>).
In the case of non-array observation spaces such as <code class="docutils literal notranslate"><span class="pre">Dict</span></code> or <code class="docutils literal notranslate"><span class="pre">Tuple</span></code>, where different sub-spaces
may have different shapes, the sub-observations are vectors (of dimension <code class="docutils literal notranslate"><span class="pre">n</span></code>).</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">Box</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">Discrete</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">Dict</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">Tuple</span></code></p></th>
<th class="head"><p>Multi Processing</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>DummyVecEnv</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>❌️</p></td>
</tr>
<tr class="row-odd"><td><p>SubprocVecEnv</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Vectorized environments are required when using wrappers for frame-stacking or normalization.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When using vectorized environments, the environments are automatically reset at the end of each episode.
Thus, the observation returned for the i-th environment when <code class="docutils literal notranslate"><span class="pre">done[i]</span></code> is true will in fact be the first observation of the next episode, not the last observation of the episode that has just terminated.
You can access the “real” final observation of the terminated episode—that is, the one that accompanied the <code class="docutils literal notranslate"><span class="pre">done</span></code> event provided by the underlying environment—using the <code class="docutils literal notranslate"><span class="pre">terminal_observation</span></code> keys in the info dicts returned by the <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code>.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When defining a custom <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code> (for instance, using gym3 <code class="docutils literal notranslate"><span class="pre">ProcgenEnv</span></code>), you should provide <code class="docutils literal notranslate"><span class="pre">terminal_observation</span></code> keys in the info dicts returned by the <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code>
(cf. note above).</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When using <code class="docutils literal notranslate"><span class="pre">SubprocVecEnv</span></code>, users must wrap the code in an <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">__name__</span> <span class="pre">==</span> <span class="pre">&quot;__main__&quot;:</span></code> if using the <code class="docutils literal notranslate"><span class="pre">forkserver</span></code> or <code class="docutils literal notranslate"><span class="pre">spawn</span></code> start method (default on Windows).
On Linux, the default start method is <code class="docutils literal notranslate"><span class="pre">fork</span></code> which is not thread safe and can create deadlocks.</p>
<p>For more information, see Python’s <a class="reference external" href="https://docs.python.org/3/library/multiprocessing.html#the-spawn-and-forkserver-start-methods">multiprocessing guidelines</a>.</p>
</div>
<section id="vecenv-api-vs-gym-api">
<h4>VecEnv API vs Gym API<a class="headerlink" href="#vecenv-api-vs-gym-api" title="Permalink to this heading"></a></h4>
<p>For consistency across Stable-Baselines3 (SB3) versions and because of its special requirements and features,
SB3 VecEnv API is not the same as Gym API.
SB3 VecEnv API is actually close to Gym 0.21 API but differs to Gym 0.26+ API:</p>
<ul>
<li><p>the <code class="docutils literal notranslate"><span class="pre">reset()</span></code> method only returns the observation (<code class="docutils literal notranslate"><span class="pre">obs</span> <span class="pre">=</span> <span class="pre">vec_env.reset()</span></code>) and not a tuple, the info at reset are stored in <code class="docutils literal notranslate"><span class="pre">vec_env.reset_infos</span></code>.</p></li>
<li><p>only the initial call to <code class="docutils literal notranslate"><span class="pre">vec_env.reset()</span></code> is required, environments are reset automatically afterward (and <code class="docutils literal notranslate"><span class="pre">reset_infos</span></code> is updated automatically).</p></li>
<li><p>the <code class="docutils literal notranslate"><span class="pre">vec_env.step(actions)</span></code> method expects an array as input
(with a batch size corresponding to the number of environments) and returns a 4-tuple (and not a 5-tuple): <code class="docutils literal notranslate"><span class="pre">obs,</span> <span class="pre">rewards,</span> <span class="pre">dones,</span> <span class="pre">infos</span></code> instead of <code class="docutils literal notranslate"><span class="pre">obs,</span> <span class="pre">reward,</span> <span class="pre">terminated,</span> <span class="pre">truncated,</span> <span class="pre">info</span></code>
where <code class="docutils literal notranslate"><span class="pre">dones</span> <span class="pre">=</span> <span class="pre">terminated</span> <span class="pre">or</span> <span class="pre">truncated</span></code> (for each env).
<code class="docutils literal notranslate"><span class="pre">obs,</span> <span class="pre">rewards,</span> <span class="pre">dones</span></code> are NumPy arrays with shape <code class="docutils literal notranslate"><span class="pre">(n_envs,</span> <span class="pre">shape_for_single_env)</span></code> (so with a batch dimension).
Additional information is passed via the <code class="docutils literal notranslate"><span class="pre">infos</span></code> value which is a list of dictionaries.</p></li>
<li><p>at the end of an episode, <code class="docutils literal notranslate"><span class="pre">infos[env_idx][&quot;TimeLimit.truncated&quot;]</span> <span class="pre">=</span> <span class="pre">truncated</span> <span class="pre">and</span> <span class="pre">not</span> <span class="pre">terminated</span></code>
tells the user if an episode was truncated or not:
you should bootstrap if <code class="docutils literal notranslate"><span class="pre">infos[env_idx][&quot;TimeLimit.truncated&quot;]</span> <span class="pre">is</span> <span class="pre">True</span></code> (episode over due to a timeout/truncation)
or <code class="docutils literal notranslate"><span class="pre">dones[env_idx]</span> <span class="pre">is</span> <span class="pre">False</span></code> (episode not finished).
Note: compared to Gym 0.26+ <code class="docutils literal notranslate"><span class="pre">infos[env_idx][&quot;TimeLimit.truncated&quot;]</span></code> and <code class="docutils literal notranslate"><span class="pre">terminated</span></code> <a class="reference external" href="https://github.com/openai/gym/issues/3102">are mutually exclusive</a>.
The conversion from SB3 to Gym API is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># done is True at the end of an episode</span>
<span class="c1"># dones[env_idx] = terminated[env_idx] or truncated[env_idx]</span>
<span class="c1"># In SB3, truncated and terminated are mutually exclusive</span>
<span class="c1"># infos[env_idx][&quot;TimeLimit.truncated&quot;] = truncated and not terminated</span>
<span class="c1"># terminated[env_idx] tells you whether you should bootstrap or not:</span>
<span class="c1"># when the episode has not ended or when the termination was a timeout/truncation</span>
<span class="n">terminated</span><span class="p">[</span><span class="n">env_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">dones</span><span class="p">[</span><span class="n">env_idx</span><span class="p">]</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">infos</span><span class="p">[</span><span class="n">env_idx</span><span class="p">][</span><span class="s2">&quot;TimeLimit.truncated&quot;</span><span class="p">]</span>
<span class="n">should_bootstrap</span><span class="p">[</span><span class="n">env_idx</span><span class="p">]</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">terminated</span><span class="p">[</span><span class="n">env_idx</span><span class="p">]</span>
</pre></div>
</div>
</li>
<li><p>at the end of an episode, because the environment resets automatically,
we provide <code class="docutils literal notranslate"><span class="pre">infos[env_idx][&quot;terminal_observation&quot;]</span></code> which contains the last observation
of an episode (and can be used when bootstrapping, see note in the previous section)</p></li>
<li><p>to overcome the current Gymnasium limitation (only one render mode allowed per env instance, see <a class="reference external" href="https://github.com/Farama-Foundation/Gymnasium/issues/100">issue #100</a>),
we recommend using <code class="docutils literal notranslate"><span class="pre">render_mode=&quot;rgb_array&quot;</span></code> since we can both have the image as a numpy array and display it with OpenCV.
if no mode is passed or <code class="docutils literal notranslate"><span class="pre">mode=&quot;rgb_array&quot;</span></code> is passed when calling <code class="docutils literal notranslate"><span class="pre">vec_env.render</span></code> then we use the default mode, otherwise, we use the OpenCV display.
Note that if <code class="docutils literal notranslate"><span class="pre">render_mode</span> <span class="pre">!=</span> <span class="pre">&quot;rgb_array&quot;</span></code>, you can only call <code class="docutils literal notranslate"><span class="pre">vec_env.render()</span></code> (without argument or with <code class="docutils literal notranslate"><span class="pre">mode=env.render_mode</span></code>).</p></li>
<li><p>the <code class="docutils literal notranslate"><span class="pre">reset()</span></code> method doesn’t take any parameter. If you want to seed the pseudo-random generator or pass options,
you should call <code class="docutils literal notranslate"><span class="pre">vec_env.seed(seed=seed)</span></code>/<code class="docutils literal notranslate"><span class="pre">vec_env.set_options(options)</span></code> and <code class="docutils literal notranslate"><span class="pre">obs</span> <span class="pre">=</span> <span class="pre">vec_env.reset()</span></code> afterward (seed and options are discarded after each call to <code class="docutils literal notranslate"><span class="pre">reset()</span></code>).</p></li>
<li><p>methods and attributes of the underlying Gym envs can be accessed, called and set using <code class="docutils literal notranslate"><span class="pre">vec_env.get_attr(&quot;attribute_name&quot;)</span></code>,
<code class="docutils literal notranslate"><span class="pre">vec_env.env_method(&quot;method_name&quot;,</span> <span class="pre">args1,</span> <span class="pre">args2,</span> <span class="pre">kwargs1=kwargs1)</span></code> and <code class="docutils literal notranslate"><span class="pre">vec_env.set_attr(&quot;attribute_name&quot;,</span> <span class="pre">new_value)</span></code>.</p></li>
</ul>
</section>
<section id="vectorized-environments-wrappers">
<h4>Vectorized Environments Wrappers<a class="headerlink" href="#vectorized-environments-wrappers" title="Permalink to this heading"></a></h4>
<p>If you want to alter or augment a <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code> without redefining it completely (e.g. stack multiple frames, monitor the <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code>, normalize the observation, …), you can use <code class="docutils literal notranslate"><span class="pre">VecEnvWrapper</span></code> for that.
They are the vectorized equivalents (i.e., they act on multiple environments at the same time) of <code class="docutils literal notranslate"><span class="pre">gym.Wrapper</span></code>.</p>
<p>You can find below an example for extracting one key from the observation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">stable_baselines3.common.vec_env.base_vec_env</span> <span class="kn">import</span> <span class="n">VecEnv</span><span class="p">,</span> <span class="n">VecEnvStepReturn</span><span class="p">,</span> <span class="n">VecEnvWrapper</span>


<span class="k">class</span> <span class="nc">VecExtractDictObs</span><span class="p">(</span><span class="n">VecEnvWrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A vectorized wrapper for filtering a specific key from dictionary observations.</span>
<span class="sd">    Similar to Gym&#39;s FilterObservation wrapper:</span>
<span class="sd">        https://github.com/openai/gym/blob/master/gym/wrappers/filter_observation.py</span>

<span class="sd">    :param venv: The vectorized environment</span>
<span class="sd">    :param key: The key of the dictionary observation</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">venv</span><span class="p">:</span> <span class="n">VecEnv</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">key</span> <span class="o">=</span> <span class="n">key</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">venv</span><span class="o">=</span><span class="n">venv</span><span class="p">,</span> <span class="n">observation_space</span><span class="o">=</span><span class="n">venv</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">spaces</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">venv</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">obs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">step_async</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actions</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">venv</span><span class="o">.</span><span class="n">step_async</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">step_wait</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">VecEnvStepReturn</span><span class="p">:</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">venv</span><span class="o">.</span><span class="n">step_wait</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">obs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">key</span><span class="p">],</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">DummyVecEnv</span><span class="p">([</span><span class="k">lambda</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;FetchReach-v1&quot;</span><span class="p">)])</span>
<span class="c1"># Wrap the VecEnv</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">VecExtractDictObs</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;observation&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="vecenv">
<h4>VecEnv<a class="headerlink" href="#vecenv" title="Permalink to this heading"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecEnv">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.vec_env.</span></span><span class="sig-name descname"><span class="pre">VecEnv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_envs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/base_vec_env.html#VecEnv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecEnv" title="Permalink to this definition"></a></dt>
<dd><p>An abstract asynchronous, vectorized environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_envs</strong> (<em>int</em>) – Number of environments</p></li>
<li><p><strong>observation_space</strong> (<em>Space</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Space</em>) – Action space</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecEnv.close">
<em class="property"><span class="pre">abstract</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/base_vec_env.html#VecEnv.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecEnv.close" title="Permalink to this definition"></a></dt>
<dd><p>Clean up the environment’s resources.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecEnv.env_is_wrapped">
<em class="property"><span class="pre">abstract</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">env_is_wrapped</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">wrapper_class</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/base_vec_env.html#VecEnv.env_is_wrapped"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecEnv.env_is_wrapped" title="Permalink to this definition"></a></dt>
<dd><p>Check if environments are wrapped with a given wrapper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method_name</strong> – The name of the environment method to invoke.</p></li>
<li><p><strong>indices</strong> (<em>None</em><em> | </em><em>int</em><em> | </em><em>Iterable</em><em>[</em><em>int</em><em>]</em>) – Indices of envs whose method to call</p></li>
<li><p><strong>method_args</strong> – Any positional arguments to provide in the call</p></li>
<li><p><strong>method_kwargs</strong> – Any keyword arguments to provide in the call</p></li>
<li><p><strong>wrapper_class</strong> (<em>Type</em><em>[</em><em>Wrapper</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>True if the env is wrapped, False otherwise, for each env queried.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>List</em>[bool]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecEnv.env_method">
<em class="property"><span class="pre">abstract</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">env_method</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">method_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">method_args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">method_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/base_vec_env.html#VecEnv.env_method"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecEnv.env_method" title="Permalink to this definition"></a></dt>
<dd><p>Call instance methods of vectorized environments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method_name</strong> (<em>str</em>) – The name of the environment method to invoke.</p></li>
<li><p><strong>indices</strong> (<em>None</em><em> | </em><em>int</em><em> | </em><em>Iterable</em><em>[</em><em>int</em><em>]</em>) – Indices of envs whose method to call</p></li>
<li><p><strong>method_args</strong> – Any positional arguments to provide in the call</p></li>
<li><p><strong>method_kwargs</strong> – Any keyword arguments to provide in the call</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of items returned by the environment’s method call</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>List</em>[<em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecEnv.get_attr">
<em class="property"><span class="pre">abstract</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">get_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attr_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/base_vec_env.html#VecEnv.get_attr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecEnv.get_attr" title="Permalink to this definition"></a></dt>
<dd><p>Return attribute from vectorized environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attr_name</strong> (<em>str</em>) – The name of the attribute whose value to return</p></li>
<li><p><strong>indices</strong> (<em>None</em><em> | </em><em>int</em><em> | </em><em>Iterable</em><em>[</em><em>int</em><em>]</em>) – Indices of envs to get attribute from</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of values of ‘attr_name’ in all environments</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>List</em>[<em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecEnv.get_images">
<span class="sig-name descname"><span class="pre">get_images</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/base_vec_env.html#VecEnv.get_images"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecEnv.get_images" title="Permalink to this definition"></a></dt>
<dd><p>Return RGB images from each environment when available</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Sequence</em>[<em>ndarray</em> | None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecEnv.getattr_depth_check">
<span class="sig-name descname"><span class="pre">getattr_depth_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">already_found</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/base_vec_env.html#VecEnv.getattr_depth_check"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecEnv.getattr_depth_check" title="Permalink to this definition"></a></dt>
<dd><p>Check if an attribute reference is being hidden in a recursive call to __getattr__</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – name of attribute to check for</p></li>
<li><p><strong>already_found</strong> (<em>bool</em>) – whether this attribute has already been found in a wrapper</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>name of module whose attribute is being shadowed, if any.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecEnv.render">
<span class="sig-name descname"><span class="pre">render</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/base_vec_env.html#VecEnv.render"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecEnv.render" title="Permalink to this definition"></a></dt>
<dd><p>Gym environment rendering</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>str</em><em> | </em><em>None</em>) – the rendering type</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray</em> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecEnv.reset">
<em class="property"><span class="pre">abstract</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/base_vec_env.html#VecEnv.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecEnv.reset" title="Permalink to this definition"></a></dt>
<dd><p>Reset all the environments and return an array of
observations, or a tuple of observation arrays.</p>
<p>If step_async is still doing work, that work will
be cancelled and step_wait() should not be called
until step_async() is invoked again.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>observation</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>] | <em>Tuple</em>[<em>ndarray</em>, …]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecEnv.seed">
<span class="sig-name descname"><span class="pre">seed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/base_vec_env.html#VecEnv.seed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecEnv.seed" title="Permalink to this definition"></a></dt>
<dd><p>Sets the random seeds for all environments, based on a given seed.
Each individual environment will still get its own seed, by incrementing the given seed.
WARNING: since gym 0.26, those seeds will only be passed to the environment
at the next reset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – The random seed. May be None for completely random seeding.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Returns a list containing the seeds for each individual env.
Note that all list elements may be None, if the env does not return anything when being seeded.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Sequence</em>[None | int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecEnv.set_attr">
<em class="property"><span class="pre">abstract</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">set_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attr_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/base_vec_env.html#VecEnv.set_attr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecEnv.set_attr" title="Permalink to this definition"></a></dt>
<dd><p>Set attribute inside vectorized environments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attr_name</strong> (<em>str</em>) – The name of attribute to assign new value</p></li>
<li><p><strong>value</strong> (<em>Any</em>) – Value to assign to <cite>attr_name</cite></p></li>
<li><p><strong>indices</strong> (<em>None</em><em> | </em><em>int</em><em> | </em><em>Iterable</em><em>[</em><em>int</em><em>]</em>) – Indices of envs to assign value</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecEnv.set_options">
<span class="sig-name descname"><span class="pre">set_options</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/base_vec_env.html#VecEnv.set_options"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecEnv.set_options" title="Permalink to this definition"></a></dt>
<dd><p>Set environment options for all environments.
If a dict is passed instead of a list, the same options will be used for all environments.
WARNING: Those options will only be passed to the environment at the next reset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>options</strong> (<em>List</em><em>[</em><em>Dict</em><em>] </em><em>| </em><em>Dict</em><em> | </em><em>None</em>) – A dictionary of environment options to pass to each environment at the next reset.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecEnv.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/base_vec_env.html#VecEnv.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecEnv.step" title="Permalink to this definition"></a></dt>
<dd><p>Step the environments with the given action</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>actions</strong> (<em>ndarray</em>) – the action</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>observation, reward, done, information</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>] | <em>Tuple</em>[<em>ndarray</em>, …], <em>ndarray</em>, <em>ndarray</em>, <em>List</em>[<em>Dict</em>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecEnv.step_async">
<em class="property"><span class="pre">abstract</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">step_async</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/base_vec_env.html#VecEnv.step_async"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecEnv.step_async" title="Permalink to this definition"></a></dt>
<dd><p>Tell all the environments to start taking a step
with the given actions.
Call step_wait() to get the results of the step.</p>
<p>You should not call this if a step_async run is
already pending.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>actions</strong> (<em>ndarray</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecEnv.step_wait">
<em class="property"><span class="pre">abstract</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">step_wait</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/base_vec_env.html#VecEnv.step_wait"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecEnv.step_wait" title="Permalink to this definition"></a></dt>
<dd><p>Wait for the step taken with step_async().</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>observation, reward, done, information</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>] | <em>Tuple</em>[<em>ndarray</em>, …], <em>ndarray</em>, <em>ndarray</em>, <em>List</em>[<em>Dict</em>]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="dummyvecenv">
<h4>DummyVecEnv<a class="headerlink" href="#dummyvecenv" title="Permalink to this heading"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.DummyVecEnv">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.vec_env.</span></span><span class="sig-name descname"><span class="pre">DummyVecEnv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_fns</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/dummy_vec_env.html#DummyVecEnv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.DummyVecEnv" title="Permalink to this definition"></a></dt>
<dd><p>Creates a simple vectorized wrapper for multiple environments, calling each environment in sequence on the current
Python process. This is useful for computationally simple environment such as <code class="docutils literal notranslate"><span class="pre">Cartpole-v1</span></code>,
as the overhead of multiprocess or multithread outweighs the environment computation time.
This can also be used for RL methods that
require a vectorized environment, but that you want a single environments to train with.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>env_fns</strong> (<em>List</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>Env</em><em>]</em><em>]</em>) – a list of functions
that return environments to vectorize</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If the same environment instance is passed as the output of two or more different env_fn.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.DummyVecEnv.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/dummy_vec_env.html#DummyVecEnv.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.DummyVecEnv.close" title="Permalink to this definition"></a></dt>
<dd><p>Clean up the environment’s resources.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.DummyVecEnv.env_is_wrapped">
<span class="sig-name descname"><span class="pre">env_is_wrapped</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">wrapper_class</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/dummy_vec_env.html#DummyVecEnv.env_is_wrapped"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.DummyVecEnv.env_is_wrapped" title="Permalink to this definition"></a></dt>
<dd><p>Check if worker environments are wrapped with a given wrapper</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>wrapper_class</strong> (<em>Type</em><em>[</em><em>Wrapper</em><em>]</em>) – </p></li>
<li><p><strong>indices</strong> (<em>None</em><em> | </em><em>int</em><em> | </em><em>Iterable</em><em>[</em><em>int</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>List</em>[bool]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.DummyVecEnv.env_method">
<span class="sig-name descname"><span class="pre">env_method</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">method_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">method_args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">method_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/dummy_vec_env.html#DummyVecEnv.env_method"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.DummyVecEnv.env_method" title="Permalink to this definition"></a></dt>
<dd><p>Call instance methods of vectorized environments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method_name</strong> (<em>str</em>) – </p></li>
<li><p><strong>indices</strong> (<em>None</em><em> | </em><em>int</em><em> | </em><em>Iterable</em><em>[</em><em>int</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>List</em>[<em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.DummyVecEnv.get_attr">
<span class="sig-name descname"><span class="pre">get_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attr_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/dummy_vec_env.html#DummyVecEnv.get_attr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.DummyVecEnv.get_attr" title="Permalink to this definition"></a></dt>
<dd><p>Return attribute from vectorized environment (see base class).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attr_name</strong> (<em>str</em>) – </p></li>
<li><p><strong>indices</strong> (<em>None</em><em> | </em><em>int</em><em> | </em><em>Iterable</em><em>[</em><em>int</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>List</em>[<em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.DummyVecEnv.get_images">
<span class="sig-name descname"><span class="pre">get_images</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/dummy_vec_env.html#DummyVecEnv.get_images"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.DummyVecEnv.get_images" title="Permalink to this definition"></a></dt>
<dd><p>Return RGB images from each environment when available</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Sequence</em>[<em>ndarray</em> | None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.DummyVecEnv.render">
<span class="sig-name descname"><span class="pre">render</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/dummy_vec_env.html#DummyVecEnv.render"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.DummyVecEnv.render" title="Permalink to this definition"></a></dt>
<dd><p>Gym environment rendering. If there are multiple environments then
they are tiled together in one image via <code class="docutils literal notranslate"><span class="pre">BaseVecEnv.render()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>str</em><em> | </em><em>None</em>) – The rendering type.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray</em> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.DummyVecEnv.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/dummy_vec_env.html#DummyVecEnv.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.DummyVecEnv.reset" title="Permalink to this definition"></a></dt>
<dd><p>Reset all the environments and return an array of
observations, or a tuple of observation arrays.</p>
<p>If step_async is still doing work, that work will
be cancelled and step_wait() should not be called
until step_async() is invoked again.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>observation</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>] | <em>Tuple</em>[<em>ndarray</em>, …]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.DummyVecEnv.set_attr">
<span class="sig-name descname"><span class="pre">set_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attr_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/dummy_vec_env.html#DummyVecEnv.set_attr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.DummyVecEnv.set_attr" title="Permalink to this definition"></a></dt>
<dd><p>Set attribute inside vectorized environments (see base class).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attr_name</strong> (<em>str</em>) – </p></li>
<li><p><strong>value</strong> (<em>Any</em>) – </p></li>
<li><p><strong>indices</strong> (<em>None</em><em> | </em><em>int</em><em> | </em><em>Iterable</em><em>[</em><em>int</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.DummyVecEnv.step_async">
<span class="sig-name descname"><span class="pre">step_async</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/dummy_vec_env.html#DummyVecEnv.step_async"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.DummyVecEnv.step_async" title="Permalink to this definition"></a></dt>
<dd><p>Tell all the environments to start taking a step
with the given actions.
Call step_wait() to get the results of the step.</p>
<p>You should not call this if a step_async run is
already pending.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>actions</strong> (<em>ndarray</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.DummyVecEnv.step_wait">
<span class="sig-name descname"><span class="pre">step_wait</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/dummy_vec_env.html#DummyVecEnv.step_wait"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.DummyVecEnv.step_wait" title="Permalink to this definition"></a></dt>
<dd><p>Wait for the step taken with step_async().</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>observation, reward, done, information</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>] | <em>Tuple</em>[<em>ndarray</em>, …], <em>ndarray</em>, <em>ndarray</em>, <em>List</em>[<em>Dict</em>]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="subprocvecenv">
<h4>SubprocVecEnv<a class="headerlink" href="#subprocvecenv" title="Permalink to this heading"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.SubprocVecEnv">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.vec_env.</span></span><span class="sig-name descname"><span class="pre">SubprocVecEnv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_fns</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/subproc_vec_env.html#SubprocVecEnv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.SubprocVecEnv" title="Permalink to this definition"></a></dt>
<dd><p>Creates a multiprocess vectorized wrapper for multiple environments, distributing each environment to its own
process, allowing significant speed up when the environment is computationally complex.</p>
<p>For performance reasons, if your environment is not IO bound, the number of environments should not exceed the
number of logical cores on your CPU.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Only ‘forkserver’ and ‘spawn’ start methods are thread-safe,
which is important when TensorFlow sessions or other non thread-safe
libraries are used in the parent (see issue #217). However, compared to
‘fork’ they incur a small start-up cost and have restrictions on
global variables. With those methods, users must wrap the code in an
<code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">__name__</span> <span class="pre">==</span> <span class="pre">&quot;__main__&quot;:</span></code> block.
For more information, see the multiprocessing documentation.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env_fns</strong> (<em>List</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>Env</em><em>]</em><em>]</em>) – Environments to run in subprocesses</p></li>
<li><p><strong>start_method</strong> (<em>str</em><em> | </em><em>None</em>) – method used to start the subprocesses.
Must be one of the methods returned by multiprocessing.get_all_start_methods().
Defaults to ‘forkserver’ on available platforms, and ‘spawn’ otherwise.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.SubprocVecEnv.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/subproc_vec_env.html#SubprocVecEnv.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.SubprocVecEnv.close" title="Permalink to this definition"></a></dt>
<dd><p>Clean up the environment’s resources.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.SubprocVecEnv.env_is_wrapped">
<span class="sig-name descname"><span class="pre">env_is_wrapped</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">wrapper_class</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/subproc_vec_env.html#SubprocVecEnv.env_is_wrapped"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.SubprocVecEnv.env_is_wrapped" title="Permalink to this definition"></a></dt>
<dd><p>Check if worker environments are wrapped with a given wrapper</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>wrapper_class</strong> (<em>Type</em><em>[</em><em>Wrapper</em><em>]</em>) – </p></li>
<li><p><strong>indices</strong> (<em>None</em><em> | </em><em>int</em><em> | </em><em>Iterable</em><em>[</em><em>int</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>List</em>[bool]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.SubprocVecEnv.env_method">
<span class="sig-name descname"><span class="pre">env_method</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">method_name</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">method_args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">method_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/subproc_vec_env.html#SubprocVecEnv.env_method"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.SubprocVecEnv.env_method" title="Permalink to this definition"></a></dt>
<dd><p>Call instance methods of vectorized environments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method_name</strong> (<em>str</em>) – </p></li>
<li><p><strong>indices</strong> (<em>None</em><em> | </em><em>int</em><em> | </em><em>Iterable</em><em>[</em><em>int</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>List</em>[<em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.SubprocVecEnv.get_attr">
<span class="sig-name descname"><span class="pre">get_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attr_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/subproc_vec_env.html#SubprocVecEnv.get_attr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.SubprocVecEnv.get_attr" title="Permalink to this definition"></a></dt>
<dd><p>Return attribute from vectorized environment (see base class).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attr_name</strong> (<em>str</em>) – </p></li>
<li><p><strong>indices</strong> (<em>None</em><em> | </em><em>int</em><em> | </em><em>Iterable</em><em>[</em><em>int</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>List</em>[<em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.SubprocVecEnv.get_images">
<span class="sig-name descname"><span class="pre">get_images</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/subproc_vec_env.html#SubprocVecEnv.get_images"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.SubprocVecEnv.get_images" title="Permalink to this definition"></a></dt>
<dd><p>Return RGB images from each environment when available</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Sequence</em>[<em>ndarray</em> | None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.SubprocVecEnv.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/subproc_vec_env.html#SubprocVecEnv.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.SubprocVecEnv.reset" title="Permalink to this definition"></a></dt>
<dd><p>Reset all the environments and return an array of
observations, or a tuple of observation arrays.</p>
<p>If step_async is still doing work, that work will
be cancelled and step_wait() should not be called
until step_async() is invoked again.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>observation</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>] | <em>Tuple</em>[<em>ndarray</em>, …]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.SubprocVecEnv.set_attr">
<span class="sig-name descname"><span class="pre">set_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attr_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/subproc_vec_env.html#SubprocVecEnv.set_attr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.SubprocVecEnv.set_attr" title="Permalink to this definition"></a></dt>
<dd><p>Set attribute inside vectorized environments (see base class).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>attr_name</strong> (<em>str</em>) – </p></li>
<li><p><strong>value</strong> (<em>Any</em>) – </p></li>
<li><p><strong>indices</strong> (<em>None</em><em> | </em><em>int</em><em> | </em><em>Iterable</em><em>[</em><em>int</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.SubprocVecEnv.step_async">
<span class="sig-name descname"><span class="pre">step_async</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/subproc_vec_env.html#SubprocVecEnv.step_async"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.SubprocVecEnv.step_async" title="Permalink to this definition"></a></dt>
<dd><p>Tell all the environments to start taking a step
with the given actions.
Call step_wait() to get the results of the step.</p>
<p>You should not call this if a step_async run is
already pending.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>actions</strong> (<em>ndarray</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.SubprocVecEnv.step_wait">
<span class="sig-name descname"><span class="pre">step_wait</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/subproc_vec_env.html#SubprocVecEnv.step_wait"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.SubprocVecEnv.step_wait" title="Permalink to this definition"></a></dt>
<dd><p>Wait for the step taken with step_async().</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>observation, reward, done, information</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>] | <em>Tuple</em>[<em>ndarray</em>, …], <em>ndarray</em>, <em>ndarray</em>, <em>List</em>[<em>Dict</em>]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="wrappers">
<h4>Wrappers<a class="headerlink" href="#wrappers" title="Permalink to this heading"></a></h4>
<section id="vecframestack">
<h5>VecFrameStack<a class="headerlink" href="#vecframestack" title="Permalink to this heading"></a></h5>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecFrameStack">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.vec_env.</span></span><span class="sig-name descname"><span class="pre">VecFrameStack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">venv</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_stack</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channels_order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_frame_stack.html#VecFrameStack"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecFrameStack" title="Permalink to this definition"></a></dt>
<dd><p>Frame stacking wrapper for vectorized environment. Designed for image observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>venv</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – Vectorized environment to wrap</p></li>
<li><p><strong>n_stack</strong> (<em>int</em>) – Number of frames to stack</p></li>
<li><p><strong>channels_order</strong> (<em>str</em><em> | </em><em>Mapping</em><em>[</em><em>str</em><em>, </em><em>str</em><em>] </em><em>| </em><em>None</em>) – If “first”, stack on first image dimension. If “last”, stack on last dimension.
If None, automatically detect channel to stack over in case of image observation or default to “last” (default).
Alternatively channels_order can be a dictionary which can be used with environments with Dict observation spaces</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecFrameStack.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_frame_stack.html#VecFrameStack.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecFrameStack.reset" title="Permalink to this definition"></a></dt>
<dd><p>Reset all environments</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecFrameStack.step_wait">
<span class="sig-name descname"><span class="pre">step_wait</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_frame_stack.html#VecFrameStack.step_wait"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecFrameStack.step_wait" title="Permalink to this definition"></a></dt>
<dd><p>Wait for the step taken with step_async().</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>observation, reward, done, information</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>], <em>ndarray</em>, <em>ndarray</em>, <em>List</em>[<em>Dict</em>[str, <em>Any</em>]]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="stackedobservations">
<h5>StackedObservations<a class="headerlink" href="#stackedobservations" title="Permalink to this heading"></a></h5>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.stacked_observations.StackedObservations">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.vec_env.stacked_observations.</span></span><span class="sig-name descname"><span class="pre">StackedObservations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_envs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_stack</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channels_order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/stacked_observations.html#StackedObservations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.stacked_observations.StackedObservations" title="Permalink to this definition"></a></dt>
<dd><p>Frame stacking wrapper for data.</p>
<p>Dimension to stack over is either first (channels-first) or last (channels-last), which is detected automatically using
<code class="docutils literal notranslate"><span class="pre">common.preprocessing.is_image_space_channels_first</span></code> if observation is an image space.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_envs</strong> – Number of environments</p></li>
<li><p><strong>n_stack</strong> – Number of frames to stack</p></li>
<li><p><strong>observation_space</strong> – Environment observation space</p></li>
<li><p><strong>channels_order</strong> – If “first”, stack on first image dimension. If “last”, stack on last dimension.
If None, automatically detect channel to stack over in case of image observation or default to “last”.
For Dict space, channels_order can also be a dictionary.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.stacked_observations.StackedObservations.compute_stacking">
<em class="property"><span class="pre">static</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">compute_stacking</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_stack</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channels_order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/stacked_observations.html#StackedObservations.compute_stacking"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.stacked_observations.StackedObservations.compute_stacking" title="Permalink to this definition"></a></dt>
<dd><p>Calculates the parameters in order to stack observations</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_stack</strong> (<em>int</em>) – Number of observations to stack</p></li>
<li><p><strong>observation_space</strong> (<em>Box</em>) – Observation space</p></li>
<li><p><strong>channels_order</strong> (<em>str</em><em> | </em><em>None</em>) – Order of the channels</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of channels_first, stack_dimension, stackedobs, repeat_axis</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[bool, int, <em>Tuple</em>[int, …], int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.stacked_observations.StackedObservations.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/stacked_observations.html#StackedObservations.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.stacked_observations.StackedObservations.reset" title="Permalink to this definition"></a></dt>
<dd><p>Reset the stacked_obs, add the reset observation to the stack, and return the stack.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>observation</strong> (<em>TObs</em>) – Reset observation</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The stacked reset observation</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>TObs</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.stacked_observations.StackedObservations.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dones</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">infos</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/stacked_observations.html#StackedObservations.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.stacked_observations.StackedObservations.update" title="Permalink to this definition"></a></dt>
<dd><p>Add the observations to the stack and use the dones to update the infos.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> (<em>TObs</em>) – Observations</p></li>
<li><p><strong>dones</strong> (<em>ndarray</em>) – Dones</p></li>
<li><p><strong>infos</strong> (<em>List</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) – Infos</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple of the stacked observations and the updated infos</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>TObs</em>, <em>List</em>[<em>Dict</em>[str, <em>Any</em>]]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="vecnormalize">
<h5>VecNormalize<a class="headerlink" href="#vecnormalize" title="Permalink to this heading"></a></h5>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecNormalize">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.vec_env.</span></span><span class="sig-name descname"><span class="pre">VecNormalize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">venv</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_reward</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_obs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_reward</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_obs_keys</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_normalize.html#VecNormalize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecNormalize" title="Permalink to this definition"></a></dt>
<dd><p>A moving average, normalizing wrapper for vectorized environment.
has support for saving/loading moving average,</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>venv</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – the vectorized environment to wrap</p></li>
<li><p><strong>training</strong> (<em>bool</em>) – Whether to update or not the moving average</p></li>
<li><p><strong>norm_obs</strong> (<em>bool</em>) – Whether to normalize observation or not (default: True)</p></li>
<li><p><strong>norm_reward</strong> (<em>bool</em>) – Whether to normalize rewards or not (default: True)</p></li>
<li><p><strong>clip_obs</strong> (<em>float</em>) – Max absolute value for observation</p></li>
<li><p><strong>clip_reward</strong> (<em>float</em>) – Max value absolute for discounted reward</p></li>
<li><p><strong>gamma</strong> (<em>float</em>) – discount factor</p></li>
<li><p><strong>epsilon</strong> (<em>float</em>) – To avoid division by zero</p></li>
<li><p><strong>norm_obs_keys</strong> (<em>List</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – Which keys from observation dict to normalize.
If not specified, all keys will be normalized.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecNormalize.get_original_obs">
<span class="sig-name descname"><span class="pre">get_original_obs</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_normalize.html#VecNormalize.get_original_obs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecNormalize.get_original_obs" title="Permalink to this definition"></a></dt>
<dd><p>Returns an unnormalized version of the observations from the most recent
step or reset.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecNormalize.get_original_reward">
<span class="sig-name descname"><span class="pre">get_original_reward</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_normalize.html#VecNormalize.get_original_reward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecNormalize.get_original_reward" title="Permalink to this definition"></a></dt>
<dd><p>Returns an unnormalized version of the rewards from the most recent step.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecNormalize.load">
<em class="property"><span class="pre">static</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">load_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">venv</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_normalize.html#VecNormalize.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecNormalize.load" title="Permalink to this definition"></a></dt>
<dd><p>Loads a saved VecNormalize object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>load_path</strong> (<em>str</em>) – the path to load from.</p></li>
<li><p><strong>venv</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – the VecEnv to wrap.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecNormalize" title="stable_baselines3.common.vec_env.vec_normalize.VecNormalize"><em>VecNormalize</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecNormalize.normalize_obs">
<span class="sig-name descname"><span class="pre">normalize_obs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_normalize.html#VecNormalize.normalize_obs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecNormalize.normalize_obs" title="Permalink to this definition"></a></dt>
<dd><p>Normalize observations using this VecNormalize’s observations statistics.
Calling this method does not update statistics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>obs</strong> (<em>ndarray</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>ndarray</em><em>]</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecNormalize.normalize_reward">
<span class="sig-name descname"><span class="pre">normalize_reward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reward</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_normalize.html#VecNormalize.normalize_reward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecNormalize.normalize_reward" title="Permalink to this definition"></a></dt>
<dd><p>Normalize rewards using this VecNormalize’s rewards statistics.
Calling this method does not update statistics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>reward</strong> (<em>ndarray</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecNormalize.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_normalize.html#VecNormalize.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecNormalize.reset" title="Permalink to this definition"></a></dt>
<dd><p>Reset all environments
:return: first observation of the episode</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecNormalize.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_normalize.html#VecNormalize.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecNormalize.save" title="Permalink to this definition"></a></dt>
<dd><p>Save current VecNormalize object with
all running statistics and settings (e.g. clip_obs)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>save_path</strong> (<em>str</em>) – The path to save to</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecNormalize.set_venv">
<span class="sig-name descname"><span class="pre">set_venv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">venv</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_normalize.html#VecNormalize.set_venv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecNormalize.set_venv" title="Permalink to this definition"></a></dt>
<dd><p>Sets the vector environment to wrap to venv.</p>
<p>Also sets attributes derived from this such as <cite>num_env</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>venv</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecNormalize.step_wait">
<span class="sig-name descname"><span class="pre">step_wait</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_normalize.html#VecNormalize.step_wait"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecNormalize.step_wait" title="Permalink to this definition"></a></dt>
<dd><p>Apply sequence of actions to sequence of environments
actions -&gt; (observations, rewards, dones)</p>
<p>where <code class="docutils literal notranslate"><span class="pre">dones</span></code> is a boolean vector indicating whether each element is new.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>] | <em>Tuple</em>[<em>ndarray</em>, …], <em>ndarray</em>, <em>ndarray</em>, <em>List</em>[<em>Dict</em>]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="vecvideorecorder">
<h5>VecVideoRecorder<a class="headerlink" href="#vecvideorecorder" title="Permalink to this heading"></a></h5>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecVideoRecorder">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.vec_env.</span></span><span class="sig-name descname"><span class="pre">VecVideoRecorder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">venv</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">video_folder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">record_video_trigger</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">video_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'rl-video'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_video_recorder.html#VecVideoRecorder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecVideoRecorder" title="Permalink to this definition"></a></dt>
<dd><p>Wraps a VecEnv or VecEnvWrapper object to record rendered image as mp4 video.
It requires ffmpeg or avconv to be installed on the machine.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>venv</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – </p></li>
<li><p><strong>video_folder</strong> (<em>str</em>) – Where to save videos</p></li>
<li><p><strong>record_video_trigger</strong> (<em>Callable</em><em>[</em><em>[</em><em>int</em><em>]</em><em>, </em><em>bool</em><em>]</em>) – Function that defines when to start recording.
The function takes the current number of step,
and returns whether we should start recording or not.</p></li>
<li><p><strong>video_length</strong> (<em>int</em>) – Length of recorded videos</p></li>
<li><p><strong>name_prefix</strong> (<em>str</em>) – Prefix to the video name</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecVideoRecorder.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_video_recorder.html#VecVideoRecorder.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecVideoRecorder.close" title="Permalink to this definition"></a></dt>
<dd><p>Clean up the environment’s resources.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecVideoRecorder.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_video_recorder.html#VecVideoRecorder.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecVideoRecorder.reset" title="Permalink to this definition"></a></dt>
<dd><p>Reset all the environments and return an array of
observations, or a tuple of observation arrays.</p>
<p>If step_async is still doing work, that work will
be cancelled and step_wait() should not be called
until step_async() is invoked again.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>observation</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>] | <em>Tuple</em>[<em>ndarray</em>, …]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecVideoRecorder.step_wait">
<span class="sig-name descname"><span class="pre">step_wait</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_video_recorder.html#VecVideoRecorder.step_wait"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecVideoRecorder.step_wait" title="Permalink to this definition"></a></dt>
<dd><p>Wait for the step taken with step_async().</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>observation, reward, done, information</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>] | <em>Tuple</em>[<em>ndarray</em>, …], <em>ndarray</em>, <em>ndarray</em>, <em>List</em>[<em>Dict</em>]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="vecchecknan">
<h5>VecCheckNan<a class="headerlink" href="#vecchecknan" title="Permalink to this heading"></a></h5>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecCheckNan">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.vec_env.</span></span><span class="sig-name descname"><span class="pre">VecCheckNan</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">venv</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raise_exception</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warn_once</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_inf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_check_nan.html#VecCheckNan"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecCheckNan" title="Permalink to this definition"></a></dt>
<dd><p>NaN and inf checking wrapper for vectorized environment, will raise a warning by default,
allowing you to know from what the NaN of inf originated from.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>venv</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – the vectorized environment to wrap</p></li>
<li><p><strong>raise_exception</strong> (<em>bool</em>) – Whether to raise a ValueError, instead of a UserWarning</p></li>
<li><p><strong>warn_once</strong> (<em>bool</em>) – Whether to only warn once.</p></li>
<li><p><strong>check_inf</strong> (<em>bool</em>) – Whether to check for +inf or -inf as well</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecCheckNan.check_array_value">
<span class="sig-name descname"><span class="pre">check_array_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_check_nan.html#VecCheckNan.check_array_value"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecCheckNan.check_array_value" title="Permalink to this definition"></a></dt>
<dd><p>Check for inf and NaN for a single numpy array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – Name of the value being check</p></li>
<li><p><strong>value</strong> (<em>ndarray</em>) – Value (numpy array) to check</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of issues found.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>List</em>[<em>Tuple</em>[str, str]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecCheckNan.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_check_nan.html#VecCheckNan.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecCheckNan.reset" title="Permalink to this definition"></a></dt>
<dd><p>Reset all the environments and return an array of
observations, or a tuple of observation arrays.</p>
<p>If step_async is still doing work, that work will
be cancelled and step_wait() should not be called
until step_async() is invoked again.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>observation</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>] | <em>Tuple</em>[<em>ndarray</em>, …]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecCheckNan.step_async">
<span class="sig-name descname"><span class="pre">step_async</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_check_nan.html#VecCheckNan.step_async"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecCheckNan.step_async" title="Permalink to this definition"></a></dt>
<dd><p>Tell all the environments to start taking a step
with the given actions.
Call step_wait() to get the results of the step.</p>
<p>You should not call this if a step_async run is
already pending.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>actions</strong> (<em>ndarray</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecCheckNan.step_wait">
<span class="sig-name descname"><span class="pre">step_wait</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_check_nan.html#VecCheckNan.step_wait"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecCheckNan.step_wait" title="Permalink to this definition"></a></dt>
<dd><p>Wait for the step taken with step_async().</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>observation, reward, done, information</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>] | <em>Tuple</em>[<em>ndarray</em>, …], <em>ndarray</em>, <em>ndarray</em>, <em>List</em>[<em>Dict</em>]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="vectransposeimage">
<h5>VecTransposeImage<a class="headerlink" href="#vectransposeimage" title="Permalink to this heading"></a></h5>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecTransposeImage">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.vec_env.</span></span><span class="sig-name descname"><span class="pre">VecTransposeImage</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">venv</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_transpose.html#VecTransposeImage"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecTransposeImage" title="Permalink to this definition"></a></dt>
<dd><p>Re-order channels, from HxWxC to CxHxW.
It is required for PyTorch convolution layers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>venv</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – </p></li>
<li><p><strong>skip</strong> (<em>bool</em>) – Skip this wrapper if needed as we rely on heuristic to apply it or not,
which may result in unwanted behavior, see GH issue #671.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecTransposeImage.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_transpose.html#VecTransposeImage.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecTransposeImage.close" title="Permalink to this definition"></a></dt>
<dd><p>Clean up the environment’s resources.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecTransposeImage.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_transpose.html#VecTransposeImage.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecTransposeImage.reset" title="Permalink to this definition"></a></dt>
<dd><p>Reset all environments</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em> | <em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecTransposeImage.step_wait">
<span class="sig-name descname"><span class="pre">step_wait</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_transpose.html#VecTransposeImage.step_wait"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecTransposeImage.step_wait" title="Permalink to this definition"></a></dt>
<dd><p>Wait for the step taken with step_async().</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>observation, reward, done, information</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>] | <em>Tuple</em>[<em>ndarray</em>, …], <em>ndarray</em>, <em>ndarray</em>, <em>List</em>[<em>Dict</em>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecTransposeImage.transpose_image">
<em class="property"><span class="pre">static</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">transpose_image</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_transpose.html#VecTransposeImage.transpose_image"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecTransposeImage.transpose_image" title="Permalink to this definition"></a></dt>
<dd><p>Transpose an image or batch of images (re-order channels).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>image</strong> (<em>ndarray</em>) – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecTransposeImage.transpose_observations">
<span class="sig-name descname"><span class="pre">transpose_observations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_transpose.html#VecTransposeImage.transpose_observations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecTransposeImage.transpose_observations" title="Permalink to this definition"></a></dt>
<dd><p>Transpose (if needed) and return new observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>observations</strong> (<em>ndarray</em><em> | </em><em>Dict</em>) – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Transposed observations</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em> | <em>Dict</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecTransposeImage.transpose_space">
<em class="property"><span class="pre">static</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">transpose_space</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_transpose.html#VecTransposeImage.transpose_space"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecTransposeImage.transpose_space" title="Permalink to this definition"></a></dt>
<dd><p>Transpose an observation space (re-order channels).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Box</em>) – </p></li>
<li><p><strong>key</strong> (<em>str</em>) – In case of dictionary space, the key of the observation space.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Box</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="vecmonitor">
<h5>VecMonitor<a class="headerlink" href="#vecmonitor" title="Permalink to this heading"></a></h5>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecMonitor">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.vec_env.</span></span><span class="sig-name descname"><span class="pre">VecMonitor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">venv</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">info_keywords</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_monitor.html#VecMonitor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecMonitor" title="Permalink to this definition"></a></dt>
<dd><p>A vectorized monitor wrapper for <em>vectorized</em> Gym environments,
it is used to record the episode reward, length, time and other data.</p>
<p>Some environments like <a class="reference external" href="https://github.com/openai/procgen">openai/procgen</a>
or <a class="reference external" href="https://github.com/openai/gym3">gym3</a> directly initialize the
vectorized environments, without giving us a chance to use the <code class="docutils literal notranslate"><span class="pre">Monitor</span></code>
wrapper. So this class simply does the job of the <code class="docutils literal notranslate"><span class="pre">Monitor</span></code> wrapper on
a vectorized level.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>venv</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The vectorized environment</p></li>
<li><p><strong>filename</strong> (<em>str</em><em> | </em><em>None</em>) – the location to save a log file, can be None for no log</p></li>
<li><p><strong>info_keywords</strong> (<em>Tuple</em><em>[</em><em>str</em><em>, </em><em>...</em><em>]</em>) – extra information to log, from the information return of env.step()</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecMonitor.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_monitor.html#VecMonitor.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecMonitor.close" title="Permalink to this definition"></a></dt>
<dd><p>Clean up the environment’s resources.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecMonitor.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_monitor.html#VecMonitor.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecMonitor.reset" title="Permalink to this definition"></a></dt>
<dd><p>Reset all the environments and return an array of
observations, or a tuple of observation arrays.</p>
<p>If step_async is still doing work, that work will
be cancelled and step_wait() should not be called
until step_async() is invoked again.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>observation</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>] | <em>Tuple</em>[<em>ndarray</em>, …]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecMonitor.step_wait">
<span class="sig-name descname"><span class="pre">step_wait</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_monitor.html#VecMonitor.step_wait"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecMonitor.step_wait" title="Permalink to this definition"></a></dt>
<dd><p>Wait for the step taken with step_async().</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>observation, reward, done, information</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>] | <em>Tuple</em>[<em>ndarray</em>, …], <em>ndarray</em>, <em>ndarray</em>, <em>List</em>[<em>Dict</em>]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="vecextractdictobs">
<h5>VecExtractDictObs<a class="headerlink" href="#vecextractdictobs" title="Permalink to this heading"></a></h5>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecExtractDictObs">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.vec_env.</span></span><span class="sig-name descname"><span class="pre">VecExtractDictObs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">venv</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_extract_dict_obs.html#VecExtractDictObs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecExtractDictObs" title="Permalink to this definition"></a></dt>
<dd><p>A vectorized wrapper for extracting dictionary observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>venv</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The vectorized environment</p></li>
<li><p><strong>key</strong> (<em>str</em>) – The key of the dictionary observation</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecExtractDictObs.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_extract_dict_obs.html#VecExtractDictObs.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecExtractDictObs.reset" title="Permalink to this definition"></a></dt>
<dd><p>Reset all the environments and return an array of
observations, or a tuple of observation arrays.</p>
<p>If step_async is still doing work, that work will
be cancelled and step_wait() should not be called
until step_async() is invoked again.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>observation</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>ndarray</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.vec_env.VecExtractDictObs.step_wait">
<span class="sig-name descname"><span class="pre">step_wait</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/vec_env/vec_extract_dict_obs.html#VecExtractDictObs.step_wait"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.vec_env.VecExtractDictObs.step_wait" title="Permalink to this definition"></a></dt>
<dd><p>Wait for the step taken with step_async().</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>observation, reward, done, information</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<em>ndarray</em> | <em>Dict</em>[str, <em>ndarray</em>] | <em>Tuple</em>[<em>ndarray</em>, …], <em>ndarray</em>, <em>ndarray</em>, <em>List</em>[<em>Dict</em>]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
</section>
<span id="document-guide/custom_policy"></span><section id="policy-networks">
<span id="custom-policy"></span><h3>Policy Networks<a class="headerlink" href="#policy-networks" title="Permalink to this heading"></a></h3>
<p>Stable Baselines3 provides policy networks for images (CnnPolicies),
other type of input features (MlpPolicies) and multiple different inputs (MultiInputPolicies).</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>For A2C and PPO, continuous actions are clipped during training and testing
(to avoid out of bound error). SAC, DDPG and TD3 squash the action, using a <code class="docutils literal notranslate"><span class="pre">tanh()</span></code> transformation,
which handles bounds more correctly.</p>
</div>
<section id="sb3-policy">
<h4>SB3 Policy<a class="headerlink" href="#sb3-policy" title="Permalink to this heading"></a></h4>
<p>SB3 networks are separated into two mains parts (see figure below):</p>
<ul class="simple">
<li><p>A features extractor (usually shared between actor and critic when applicable, to save computation)
whose role is to extract features (i.e. convert to a feature vector) from high-dimensional observations, for instance, a CNN that extracts features from images.
This is the <code class="docutils literal notranslate"><span class="pre">features_extractor_class</span></code> parameter. You can change the default parameters of that features extractor
by passing a <code class="docutils literal notranslate"><span class="pre">features_extractor_kwargs</span></code> parameter.</p></li>
<li><p>A (fully-connected) network that maps the features to actions/value. Its architecture is controlled by the <code class="docutils literal notranslate"><span class="pre">net_arch</span></code> parameter.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All observations are first pre-processed (e.g. images are normalized, discrete obs are converted to one-hot vectors, …) before being fed to the features extractor.
In the case of vector observations, the features extractor is just a <code class="docutils literal notranslate"><span class="pre">Flatten</span></code> layer.</p>
</div>
<img alt="_images/net_arch.png" src="_images/net_arch.png" />
<p>SB3 policies are usually composed of several networks (actor/critic networks + target networks when applicable) together
with the associated optimizers.</p>
<p>Each of these network have a features extractor followed by a fully-connected network.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When we refer to “policy” in Stable-Baselines3, this is usually an abuse of language compared to RL terminology.
In SB3, “policy” refers to the class that handles all the networks useful for training,
so not only the network used to predict actions (the “learned controller”).</p>
</div>
<img alt="_images/sb3_policy.png" src="_images/sb3_policy.png" />
</section>
<section id="default-network-architecture">
<h4>Default Network Architecture<a class="headerlink" href="#default-network-architecture" title="Permalink to this heading"></a></h4>
<p>The default network architecture used by SB3 depends on the algorithm and the observation space.
You can visualize the architecture by printing <code class="docutils literal notranslate"><span class="pre">model.policy</span></code> (see <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/329">issue #329</a>).</p>
<p>For 1D observation space, a 2 layers fully connected net is used with:</p>
<ul class="simple">
<li><p>64 units (per layer) for PPO/A2C/DQN</p></li>
<li><p>256 units for SAC</p></li>
<li><p>[400, 300] units for TD3/DDPG (values are taken from the original TD3 paper)</p></li>
</ul>
<p>For image observation spaces, the “Nature CNN” (see code for more details) is used for feature extraction, and SAC/TD3 also keeps the same fully connected network after it.
The other algorithms only have a linear layer after the CNN.
The CNN is shared between actor and critic for A2C/PPO (on-policy algorithms) to reduce computation.
Off-policy algorithms (TD3, DDPG, SAC, …) have separate feature extractors: one for the actor and one for the critic, since the best performance is obtained with this configuration.</p>
<p>For mixed observations (dictionary observations), the two architectures from above are used, i.e., CNN for images and then two layers fully-connected network
(with a smaller output size for the CNN).</p>
</section>
<section id="custom-network-architecture">
<h4>Custom Network Architecture<a class="headerlink" href="#custom-network-architecture" title="Permalink to this heading"></a></h4>
<p>One way of customising the policy network architecture is to pass arguments when creating the model,
using <code class="docutils literal notranslate"><span class="pre">policy_kwargs</span></code> parameter:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>An extra linear layer will be added on top of the layers specified in <code class="docutils literal notranslate"><span class="pre">net_arch</span></code>, in order to have the right output dimensions and activation functions (e.g. Softmax for discrete actions).</p>
<p>In the following example, as CartPole’s action space has a dimension of 2, the final dimensions of the <code class="docutils literal notranslate"><span class="pre">net_arch</span></code>’s layers will be:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>        obs
        &lt;4&gt;
   /            \
 &lt;32&gt;          &lt;32&gt;
  |              |
 &lt;32&gt;          &lt;32&gt;
  |              |
 &lt;2&gt;            &lt;1&gt;
action         value
</pre></div>
</div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>

<span class="c1"># Custom actor (pi) and value function (vf) networks</span>
<span class="c1"># of two layers of size 32 each with Relu activation function</span>
<span class="c1"># Note: an extra linear layer will be added on top of the pi and the vf nets, respectively</span>
<span class="n">policy_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">activation_fn</span><span class="o">=</span><span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
                     <span class="n">net_arch</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">pi</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span> <span class="n">vf</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">]))</span>
<span class="c1"># Create the agent</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">policy_kwargs</span><span class="o">=</span><span class="n">policy_kwargs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Retrieve the environment</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_env</span><span class="p">()</span>
<span class="c1"># Train the agent</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">20_000</span><span class="p">)</span>
<span class="c1"># Save the agent</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;ppo_cartpole&quot;</span><span class="p">)</span>

<span class="k">del</span> <span class="n">model</span>
<span class="c1"># the policy_kwargs are automatically loaded</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;ppo_cartpole&quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="custom-feature-extractor">
<h4>Custom Feature Extractor<a class="headerlink" href="#custom-feature-extractor" title="Permalink to this heading"></a></h4>
<p>If you want to have a custom features extractor (e.g. custom CNN when using images), you can define class
that derives from <code class="docutils literal notranslate"><span class="pre">BaseFeaturesExtractor</span></code> and then pass it to the model when training.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For on-policy algorithms, the features extractor is shared by default between the actor and the critic to save computation (when applicable).
However, this can be changed setting <code class="docutils literal notranslate"><span class="pre">share_features_extractor=False</span></code> in the
<code class="docutils literal notranslate"><span class="pre">policy_kwargs</span></code> (both for on-policy and off-policy algorithms).</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">gymnasium</span> <span class="kn">import</span> <span class="n">spaces</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.torch_layers</span> <span class="kn">import</span> <span class="n">BaseFeaturesExtractor</span>


<span class="k">class</span> <span class="nc">CustomCNN</span><span class="p">(</span><span class="n">BaseFeaturesExtractor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    :param observation_space: (gym.Space)</span>
<span class="sd">    :param features_dim: (int) Number of features extracted.</span>
<span class="sd">        This corresponds to the number of unit for the last layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_space</span><span class="p">:</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">,</span> <span class="n">features_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">features_dim</span><span class="p">)</span>
        <span class="c1"># We assume CxHxW images (channels first)</span>
        <span class="c1"># Re-ordering will be done by pre-preprocessing or wrapper</span>
        <span class="n">n_input_channels</span> <span class="o">=</span> <span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">n_input_channels</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
        <span class="p">)</span>

        <span class="c1"># Compute shape by doing one forward pass</span>
        <span class="k">with</span> <span class="n">th</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">n_flatten</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cnn</span><span class="p">(</span>
                <span class="n">th</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">observation_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()[</span><span class="kc">None</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_flatten</span><span class="p">,</span> <span class="n">features_dim</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observations</span><span class="p">:</span> <span class="n">th</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">th</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cnn</span><span class="p">(</span><span class="n">observations</span><span class="p">))</span>

<span class="n">policy_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">features_extractor_class</span><span class="o">=</span><span class="n">CustomCNN</span><span class="p">,</span>
    <span class="n">features_extractor_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">features_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span><span class="s2">&quot;CnnPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;BreakoutNoFrameskip-v4&quot;</span><span class="p">,</span> <span class="n">policy_kwargs</span><span class="o">=</span><span class="n">policy_kwargs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="multiple-inputs-and-dictionary-observations">
<h4>Multiple Inputs and Dictionary Observations<a class="headerlink" href="#multiple-inputs-and-dictionary-observations" title="Permalink to this heading"></a></h4>
<p>Stable Baselines3 supports handling of multiple inputs by using <code class="docutils literal notranslate"><span class="pre">Dict</span></code> Gym space. This can be done using
<code class="docutils literal notranslate"><span class="pre">MultiInputPolicy</span></code>, which by default uses the <code class="docutils literal notranslate"><span class="pre">CombinedExtractor</span></code> features extractor to turn multiple
inputs into a single vector, handled by the <code class="docutils literal notranslate"><span class="pre">net_arch</span></code> network.</p>
<p>By default, <code class="docutils literal notranslate"><span class="pre">CombinedExtractor</span></code> processes multiple inputs as follows:</p>
<ol class="arabic simple">
<li><p>If input is an image (automatically detected, see <code class="docutils literal notranslate"><span class="pre">common.preprocessing.is_image_space</span></code>), process image with Nature Atari CNN network and
output a latent vector of size <code class="docutils literal notranslate"><span class="pre">256</span></code>.</p></li>
<li><p>If input is not an image, flatten it (no layers).</p></li>
<li><p>Concatenate all previous vectors into one long vector and pass it to policy.</p></li>
</ol>
<p>Much like above, you can define custom features extractors. The following example assumes the environment has two keys in the
observation space dictionary: “image” is a (1,H,W) image (channel first), and “vector” is a (D,) dimensional vector. We process “image” with a simple
downsampling and “vector” with a single linear layer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="kn">from</span> <span class="nn">stable_baselines3.common.torch_layers</span> <span class="kn">import</span> <span class="n">BaseFeaturesExtractor</span>

<span class="k">class</span> <span class="nc">CustomCombinedExtractor</span><span class="p">(</span><span class="n">BaseFeaturesExtractor</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation_space</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Dict</span><span class="p">):</span>
        <span class="c1"># We do not know features-dim here before going over all the items,</span>
        <span class="c1"># so put something dummy for now. PyTorch requires calling</span>
        <span class="c1"># nn.Module.__init__ before adding modules</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">observation_space</span><span class="p">,</span> <span class="n">features_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">extractors</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">total_concat_size</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># We need to know size of the output of this extractor,</span>
        <span class="c1"># so go over all the spaces and compute output feature sizes</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">subspace</span> <span class="ow">in</span> <span class="n">observation_space</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;image&quot;</span><span class="p">:</span>
                <span class="c1"># We will just downsample one channel of the image by 4x4 and flatten.</span>
                <span class="c1"># Assume the image is single-channel (subspace.shape[0] == 0)</span>
                <span class="n">extractors</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
                <span class="n">total_concat_size</span> <span class="o">+=</span> <span class="n">subspace</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">subspace</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span>
            <span class="k">elif</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;vector&quot;</span><span class="p">:</span>
                <span class="c1"># Run through a simple MLP</span>
                <span class="n">extractors</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">subspace</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">16</span><span class="p">)</span>
                <span class="n">total_concat_size</span> <span class="o">+=</span> <span class="mi">16</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">extractors</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">(</span><span class="n">extractors</span><span class="p">)</span>

        <span class="c1"># Update the features dim manually</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_features_dim</span> <span class="o">=</span> <span class="n">total_concat_size</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observations</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">th</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">encoded_tensor_list</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># self.extractors contain nn.Modules that do all the processing.</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">extractor</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">extractors</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">encoded_tensor_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">extractor</span><span class="p">(</span><span class="n">observations</span><span class="p">[</span><span class="n">key</span><span class="p">]))</span>
        <span class="c1"># Return a (B, self._features_dim) PyTorch tensor, where B is batch dimension.</span>
        <span class="k">return</span> <span class="n">th</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">encoded_tensor_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="on-policy-algorithms">
<h4>On-Policy Algorithms<a class="headerlink" href="#on-policy-algorithms" title="Permalink to this heading"></a></h4>
<section id="custom-networks">
<h5>Custom Networks<a class="headerlink" href="#custom-networks" title="Permalink to this heading"></a></h5>
<p>If you need a network architecture that is different for the actor and the critic when using <code class="docutils literal notranslate"><span class="pre">PPO</span></code>, <code class="docutils literal notranslate"><span class="pre">A2C</span></code> or <code class="docutils literal notranslate"><span class="pre">TRPO</span></code>,
you can pass a dictionary of the following structure: <code class="docutils literal notranslate"><span class="pre">dict(pi=[&lt;actor</span> <span class="pre">network</span> <span class="pre">architecture&gt;],</span> <span class="pre">vf=[&lt;critic</span> <span class="pre">network</span> <span class="pre">architecture&gt;])</span></code>.</p>
<p>For example, if you want a different architecture for the actor (aka <code class="docutils literal notranslate"><span class="pre">pi</span></code>) and the critic (value-function aka <code class="docutils literal notranslate"><span class="pre">vf</span></code>) networks,
then you can specify <code class="docutils literal notranslate"><span class="pre">net_arch=dict(pi=[32,</span> <span class="pre">32],</span> <span class="pre">vf=[64,</span> <span class="pre">64])</span></code>.</p>
<p>Otherwise, to have actor and critic that share the same network architecture,
you only need to specify <code class="docutils literal notranslate"><span class="pre">net_arch=[128,</span> <span class="pre">128]</span></code> (here, two hidden layers of 128 units each, this is equivalent to <code class="docutils literal notranslate"><span class="pre">net_arch=dict(pi=[128,</span> <span class="pre">128],</span> <span class="pre">vf=[128,</span> <span class="pre">128])</span></code>).</p>
<p>If shared layers are needed, you need to implement a custom policy network (see <a class="reference external" href="#advanced-example">advanced example below</a>).</p>
<section id="examples">
<h6>Examples<a class="headerlink" href="#examples" title="Permalink to this heading"></a></h6>
<p>Same architecture for actor and critic with two layers of size 128: <code class="docutils literal notranslate"><span class="pre">net_arch=[128,</span> <span class="pre">128]</span></code></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>        obs
   /            \
 &lt;128&gt;          &lt;128&gt;
  |              |
 &lt;128&gt;          &lt;128&gt;
  |              |
action         value
</pre></div>
</div>
<p>Different architectures for actor and critic: <code class="docutils literal notranslate"><span class="pre">net_arch=dict(pi=[32,</span> <span class="pre">32],</span> <span class="pre">vf=[64,</span> <span class="pre">64])</span></code></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>        obs
   /            \
 &lt;32&gt;          &lt;64&gt;
  |              |
 &lt;32&gt;          &lt;64&gt;
  |              |
action         value
</pre></div>
</div>
</section>
<section id="advanced-example">
<h6>Advanced Example<a class="headerlink" href="#advanced-example" title="Permalink to this heading"></a></h6>
<p>If your task requires even more granular control over the policy/value architecture, you can redefine the policy directly:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">from</span> <span class="nn">gymnasium</span> <span class="kn">import</span> <span class="n">spaces</span>
<span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.policies</span> <span class="kn">import</span> <span class="n">ActorCriticPolicy</span>


<span class="k">class</span> <span class="nc">CustomNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Custom network for policy and value function.</span>
<span class="sd">    It receives as input the features extracted by the features extractor.</span>

<span class="sd">    :param feature_dim: dimension of the features extracted with the features_extractor (e.g. features from a CNN)</span>
<span class="sd">    :param last_layer_dim_pi: (int) number of units for the last layer of the policy network</span>
<span class="sd">    :param last_layer_dim_vf: (int) number of units for the last layer of the value network</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">feature_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">last_layer_dim_pi</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
        <span class="n">last_layer_dim_vf</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># IMPORTANT:</span>
        <span class="c1"># Save output dimensions, used to create the distributions</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim_pi</span> <span class="o">=</span> <span class="n">last_layer_dim_pi</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim_vf</span> <span class="o">=</span> <span class="n">last_layer_dim_vf</span>

        <span class="c1"># Policy network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">feature_dim</span><span class="p">,</span> <span class="n">last_layer_dim_pi</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="c1"># Value network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">feature_dim</span><span class="p">,</span> <span class="n">last_layer_dim_vf</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="n">th</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">th</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">th</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :return: (th.Tensor, th.Tensor) latent_policy, latent_value of the specified network.</span>
<span class="sd">            If all layers are shared, then ``latent_policy == latent_value``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_actor</span><span class="p">(</span><span class="n">features</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_critic</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward_actor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="n">th</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">th</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">policy_net</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward_critic</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="n">th</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">th</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_net</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">CustomActorCriticPolicy</span><span class="p">(</span><span class="n">ActorCriticPolicy</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">observation_space</span><span class="p">:</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span>
        <span class="n">action_space</span><span class="p">:</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Space</span><span class="p">,</span>
        <span class="n">lr_schedule</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">float</span><span class="p">],</span> <span class="nb">float</span><span class="p">],</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># Disable orthogonal initialization</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;ortho_init&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">observation_space</span><span class="p">,</span>
            <span class="n">action_space</span><span class="p">,</span>
            <span class="n">lr_schedule</span><span class="p">,</span>
            <span class="c1"># Pass remaining arguments to base class</span>
            <span class="o">*</span><span class="n">args</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>


    <span class="k">def</span> <span class="nf">_build_mlp_extractor</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_extractor</span> <span class="o">=</span> <span class="n">CustomNetwork</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features_dim</span><span class="p">)</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span><span class="n">CustomActorCriticPolicy</span><span class="p">,</span> <span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="mi">5000</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="off-policy-algorithms">
<h4>Off-Policy Algorithms<a class="headerlink" href="#off-policy-algorithms" title="Permalink to this heading"></a></h4>
<p>If you need a network architecture that is different for the actor and the critic when using <code class="docutils literal notranslate"><span class="pre">SAC</span></code>, <code class="docutils literal notranslate"><span class="pre">DDPG</span></code>, <code class="docutils literal notranslate"><span class="pre">TQC</span></code> or <code class="docutils literal notranslate"><span class="pre">TD3</span></code>,
you can pass a dictionary of the following structure: <code class="docutils literal notranslate"><span class="pre">dict(pi=[&lt;actor</span> <span class="pre">network</span> <span class="pre">architecture&gt;],</span> <span class="pre">qf=[&lt;critic</span> <span class="pre">network</span> <span class="pre">architecture&gt;])</span></code>.</p>
<p>For example, if you want a different architecture for the actor (aka <code class="docutils literal notranslate"><span class="pre">pi</span></code>) and the critic (Q-function aka <code class="docutils literal notranslate"><span class="pre">qf</span></code>) networks,
then you can specify <code class="docutils literal notranslate"><span class="pre">net_arch=dict(pi=[64,</span> <span class="pre">64],</span> <span class="pre">qf=[400,</span> <span class="pre">300])</span></code>.</p>
<p>Otherwise, to have actor and critic that share the same network architecture,
you only need to specify <code class="docutils literal notranslate"><span class="pre">net_arch=[256,</span> <span class="pre">256]</span></code> (here, two hidden layers of 256 units each).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For advanced customization of off-policy algorithms policies, please take a look at the code.
A good understanding of the algorithm used is required, see discussion in <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/425">issue #425</a></p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">SAC</span>

<span class="c1"># Custom actor architecture with two layers of 64 units each</span>
<span class="c1"># Custom critic architecture with two layers of 400 and 300 units</span>
<span class="n">policy_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">net_arch</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">pi</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span> <span class="n">qf</span><span class="o">=</span><span class="p">[</span><span class="mi">400</span><span class="p">,</span> <span class="mi">300</span><span class="p">]))</span>
<span class="c1"># Create the agent</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">policy_kwargs</span><span class="o">=</span><span class="n">policy_kwargs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="mi">5000</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<span id="document-guide/custom_env"></span><section id="using-custom-environments">
<span id="custom-env"></span><h3>Using Custom Environments<a class="headerlink" href="#using-custom-environments" title="Permalink to this heading"></a></h3>
<p>To use the RL baselines with custom environments, they just need to follow the <em>gymnasium</em> <a class="reference external" href="https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/#sphx-glr-tutorials-gymnasium-basics-environment-creation-py">interface</a>.
That is to say, your environment must implement the following methods (and inherits from Gym Class):</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you are using images as input, the observation must be of type <code class="docutils literal notranslate"><span class="pre">np.uint8</span></code> and be contained in [0, 255].
By default, the observation is normalized by SB3 pre-processing (dividing by 255 to have values in [0, 1]) when using CNN policies.
Images can be either channel-first or channel-last.</p>
<p>If you want to use <code class="docutils literal notranslate"><span class="pre">CnnPolicy</span></code> or <code class="docutils literal notranslate"><span class="pre">MultiInputPolicy</span></code> with image-like observation (3D tensor) that are already normalized, you must pass <code class="docutils literal notranslate"><span class="pre">normalize_images=False</span></code>
to the policy (using <code class="docutils literal notranslate"><span class="pre">policy_kwargs</span></code> parameter, <code class="docutils literal notranslate"><span class="pre">policy_kwargs=dict(normalize_images=False)</span></code>)
and make sure your image is in the <strong>channel-first</strong> format.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although SB3 supports both channel-last and channel-first images as input, we recommend using the channel-first convention when possible.
Under the hood, when a channel-last image is passed, SB3 uses a <code class="docutils literal notranslate"><span class="pre">VecTransposeImage</span></code> wrapper to re-order the channels.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">gymnasium</span> <span class="kn">import</span> <span class="n">spaces</span>


<span class="k">class</span> <span class="nc">CustomEnv</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Custom Environment that follows gym interface.&quot;&quot;&quot;</span>

    <span class="n">metadata</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;render_modes&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;human&quot;</span><span class="p">],</span> <span class="s2">&quot;render_fps&quot;</span><span class="p">:</span> <span class="mi">30</span><span class="p">}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="o">...</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Define action and observation space</span>
        <span class="c1"># They must be gym.spaces objects</span>
        <span class="c1"># Example when using discrete actions:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">(</span><span class="n">N_DISCRETE_ACTIONS</span><span class="p">)</span>
        <span class="c1"># Example for using image as input (channel-first; channel-last also works):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">255</span><span class="p">,</span>
                                            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">N_CHANNELS</span><span class="p">,</span> <span class="n">HEIGHT</span><span class="p">,</span> <span class="n">WIDTH</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="k">return</span> <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="k">return</span> <span class="n">observation</span><span class="p">,</span> <span class="n">info</span>

    <span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="o">...</span>

    <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="o">...</span>
</pre></div>
</div>
<p>Then you can define and train a RL agent with:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Instantiate the env</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">CustomEnv</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="c1"># Define and Train the agent</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">A2C</span><span class="p">(</span><span class="s2">&quot;CnnPolicy&quot;</span><span class="p">,</span> <span class="n">env</span><span class="p">)</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
<p>To check that your environment follows the Gym interface that SB3 supports, please use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3.common.env_checker</span> <span class="kn">import</span> <span class="n">check_env</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">CustomEnv</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="c1"># It will check your custom environment and output additional warnings if needed</span>
<span class="n">check_env</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
</pre></div>
</div>
<p>Gymnasium also have its own <a class="reference external" href="https://gymnasium.farama.org/api/utils/#gymnasium.utils.env_checker.check_env">env checker</a> but it checks a superset of what SB3 supports (SB3 does not support all Gym features).</p>
<p>We have created a <a class="reference external" href="https://colab.research.google.com/github/araffin/rl-tutorial-jnrr19/blob/sb3/5_custom_gym_env.ipynb">colab notebook</a> for a concrete example on creating a custom environment along with an example of using it with Stable-Baselines3 interface.</p>
<p>Alternatively, you may look at Gymnasium <a class="reference external" href="https://gymnasium.farama.org">built-in environments</a>.</p>
<p>Optionally, you can also register the environment with gym, that will allow you to create the RL agent in one line (and use <code class="docutils literal notranslate"><span class="pre">gym.make()</span></code> to instantiate the env):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gymnasium.envs.registration</span> <span class="kn">import</span> <span class="n">register</span>
<span class="c1"># Example for the CartPole environment</span>
<span class="n">register</span><span class="p">(</span>
    <span class="c1"># unique identifier for the env `name-version`</span>
    <span class="nb">id</span><span class="o">=</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span>
    <span class="c1"># path to the class for creating the env</span>
    <span class="c1"># Note: entry_point also accept a class as input (and not only a string)</span>
    <span class="n">entry_point</span><span class="o">=</span><span class="s2">&quot;gym.envs.classic_control:CartPoleEnv&quot;</span><span class="p">,</span>
    <span class="c1"># Max number of steps per episode, using a `TimeLimitWrapper`</span>
    <span class="n">max_episode_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>In the project, for testing purposes, we use a custom environment named <code class="docutils literal notranslate"><span class="pre">IdentityEnv</span></code>
defined <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/blob/master/stable_baselines3/common/envs/identity_env.py">in this file</a>.
An example of how to use it can be found <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/blob/master/tests/test_identity.py">here</a>.</p>
</section>
<span id="document-guide/callbacks"></span><section id="callbacks">
<span id="id1"></span><h3>Callbacks<a class="headerlink" href="#callbacks" title="Permalink to this heading"></a></h3>
<p>A callback is a set of functions that will be called at given stages of the training procedure.
You can use callbacks to access internal state of the RL model during training.
It allows one to do monitoring, auto saving, model manipulation, progress bars, …</p>
<section id="custom-callback">
<h4>Custom Callback<a class="headerlink" href="#custom-callback" title="Permalink to this heading"></a></h4>
<p>To build a custom callback, you need to create a class that derives from <code class="docutils literal notranslate"><span class="pre">BaseCallback</span></code>.
This will give you access to events (<code class="docutils literal notranslate"><span class="pre">_on_training_start</span></code>, <code class="docutils literal notranslate"><span class="pre">_on_step</span></code>) and useful variables (like <cite>self.model</cite> for the RL model).</p>
<p>You can find two examples of custom callbacks in the documentation: one for saving the best model according to the training reward (see <a class="reference internal" href="index.html#examples"><span class="std std-ref">Examples</span></a>), and one for logging additional values with Tensorboard (see <a class="reference internal" href="index.html#tensorboard"><span class="std std-ref">Tensorboard section</span></a>).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">BaseCallback</span>


<span class="k">class</span> <span class="nc">CustomCallback</span><span class="p">(</span><span class="n">BaseCallback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A custom callback that derives from ``BaseCallback``.</span>

<span class="sd">    :param verbose: Verbosity level: 0 for no output, 1 for info messages, 2 for debug messages</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">verbose</span><span class="p">)</span>
        <span class="c1"># Those variables will be accessible in the callback</span>
        <span class="c1"># (they are defined in the base class)</span>
        <span class="c1"># The RL model</span>
        <span class="c1"># self.model = None  # type: BaseAlgorithm</span>
        <span class="c1"># An alias for self.model.get_env(), the environment used for training</span>
        <span class="c1"># self.training_env = None  # type: Union[gym.Env, VecEnv, None]</span>
        <span class="c1"># Number of time the callback was called</span>
        <span class="c1"># self.n_calls = 0  # type: int</span>
        <span class="c1"># self.num_timesteps = 0  # type: int</span>
        <span class="c1"># local and global variables</span>
        <span class="c1"># self.locals = None  # type: Dict[str, Any]</span>
        <span class="c1"># self.globals = None  # type: Dict[str, Any]</span>
        <span class="c1"># The logger object, used to report things in the terminal</span>
        <span class="c1"># self.logger = None  # stable_baselines3.common.logger</span>
        <span class="c1"># # Sometimes, for event callback, it is useful</span>
        <span class="c1"># # to have access to the parent object</span>
        <span class="c1"># self.parent = None  # type: Optional[BaseCallback]</span>

    <span class="k">def</span> <span class="nf">_on_training_start</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method is called before the first rollout starts.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">_on_rollout_start</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A rollout is the collection of environment interaction</span>
<span class="sd">        using the current policy.</span>
<span class="sd">        This event is triggered before collecting new samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">_on_step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method will be called by the model after each call to `env.step()`.</span>

<span class="sd">        For child callback (of an `EventCallback`), this will be called</span>
<span class="sd">        when the event is triggered.</span>

<span class="sd">        :return: If the callback returns False, training is aborted early.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">_on_rollout_end</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This event is triggered before updating the policy.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">_on_training_end</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This event is triggered before exiting the `learn()` method.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">self.num_timesteps</span></code> corresponds to the total number of steps taken in the environment, i.e., it is the number of environments multiplied by the number of time <code class="docutils literal notranslate"><span class="pre">env.step()</span></code> was called</p>
<p>For the other algorithms, <code class="docutils literal notranslate"><span class="pre">self.num_timesteps</span></code> is incremented by <code class="docutils literal notranslate"><span class="pre">n_envs</span></code> (number of environments) after each call to <code class="docutils literal notranslate"><span class="pre">env.step()</span></code></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For off-policy algorithms like SAC, DDPG, TD3 or DQN, the notion of <code class="docutils literal notranslate"><span class="pre">rollout</span></code> corresponds to the steps taken in the environment between two updates.</p>
</div>
</section>
<section id="event-callback">
<span id="eventcallback"></span><h4>Event Callback<a class="headerlink" href="#event-callback" title="Permalink to this heading"></a></h4>
<p>Compared to Keras, Stable Baselines provides a second type of <code class="docutils literal notranslate"><span class="pre">BaseCallback</span></code>, named <code class="docutils literal notranslate"><span class="pre">EventCallback</span></code> that is meant to trigger events. When an event is triggered, then a child callback is called.</p>
<p>As an example, <a class="reference internal" href="#evalcallback"><span class="std std-ref">EvalCallback</span></a> is an <code class="docutils literal notranslate"><span class="pre">EventCallback</span></code> that will trigger its child callback when there is a new best model.
A child callback is for instance <a class="reference internal" href="#stoptrainingcallback"><span class="std std-ref">StopTrainingOnRewardThreshold</span></a> that stops the training if the mean reward achieved by the RL model is above a threshold.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We recommend taking a look at the source code of <a class="reference internal" href="#evalcallback"><span class="std std-ref">EvalCallback</span></a> and <a class="reference internal" href="#stoptrainingcallback"><span class="std std-ref">StopTrainingOnRewardThreshold</span></a> to have a better overview of what can be achieved with this kind of callbacks.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">EventCallback</span><span class="p">(</span><span class="n">BaseCallback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for triggering callback on event.</span>

<span class="sd">    :param callback: Callback that will be called when an event is triggered.</span>
<span class="sd">    :param verbose: Verbosity level: 0 for no output, 1 for info messages, 2 for debug messages</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">callback</span><span class="p">:</span> <span class="n">BaseCallback</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback</span> <span class="o">=</span> <span class="n">callback</span>
        <span class="c1"># Give access to the parent</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span>
    <span class="o">...</span>

    <span class="k">def</span> <span class="nf">_on_event</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">callback</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="callback-collection">
<h4>Callback Collection<a class="headerlink" href="#callback-collection" title="Permalink to this heading"></a></h4>
<p>Stable Baselines provides you with a set of common callbacks for:</p>
<ul class="simple">
<li><p>saving the model periodically (<a class="reference internal" href="#checkpointcallback"><span class="std std-ref">CheckpointCallback</span></a>)</p></li>
<li><p>evaluating the model periodically and saving the best one (<a class="reference internal" href="#evalcallback"><span class="std std-ref">EvalCallback</span></a>)</p></li>
<li><p>chaining callbacks (<a class="reference internal" href="#callbacklist"><span class="std std-ref">CallbackList</span></a>)</p></li>
<li><p>triggering callback on events (<a class="reference internal" href="#eventcallback"><span class="std std-ref">Event Callback</span></a>, <a class="reference internal" href="#everyntimesteps"><span class="std std-ref">EveryNTimesteps</span></a>)</p></li>
<li><p>stopping the training early based on a reward threshold (<a class="reference internal" href="#stoptrainingcallback"><span class="std std-ref">StopTrainingOnRewardThreshold</span></a>)</p></li>
</ul>
<section id="checkpointcallback">
<span id="id2"></span><h5>CheckpointCallback<a class="headerlink" href="#checkpointcallback" title="Permalink to this heading"></a></h5>
<p>Callback for saving a model every <code class="docutils literal notranslate"><span class="pre">save_freq</span></code> calls to <code class="docutils literal notranslate"><span class="pre">env.step()</span></code>, you must specify a log folder (<code class="docutils literal notranslate"><span class="pre">save_path</span></code>)
and optionally a prefix for the checkpoints (<code class="docutils literal notranslate"><span class="pre">rl_model</span></code> by default).
If you are using this callback to stop and resume training, you may want to optionally save the replay buffer if the
model has one (<code class="docutils literal notranslate"><span class="pre">save_replay_buffer</span></code>, <code class="docutils literal notranslate"><span class="pre">False</span></code> by default).
Additionally, if your environment uses a <a class="reference internal" href="index.html#vec-env"><span class="std std-ref">VecNormalize</span></a> wrapper, you can save the
corresponding statistics using <code class="docutils literal notranslate"><span class="pre">save_vecnormalize</span></code> (<code class="docutils literal notranslate"><span class="pre">False</span></code> by default).</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When using multiple environments, each call to <code class="docutils literal notranslate"><span class="pre">env.step()</span></code> will effectively correspond to <code class="docutils literal notranslate"><span class="pre">n_envs</span></code> steps.
If you want the <code class="docutils literal notranslate"><span class="pre">save_freq</span></code> to be similar when using a different number of environments,
you need to account for it using <code class="docutils literal notranslate"><span class="pre">save_freq</span> <span class="pre">=</span> <span class="pre">max(save_freq</span> <span class="pre">//</span> <span class="pre">n_envs,</span> <span class="pre">1)</span></code>.
The same goes for the other callbacks.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">SAC</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">CheckpointCallback</span>

<span class="c1"># Save a checkpoint every 1000 steps</span>
<span class="n">checkpoint_callback</span> <span class="o">=</span> <span class="n">CheckpointCallback</span><span class="p">(</span>
  <span class="n">save_freq</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
  <span class="n">save_path</span><span class="o">=</span><span class="s2">&quot;./logs/&quot;</span><span class="p">,</span>
  <span class="n">name_prefix</span><span class="o">=</span><span class="s2">&quot;rl_model&quot;</span><span class="p">,</span>
  <span class="n">save_replay_buffer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="n">save_vecnormalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">checkpoint_callback</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="evalcallback">
<span id="id3"></span><h5>EvalCallback<a class="headerlink" href="#evalcallback" title="Permalink to this heading"></a></h5>
<p>Evaluate periodically the performance of an agent, using a separate test environment.
It will save the best model if <code class="docutils literal notranslate"><span class="pre">best_model_save_path</span></code> folder is specified and save the evaluations results in a NumPy archive (<code class="docutils literal notranslate"><span class="pre">evaluations.npz</span></code>) if <code class="docutils literal notranslate"><span class="pre">log_path</span></code> folder is specified.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can pass child callbacks via <code class="docutils literal notranslate"><span class="pre">callback_after_eval</span></code> and <code class="docutils literal notranslate"><span class="pre">callback_on_new_best</span></code> arguments. <code class="docutils literal notranslate"><span class="pre">callback_after_eval</span></code> will be triggered after every evaluation, and <code class="docutils literal notranslate"><span class="pre">callback_on_new_best</span></code> will be triggered each time there is a new best model.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>You need to make sure that <code class="docutils literal notranslate"><span class="pre">eval_env</span></code> is wrapped the same way as the training environment, for instance using the <code class="docutils literal notranslate"><span class="pre">VecTransposeImage</span></code> wrapper if you have a channel-last image as input.
The <code class="docutils literal notranslate"><span class="pre">EvalCallback</span></code> class outputs a warning if it is not the case.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">SAC</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">EvalCallback</span>

<span class="c1"># Separate evaluation env</span>
<span class="n">eval_env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">)</span>
<span class="c1"># Use deterministic actions for evaluation</span>
<span class="n">eval_callback</span> <span class="o">=</span> <span class="n">EvalCallback</span><span class="p">(</span><span class="n">eval_env</span><span class="p">,</span> <span class="n">best_model_save_path</span><span class="o">=</span><span class="s2">&quot;./logs/&quot;</span><span class="p">,</span>
                             <span class="n">log_path</span><span class="o">=</span><span class="s2">&quot;./logs/&quot;</span><span class="p">,</span> <span class="n">eval_freq</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
                             <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">render</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">eval_callback</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="progressbarcallback">
<span id="id4"></span><h5>ProgressBarCallback<a class="headerlink" href="#progressbarcallback" title="Permalink to this heading"></a></h5>
<p>Display a progress bar with the current progress, elapsed time and estimated remaining time.
This callback is integrated inside SB3 via the <code class="docutils literal notranslate"><span class="pre">progress_bar</span></code> argument of the <code class="docutils literal notranslate"><span class="pre">learn()</span></code> method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">ProgressBarCallback</span></code> callback requires <code class="docutils literal notranslate"><span class="pre">tqdm</span></code> and <code class="docutils literal notranslate"><span class="pre">rich</span></code> packages to be installed. This is done automatically when using <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">stable-baselines3[extra]</span></code></p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">ProgressBarCallback</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">)</span>
<span class="c1"># Display progress bar using the progress bar callback</span>
<span class="c1"># this is equivalent to model.learn(100_000, callback=ProgressBarCallback())</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="mi">100_000</span><span class="p">,</span> <span class="n">progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="callbacklist">
<span id="id5"></span><h5>CallbackList<a class="headerlink" href="#callbacklist" title="Permalink to this heading"></a></h5>
<p>Class for chaining callbacks, they will be called sequentially.
Alternatively, you can pass directly a list of callbacks to the <code class="docutils literal notranslate"><span class="pre">learn()</span></code> method, it will be converted automatically to a <code class="docutils literal notranslate"><span class="pre">CallbackList</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">SAC</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">CallbackList</span><span class="p">,</span> <span class="n">CheckpointCallback</span><span class="p">,</span> <span class="n">EvalCallback</span>

<span class="n">checkpoint_callback</span> <span class="o">=</span> <span class="n">CheckpointCallback</span><span class="p">(</span><span class="n">save_freq</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s2">&quot;./logs/&quot;</span><span class="p">)</span>
<span class="c1"># Separate evaluation env</span>
<span class="n">eval_env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">)</span>
<span class="n">eval_callback</span> <span class="o">=</span> <span class="n">EvalCallback</span><span class="p">(</span><span class="n">eval_env</span><span class="p">,</span> <span class="n">best_model_save_path</span><span class="o">=</span><span class="s2">&quot;./logs/best_model&quot;</span><span class="p">,</span>
                             <span class="n">log_path</span><span class="o">=</span><span class="s2">&quot;./logs/results&quot;</span><span class="p">,</span> <span class="n">eval_freq</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="c1"># Create the callback list</span>
<span class="n">callback</span> <span class="o">=</span> <span class="n">CallbackList</span><span class="p">([</span><span class="n">checkpoint_callback</span><span class="p">,</span> <span class="n">eval_callback</span><span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">)</span>
<span class="c1"># Equivalent to:</span>
<span class="c1"># model.learn(5000, callback=[checkpoint_callback, eval_callback])</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">callback</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="stoptrainingonrewardthreshold">
<span id="stoptrainingcallback"></span><h5>StopTrainingOnRewardThreshold<a class="headerlink" href="#stoptrainingonrewardthreshold" title="Permalink to this heading"></a></h5>
<p>Stop the training once a threshold in episodic reward (mean episode reward over the evaluations) has been reached (i.e., when the model is good enough).
It must be used with the <a class="reference internal" href="#evalcallback"><span class="std std-ref">EvalCallback</span></a> and use the event triggered by a new best model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">SAC</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">EvalCallback</span><span class="p">,</span> <span class="n">StopTrainingOnRewardThreshold</span>

<span class="c1"># Separate evaluation env</span>
<span class="n">eval_env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">)</span>
<span class="c1"># Stop training when the model reaches the reward threshold</span>
<span class="n">callback_on_best</span> <span class="o">=</span> <span class="n">StopTrainingOnRewardThreshold</span><span class="p">(</span><span class="n">reward_threshold</span><span class="o">=-</span><span class="mi">200</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">eval_callback</span> <span class="o">=</span> <span class="n">EvalCallback</span><span class="p">(</span><span class="n">eval_env</span><span class="p">,</span> <span class="n">callback_on_new_best</span><span class="o">=</span><span class="n">callback_on_best</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Almost infinite number of timesteps, but the training will stop</span>
<span class="c1"># early as soon as the reward threshold is reached</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e10</span><span class="p">),</span> <span class="n">callback</span><span class="o">=</span><span class="n">eval_callback</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="everyntimesteps">
<span id="id6"></span><h5>EveryNTimesteps<a class="headerlink" href="#everyntimesteps" title="Permalink to this heading"></a></h5>
<p>An <a class="reference internal" href="#eventcallback"><span class="std std-ref">Event Callback</span></a> that will trigger its child callback every <code class="docutils literal notranslate"><span class="pre">n_steps</span></code> timesteps.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Because of the way <code class="docutils literal notranslate"><span class="pre">PPO1</span></code> and <code class="docutils literal notranslate"><span class="pre">TRPO</span></code> work (they rely on MPI), <code class="docutils literal notranslate"><span class="pre">n_steps</span></code> is a lower bound between two events.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">CheckpointCallback</span><span class="p">,</span> <span class="n">EveryNTimesteps</span>

<span class="c1"># this is equivalent to defining CheckpointCallback(save_freq=500)</span>
<span class="c1"># checkpoint_callback will be triggered every 500 steps</span>
<span class="n">checkpoint_on_event</span> <span class="o">=</span> <span class="n">CheckpointCallback</span><span class="p">(</span><span class="n">save_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s2">&quot;./logs/&quot;</span><span class="p">)</span>
<span class="n">event_callback</span> <span class="o">=</span> <span class="n">EveryNTimesteps</span><span class="p">(</span><span class="n">n_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">checkpoint_on_event</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">2e4</span><span class="p">),</span> <span class="n">callback</span><span class="o">=</span><span class="n">event_callback</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="stoptrainingonmaxepisodes">
<span id="id7"></span><h5>StopTrainingOnMaxEpisodes<a class="headerlink" href="#stoptrainingonmaxepisodes" title="Permalink to this heading"></a></h5>
<p>Stop the training upon reaching the maximum number of episodes, regardless of the model’s <code class="docutils literal notranslate"><span class="pre">total_timesteps</span></code> value.
Also, presumes that, for multiple environments, the desired behavior is that the agent trains on each env for <code class="docutils literal notranslate"><span class="pre">max_episodes</span></code>
and in total for <code class="docutils literal notranslate"><span class="pre">max_episodes</span> <span class="pre">*</span> <span class="pre">n_envs</span></code> episodes.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For multiple environments, the agent will train for a total of <code class="docutils literal notranslate"><span class="pre">max_episodes</span> <span class="pre">*</span> <span class="pre">n_envs</span></code> episodes.
However, it can’t be guaranteed that this training will occur for an exact number of <code class="docutils literal notranslate"><span class="pre">max_episodes</span></code> per environment.
Thus, there is an assumption that, on average, each environment ran for <code class="docutils literal notranslate"><span class="pre">max_episodes</span></code>.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">A2C</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">StopTrainingOnMaxEpisodes</span>

<span class="c1"># Stops training when the model reaches the maximum number of episodes</span>
<span class="n">callback_max_episodes</span> <span class="o">=</span> <span class="n">StopTrainingOnMaxEpisodes</span><span class="p">(</span><span class="n">max_episodes</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">A2C</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Almost infinite number of timesteps, but the training will stop</span>
<span class="c1"># early as soon as the max number of episodes is reached</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e10</span><span class="p">),</span> <span class="n">callback</span><span class="o">=</span><span class="n">callback_max_episodes</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="stoptrainingonnomodelimprovement">
<span id="id8"></span><h5>StopTrainingOnNoModelImprovement<a class="headerlink" href="#stoptrainingonnomodelimprovement" title="Permalink to this heading"></a></h5>
<p>Stop the training if there is no new best model (no new best mean reward) after more than a specific number of consecutive evaluations.
The idea is to save time in experiments when you know that the learning curves are somehow well-behaved and, therefore,
after many evaluations without improvement the learning has probably stabilized.
It must be used with the <a class="reference internal" href="#evalcallback"><span class="std std-ref">EvalCallback</span></a> and use the event triggered after every evaluation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">SAC</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">EvalCallback</span><span class="p">,</span> <span class="n">StopTrainingOnNoModelImprovement</span>

<span class="c1"># Separate evaluation env</span>
<span class="n">eval_env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">)</span>
<span class="c1"># Stop training if there is no improvement after more than 3 evaluations</span>
<span class="n">stop_train_callback</span> <span class="o">=</span> <span class="n">StopTrainingOnNoModelImprovement</span><span class="p">(</span><span class="n">max_no_improvement_evals</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">min_evals</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">eval_callback</span> <span class="o">=</span> <span class="n">EvalCallback</span><span class="p">(</span><span class="n">eval_env</span><span class="p">,</span> <span class="n">eval_freq</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">callback_after_eval</span><span class="o">=</span><span class="n">stop_train_callback</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Almost infinite number of timesteps, but the training will stop early</span>
<span class="c1"># as soon as the the number of consecutive evaluations without model</span>
<span class="c1"># improvement is greater than 3</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e10</span><span class="p">),</span> <span class="n">callback</span><span class="o">=</span><span class="n">eval_callback</span><span class="p">)</span>
</pre></div>
</div>
<span class="target" id="module-stable_baselines3.common.callbacks"></span><dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.BaseCallback">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.callbacks.</span></span><span class="sig-name descname"><span class="pre">BaseCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#BaseCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.BaseCallback" title="Permalink to this definition"></a></dt>
<dd><p>Base class for callback.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 1 for info messages, 2 for debug messages</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.BaseCallback.init_callback">
<span class="sig-name descname"><span class="pre">init_callback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#BaseCallback.init_callback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.BaseCallback.init_callback" title="Permalink to this definition"></a></dt>
<dd><p>Initialize the callback by saving references to the
RL model and the training environment for convenience.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.base_class.BaseAlgorithm" title="stable_baselines3.common.base_class.BaseAlgorithm"><em>base_class.BaseAlgorithm</em></a>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.BaseCallback.on_step">
<span class="sig-name descname"><span class="pre">on_step</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#BaseCallback.on_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.BaseCallback.on_step" title="Permalink to this definition"></a></dt>
<dd><p>This method will be called by the model after each call to <code class="docutils literal notranslate"><span class="pre">env.step()</span></code>.</p>
<p>For child callback (of an <code class="docutils literal notranslate"><span class="pre">EventCallback</span></code>), this will be called
when the event is triggered.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>If the callback returns False, training is aborted early.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.BaseCallback.update_child_locals">
<span class="sig-name descname"><span class="pre">update_child_locals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">locals_</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#BaseCallback.update_child_locals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.BaseCallback.update_child_locals" title="Permalink to this definition"></a></dt>
<dd><p>Update the references to the local variables on sub callbacks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>locals</strong> – the local variables during rollout collection</p></li>
<li><p><strong>locals_</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.BaseCallback.update_locals">
<span class="sig-name descname"><span class="pre">update_locals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">locals_</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#BaseCallback.update_locals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.BaseCallback.update_locals" title="Permalink to this definition"></a></dt>
<dd><p>Update the references to the local variables.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>locals</strong> – the local variables during rollout collection</p></li>
<li><p><strong>locals_</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.CallbackList">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.callbacks.</span></span><span class="sig-name descname"><span class="pre">CallbackList</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">callbacks</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#CallbackList"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.CallbackList" title="Permalink to this definition"></a></dt>
<dd><p>Class for chaining callbacks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>callbacks</strong> (<em>List</em><em>[</em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a><em>]</em>) – A list of callbacks that will be called
sequentially.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.CallbackList.update_child_locals">
<span class="sig-name descname"><span class="pre">update_child_locals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">locals_</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#CallbackList.update_child_locals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.CallbackList.update_child_locals" title="Permalink to this definition"></a></dt>
<dd><p>Update the references to the local variables.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>locals</strong> – the local variables during rollout collection</p></li>
<li><p><strong>locals_</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.CheckpointCallback">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.callbacks.</span></span><span class="sig-name descname"><span class="pre">CheckpointCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_freq</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name_prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'rl_model'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_replay_buffer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_vecnormalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#CheckpointCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.CheckpointCallback" title="Permalink to this definition"></a></dt>
<dd><p>Callback for saving a model every <code class="docutils literal notranslate"><span class="pre">save_freq</span></code> calls
to <code class="docutils literal notranslate"><span class="pre">env.step()</span></code>.
By default, it only saves model checkpoints,
you need to pass <code class="docutils literal notranslate"><span class="pre">save_replay_buffer=True</span></code>,
and <code class="docutils literal notranslate"><span class="pre">save_vecnormalize=True</span></code> to also save replay buffer checkpoints
and normalization statistics checkpoints.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When using multiple environments, each call to  <code class="docutils literal notranslate"><span class="pre">env.step()</span></code>
will effectively correspond to <code class="docutils literal notranslate"><span class="pre">n_envs</span></code> steps.
To account for that, you can use <code class="docutils literal notranslate"><span class="pre">save_freq</span> <span class="pre">=</span> <span class="pre">max(save_freq</span> <span class="pre">//</span> <span class="pre">n_envs,</span> <span class="pre">1)</span></code></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>save_freq</strong> (<em>int</em>) – Save checkpoints every <code class="docutils literal notranslate"><span class="pre">save_freq</span></code> call of the callback.</p></li>
<li><p><strong>save_path</strong> (<em>str</em>) – Path to the folder where the model will be saved.</p></li>
<li><p><strong>name_prefix</strong> (<em>str</em>) – Common prefix to the saved models</p></li>
<li><p><strong>save_replay_buffer</strong> (<em>bool</em>) – Save the model replay buffer</p></li>
<li><p><strong>save_vecnormalize</strong> (<em>bool</em>) – Save the <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> statistics</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 2 for indicating when saving model checkpoint</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.ConvertCallback">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.callbacks.</span></span><span class="sig-name descname"><span class="pre">ConvertCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#ConvertCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.ConvertCallback" title="Permalink to this definition"></a></dt>
<dd><p>Convert functional callback (old-style) to object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>, </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>bool</em><em>] </em><em>| </em><em>None</em>) – </p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 1 for info messages, 2 for debug messages</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.EvalCallback">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.callbacks.</span></span><span class="sig-name descname"><span class="pre">EvalCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eval_env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_on_new_best</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback_after_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_eval_episodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_model_save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">render</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#EvalCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.EvalCallback" title="Permalink to this definition"></a></dt>
<dd><p>Callback for evaluating an agent.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When using multiple environments, each call to  <code class="docutils literal notranslate"><span class="pre">env.step()</span></code>
will effectively correspond to <code class="docutils literal notranslate"><span class="pre">n_envs</span></code> steps.
To account for that, you can use <code class="docutils literal notranslate"><span class="pre">eval_freq</span> <span class="pre">=</span> <span class="pre">max(eval_freq</span> <span class="pre">//</span> <span class="pre">n_envs,</span> <span class="pre">1)</span></code></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eval_env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The environment used for initialization</p></li>
<li><p><strong>callback_on_new_best</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a><em> | </em><em>None</em>) – Callback to trigger
when there is a new best model according to the <code class="docutils literal notranslate"><span class="pre">mean_reward</span></code></p></li>
<li><p><strong>callback_after_eval</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a><em> | </em><em>None</em>) – Callback to trigger after every evaluation</p></li>
<li><p><strong>n_eval_episodes</strong> (<em>int</em>) – The number of episodes to test the agent</p></li>
<li><p><strong>eval_freq</strong> (<em>int</em>) – Evaluate the agent every <code class="docutils literal notranslate"><span class="pre">eval_freq</span></code> call of the callback.</p></li>
<li><p><strong>log_path</strong> (<em>str</em><em> | </em><em>None</em>) – Path to a folder where the evaluations (<code class="docutils literal notranslate"><span class="pre">evaluations.npz</span></code>)
will be saved. It will be updated at each evaluation.</p></li>
<li><p><strong>best_model_save_path</strong> (<em>str</em><em> | </em><em>None</em>) – Path to a folder where the best model
according to performance on the eval env will be saved.</p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – Whether the evaluation should
use a stochastic or deterministic actions.</p></li>
<li><p><strong>render</strong> (<em>bool</em>) – Whether to render or not the environment during evaluation</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 1 for indicating information about evaluation results</p></li>
<li><p><strong>warn</strong> (<em>bool</em>) – Passed to <code class="docutils literal notranslate"><span class="pre">evaluate_policy</span></code> (warns if <code class="docutils literal notranslate"><span class="pre">eval_env</span></code> has not been
wrapped with a Monitor wrapper)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.EvalCallback.update_child_locals">
<span class="sig-name descname"><span class="pre">update_child_locals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">locals_</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#EvalCallback.update_child_locals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.EvalCallback.update_child_locals" title="Permalink to this definition"></a></dt>
<dd><p>Update the references to the local variables.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>locals</strong> – the local variables during rollout collection</p></li>
<li><p><strong>locals_</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.EventCallback">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.callbacks.</span></span><span class="sig-name descname"><span class="pre">EventCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#EventCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.EventCallback" title="Permalink to this definition"></a></dt>
<dd><p>Base class for triggering callback on event.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>callback</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a><em> | </em><em>None</em>) – Callback that will be called
when an event is triggered.</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 1 for info messages, 2 for debug messages</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.EventCallback.init_callback">
<span class="sig-name descname"><span class="pre">init_callback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#EventCallback.init_callback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.EventCallback.init_callback" title="Permalink to this definition"></a></dt>
<dd><p>Initialize the callback by saving references to the
RL model and the training environment for convenience.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.base_class.BaseAlgorithm" title="stable_baselines3.common.base_class.BaseAlgorithm"><em>base_class.BaseAlgorithm</em></a>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.EventCallback.update_child_locals">
<span class="sig-name descname"><span class="pre">update_child_locals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">locals_</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#EventCallback.update_child_locals"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.EventCallback.update_child_locals" title="Permalink to this definition"></a></dt>
<dd><p>Update the references to the local variables.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>locals</strong> – the local variables during rollout collection</p></li>
<li><p><strong>locals_</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.EveryNTimesteps">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.callbacks.</span></span><span class="sig-name descname"><span class="pre">EveryNTimesteps</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#EveryNTimesteps"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.EveryNTimesteps" title="Permalink to this definition"></a></dt>
<dd><p>Trigger a callback every <code class="docutils literal notranslate"><span class="pre">n_steps</span></code> timesteps</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_steps</strong> (<em>int</em>) – Number of timesteps between two trigger.</p></li>
<li><p><strong>callback</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – Callback that will be called
when the event is triggered.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.ProgressBarCallback">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.callbacks.</span></span><span class="sig-name descname"><span class="pre">ProgressBarCallback</span></span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#ProgressBarCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.ProgressBarCallback" title="Permalink to this definition"></a></dt>
<dd><p>Display a progress bar when training SB3 agent
using tqdm and rich packages.</p>
<dl class="field-list simple">
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.StopTrainingOnMaxEpisodes">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.callbacks.</span></span><span class="sig-name descname"><span class="pre">StopTrainingOnMaxEpisodes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_episodes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#StopTrainingOnMaxEpisodes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.StopTrainingOnMaxEpisodes" title="Permalink to this definition"></a></dt>
<dd><p>Stop the training once a maximum number of episodes are played.</p>
<p>For multiple environments presumes that, the desired behavior is that the agent trains on each env for <code class="docutils literal notranslate"><span class="pre">max_episodes</span></code>
and in total for <code class="docutils literal notranslate"><span class="pre">max_episodes</span> <span class="pre">*</span> <span class="pre">n_envs</span></code> episodes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_episodes</strong> (<em>int</em>) – Maximum number of episodes to stop training.</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 1 for indicating information about when training ended by
reaching <code class="docutils literal notranslate"><span class="pre">max_episodes</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.StopTrainingOnNoModelImprovement">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.callbacks.</span></span><span class="sig-name descname"><span class="pre">StopTrainingOnNoModelImprovement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_no_improvement_evals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_evals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#StopTrainingOnNoModelImprovement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.StopTrainingOnNoModelImprovement" title="Permalink to this definition"></a></dt>
<dd><p>Stop the training early if there is no new best model (new best mean reward) after more than N consecutive evaluations.</p>
<p>It is possible to define a minimum number of evaluations before start to count evaluations without improvement.</p>
<p>It must be used with the <code class="docutils literal notranslate"><span class="pre">EvalCallback</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_no_improvement_evals</strong> (<em>int</em>) – Maximum number of consecutive evaluations without a new best model.</p></li>
<li><p><strong>min_evals</strong> (<em>int</em>) – Number of evaluations before start to count evaluations without improvements.</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 1 for indicating when training ended because no new best model</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.callbacks.StopTrainingOnRewardThreshold">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.callbacks.</span></span><span class="sig-name descname"><span class="pre">StopTrainingOnRewardThreshold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reward_threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/callbacks.html#StopTrainingOnRewardThreshold"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.callbacks.StopTrainingOnRewardThreshold" title="Permalink to this definition"></a></dt>
<dd><p>Stop the training once a threshold in episodic reward
has been reached (i.e. when the model is good enough).</p>
<p>It must be used with the <code class="docutils literal notranslate"><span class="pre">EvalCallback</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>reward_threshold</strong> (<em>float</em>) – Minimum expected reward per episode
to stop training.</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 1 for indicating when training ended because episodic reward
threshold reached</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>
<span id="document-guide/tensorboard"></span><section id="tensorboard-integration">
<span id="tensorboard"></span><h3>Tensorboard Integration<a class="headerlink" href="#tensorboard-integration" title="Permalink to this heading"></a></h3>
<section id="basic-usage">
<h4>Basic Usage<a class="headerlink" href="#basic-usage" title="Permalink to this heading"></a></h4>
<p>To use Tensorboard with stable baselines3, you simply need to pass the location of the log folder to the RL agent:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">A2C</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">A2C</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tensorboard_log</span><span class="o">=</span><span class="s2">&quot;./a2c_cartpole_tensorboard/&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">10_000</span><span class="p">)</span>
</pre></div>
</div>
<p>You can also define custom logging name when training (by default it is the algorithm name)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">A2C</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">A2C</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tensorboard_log</span><span class="o">=</span><span class="s2">&quot;./a2c_cartpole_tensorboard/&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">10_000</span><span class="p">,</span> <span class="n">tb_log_name</span><span class="o">=</span><span class="s2">&quot;first_run&quot;</span><span class="p">)</span>
<span class="c1"># Pass reset_num_timesteps=False to continue the training curve in tensorboard</span>
<span class="c1"># By default, it will create a new curve</span>
<span class="c1"># Keep tb_log_name constant to have continuous curve (see note below)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">10_000</span><span class="p">,</span> <span class="n">tb_log_name</span><span class="o">=</span><span class="s2">&quot;second_run&quot;</span><span class="p">,</span> <span class="n">reset_num_timesteps</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">10_000</span><span class="p">,</span> <span class="n">tb_log_name</span><span class="o">=</span><span class="s2">&quot;third_run&quot;</span><span class="p">,</span> <span class="n">reset_num_timesteps</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you specify different <code class="docutils literal notranslate"><span class="pre">tb_log_name</span></code> in subsequent runs, you will have split graphs, like in the figure below.
If you want them to be continuous, you must keep the same <code class="docutils literal notranslate"><span class="pre">tb_log_name</span></code> (see <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/975#issuecomment-1198992211">issue #975</a>).
And, if you still managed to get your graphs split by other means, just put tensorboard log files into the same folder.</p>
<a class="reference internal image-reference" href="_images/split_graph.png"><img alt="split_graph" src="_images/split_graph.png" style="width: 330px;" /></a>
</div>
<p>Once the learn function is called, you can monitor the RL agent during or after the training, with the following bash command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tensorboard<span class="w"> </span>--logdir<span class="w"> </span>./a2c_cartpole_tensorboard/
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can find explanations about the logger output and names in the <a class="reference internal" href="index.html#logger"><span class="std std-ref">Logger</span></a> section.</p>
</div>
<p>you can also add past logging folders:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tensorboard<span class="w"> </span>--logdir<span class="w"> </span>./a2c_cartpole_tensorboard/<span class="p">;</span>./ppo2_cartpole_tensorboard/
</pre></div>
</div>
<p>It will display information such as the episode reward (when using a <code class="docutils literal notranslate"><span class="pre">Monitor</span></code> wrapper), the model losses and other parameter unique to some models.</p>
<a class="reference internal image-reference" href="_images/Tensorboard_example.png"><img alt="plotting" src="_images/Tensorboard_example.png" style="width: 600px;" /></a>
</section>
<section id="logging-more-values">
<h4>Logging More Values<a class="headerlink" href="#logging-more-values" title="Permalink to this heading"></a></h4>
<p>Using a callback, you can easily log more values with TensorBoard.
Here is a simple example on how to log both additional tensor or arbitrary scalar value:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">SAC</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">BaseCallback</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">tensorboard_log</span><span class="o">=</span><span class="s2">&quot;/tmp/sac/&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">TensorboardCallback</span><span class="p">(</span><span class="n">BaseCallback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Custom callback for plotting additional values in tensorboard.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">verbose</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_on_step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="c1"># Log scalar value (here a random variable)</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="s2">&quot;random_value&quot;</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">True</span>


<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">TensorboardCallback</span><span class="p">())</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you want to log values more often than the default to tensorboard, you manually call <code class="docutils literal notranslate"><span class="pre">self.logger.dump(self.num_timesteps)</span></code> in a callback
(see <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/506">issue #506</a>).</p>
</div>
</section>
<section id="logging-images">
<h4>Logging Images<a class="headerlink" href="#logging-images" title="Permalink to this heading"></a></h4>
<p>TensorBoard supports periodic logging of image data, which helps evaluating agents at various stages during training.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>To support image logging <a class="reference external" href="https://github.com/python-pillow/Pillow">pillow</a> must be installed otherwise, TensorBoard ignores the image and logs a warning.</p>
</div>
<p>Here is an example of how to render an image to TensorBoard at regular intervals:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">SAC</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">BaseCallback</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.logger</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">tensorboard_log</span><span class="o">=</span><span class="s2">&quot;/tmp/sac/&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ImageRecorderCallback</span><span class="p">(</span><span class="n">BaseCallback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">verbose</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_on_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">)</span>
        <span class="c1"># &quot;HWC&quot; specify the dataformat of the image, here channel last</span>
        <span class="c1"># (H for height, W for width, C for channel)</span>
        <span class="c1"># See https://pytorch.org/docs/stable/tensorboard.html</span>
        <span class="c1"># for supported formats</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="s2">&quot;trajectory/image&quot;</span><span class="p">,</span> <span class="n">Image</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="s2">&quot;HWC&quot;</span><span class="p">),</span> <span class="n">exclude</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;stdout&quot;</span><span class="p">,</span> <span class="s2">&quot;log&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">,</span> <span class="s2">&quot;csv&quot;</span><span class="p">))</span>
        <span class="k">return</span> <span class="kc">True</span>


<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">ImageRecorderCallback</span><span class="p">())</span>
</pre></div>
</div>
</section>
<section id="logging-figures-plots">
<h4>Logging Figures/Plots<a class="headerlink" href="#logging-figures-plots" title="Permalink to this heading"></a></h4>
<p>TensorBoard supports periodic logging of figures/plots created with matplotlib, which helps evaluate agents at various stages during training.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>To support figure logging <a class="reference external" href="https://matplotlib.org/">matplotlib</a> must be installed otherwise, TensorBoard ignores the figure and logs a warning.</p>
</div>
<p>Here is an example of how to store a plot in TensorBoard at regular intervals:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">SAC</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">BaseCallback</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.logger</span> <span class="kn">import</span> <span class="n">Figure</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">tensorboard_log</span><span class="o">=</span><span class="s2">&quot;/tmp/sac/&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">FigureRecorderCallback</span><span class="p">(</span><span class="n">BaseCallback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">verbose</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_on_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Plot values (here a random variable)</span>
        <span class="n">figure</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
        <span class="n">figure</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
        <span class="c1"># Close the figure after logging it</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">record</span><span class="p">(</span><span class="s2">&quot;trajectory/figure&quot;</span><span class="p">,</span> <span class="n">Figure</span><span class="p">(</span><span class="n">figure</span><span class="p">,</span> <span class="n">close</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">exclude</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;stdout&quot;</span><span class="p">,</span> <span class="s2">&quot;log&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">,</span> <span class="s2">&quot;csv&quot;</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="k">return</span> <span class="kc">True</span>


<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">FigureRecorderCallback</span><span class="p">())</span>
</pre></div>
</div>
</section>
<section id="logging-videos">
<h4>Logging Videos<a class="headerlink" href="#logging-videos" title="Permalink to this heading"></a></h4>
<p>TensorBoard supports periodic logging of video data, which helps evaluate agents at various stages during training.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>To support video logging <a class="reference external" href="https://zulko.github.io/moviepy/">moviepy</a> must be installed otherwise, TensorBoard ignores the video and logs a warning.</p>
</div>
<p>Here is an example of how to render an episode and log the resulting video to TensorBoard at regular intervals:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span>

<span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">A2C</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">BaseCallback</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.evaluation</span> <span class="kn">import</span> <span class="n">evaluate_policy</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.logger</span> <span class="kn">import</span> <span class="n">Video</span>


<span class="k">class</span> <span class="nc">VideoRecorderCallback</span><span class="p">(</span><span class="n">BaseCallback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eval_env</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">,</span> <span class="n">render_freq</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_eval_episodes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Records a video of an agent&#39;s trajectory traversing ``eval_env`` and logs it to TensorBoard</span>

<span class="sd">        :param eval_env: A gym environment from which the trajectory is recorded</span>
<span class="sd">        :param render_freq: Render the agent&#39;s trajectory every eval_freq call of the callback.</span>
<span class="sd">        :param n_eval_episodes: Number of episodes to render</span>
<span class="sd">        :param deterministic: Whether to use deterministic or stochastic policy</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_eval_env</span> <span class="o">=</span> <span class="n">eval_env</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_render_freq</span> <span class="o">=</span> <span class="n">render_freq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_eval_episodes</span> <span class="o">=</span> <span class="n">n_eval_episodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_deterministic</span> <span class="o">=</span> <span class="n">deterministic</span>

    <span class="k">def</span> <span class="nf">_on_step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_calls</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_render_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">screens</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">def</span> <span class="nf">grab_screens</span><span class="p">(</span><span class="n">_locals</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">_globals</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">                </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">                Renders the environment in its current state, recording the screen in the captured `screens` list</span>

<span class="sd">                :param _locals: A dictionary containing all local variables of the callback&#39;s scope</span>
<span class="sd">                :param _globals: A dictionary containing all global variables of the callback&#39;s scope</span>
<span class="sd">                &quot;&quot;&quot;</span>
                <span class="n">screen</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_eval_env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">)</span>
                <span class="c1"># PyTorch uses CxHxW vs HxWxC gym (and tensorflow) image convention</span>
                <span class="n">screens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">screen</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

            <span class="n">evaluate_policy</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_eval_env</span><span class="p">,</span>
                <span class="n">callback</span><span class="o">=</span><span class="n">grab_screens</span><span class="p">,</span>
                <span class="n">n_eval_episodes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_eval_episodes</span><span class="p">,</span>
                <span class="n">deterministic</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_deterministic</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">record</span><span class="p">(</span>
                <span class="s2">&quot;trajectory/video&quot;</span><span class="p">,</span>
                <span class="n">Video</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">ByteTensor</span><span class="p">([</span><span class="n">screens</span><span class="p">]),</span> <span class="n">fps</span><span class="o">=</span><span class="mi">40</span><span class="p">),</span>
                <span class="n">exclude</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;stdout&quot;</span><span class="p">,</span> <span class="s2">&quot;log&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">,</span> <span class="s2">&quot;csv&quot;</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="kc">True</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">A2C</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">tensorboard_log</span><span class="o">=</span><span class="s2">&quot;runs/&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">video_recorder</span> <span class="o">=</span> <span class="n">VideoRecorderCallback</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">),</span> <span class="n">render_freq</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">5e4</span><span class="p">),</span> <span class="n">callback</span><span class="o">=</span><span class="n">video_recorder</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="logging-hyperparameters">
<h4>Logging Hyperparameters<a class="headerlink" href="#logging-hyperparameters" title="Permalink to this heading"></a></h4>
<p>TensorBoard supports logging of hyperparameters in its HPARAMS tab, which helps to compare agents trainings.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>To display hyperparameters in the HPARAMS section, a <code class="docutils literal notranslate"><span class="pre">metric_dict</span></code> must be given (as well as a <code class="docutils literal notranslate"><span class="pre">hparam_dict</span></code>).</p>
</div>
<p>Here is an example of how to save hyperparameters in TensorBoard:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">A2C</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">BaseCallback</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.logger</span> <span class="kn">import</span> <span class="n">HParam</span>


<span class="k">class</span> <span class="nc">HParamCallback</span><span class="p">(</span><span class="n">BaseCallback</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Saves the hyperparameters and metrics at the start of the training, and logs them to TensorBoard.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_on_training_start</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">hparam_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;algorithm&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
            <span class="s2">&quot;learning rate&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="c1"># define the metrics that will appear in the `HPARAMS` Tensorboard tab by referencing their tag</span>
        <span class="c1"># Tensorbaord will find &amp; display metrics from the `SCALARS` tab</span>
        <span class="n">metric_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;rollout/ep_len_mean&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;train/value_loss&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">record</span><span class="p">(</span>
            <span class="s2">&quot;hparams&quot;</span><span class="p">,</span>
            <span class="n">HParam</span><span class="p">(</span><span class="n">hparam_dict</span><span class="p">,</span> <span class="n">metric_dict</span><span class="p">),</span>
            <span class="n">exclude</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;stdout&quot;</span><span class="p">,</span> <span class="s2">&quot;log&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">,</span> <span class="s2">&quot;csv&quot;</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_on_step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">A2C</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">tensorboard_log</span><span class="o">=</span><span class="s2">&quot;runs/&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">5e4</span><span class="p">),</span> <span class="n">callback</span><span class="o">=</span><span class="n">HParamCallback</span><span class="p">())</span>
</pre></div>
</div>
</section>
<section id="directly-accessing-the-summary-writer">
<h4>Directly Accessing The Summary Writer<a class="headerlink" href="#directly-accessing-the-summary-writer" title="Permalink to this heading"></a></h4>
<p>If you would like to log arbitrary data (in one of the formats supported by <a class="reference external" href="https://pytorch.org/docs/stable/tensorboard.html">pytorch</a>), you
can get direct access to the underlying SummaryWriter in a callback:</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This is method is not recommended and should only be used by advanced users.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you want a concrete example, you can watch <a class="reference external" href="https://www.youtube.com/watch?v=v8j2bpcE4Rg&amp;t=4619s">how to log lap time with donkeycar env</a>,
or read the code in the <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo/blob/feat/gym-donkeycar/rl_zoo3/callbacks.py#L251-L270">RL Zoo</a>.
You might also want to take a look at <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/1160">issue #1160</a> and <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/1219">issue #1219</a>.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">SAC</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.callbacks</span> <span class="kn">import</span> <span class="n">BaseCallback</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.logger</span> <span class="kn">import</span> <span class="n">TensorBoardOutputFormat</span>



<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">tensorboard_log</span><span class="o">=</span><span class="s2">&quot;/tmp/sac/&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">SummaryWriterCallback</span><span class="p">(</span><span class="n">BaseCallback</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">_on_training_start</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_log_freq</span> <span class="o">=</span> <span class="mi">1000</span>  <span class="c1"># log every 1000 calls</span>

        <span class="n">output_formats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">output_formats</span>
        <span class="c1"># Save reference to tensorboard formatter object</span>
        <span class="c1"># note: the failure case (not formatter found) is not handled here, should be done with try/except.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tb_formatter</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">formatter</span> <span class="k">for</span> <span class="n">formatter</span> <span class="ow">in</span> <span class="n">output_formats</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">formatter</span><span class="p">,</span> <span class="n">TensorBoardOutputFormat</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_on_step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_calls</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># You can have access to info from the env using self.locals.</span>
            <span class="c1"># for instance, when using one env (index 0 of locals[&quot;infos&quot;]):</span>
            <span class="c1"># lap_count = self.locals[&quot;infos&quot;][0][&quot;lap_count&quot;]</span>
            <span class="c1"># self.tb_formatter.writer.add_scalar(&quot;train/lap_count&quot;, lap_count, self.num_timesteps)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">tb_formatter</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">add_text</span><span class="p">(</span><span class="s2">&quot;direct_access&quot;</span><span class="p">,</span> <span class="s2">&quot;this is a value&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_timesteps</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tb_formatter</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>


<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="mi">50000</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">SummaryWriterCallback</span><span class="p">())</span>
</pre></div>
</div>
</section>
</section>
<span id="document-guide/integrations"></span><section id="integrations">
<span id="id1"></span><h3>Integrations<a class="headerlink" href="#integrations" title="Permalink to this heading"></a></h3>
<section id="weights-biases">
<h4>Weights &amp; Biases<a class="headerlink" href="#weights-biases" title="Permalink to this heading"></a></h4>
<p>Weights &amp; Biases provides a callback for experiment tracking that allows to visualize and share results.</p>
<p>The full documentation is available here: <a class="reference external" href="https://docs.wandb.ai/guides/integrations/other/stable-baselines-3">https://docs.wandb.ai/guides/integrations/other/stable-baselines-3</a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">wandb</span>
<span class="kn">from</span> <span class="nn">wandb.integration.sb3</span> <span class="kn">import</span> <span class="n">WandbCallback</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>

<span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;policy_type&quot;</span><span class="p">:</span> <span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span>
    <span class="s2">&quot;total_timesteps&quot;</span><span class="p">:</span> <span class="mi">25000</span><span class="p">,</span>
    <span class="s2">&quot;env_id&quot;</span><span class="p">:</span> <span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">run</span> <span class="o">=</span> <span class="n">wandb</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
    <span class="n">project</span><span class="o">=</span><span class="s2">&quot;sb3&quot;</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
    <span class="n">sync_tensorboard</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># auto-upload sb3&#39;s tensorboard metrics</span>
    <span class="c1"># monitor_gym=True,  # auto-upload the videos of agents playing the game</span>
    <span class="c1"># save_code=True,  # optional</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;policy_type&quot;</span><span class="p">],</span> <span class="n">config</span><span class="p">[</span><span class="s2">&quot;env_id&quot;</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tensorboard_log</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;runs/</span><span class="si">{</span><span class="n">run</span><span class="o">.</span><span class="n">id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span>
    <span class="n">total_timesteps</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;total_timesteps&quot;</span><span class="p">],</span>
    <span class="n">callback</span><span class="o">=</span><span class="n">WandbCallback</span><span class="p">(</span>
        <span class="n">model_save_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;models/</span><span class="si">{</span><span class="n">run</span><span class="o">.</span><span class="n">id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">)</span>
<span class="n">run</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="hugging-face">
<h4>Hugging Face 🤗<a class="headerlink" href="#hugging-face" title="Permalink to this heading"></a></h4>
<p>The Hugging Face Hub 🤗 is a central place where anyone can share and explore models. It allows you to host your saved models 💾.</p>
<p>You can see the list of stable-baselines3 saved models here: <a class="reference external" href="https://huggingface.co/models?library=stable-baselines3">https://huggingface.co/models?library=stable-baselines3</a>
Most of them are available via the RL Zoo.</p>
<p>Official pre-trained models are saved in the SB3 organization on the hub: <a class="reference external" href="https://huggingface.co/sb3">https://huggingface.co/sb3</a></p>
<p>We wrote a tutorial on how to use 🤗 Hub and Stable-Baselines3
<a class="reference external" href="https://colab.research.google.com/github/huggingface/huggingface_sb3/blob/main/notebooks/sb3_huggingface.ipynb">here</a>.</p>
<section id="installation">
<h5>Installation<a class="headerlink" href="#installation" title="Permalink to this heading"></a></h5>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>huggingface_sb3
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you use the <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">RL Zoo</a>, pushing/loading models from the hub are already integrated:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download model and save it into the logs/ folder</span>
python<span class="w"> </span>-m<span class="w"> </span>rl_zoo3.load_from_hub<span class="w"> </span>--algo<span class="w"> </span>a2c<span class="w"> </span>--env<span class="w"> </span>LunarLander-v2<span class="w"> </span>-orga<span class="w"> </span>sb3<span class="w"> </span>-f<span class="w"> </span>logs/
<span class="c1"># Test the agent</span>
python<span class="w"> </span>-m<span class="w"> </span>rl_zoo3.enjoy<span class="w"> </span>--algo<span class="w"> </span>a2c<span class="w"> </span>--env<span class="w"> </span>LunarLander-v2<span class="w">  </span>-f<span class="w"> </span>logs/
<span class="c1"># Push model, config and hyperparameters to the hub</span>
python<span class="w"> </span>-m<span class="w"> </span>rl_zoo3.push_to_hub<span class="w"> </span>--algo<span class="w"> </span>a2c<span class="w"> </span>--env<span class="w"> </span>LunarLander-v2<span class="w"> </span>-f<span class="w"> </span>logs/<span class="w"> </span>-orga<span class="w"> </span>sb3<span class="w"> </span>-m<span class="w"> </span><span class="s2">&quot;Initial commit&quot;</span>
</pre></div>
</div>
</div>
</section>
<section id="download-a-model-from-the-hub">
<h5>Download a model from the Hub<a class="headerlink" href="#download-a-model-from-the-hub" title="Permalink to this heading"></a></h5>
<p>You need to copy the repo-id that contains your saved model.
For instance <code class="docutils literal notranslate"><span class="pre">sb3/demo-hf-CartPole-v1</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>

<span class="kn">from</span> <span class="nn">huggingface_sb3</span> <span class="kn">import</span> <span class="n">load_from_hub</span>
<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.evaluation</span> <span class="kn">import</span> <span class="n">evaluate_policy</span>

<span class="c1"># Retrieve the model from the hub</span>
<span class="c1">## repo_id = id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name})</span>
<span class="c1">## filename = name of the model zip file from the repository</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">load_from_hub</span><span class="p">(</span>
    <span class="n">repo_id</span><span class="o">=</span><span class="s2">&quot;sb3/demo-hf-CartPole-v1&quot;</span><span class="p">,</span>
    <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;ppo-CartPole-v1.zip&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>

<span class="c1"># Evaluate the agent and watch it</span>
<span class="n">eval_env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">)</span>
<span class="n">mean_reward</span><span class="p">,</span> <span class="n">std_reward</span> <span class="o">=</span> <span class="n">evaluate_policy</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">eval_env</span><span class="p">,</span> <span class="n">render</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">n_eval_episodes</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">warn</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mean_reward=</span><span class="si">{</span><span class="n">mean_reward</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> +/- </span><span class="si">{</span><span class="n">std_reward</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>You need to define two parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">repo-id</span></code>: the name of the Hugging Face repo you want to download.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">filename</span></code>: the file you want to download.</p></li>
</ul>
</section>
<section id="upload-a-model-to-the-hub">
<h5>Upload a model to the Hub<a class="headerlink" href="#upload-a-model-to-the-hub" title="Permalink to this heading"></a></h5>
<p>You can easily upload your models using two different functions:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">package_to_hub()</span></code>: save the model, evaluate it, generate a model card and record a replay video of your agent before pushing the complete repo to the Hub.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">push_to_hub()</span></code>: simply push a file to the Hub.</p></li>
</ol>
<p>First, you need to be logged in to Hugging Face to upload a model:</p>
<ul class="simple">
<li><p>If you’re using Colab/Jupyter Notebooks:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">notebook_login</span>
<span class="n">notebook_login</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Otherwise:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>huggingface-cli<span class="w"> </span>login
</pre></div>
</div>
<p>Then, in this example, we train a PPO agent to play CartPole-v1 and push it to a new repo <code class="docutils literal notranslate"><span class="pre">sb3/demo-hf-CartPole-v1</span></code></p>
<section id="with-package-to-hub">
<h6>With <code class="docutils literal notranslate"><span class="pre">package_to_hub()</span></code><a class="headerlink" href="#with-package-to-hub" title="Permalink to this heading"></a></h6>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.env_util</span> <span class="kn">import</span> <span class="n">make_vec_env</span>

<span class="kn">from</span> <span class="nn">huggingface_sb3</span> <span class="kn">import</span> <span class="n">package_to_hub</span>

<span class="c1"># Create the environment</span>
<span class="n">env_id</span> <span class="o">=</span> <span class="s2">&quot;CartPole-v1&quot;</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">make_vec_env</span><span class="p">(</span><span class="n">env_id</span><span class="p">,</span> <span class="n">n_envs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Create the evaluation environment</span>
<span class="n">eval_env</span> <span class="o">=</span> <span class="n">make_vec_env</span><span class="p">(</span><span class="n">env_id</span><span class="p">,</span> <span class="n">n_envs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Instantiate the agent</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Train the agent</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mi">5000</span><span class="p">))</span>

<span class="c1"># This method save, evaluate, generate a model card and record a replay video of your agent before pushing the repo to the hub</span>
<span class="n">package_to_hub</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
             <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;ppo-CartPole-v1&quot;</span><span class="p">,</span>
             <span class="n">model_architecture</span><span class="o">=</span><span class="s2">&quot;PPO&quot;</span><span class="p">,</span>
             <span class="n">env_id</span><span class="o">=</span><span class="n">env_id</span><span class="p">,</span>
             <span class="n">eval_env</span><span class="o">=</span><span class="n">eval_env</span><span class="p">,</span>
             <span class="n">repo_id</span><span class="o">=</span><span class="s2">&quot;sb3/demo-hf-CartPole-v1&quot;</span><span class="p">,</span>
             <span class="n">commit_message</span><span class="o">=</span><span class="s2">&quot;Test commit&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>You need to define seven parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model</span></code>: your trained model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model_architecture</span></code>: name of the architecture of your model (DQN, PPO, A2C, SAC…).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">env_id</span></code>: name of the environment.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">eval_env</span></code>: environment used to evaluate the agent.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">repo-id</span></code>: the name of the Hugging Face repo you want to create or update. It’s &lt;your huggingface username&gt;/&lt;the repo name&gt;.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">commit-message</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">filename</span></code>: the file you want to push to the Hub.</p></li>
</ul>
</section>
<section id="with-push-to-hub">
<h6>With <code class="docutils literal notranslate"><span class="pre">push_to_hub()</span></code><a class="headerlink" href="#with-push-to-hub" title="Permalink to this heading"></a></h6>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.env_util</span> <span class="kn">import</span> <span class="n">make_vec_env</span>

<span class="kn">from</span> <span class="nn">huggingface_sb3</span> <span class="kn">import</span> <span class="n">push_to_hub</span>

<span class="c1"># Create the environment</span>
<span class="n">env_id</span> <span class="o">=</span> <span class="s2">&quot;CartPole-v1&quot;</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">make_vec_env</span><span class="p">(</span><span class="n">env_id</span><span class="p">,</span> <span class="n">n_envs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Instantiate the agent</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Train the agent</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mi">5000</span><span class="p">))</span>

<span class="c1"># Save the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;ppo-CartPole-v1&quot;</span><span class="p">)</span>

<span class="c1"># Push this saved model .zip file to the hf repo</span>
<span class="c1"># If this repo does not exists it will be created</span>
<span class="c1">## repo_id = id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name})</span>
<span class="c1">## filename: the name of the file == &quot;name&quot; inside model.save(&quot;ppo-CartPole-v1&quot;)</span>
<span class="n">push_to_hub</span><span class="p">(</span>
  <span class="n">repo_id</span><span class="o">=</span><span class="s2">&quot;sb3/demo-hf-CartPole-v1&quot;</span><span class="p">,</span>
  <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;ppo-CartPole-v1.zip&quot;</span><span class="p">,</span>
  <span class="n">commit_message</span><span class="o">=</span><span class="s2">&quot;Added CartPole-v1 model trained with PPO&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>You need to define three parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">repo-id</span></code>: the name of the Hugging Face repo you want to create or update. It’s &lt;your huggingface username&gt;/&lt;the repo name&gt;.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">filename</span></code>: the file you want to push to the Hub.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">commit-message</span></code>.</p></li>
</ul>
</section>
</section>
</section>
<section id="mlflow">
<h4>MLFLow<a class="headerlink" href="#mlflow" title="Permalink to this heading"></a></h4>
<p>If you want to use <a class="reference external" href="https://github.com/mlflow/mlflow">MLFLow</a> to track your SB3 experiments,
you can adapt the following code which defines a custom logger output:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">SAC</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.logger</span> <span class="kn">import</span> <span class="n">HumanOutputFormat</span><span class="p">,</span> <span class="n">KVWriter</span><span class="p">,</span> <span class="n">Logger</span>


<span class="k">class</span> <span class="nc">MLflowOutputFormat</span><span class="p">(</span><span class="n">KVWriter</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Dumps key/value pairs into MLflow&#39;s numeric format.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">write</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">key_values</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">key_excluded</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="o">...</span><span class="p">]]],</span>
        <span class="n">step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">),</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">excluded</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
            <span class="nb">sorted</span><span class="p">(</span><span class="n">key_values</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">key_excluded</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="p">):</span>

            <span class="k">if</span> <span class="n">excluded</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;mlflow&quot;</span> <span class="ow">in</span> <span class="n">excluded</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ScalarType</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>


<span class="n">loggers</span> <span class="o">=</span> <span class="n">Logger</span><span class="p">(</span>
    <span class="n">folder</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">output_formats</span><span class="o">=</span><span class="p">[</span><span class="n">HumanOutputFormat</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">),</span> <span class="n">MLflowOutputFormat</span><span class="p">()],</span>
<span class="p">)</span>

<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="c1"># Set custom logger</span>
    <span class="n">model</span><span class="o">.</span><span class="n">set_logger</span><span class="p">(</span><span class="n">loggers</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<span id="document-guide/rl_zoo"></span><section id="rl-baselines3-zoo">
<span id="rl-zoo"></span><h3>RL Baselines3 Zoo<a class="headerlink" href="#rl-baselines3-zoo" title="Permalink to this heading"></a></h3>
<p><a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">RL Baselines3 Zoo</a> is a training framework for Reinforcement Learning (RL).</p>
<p>It provides scripts for training, evaluating agents, tuning hyperparameters, plotting results and recording videos.</p>
<p>In addition, it includes a collection of tuned hyperparameters for common environments and RL algorithms, and agents trained with those settings.</p>
<p>Goals of this repository:</p>
<ol class="arabic simple">
<li><p>Provide a simple interface to train and enjoy RL agents</p></li>
<li><p>Benchmark the different Reinforcement Learning algorithms</p></li>
<li><p>Provide tuned hyperparameters for each environment and RL algorithm</p></li>
<li><p>Have fun with the trained agents!</p></li>
</ol>
<p>Documentation is available online: <a class="reference external" href="https://rl-baselines3-zoo.readthedocs.io/">https://rl-baselines3-zoo.readthedocs.io/</a></p>
<section id="installation">
<h4>Installation<a class="headerlink" href="#installation" title="Permalink to this heading"></a></h4>
<p>Option 1: install the python package <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">rl_zoo3</span></code></p>
<p>or:</p>
<ol class="arabic simple">
<li><p>Clone the repository:</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="o">--</span><span class="n">recursive</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">DLR</span><span class="o">-</span><span class="n">RM</span><span class="o">/</span><span class="n">rl</span><span class="o">-</span><span class="n">baselines3</span><span class="o">-</span><span class="n">zoo</span>
<span class="n">cd</span> <span class="n">rl</span><span class="o">-</span><span class="n">baselines3</span><span class="o">-</span><span class="n">zoo</span><span class="o">/</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can remove the <code class="docutils literal notranslate"><span class="pre">--recursive</span></code> option if you don’t want to download the trained agents</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you only need the training/plotting scripts and additional callbacks/wrappers from the RL Zoo, you can also install it via pip: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">rl_zoo3</span></code></p>
</div>
<p>2. Install dependencies</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="n">swig</span> <span class="n">cmake</span> <span class="n">ffmpeg</span>
<span class="c1"># full dependencies</span>
<span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">r</span> <span class="n">requirements</span><span class="o">.</span><span class="n">txt</span>
<span class="c1"># minimal dependencies</span>
<span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">e</span> <span class="o">.</span>
</pre></div>
</div>
</section>
<section id="train-an-agent">
<h4>Train an Agent<a class="headerlink" href="#train-an-agent" title="Permalink to this heading"></a></h4>
<p>The hyperparameters for each environment are defined in
<code class="docutils literal notranslate"><span class="pre">hyperparameters/algo_name.yml</span></code>.</p>
<p>If the environment exists in this file, then you can train an agent
using:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">rl_zoo3</span><span class="o">.</span><span class="n">train</span> <span class="o">--</span><span class="n">algo</span> <span class="n">algo_name</span> <span class="o">--</span><span class="n">env</span> <span class="n">env_id</span>
</pre></div>
</div>
<p>For example (with evaluation and checkpoints):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">rl_zoo3</span><span class="o">.</span><span class="n">train</span> <span class="o">--</span><span class="n">algo</span> <span class="n">ppo</span> <span class="o">--</span><span class="n">env</span> <span class="n">CartPole</span><span class="o">-</span><span class="n">v1</span> <span class="o">--</span><span class="nb">eval</span><span class="o">-</span><span class="n">freq</span> <span class="mi">10000</span> <span class="o">--</span><span class="n">save</span><span class="o">-</span><span class="n">freq</span> <span class="mi">50000</span>
</pre></div>
</div>
<p>Continue training (here, load pretrained agent for Breakout and continue
training for 5000 steps):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">rl_zoo3</span><span class="o">.</span><span class="n">train</span> <span class="o">--</span><span class="n">algo</span> <span class="n">a2c</span> <span class="o">--</span><span class="n">env</span> <span class="n">BreakoutNoFrameskip</span><span class="o">-</span><span class="n">v4</span> <span class="o">-</span><span class="n">i</span> <span class="n">trained_agents</span><span class="o">/</span><span class="n">a2c</span><span class="o">/</span><span class="n">BreakoutNoFrameskip</span><span class="o">-</span><span class="n">v4_1</span><span class="o">/</span><span class="n">BreakoutNoFrameskip</span><span class="o">-</span><span class="n">v4</span><span class="o">.</span><span class="n">zip</span> <span class="o">-</span><span class="n">n</span> <span class="mi">5000</span>
</pre></div>
</div>
</section>
<section id="enjoy-a-trained-agent">
<h4>Enjoy a Trained Agent<a class="headerlink" href="#enjoy-a-trained-agent" title="Permalink to this heading"></a></h4>
<p>If the trained agent exists, then you can see it in action using:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">rl_zoo3</span><span class="o">.</span><span class="n">enjoy</span> <span class="o">--</span><span class="n">algo</span> <span class="n">algo_name</span> <span class="o">--</span><span class="n">env</span> <span class="n">env_id</span>
</pre></div>
</div>
<p>For example, enjoy A2C on Breakout during 5000 timesteps:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">rl_zoo3</span><span class="o">.</span><span class="n">enjoy</span> <span class="o">--</span><span class="n">algo</span> <span class="n">a2c</span> <span class="o">--</span><span class="n">env</span> <span class="n">BreakoutNoFrameskip</span><span class="o">-</span><span class="n">v4</span> <span class="o">--</span><span class="n">folder</span> <span class="n">rl</span><span class="o">-</span><span class="n">trained</span><span class="o">-</span><span class="n">agents</span><span class="o">/</span> <span class="o">-</span><span class="n">n</span> <span class="mi">5000</span>
</pre></div>
</div>
</section>
<section id="hyperparameter-optimization">
<h4>Hyperparameter Optimization<a class="headerlink" href="#hyperparameter-optimization" title="Permalink to this heading"></a></h4>
<p>We use <a class="reference external" href="https://optuna.org/">Optuna</a> for optimizing the hyperparameters.</p>
<p>Tune the hyperparameters for PPO, using a random sampler and median pruner, 2 parallels jobs,
with a budget of 1000 trials and a maximum of 50000 steps:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">rl_zoo3</span><span class="o">.</span><span class="n">train</span> <span class="o">--</span><span class="n">algo</span> <span class="n">ppo</span> <span class="o">--</span><span class="n">env</span> <span class="n">MountainCar</span><span class="o">-</span><span class="n">v0</span> <span class="o">-</span><span class="n">n</span> <span class="mi">50000</span> <span class="o">-</span><span class="n">optimize</span> <span class="o">--</span><span class="n">n</span><span class="o">-</span><span class="n">trials</span> <span class="mi">1000</span> <span class="o">--</span><span class="n">n</span><span class="o">-</span><span class="n">jobs</span> <span class="mi">2</span> \
  <span class="o">--</span><span class="n">sampler</span> <span class="n">random</span> <span class="o">--</span><span class="n">pruner</span> <span class="n">median</span>
</pre></div>
</div>
</section>
<section id="colab-notebook-try-it-online">
<h4>Colab Notebook: Try it Online!<a class="headerlink" href="#colab-notebook-try-it-online" title="Permalink to this heading"></a></h4>
<p>You can train agents online using Google <a class="reference external" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/rl-baselines-zoo.ipynb">colab notebook</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can find more information about the rl baselines3 zoo in the repo <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">README</a>. For instance, how to record a video of a trained agent.</p>
</div>
</section>
</section>
<span id="document-guide/sb3_contrib"></span><section id="sb3-contrib">
<span id="id1"></span><h3>SB3 Contrib<a class="headerlink" href="#sb3-contrib" title="Permalink to this heading"></a></h3>
<p>We implement experimental features in a separate contrib repository:
<a class="reference external" href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib">SB3-Contrib</a></p>
<p>This allows Stable-Baselines3 (SB3) to maintain a stable and compact core, while still
providing the latest features, like RecurrentPPO (PPO LSTM), Truncated Quantile Critics (TQC), Augmented Random Search (ARS), Trust Region Policy Optimization (TRPO) or
Quantile Regression DQN (QR-DQN).</p>
<section id="why-create-this-repository">
<h4>Why create this repository?<a class="headerlink" href="#why-create-this-repository" title="Permalink to this heading"></a></h4>
<p>Over the span of stable-baselines and stable-baselines3, the community
has been eager to contribute in form of better logging utilities,
environment wrappers, extended support (e.g. different action spaces)
and learning algorithms.</p>
<p>However sometimes these utilities were too niche to be considered for
stable-baselines or proved to be too difficult to integrate well into
the existing code without creating a mess. sb3-contrib aims to fix this by not
requiring the neatest code integration with existing code and not
setting limits on what is too niche: almost everything remotely useful
goes!
We hope this allows us to provide reliable implementations
following stable-baselines usual standards (consistent style, documentation, etc)
beyond the relatively small scope of utilities in the main repository.</p>
<section id="features">
<h5>Features<a class="headerlink" href="#features" title="Permalink to this heading"></a></h5>
<p>See documentation for the full list of included features.</p>
<p><strong>RL Algorithms</strong>:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1803.07055">Augmented Random Search (ARS)</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1710.10044">Quantile Regression DQN (QR-DQN)</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2006.14171">PPO with invalid action masking (Maskable PPO)</a></p></li>
<li><p><a class="reference external" href="https://ppo-details.cleanrl.dev//2021/11/05/ppo-implementation-details/">PPO with recurrent policy (RecurrentPPO aka PPO LSTM)</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2005.04269">Truncated Quantile Critics (TQC)</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1502.05477">Trust Region Policy Optimization (TRPO)</a></p></li>
</ul>
<p><strong>Gym Wrappers</strong>:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1712.00378">Time Feature Wrapper</a></p></li>
</ul>
</section>
<section id="documentation">
<h5>Documentation<a class="headerlink" href="#documentation" title="Permalink to this heading"></a></h5>
<p>Documentation is available online: <a class="reference external" href="https://sb3-contrib.readthedocs.io/">https://sb3-contrib.readthedocs.io/</a></p>
</section>
<section id="installation">
<h5>Installation<a class="headerlink" href="#installation" title="Permalink to this heading"></a></h5>
<p>To install Stable-Baselines3 contrib with pip, execute:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">sb3</span><span class="o">-</span><span class="n">contrib</span>
</pre></div>
</div>
<p>We recommend to use the <code class="docutils literal notranslate"><span class="pre">master</span></code> version of Stable Baselines3 and SB3-Contrib.</p>
<p>To install Stable Baselines3 <code class="docutils literal notranslate"><span class="pre">master</span></code> version:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">git</span><span class="o">+</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">DLR</span><span class="o">-</span><span class="n">RM</span><span class="o">/</span><span class="n">stable</span><span class="o">-</span><span class="n">baselines3</span>
</pre></div>
</div>
<p>To install Stable Baselines3 contrib <code class="docutils literal notranslate"><span class="pre">master</span></code> version:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">git</span><span class="o">+</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">Stable</span><span class="o">-</span><span class="n">Baselines</span><span class="o">-</span><span class="n">Team</span><span class="o">/</span><span class="n">stable</span><span class="o">-</span><span class="n">baselines3</span><span class="o">-</span><span class="n">contrib</span>
</pre></div>
</div>
</section>
<section id="example">
<h5>Example<a class="headerlink" href="#example" title="Permalink to this heading"></a></h5>
<p>SB3-Contrib follows the SB3 API and folder structure. So, if you are familiar with SB3,
using SB3-Contrib should be easy too.</p>
<p>Here is an example of training a Quantile Regression DQN (QR-DQN) agent on the CartPole environment.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sb3_contrib</span> <span class="kn">import</span> <span class="n">QRDQN</span>

<span class="n">policy_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_quantiles</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">QRDQN</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">policy_kwargs</span><span class="o">=</span><span class="n">policy_kwargs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;qrdqn_cartpole&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>
<span id="document-guide/sbx"></span><section id="stable-baselines-jax-sbx">
<span id="sbx"></span><h3>Stable Baselines Jax (SBX)<a class="headerlink" href="#stable-baselines-jax-sbx" title="Permalink to this heading"></a></h3>
<p><a class="reference external" href="https://github.com/araffin/sbx">Stable Baselines Jax (SBX)</a> is a proof of concept version of Stable-Baselines3 in Jax.</p>
<p>It provides a minimal number of features compared to SB3 but can be much faster (up to 20x times!): <a class="reference external" href="https://twitter.com/araffin2/status/1590714558628253698">https://twitter.com/araffin2/status/1590714558628253698</a></p>
<p>Implemented algorithms:</p>
<ul class="simple">
<li><p>Soft Actor-Critic (SAC) and SAC-N</p></li>
<li><p>Truncated Quantile Critics (TQC)</p></li>
<li><p>Dropout Q-Functions for Doubly Efficient Reinforcement Learning (DroQ)</p></li>
<li><p>Proximal Policy Optimization (PPO)</p></li>
<li><p>Deep Q Network (DQN)</p></li>
<li><p>Twin Delayed DDPG (TD3)</p></li>
<li><p>Deep Deterministic Policy Gradient (DDPG)</p></li>
</ul>
<p>As SBX follows SB3 API, it is also compatible with the <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">RL Zoo</a>.
For that you will need to create two files:</p>
<p><code class="docutils literal notranslate"><span class="pre">train_sbx.py</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">rl_zoo3</span>
<span class="kn">import</span> <span class="nn">rl_zoo3.train</span>
<span class="kn">from</span> <span class="nn">rl_zoo3.train</span> <span class="kn">import</span> <span class="n">train</span>

<span class="kn">from</span> <span class="nn">sbx</span> <span class="kn">import</span> <span class="n">DDPG</span><span class="p">,</span> <span class="n">DQN</span><span class="p">,</span> <span class="n">PPO</span><span class="p">,</span> <span class="n">SAC</span><span class="p">,</span> <span class="n">TD3</span><span class="p">,</span> <span class="n">TQC</span><span class="p">,</span> <span class="n">DroQ</span>

<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span><span class="p">[</span><span class="s2">&quot;ddpg&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">DDPG</span>
<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span><span class="p">[</span><span class="s2">&quot;dqn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">DQN</span>
<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span><span class="p">[</span><span class="s2">&quot;droq&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">DroQ</span>
<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span><span class="p">[</span><span class="s2">&quot;sac&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">SAC</span>
<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span><span class="p">[</span><span class="s2">&quot;ppo&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">PPO</span>
<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span><span class="p">[</span><span class="s2">&quot;td3&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">TD3</span>
<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span><span class="p">[</span><span class="s2">&quot;tqc&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">TQC</span>
<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">ALGOS</span> <span class="o">=</span> <span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span>
<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">ALGOS</span> <span class="o">=</span> <span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<p>Then you can call <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">train_sbx.py</span> <span class="pre">--algo</span> <span class="pre">sac</span> <span class="pre">--env</span> <span class="pre">Pendulum-v1</span></code> and use the RL Zoo CLI.</p>
<p><code class="docutils literal notranslate"><span class="pre">enjoy_sbx.py</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">rl_zoo3</span>
<span class="kn">import</span> <span class="nn">rl_zoo3.enjoy</span>
<span class="kn">from</span> <span class="nn">rl_zoo3.enjoy</span> <span class="kn">import</span> <span class="n">enjoy</span>

<span class="kn">from</span> <span class="nn">sbx</span> <span class="kn">import</span> <span class="n">DDPG</span><span class="p">,</span> <span class="n">DQN</span><span class="p">,</span> <span class="n">PPO</span><span class="p">,</span> <span class="n">SAC</span><span class="p">,</span> <span class="n">TD3</span><span class="p">,</span> <span class="n">TQC</span><span class="p">,</span> <span class="n">DroQ</span>

<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span><span class="p">[</span><span class="s2">&quot;ddpg&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">DDPG</span>
<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span><span class="p">[</span><span class="s2">&quot;dqn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">DQN</span>
<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span><span class="p">[</span><span class="s2">&quot;droq&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">DroQ</span>
<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span><span class="p">[</span><span class="s2">&quot;sac&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">SAC</span>
<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span><span class="p">[</span><span class="s2">&quot;ppo&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">PPO</span>
<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span><span class="p">[</span><span class="s2">&quot;td3&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">TD3</span>
<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span><span class="p">[</span><span class="s2">&quot;tqc&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">TQC</span>
<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">enjoy</span><span class="o">.</span><span class="n">ALGOS</span> <span class="o">=</span> <span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span>
<span class="n">rl_zoo3</span><span class="o">.</span><span class="n">exp_manager</span><span class="o">.</span><span class="n">ALGOS</span> <span class="o">=</span> <span class="n">rl_zoo3</span><span class="o">.</span><span class="n">ALGOS</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">enjoy</span><span class="p">()</span>
</pre></div>
</div>
</section>
<span id="document-guide/imitation"></span><section id="imitation-learning">
<span id="imitation"></span><h3>Imitation Learning<a class="headerlink" href="#imitation-learning" title="Permalink to this heading"></a></h3>
<p>The <a class="reference external" href="https://github.com/HumanCompatibleAI/imitation">imitation</a> library implements
imitation learning algorithms on top of Stable-Baselines3, including:</p>
<blockquote>
<div><ul class="simple">
<li><p>Behavioral Cloning</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1011.0686">DAgger</a> with synthetic examples</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1710.11248">Adversarial Inverse Reinforcement Learning</a> (AIRL)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1606.03476">Generative Adversarial Imitation Learning</a>  (GAIL)</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1706.03741">Deep RL from Human Preferences</a> (DRLHP)</p></li>
</ul>
</div></blockquote>
<p>You can install imitation with <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">imitation</span></code>. The <a class="reference external" href="https://imitation.readthedocs.io/en/latest/">imitation
documentation</a> has more details
on how to use the library, including <a class="reference external" href="https://imitation.readthedocs.io/en/latest/getting-started/first-steps.html">a quick start guide</a>
for the impatient.</p>
</section>
<span id="document-guide/migration"></span><section id="migrating-from-stable-baselines">
<span id="migration"></span><h3>Migrating from Stable-Baselines<a class="headerlink" href="#migrating-from-stable-baselines" title="Permalink to this heading"></a></h3>
<p>This is a guide to migrate from Stable-Baselines (SB2) to Stable-Baselines3 (SB3).</p>
<p>It also references the main changes.</p>
<section id="overview">
<h4>Overview<a class="headerlink" href="#overview" title="Permalink to this heading"></a></h4>
<p>Overall Stable-Baselines3 (SB3) keeps the high-level API of Stable-Baselines (SB2).
Most of the changes are to ensure more consistency and are internal ones.
Because of the backend change, from Tensorflow to PyTorch, the internal code is much more readable and easy to debug
at the cost of some speed (dynamic graph vs static graph., see <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/90">Issue #90</a>)
However, the algorithms were extensively benchmarked on Atari games and continuous control PyBullet envs
(see <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/48">Issue #48</a>  and <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/49">Issue #49</a>)
so you should not expect performance drop when switching from SB2 to SB3.</p>
</section>
<section id="how-to-migrate">
<h4>How to migrate?<a class="headerlink" href="#how-to-migrate" title="Permalink to this heading"></a></h4>
<p>In most cases, replacing <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">stable_baselines</span></code> by <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">stable_baselines3</span></code> will be sufficient.
Some files were moved to the common folder (cf below) and could result to import errors.
Some algorithms were removed because of their complexity to improve the maintainability of the project.
We recommend reading this guide carefully to understand all the changes that were made.
You can also take a look at the <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">rl-zoo3</a> and compare the imports
to the <a class="reference external" href="https://github.com/araffin/rl-baselines-zoo">rl-zoo</a> of SB2 to have a concrete example of successful migration.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you experience massive slow-down switching to PyTorch, you may need to play with the number of threads used,
using <code class="docutils literal notranslate"><span class="pre">torch.set_num_threads(1)</span></code> or <code class="docutils literal notranslate"><span class="pre">OMP_NUM_THREADS=1</span></code>, see <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/122">issue #122</a>
and <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/90">issue #90</a>.</p>
</div>
</section>
<section id="breaking-changes">
<h4>Breaking Changes<a class="headerlink" href="#breaking-changes" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>SB3 requires python 3.7+ (instead of python 3.5+ for SB2)</p></li>
<li><p>Dropped MPI support</p></li>
<li><p>Dropped layer normalized policies (<code class="docutils literal notranslate"><span class="pre">MlpLnLstmPolicy</span></code>, <code class="docutils literal notranslate"><span class="pre">CnnLnLstmPolicy</span></code>)</p></li>
<li><p>LSTM policies (<code class="docutils literal notranslate"><span class="pre">`MlpLstmPolicy`</span></code>, <code class="docutils literal notranslate"><span class="pre">`CnnLstmPolicy`</span></code>) are not supported for the time being
(see <a class="reference external" href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib/pull/53">PR #53</a> for a recurrent PPO implementation)</p></li>
<li><p>Dropped parameter noise for DDPG and DQN</p></li>
<li><p>PPO is now closer to the original implementation (no clipping of the value function by default), cf PPO section below</p></li>
<li><p>Orthogonal initialization is only used by A2C/PPO</p></li>
<li><p>The features extractor (CNN extractor) is shared between policy and q-networks for DDPG/SAC/TD3 and only the policy loss used to update it (much faster)</p></li>
<li><p>Tensorboard legacy logging was dropped in favor of having one logger for the terminal and Tensorboard (cf <a class="reference internal" href="index.html#tensorboard"><span class="std std-ref">Tensorboard integration</span></a>)</p></li>
<li><p>We dropped ACKTR/ACER support because of their complexity compared to simpler alternatives (PPO, SAC, TD3) performing as good.</p></li>
<li><p>We dropped GAIL support as we are focusing on model-free RL only, you can however take a look at the <a class="reference internal" href="index.html#imitation"><span class="std std-ref">imitation project</span></a> which implements
GAIL and other imitation learning algorithms on top of SB3.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">action_probability</span></code> is currently not implemented in the base class</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pretrain()</span></code> method for behavior cloning was removed (see <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/27">issue #27</a>)</p></li>
</ul>
<p>You can take a look at the <a class="reference external" href="https://github.com/hill-a/stable-baselines/issues/576">issue about SB3 implementation design</a> for more details.</p>
<section id="moved-files">
<h5>Moved Files<a class="headerlink" href="#moved-files" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">bench/monitor.py</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">common/monitor.py</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">logger.py</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">common/logger.py</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">results_plotter.py</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">common/results_plotter.py</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">common/cmd_util.py</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">common/env_util.py</span></code></p></li>
</ul>
<p>Utility functions are no longer exported from <code class="docutils literal notranslate"><span class="pre">common</span></code> module, you should import them with their absolute path, e.g.:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3.common.env_util</span> <span class="kn">import</span> <span class="n">make_atari_env</span><span class="p">,</span> <span class="n">make_vec_env</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.utils</span> <span class="kn">import</span> <span class="n">set_random_seed</span>
</pre></div>
</div>
<p>instead of <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">stable_baselines3.common</span> <span class="pre">import</span> <span class="pre">make_atari_env</span></code></p>
</section>
<section id="changes-and-renaming-in-parameters">
<h5>Changes and renaming in parameters<a class="headerlink" href="#changes-and-renaming-in-parameters" title="Permalink to this heading"></a></h5>
<section id="base-class-all-algorithms">
<h6>Base-class (all algorithms)<a class="headerlink" href="#base-class-all-algorithms" title="Permalink to this heading"></a></h6>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">load_parameters</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">set_parameters</span></code></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">get/set_parameters</span></code> return a dictionary mapping object names
to their respective PyTorch tensors and other objects representing
their parameters, instead of simpler mapping of parameter name to
a NumPy array. These functions also return PyTorch tensors rather
than NumPy arrays.</p></li>
</ul>
</li>
</ul>
</section>
<section id="policies">
<h6>Policies<a class="headerlink" href="#policies" title="Permalink to this heading"></a></h6>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cnn_extractor</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">features_extractor</span></code>, as <code class="docutils literal notranslate"><span class="pre">features_extractor</span></code> in now used with <code class="docutils literal notranslate"><span class="pre">MlpPolicy</span></code> too</p></li>
</ul>
</section>
<section id="a2c">
<h6>A2C<a class="headerlink" href="#a2c" title="Permalink to this heading"></a></h6>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">epsilon</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">rms_prop_eps</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lr_schedule</span></code> is part of <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> (it can be a callable).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">alpha</span></code>, <code class="docutils literal notranslate"><span class="pre">momentum</span></code> are modifiable through <code class="docutils literal notranslate"><span class="pre">policy_kwargs</span></code> key <code class="docutils literal notranslate"><span class="pre">optimizer_kwargs</span></code>.</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>PyTorch implementation of RMSprop <a class="reference external" href="https://github.com/pytorch/pytorch/issues/23796">differs from Tensorflow’s</a>,
which leads to <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/pull/110#issuecomment-663255241">different and potentially more unstable results</a>.
Use <code class="docutils literal notranslate"><span class="pre">stable_baselines3.common.sb2_compat.rmsprop_tf_like.RMSpropTFLike</span></code> optimizer to match the results
with TensorFlow’s implementation. This can be done through <code class="docutils literal notranslate"><span class="pre">policy_kwargs</span></code>: <code class="docutils literal notranslate"><span class="pre">A2C(policy_kwargs=dict(optimizer_class=RMSpropTFLike,</span> <span class="pre">optimizer_kwargs=dict(eps=1e-5)))</span></code></p>
</div>
</section>
<section id="ppo">
<h6>PPO<a class="headerlink" href="#ppo" title="Permalink to this heading"></a></h6>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cliprange</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">clip_range</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cliprange_vf</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">clip_range_vf</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nminibatches</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">batch_size</span></code></p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p><code class="docutils literal notranslate"><span class="pre">nminibatches</span></code> gave different batch size depending on the number of environments:  <code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">=</span> <span class="pre">(n_steps</span> <span class="pre">*</span> <span class="pre">n_envs)</span> <span class="pre">//</span> <span class="pre">nminibatches</span></code></p>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">clip_range_vf</span></code> behavior for PPO is slightly different: Set it to <code class="docutils literal notranslate"><span class="pre">None</span></code> (default) to deactivate clipping (in SB2, you had to pass <code class="docutils literal notranslate"><span class="pre">-1</span></code>, <code class="docutils literal notranslate"><span class="pre">None</span></code> meant to use <code class="docutils literal notranslate"><span class="pre">clip_range</span></code> for the clipping)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lam</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">gae_lambda</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">noptepochs</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">n_epochs</span></code></p></li>
</ul>
<p>PPO default hyperparameters are the one tuned for continuous control environment.
We recommend taking a look at the <a class="reference internal" href="index.html#rl-zoo"><span class="std std-ref">RL Zoo</span></a> for hyperparameters tuned for Atari games.</p>
</section>
<section id="dqn">
<h6>DQN<a class="headerlink" href="#dqn" title="Permalink to this heading"></a></h6>
<p>Only the vanilla DQN is implemented right now but extensions will follow.
Default hyperparameters are taken from the Nature paper, except for the optimizer and learning rate that were taken from Stable Baselines defaults.</p>
</section>
<section id="ddpg">
<h6>DDPG<a class="headerlink" href="#ddpg" title="Permalink to this heading"></a></h6>
<p>DDPG now follows the same interface as SAC/TD3.
For state/reward normalization, you should use <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> as for all other algorithms.</p>
</section>
<section id="sac-td3">
<h6>SAC/TD3<a class="headerlink" href="#sac-td3" title="Permalink to this heading"></a></h6>
<p>SAC/TD3 now accept any number of critics, e.g. <code class="docutils literal notranslate"><span class="pre">policy_kwargs=dict(n_critics=3)</span></code>, instead of only two before.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>SAC/TD3 default hyperparameters (including network architecture) now match the ones from the original papers.
DDPG is using TD3 defaults.</p>
</div>
</section>
<section id="sac">
<h6>SAC<a class="headerlink" href="#sac" title="Permalink to this heading"></a></h6>
<p>SAC implementation matches the latest version of the original implementation: it uses two Q function networks and two target Q function networks
instead of two Q function networks and one Value function network (SB2 implementation, first version of the original implementation).
Despite this change, no change in performance should be expected.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>SAC <code class="docutils literal notranslate"><span class="pre">predict()</span></code> method has now <code class="docutils literal notranslate"><span class="pre">deterministic=False</span></code> by default for consistency.
To match SB2 behavior, you need to explicitly pass <code class="docutils literal notranslate"><span class="pre">deterministic=True</span></code></p>
</div>
</section>
<section id="her">
<h6>HER<a class="headerlink" href="#her" title="Permalink to this heading"></a></h6>
<p>The <code class="docutils literal notranslate"><span class="pre">HER</span></code> implementation now only supports online sampling of the new goals. This is done in a vectorized version.
The goal selection strategy <code class="docutils literal notranslate"><span class="pre">RANDOM</span></code> is no longer supported.</p>
</section>
</section>
<section id="new-logger-api">
<h5>New logger API<a class="headerlink" href="#new-logger-api" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Methods were renamed in the logger:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">logkv</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">record</span></code>, <code class="docutils literal notranslate"><span class="pre">writekvs</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">write</span></code>, <code class="docutils literal notranslate"><span class="pre">writeseq</span></code> -&gt;  <code class="docutils literal notranslate"><span class="pre">write_sequence</span></code>,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">logkvs</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">record_dict</span></code>, <code class="docutils literal notranslate"><span class="pre">dumpkvs</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">dump</span></code>,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">getkvs</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">get_log_dict</span></code>, <code class="docutils literal notranslate"><span class="pre">logkv_mean</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">record_mean</span></code>,</p></li>
</ul>
</li>
</ul>
</section>
<section id="internal-changes">
<h5>Internal Changes<a class="headerlink" href="#internal-changes" title="Permalink to this heading"></a></h5>
<p>Please read the <a class="reference internal" href="index.html#developer"><span class="std std-ref">Developer Guide</span></a> section.</p>
</section>
</section>
<section id="new-features-sb3-vs-sb2">
<h4>New Features (SB3 vs SB2)<a class="headerlink" href="#new-features-sb3-vs-sb2" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Much cleaner and consistent base code (and no more warnings =D!) and static type checks</p></li>
<li><p>Independent saving/loading/predict for policies</p></li>
<li><p>A2C now supports Generalized Advantage Estimation (GAE) and advantage normalization (both are deactivated by default)</p></li>
<li><p>Generalized State-Dependent Exploration (gSDE) exploration is available for A2C/PPO/SAC. It allows using RL directly on real robots (cf <a class="reference external" href="https://arxiv.org/abs/2005.05719">https://arxiv.org/abs/2005.05719</a>)</p></li>
<li><p>Better saving/loading: optimizers are now included in the saved parameters and there are two new methods <code class="docutils literal notranslate"><span class="pre">save_replay_buffer</span></code> and <code class="docutils literal notranslate"><span class="pre">load_replay_buffer</span></code> for the replay buffer when using off-policy algorithms (DQN/DDPG/SAC/TD3)</p></li>
<li><p>You can pass <code class="docutils literal notranslate"><span class="pre">optimizer_class</span></code> and <code class="docutils literal notranslate"><span class="pre">optimizer_kwargs</span></code> to <code class="docutils literal notranslate"><span class="pre">policy_kwargs</span></code> in order to easily
customize optimizers</p></li>
<li><p>Seeding now works properly to have deterministic results</p></li>
<li><p>Replay buffer does not grow, allocate everything at build time (faster)</p></li>
<li><p>We added a memory efficient replay buffer variant (pass <code class="docutils literal notranslate"><span class="pre">optimize_memory_usage=True</span></code> to the constructor), it reduces drastically the memory used especially when using images</p></li>
<li><p>You can specify an arbitrary number of critics for SAC/TD3 (e.g. <code class="docutils literal notranslate"><span class="pre">policy_kwargs=dict(n_critics=3)</span></code>)</p></li>
</ul>
</section>
</section>
<span id="document-guide/checking_nan"></span><section id="dealing-with-nans-and-infs">
<h3>Dealing with NaNs and infs<a class="headerlink" href="#dealing-with-nans-and-infs" title="Permalink to this heading"></a></h3>
<p>During the training of a model on a given environment, it is possible that the RL model becomes completely
corrupted when a NaN or an inf is given or returned from the RL model.</p>
<section id="how-and-why">
<h4>How and why?<a class="headerlink" href="#how-and-why" title="Permalink to this heading"></a></h4>
<p>The issue arises when NaNs or infs do not crash, but simply get propagated through the training,
until all the floating point number converge to NaN or inf. This is in line with the
<a class="reference external" href="https://ieeexplore.ieee.org/document/4610935">IEEE Standard for Floating-Point Arithmetic (IEEE 754)</a> standard, as it says:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<dl class="simple">
<dt>Five possible exceptions can occur:</dt><dd><ul class="simple">
<li><p>Invalid operation (<span class="math notranslate nohighlight">\(\sqrt{-1}\)</span>, <span class="math notranslate nohighlight">\(\inf \times 1\)</span>, <span class="math notranslate nohighlight">\(\text{NaN}\ \mathrm{mod}\ 1\)</span>, …) return NaN</p></li>
<li><dl class="simple">
<dt>Division by zero:</dt><dd><ul>
<li><p>if the operand is not zero (<span class="math notranslate nohighlight">\(1/0\)</span>, <span class="math notranslate nohighlight">\(-2/0\)</span>, …) returns <span class="math notranslate nohighlight">\(\pm\inf\)</span></p></li>
<li><p>if the operand is zero (<span class="math notranslate nohighlight">\(0/0\)</span>) returns signaling NaN</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Overflow (exponent too high to represent) returns <span class="math notranslate nohighlight">\(\pm\inf\)</span></p></li>
<li><p>Underflow (exponent too low to represent) returns <span class="math notranslate nohighlight">\(0\)</span></p></li>
<li><p>Inexact (not representable exactly in base 2, eg: <span class="math notranslate nohighlight">\(1/5\)</span>) returns the rounded value (ex: <code class="code docutils literal notranslate"><span class="pre">assert</span> <span class="pre">(1/5)</span> <span class="pre">*</span> <span class="pre">3</span> <span class="pre">==</span> <span class="pre">0.6000000000000001</span></code>)</p></li>
</ul>
</dd>
</dl>
</div>
<p>And of these, only <code class="docutils literal notranslate"><span class="pre">Division</span> <span class="pre">by</span> <span class="pre">zero</span></code> will signal an exception, the rest will propagate invalid values quietly.</p>
<p>In python, dividing by zero will indeed raise the exception: <code class="docutils literal notranslate"><span class="pre">ZeroDivisionError:</span> <span class="pre">float</span> <span class="pre">division</span> <span class="pre">by</span> <span class="pre">zero</span></code>,
but ignores the rest.</p>
<p>The default in numpy, will warn: <code class="docutils literal notranslate"><span class="pre">RuntimeWarning:</span> <span class="pre">invalid</span> <span class="pre">value</span> <span class="pre">encountered</span></code>
but will not halt the code.</p>
</section>
<section id="anomaly-detection-with-pytorch">
<h4>Anomaly detection with PyTorch<a class="headerlink" href="#anomaly-detection-with-pytorch" title="Permalink to this heading"></a></h4>
<p>To enable NaN detection in PyTorch you can do</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="n">th</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">set_detect_anomaly</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="numpy-parameters">
<h4>Numpy parameters<a class="headerlink" href="#numpy-parameters" title="Permalink to this heading"></a></h4>
<p>Numpy has a convenient way of dealing with invalid value: <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.seterr.html">numpy.seterr</a>,
which defines for the python process, how it should handle floating point error.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">seterr</span><span class="p">(</span><span class="nb">all</span><span class="o">=</span><span class="s2">&quot;raise&quot;</span><span class="p">)</span>  <span class="c1"># define before your code.</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;numpy test:&quot;</span><span class="p">)</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">a</span> <span class="o">/</span> <span class="n">b</span>  <span class="c1"># this will now raise an exception instead of a warning.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
</pre></div>
</div>
<p>but this will also avoid overflow issues on floating point numbers:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">seterr</span><span class="p">(</span><span class="nb">all</span><span class="o">=</span><span class="s2">&quot;raise&quot;</span><span class="p">)</span>  <span class="c1"># define before your code.</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;numpy overflow test:&quot;</span><span class="p">)</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">a</span> <span class="o">**</span> <span class="n">b</span>  <span class="c1"># this will now raise an exception</span>
<span class="nb">print</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
</pre></div>
</div>
<p>but will not avoid the propagation issues:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">seterr</span><span class="p">(</span><span class="nb">all</span><span class="o">=</span><span class="s2">&quot;raise&quot;</span><span class="p">)</span>  <span class="c1"># define before your code.</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;numpy propagation test:&quot;</span><span class="p">)</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="s2">&quot;NaN&quot;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">val</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>  <span class="c1"># this will neither warn nor raise anything</span>
<span class="nb">print</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="vecchecknan-wrapper">
<h4>VecCheckNan Wrapper<a class="headerlink" href="#vecchecknan-wrapper" title="Permalink to this heading"></a></h4>
<p>In order to find when and from where the invalid value originated from, stable-baselines3 comes with a <code class="docutils literal notranslate"><span class="pre">VecCheckNan</span></code> wrapper.</p>
<p>It will monitor the actions, observations, and rewards, indicating what action or observation caused it and from what.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">gymnasium</span> <span class="kn">import</span> <span class="n">spaces</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.vec_env</span> <span class="kn">import</span> <span class="n">DummyVecEnv</span><span class="p">,</span> <span class="n">VecCheckNan</span>

<span class="k">class</span> <span class="nc">NanAndInfEnv</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">Env</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Custom Environment that raised NaNs and Infs&quot;&quot;&quot;</span>
    <span class="n">metadata</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;render.modes&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;human&quot;</span><span class="p">]}</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NanAndInfEnv</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">_action</span><span class="p">):</span>
        <span class="n">randf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">randf</span> <span class="o">&gt;</span> <span class="mf">0.99</span><span class="p">:</span>
            <span class="n">obs</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;NaN&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">randf</span> <span class="o">&gt;</span> <span class="mf">0.98</span><span class="p">:</span>
            <span class="n">obs</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">obs</span> <span class="o">=</span> <span class="n">randf</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">obs</span><span class="p">],</span> <span class="mf">0.0</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">close</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">pass</span>

<span class="c1"># Create environment</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">DummyVecEnv</span><span class="p">([</span><span class="k">lambda</span><span class="p">:</span> <span class="n">NanAndInfEnv</span><span class="p">()])</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">VecCheckNan</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">raise_exception</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Instantiate the agent</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">env</span><span class="p">)</span>

<span class="c1"># Train the agent</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">2e5</span><span class="p">))</span>  <span class="c1"># this will crash explaining that the invalid value originated from the environment.</span>
</pre></div>
</div>
</section>
<section id="rl-model-hyperparameters">
<h4>RL Model hyperparameters<a class="headerlink" href="#rl-model-hyperparameters" title="Permalink to this heading"></a></h4>
<p>Depending on your hyperparameters, NaN can occurs much more often.
A great example of this: <a class="reference external" href="https://github.com/hill-a/stable-baselines/issues/340">https://github.com/hill-a/stable-baselines/issues/340</a></p>
<p>Be aware, the hyperparameters given by default seem to work in most cases,
however your environment might not play nice with them.
If this is the case, try to read up on the effect each hyperparameters has on the model,
so that you can try and tune them to get a stable model. Alternatively, you can try automatic hyperparameter tuning (included in the rl zoo).</p>
</section>
<section id="missing-values-from-datasets">
<h4>Missing values from datasets<a class="headerlink" href="#missing-values-from-datasets" title="Permalink to this heading"></a></h4>
<p>If your environment is generated from an external dataset, do not forget to make sure your dataset does not contain NaNs.
As some datasets will sometimes fill missing values with NaNs as a surrogate value.</p>
<p>Here is some reading material about finding NaNs: <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html">https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html</a></p>
<p>And filling the missing values with something else (imputation): <a class="reference external" href="https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4">https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4</a></p>
</section>
</section>
<span id="document-guide/developer"></span><section id="developer-guide">
<span id="developer"></span><h3>Developer Guide<a class="headerlink" href="#developer-guide" title="Permalink to this heading"></a></h3>
<p>This guide is meant for those who want to understand the internals and the design choices of Stable-Baselines3.</p>
<p>At first, you should read the two issues where the design choices were discussed:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/hill-a/stable-baselines/issues/576">https://github.com/hill-a/stable-baselines/issues/576</a></p></li>
<li><p><a class="reference external" href="https://github.com/hill-a/stable-baselines/issues/733">https://github.com/hill-a/stable-baselines/issues/733</a></p></li>
</ul>
<p>The library is not meant to be modular, although inheritance is used to reduce code duplication.</p>
<section id="algorithms-structure">
<h4>Algorithms Structure<a class="headerlink" href="#algorithms-structure" title="Permalink to this heading"></a></h4>
<p>Each algorithm (on-policy and off-policy ones) follows a common structure.
Policy contains code for acting in the environment, and algorithm updates this policy.
There is one folder per algorithm, and in that folder there is the algorithm and the policy definition (<code class="docutils literal notranslate"><span class="pre">policies.py</span></code>).</p>
<p>Each algorithm has two main methods:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.collect_rollouts()</span></code> which defines how new samples are collected, usually inherited from the base class. Those samples are then stored in a <code class="docutils literal notranslate"><span class="pre">RolloutBuffer</span></code> (discarded after the gradient update) or <code class="docutils literal notranslate"><span class="pre">ReplayBuffer</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.train()</span></code> which updates the parameters using samples from the buffer</p></li>
</ul>
<img alt="_images/sb3_loop.png" src="_images/sb3_loop.png" />
</section>
<section id="where-to-start">
<h4>Where to start?<a class="headerlink" href="#where-to-start" title="Permalink to this heading"></a></h4>
<p>The first thing you need to read and understand are the base classes in the <code class="docutils literal notranslate"><span class="pre">common/</span></code> folder:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">BaseAlgorithm</span></code> in <code class="docutils literal notranslate"><span class="pre">base_class.py</span></code> which defines how an RL class should look like.
It contains also all the “glue code” for saving/loading and the common operations (wrapping environments)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BasePolicy</span></code> in <code class="docutils literal notranslate"><span class="pre">policies.py</span></code> which defines how a policy class should look like.
It contains also all the magic for the <code class="docutils literal notranslate"><span class="pre">.predict()</span></code> method, to handle as many spaces/cases as possible</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">OffPolicyAlgorithm</span></code> in <code class="docutils literal notranslate"><span class="pre">off_policy_algorithm.py</span></code> that contains the implementation of <code class="docutils literal notranslate"><span class="pre">collect_rollouts()</span></code> for the off-policy algorithms,
and similarly <code class="docutils literal notranslate"><span class="pre">OnPolicyAlgorithm</span></code> in <code class="docutils literal notranslate"><span class="pre">on_policy_algorithm.py</span></code>.</p></li>
</ul>
<p>All the environments handled internally are assumed to be <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code> (<code class="docutils literal notranslate"><span class="pre">gym.Env</span></code> are automatically wrapped).</p>
</section>
<section id="pre-processing">
<h4>Pre-Processing<a class="headerlink" href="#pre-processing" title="Permalink to this heading"></a></h4>
<p>To handle different observation spaces, some pre-processing needs to be done (e.g. one-hot encoding for discrete observation).
Most of the code for pre-processing is in <code class="docutils literal notranslate"><span class="pre">common/preprocessing.py</span></code> and <code class="docutils literal notranslate"><span class="pre">common/policies.py</span></code>.</p>
<p>For images, environment is automatically wrapped with <code class="docutils literal notranslate"><span class="pre">VecTransposeImage</span></code> if observations are detected to be images with
channel-last convention to transform it to PyTorch’s channel-first convention.</p>
</section>
<section id="policy-structure">
<h4>Policy Structure<a class="headerlink" href="#policy-structure" title="Permalink to this heading"></a></h4>
<p>When we refer to “policy” in Stable-Baselines3, this is usually an abuse of language compared to RL terminology.
In SB3, “policy” refers to the class that handles all the networks useful for training,
so not only the network used to predict actions (the “learned controller”).
For instance, the <code class="docutils literal notranslate"><span class="pre">TD3</span></code> policy contains the actor, the critic and the target networks.</p>
<p>To avoid the hassle of importing specific policy classes for specific algorithm (e.g. both A2C and PPO use <code class="docutils literal notranslate"><span class="pre">ActorCriticPolicy</span></code>),
SB3 uses names like “MlpPolicy” and “CnnPolicy” to refer policies using small feed-forward networks or convolutional networks,
respectively. Importing <code class="docutils literal notranslate"><span class="pre">[algorithm]/policies.py</span></code> registers an appropriate policy for that algorithm under those names.</p>
</section>
<section id="probability-distributions">
<h4>Probability distributions<a class="headerlink" href="#probability-distributions" title="Permalink to this heading"></a></h4>
<p>When needed, the policies handle the different probability distributions.
All distributions are located in <code class="docutils literal notranslate"><span class="pre">common/distributions.py</span></code> and follow the same interface.
Each distribution corresponds to a type of action space (e.g. <code class="docutils literal notranslate"><span class="pre">Categorical</span></code> is the one used for discrete actions.
For continuous actions, we can use multiple distributions (“DiagGaussian”, “SquashedGaussian” or “StateDependentDistribution”)</p>
</section>
<section id="state-dependent-exploration">
<h4>State-Dependent Exploration<a class="headerlink" href="#state-dependent-exploration" title="Permalink to this heading"></a></h4>
<p>State-Dependent Exploration (SDE) is a type of exploration that allows to use RL directly on real robots,
that was the starting point for the Stable-Baselines3 library.
I (&#64;araffin) published a paper about a generalized version of SDE (the one implemented in SB3): <a class="reference external" href="https://arxiv.org/abs/2005.05719">https://arxiv.org/abs/2005.05719</a></p>
</section>
<section id="misc">
<h4>Misc<a class="headerlink" href="#misc" title="Permalink to this heading"></a></h4>
<p>The rest of the <code class="docutils literal notranslate"><span class="pre">common/</span></code> is composed of helpers (e.g. evaluation helpers) or basic components (like the callbacks).
The <code class="docutils literal notranslate"><span class="pre">type_aliases.py</span></code> file contains common type hint aliases like <code class="docutils literal notranslate"><span class="pre">GymStepReturn</span></code>.</p>
<p>Et voilà?</p>
<p>After reading this guide and the mentioned files, you should be now able to understand the design logic behind the library ;)</p>
</section>
</section>
<span id="document-guide/save_format"></span><section id="on-saving-and-loading">
<span id="save-format"></span><h3>On saving and loading<a class="headerlink" href="#on-saving-and-loading" title="Permalink to this heading"></a></h3>
<p>Stable Baselines3 (SB3) stores both neural network parameters and algorithm-related parameters such as
exploration schedule, number of environments and observation/action space. This allows continual learning and easy
use of trained agents without training, but it is not without its issues. Following describes the format
used to save agents in SB3 along with its pros and shortcomings.</p>
<p>Terminology used in this page:</p>
<ul class="simple">
<li><p><em>parameters</em> refer to neural network parameters (also called “weights”). This is a dictionary
mapping variable name to a PyTorch tensor.</p></li>
<li><p><em>data</em> refers to RL algorithm parameters, e.g. learning rate, exploration schedule, action/observation space.
These depend on the algorithm used. This is a dictionary mapping classes variable names to their values.</p></li>
</ul>
<section id="zip-archive">
<h4>Zip-archive<a class="headerlink" href="#zip-archive" title="Permalink to this heading"></a></h4>
<p>A zip-archived JSON dump, PyTorch state dictionaries and PyTorch variables. The data dictionary (class parameters)
is stored as a JSON file, model parameters and optimizers are serialized with <code class="docutils literal notranslate"><span class="pre">torch.save()</span></code> function and these files
are stored under a single .zip archive.</p>
<p>Any objects that are not JSON serializable are serialized with cloudpickle and stored as base64-encoded
string in the JSON file, along with some information that was stored in the serialization. This allows
inspecting stored objects without deserializing the object itself.</p>
<p>This format allows skipping elements in the file, i.e. we can skip deserializing objects that are
broken/non-serializable.
This can be done via <code class="docutils literal notranslate"><span class="pre">custom_objects</span></code> argument to load functions.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you encounter loading issue, for instance pickle issues or error after loading
(see <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/171">#171</a> or <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/573">#573</a>),
you can pass <code class="docutils literal notranslate"><span class="pre">print_system_info=True</span></code>
to compare the system on which the model was trained vs the current one
<code class="docutils literal notranslate"><span class="pre">model</span> <span class="pre">=</span> <span class="pre">PPO.load(&quot;ppo_saved&quot;,</span> <span class="pre">print_system_info=True)</span></code></p>
</div>
<p>File structure:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>saved_model.zip/
├── data              JSON file of class-parameters (dictionary)
├── *.optimizer.pth   PyTorch optimizers serialized
├── policy.pth        PyTorch state dictionary of the policy saved
├── pytorch_variables.pth Additional PyTorch variables
├── _stable_baselines3_version contains the SB3 version with which the model was saved
├── system_info.txt contains system info (os, python version, ...) on which the model was saved
</pre></div>
</div>
<p>Pros:</p>
<ul class="simple">
<li><p>More robust to unserializable objects (one bad object does not break everything).</p></li>
<li><p>Saved files can be inspected/extracted with zip-archive explorers and by other languages.</p></li>
</ul>
<p>Cons:</p>
<ul class="simple">
<li><p>More complex implementation.</p></li>
<li><p>Still relies partly on cloudpickle for complex objects (e.g. custom functions)
with can lead to <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/172">incompatibilities</a> between Python versions.</p></li>
</ul>
</section>
</section>
<span id="document-guide/export"></span><section id="exporting-models">
<span id="export"></span><h3>Exporting models<a class="headerlink" href="#exporting-models" title="Permalink to this heading"></a></h3>
<p>After training an agent, you may want to deploy/use it in another language
or framework, like <a class="reference external" href="https://github.com/tensorflow/tfjs">tensorflowjs</a>.
Stable Baselines3 does not include tools to export models to other frameworks, but
this document aims to cover parts that are required for exporting along with
more detailed stories from users of Stable Baselines3.</p>
<section id="background">
<h4>Background<a class="headerlink" href="#background" title="Permalink to this heading"></a></h4>
<p>In Stable Baselines3, the controller is stored inside policies which convert
observations into actions. Each learning algorithm (e.g. DQN, A2C, SAC)
contains a policy object which represents the currently learned behavior,
accessible via <code class="docutils literal notranslate"><span class="pre">model.policy</span></code>.</p>
<p>Policies hold enough information to do the inference (i.e. predict actions),
so it is enough to export these policies (cf <a class="reference internal" href="index.html#examples"><span class="std std-ref">examples</span></a>)
to do inference in another framework.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When using CNN policies, the observation is normalized during pre-preprocessing.
This pre-processing is done <em>inside</em> the policy (dividing by 255 to have values in [0, 1])</p>
</div>
</section>
<section id="export-to-onnx">
<h4>Export to ONNX<a class="headerlink" href="#export-to-onnx" title="Permalink to this heading"></a></h4>
<p>As of June 2021, ONNX format  <a class="reference external" href="https://github.com/onnx/onnx/issues/3033">doesn’t support</a> exporting models that use the <code class="docutils literal notranslate"><span class="pre">broadcast_tensors</span></code> functionality of pytorch. So in order to export the trained stable-baseline3 models in the ONNX format, we need to first remove the layers that use broadcasting. This can be done by creating a class that removes the unsupported layers.</p>
<p>The following examples are for <code class="docutils literal notranslate"><span class="pre">MlpPolicy</span></code> only, and are general examples. Note that you have to preprocess the observation the same way stable-baselines3 agent does (see <code class="docutils literal notranslate"><span class="pre">common.preprocessing.preprocess_obs</span></code>).</p>
<p>For PPO, assuming a shared feature extractor.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The following example is for continuous actions only.
When using discrete or binary actions, you must do some <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/blob/f3a35aa786ee41ffff599b99fa1607c067e89074/stable_baselines3/common/policies.py#L621-L637">post-processing</a>
to obtain the action (e.g., convert action logits to action).</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>


<span class="k">class</span> <span class="nc">OnnxablePolicy</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">extractor</span><span class="p">,</span> <span class="n">action_net</span><span class="p">,</span> <span class="n">value_net</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">extractor</span> <span class="o">=</span> <span class="n">extractor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_net</span> <span class="o">=</span> <span class="n">action_net</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value_net</span> <span class="o">=</span> <span class="n">value_net</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">):</span>
        <span class="c1"># NOTE: You may have to process (normalize) observation in the correct</span>
        <span class="c1">#       way before using this. See `common.preprocessing.preprocess_obs`</span>
        <span class="n">action_hidden</span><span class="p">,</span> <span class="n">value_hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">extractor</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_net</span><span class="p">(</span><span class="n">action_hidden</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_net</span><span class="p">(</span><span class="n">value_hidden</span><span class="p">)</span>


<span class="c1"># Example: model = PPO(&quot;MlpPolicy&quot;, &quot;Pendulum-v1&quot;)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;PathToTrainedModel.zip&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">onnxable_model</span> <span class="o">=</span> <span class="n">OnnxablePolicy</span><span class="p">(</span>
    <span class="n">model</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">mlp_extractor</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">action_net</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">value_net</span>
<span class="p">)</span>

<span class="n">observation_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span>
<span class="n">dummy_input</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">observation_size</span><span class="p">)</span>
<span class="n">th</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span>
    <span class="n">onnxable_model</span><span class="p">,</span>
    <span class="n">dummy_input</span><span class="p">,</span>
    <span class="s2">&quot;my_ppo_model.onnx&quot;</span><span class="p">,</span>
    <span class="n">opset_version</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
    <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="c1">##### Load and test with onnx</span>

<span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">import</span> <span class="nn">onnxruntime</span> <span class="k">as</span> <span class="nn">ort</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">onnx_path</span> <span class="o">=</span> <span class="s2">&quot;my_ppo_model.onnx&quot;</span>
<span class="n">onnx_model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">onnx_path</span><span class="p">)</span>
<span class="n">onnx</span><span class="o">.</span><span class="n">checker</span><span class="o">.</span><span class="n">check_model</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span>

<span class="n">observation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">observation_size</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">ort_sess</span> <span class="o">=</span> <span class="n">ort</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span><span class="n">onnx_path</span><span class="p">)</span>
<span class="n">action</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="n">ort_sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="n">observation</span><span class="p">})</span>
</pre></div>
</div>
<p>For SAC the procedure is similar. The example shown only exports the actor network as the actor is sufficient to roll out the trained policies.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">SAC</span>


<span class="k">class</span> <span class="nc">OnnxablePolicy</span><span class="p">(</span><span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actor</span><span class="p">:</span> <span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Removing the flatten layer because it can&#39;t be onnxed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actor</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">actor</span><span class="o">.</span><span class="n">latent_pi</span><span class="p">,</span>
            <span class="n">actor</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span>
            <span class="c1"># For gSDE</span>
            <span class="c1"># th.nn.Hardtanh(min_val=-actor.clip_mean, max_val=actor.clip_mean),</span>
            <span class="c1"># Squash the output</span>
            <span class="n">th</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observation</span><span class="p">:</span> <span class="n">th</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">th</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># NOTE: You may have to process (normalize) observation in the correct</span>
        <span class="c1">#       way before using this. See `common.preprocessing.preprocess_obs`</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>


<span class="c1"># Example: model = SAC(&quot;MlpPolicy&quot;, &quot;Pendulum-v1&quot;)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;PathToTrainedModel.zip&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="n">onnxable_model</span> <span class="o">=</span> <span class="n">OnnxablePolicy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">actor</span><span class="p">)</span>

<span class="n">observation_size</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span>
<span class="n">dummy_input</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">observation_size</span><span class="p">)</span>
<span class="n">th</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">export</span><span class="p">(</span>
    <span class="n">onnxable_model</span><span class="p">,</span>
    <span class="n">dummy_input</span><span class="p">,</span>
    <span class="s2">&quot;my_sac_actor.onnx&quot;</span><span class="p">,</span>
    <span class="n">opset_version</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
    <span class="n">input_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="c1">##### Load and test with onnx</span>

<span class="kn">import</span> <span class="nn">onnxruntime</span> <span class="k">as</span> <span class="nn">ort</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">onnx_path</span> <span class="o">=</span> <span class="s2">&quot;my_sac_actor.onnx&quot;</span>

<span class="n">observation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">observation_size</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">ort_sess</span> <span class="o">=</span> <span class="n">ort</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span><span class="n">onnx_path</span><span class="p">)</span>
<span class="n">action</span> <span class="o">=</span> <span class="n">ort_sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="n">observation</span><span class="p">})</span>
</pre></div>
</div>
<p>For more discussion around the topic refer to this <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/383">issue.</a></p>
</section>
<section id="trace-export-to-c">
<h4>Trace/Export to C++<a class="headerlink" href="#trace-export-to-c" title="Permalink to this heading"></a></h4>
<p>You can use PyTorch JIT to trace and save a trained model that can be re-used in other applications
(for instance inference code written in C++).</p>
<p>There is a draft PR in the RL Zoo about C++ export: <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo/pull/228">https://github.com/DLR-RM/rl-baselines3-zoo/pull/228</a></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># See &quot;ONNX export&quot; for imports and OnnxablePolicy</span>
<span class="n">jit_path</span> <span class="o">=</span> <span class="s2">&quot;sac_traced.pt&quot;</span>

<span class="c1"># Trace and optimize the module</span>
<span class="n">traced_module</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">onnxable_model</span><span class="o">.</span><span class="n">eval</span><span class="p">(),</span> <span class="n">dummy_input</span><span class="p">)</span>
<span class="n">frozen_module</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">freeze</span><span class="p">(</span><span class="n">traced_module</span><span class="p">)</span>
<span class="n">frozen_module</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">optimize_for_inference</span><span class="p">(</span><span class="n">frozen_module</span><span class="p">)</span>
<span class="n">th</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">frozen_module</span><span class="p">,</span> <span class="n">jit_path</span><span class="p">)</span>

<span class="c1">##### Load and test with torch</span>

<span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>

<span class="n">dummy_input</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">observation_size</span><span class="p">)</span>
<span class="n">loaded_module</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">jit_path</span><span class="p">)</span>
<span class="n">action_jit</span> <span class="o">=</span> <span class="n">loaded_module</span><span class="p">(</span><span class="n">dummy_input</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="export-to-tensorflowjs-onnx-js">
<h4>Export to tensorflowjs / ONNX-JS<a class="headerlink" href="#export-to-tensorflowjs-onnx-js" title="Permalink to this heading"></a></h4>
<p>TODO: contributors help is welcomed!
Probably a good starting point: <a class="reference external" href="https://github.com/elliotwaite/pytorch-to-javascript-with-onnx-js">https://github.com/elliotwaite/pytorch-to-javascript-with-onnx-js</a></p>
</section>
<section id="export-to-tflite-coral-edge-tpu">
<h4>Export to TFLite / Coral (Edge TPU)<a class="headerlink" href="#export-to-tflite-coral-edge-tpu" title="Permalink to this heading"></a></h4>
<p>Full example code: <a class="reference external" href="https://github.com/chunky/sb3_to_coral">https://github.com/chunky/sb3_to_coral</a></p>
<p>Google created a chip called the “Coral” for deploying AI to the
edge. It’s available in a variety of form factors, including USB (using
the Coral on a Raspberry Pi, with a SB3-developed model, was the original
motivation for the code example above).</p>
<p>The Coral chip is fast, with very low power consumption, but only has limited
on-device training abilities. More information is on the webpage here:
<a class="reference external" href="https://coral.ai">https://coral.ai</a>.</p>
<p>To deploy to a Coral, one must work via TFLite, and quantize the
network to reflect the Coral’s capabilities. The full chain to go from
SB3 to Coral is: SB3 (Torch) =&gt; ONNX =&gt; TensorFlow =&gt; TFLite =&gt; Coral.</p>
<p>The code linked above is a complete, minimal, example that:</p>
<ol class="arabic simple">
<li><p>Creates a model using SB3</p></li>
<li><p>Follows the path of exports all the way to TFLite and Google Coral</p></li>
<li><p>Demonstrates the forward pass for most exported variants</p></li>
</ol>
<p>There are a number of pitfalls along the way to the complete conversion
that this example covers, including:</p>
<ul class="simple">
<li><p>Making the Gym’s observation work with ONNX properly</p></li>
<li><p>Quantising the TFLite model appropriately to align with Gym
while still taking advantage of Coral</p></li>
<li><p>Using OnnxablePolicy described as described in the above example</p></li>
</ul>
</section>
<section id="manual-export">
<h4>Manual export<a class="headerlink" href="#manual-export" title="Permalink to this heading"></a></h4>
<p>You can also manually export required parameters (weights) and construct the
network in your desired framework.</p>
<p>You can access parameters of the model via agents’
<a class="reference internal" href="index.html#stable_baselines3.common.base_class.BaseAlgorithm.get_parameters" title="stable_baselines3.common.base_class.BaseAlgorithm.get_parameters"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_parameters</span></code></a> function.
As policies are also PyTorch modules, you can also access <code class="docutils literal notranslate"><span class="pre">model.policy.state_dict()</span></code> directly.
To find the architecture of the networks for each algorithm, best is to check the <code class="docutils literal notranslate"><span class="pre">policies.py</span></code> file located
in their respective folders.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In most cases, we recommend using PyTorch methods <code class="docutils literal notranslate"><span class="pre">state_dict()</span></code> and <code class="docutils literal notranslate"><span class="pre">load_state_dict()</span></code> from the policy,
unless you need to access the optimizers’ state dict too. In that case, you need to call <code class="docutils literal notranslate"><span class="pre">get_parameters()</span></code>.</p>
</div>
</section>
</section>
</div>
<div class="toctree-wrapper compound">
<span id="document-modules/base"></span><span class="target" id="module-stable_baselines3.common.base_class"><span id="base-algo"></span></span><p>Abstract base classes for RL algorithms.</p>
<section id="base-rl-class">
<h3>Base RL Class<a class="headerlink" href="#base-rl-class" title="Permalink to this heading"></a></h3>
<p>Common interface for all the RL algorithms</p>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.base_class.BaseAlgorithm">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.base_class.</span></span><span class="sig-name descname"><span class="pre">BaseAlgorithm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">policy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stats_window_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensorboard_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">support_multi_env</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor_wrapper</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sde_sample_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supported_action_spaces</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/base_class.html#BaseAlgorithm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.base_class.BaseAlgorithm" title="Permalink to this definition"></a></dt>
<dd><p>The base of RL algorithms</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>policy</strong> (<em>BasePolicy</em>) – The policy model to use (MlpPolicy, CnnPolicy, …)</p></li>
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.VecEnv"><em>VecEnv</em></a><em> | </em><em>str</em><em> | </em><em>None</em>) – The environment to learn from
(if registered in Gym, can be str. Can be None for loading trained models)</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – learning rate for the optimizer,
it can be a function of the current progress remaining (from 1 to 0)</p></li>
<li><p><strong>policy_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional arguments to be passed to the policy on creation</p></li>
<li><p><strong>stats_window_size</strong> (<em>int</em>) – Window size for the rollout logging, specifying the number of episodes to average
the reported success rate, mean episode length, and mean reward over</p></li>
<li><p><strong>tensorboard_log</strong> (<em>str</em><em> | </em><em>None</em>) – the log location for tensorboard (if None, no logging)</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 1 for info messages (such as device or wrappers used), 2 for
debug messages</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device on which the code should run.
By default, it will try to use a Cuda compatible device and fallback to cpu
if it is not possible.</p></li>
<li><p><strong>support_multi_env</strong> (<em>bool</em>) – Whether the algorithm supports training
with multiple environments (as in A2C)</p></li>
<li><p><strong>monitor_wrapper</strong> (<em>bool</em>) – When creating an environment, whether to wrap it
or not in a Monitor wrapper.</p></li>
<li><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – Seed for the pseudo random generators</p></li>
<li><p><strong>use_sde</strong> (<em>bool</em>) – Whether to use generalized State Dependent Exploration (gSDE)
instead of action noise exploration (default: False)</p></li>
<li><p><strong>sde_sample_freq</strong> (<em>int</em>) – Sample a new noise matrix every n steps when using gSDE
Default: -1 (only sample at the beginning of the rollout)</p></li>
<li><p><strong>supported_action_spaces</strong> (<em>Tuple</em><em>[</em><em>Type</em><em>[</em><em>Space</em><em>]</em><em>, </em><em>...</em><em>] </em><em>| </em><em>None</em>) – The action spaces supported by the algorithm.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.base_class.BaseAlgorithm.get_env">
<span class="sig-name descname"><span class="pre">get_env</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/base_class.html#BaseAlgorithm.get_env"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.base_class.BaseAlgorithm.get_env" title="Permalink to this definition"></a></dt>
<dd><p>Returns the current environment (can be None if not defined).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The current environment</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.base_class.BaseAlgorithm.get_parameters">
<span class="sig-name descname"><span class="pre">get_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/base_class.html#BaseAlgorithm.get_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.base_class.BaseAlgorithm.get_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Return the parameters of the agent. This includes parameters from different networks, e.g.
critics (value functions) and policies (pi functions).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Mapping of from names of the objects to PyTorch state-dicts.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Dict</em>[str, <em>Dict</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.base_class.BaseAlgorithm.get_vec_normalize_env">
<span class="sig-name descname"><span class="pre">get_vec_normalize_env</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/base_class.html#BaseAlgorithm.get_vec_normalize_env"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.base_class.BaseAlgorithm.get_vec_normalize_env" title="Permalink to this definition"></a></dt>
<dd><p>Return the <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> wrapper of the training env
if it exists.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> env.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecNormalize" title="stable_baselines3.common.vec_env.vec_normalize.VecNormalize"><em>VecNormalize</em></a> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.base_class.BaseAlgorithm.learn">
<em class="property"><span class="pre">abstract</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">total_timesteps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tb_log_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'run'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_num_timesteps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">progress_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/base_class.html#BaseAlgorithm.learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.base_class.BaseAlgorithm.learn" title="Permalink to this definition"></a></dt>
<dd><p>Return a trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>total_timesteps</strong> (<em>int</em>) – The total number of samples (env steps) to train on</p></li>
<li><p><strong>callback</strong> (<em>None</em><em> | </em><em>Callable</em><em> | </em><em>List</em><em>[</em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a><em>] </em><em>| </em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – callback(s) called at every step with state of the algorithm.</p></li>
<li><p><strong>log_interval</strong> (<em>int</em>) – The number of episodes before logging.</p></li>
<li><p><strong>tb_log_name</strong> (<em>str</em>) – the name of the run for TensorBoard logging</p></li>
<li><p><strong>reset_num_timesteps</strong> (<em>bool</em>) – whether or not to reset the current timestep number (used in logging)</p></li>
<li><p><strong>progress_bar</strong> (<em>bool</em>) – Display a progress bar using tqdm and rich.</p></li>
<li><p><strong>self</strong> (<em>SelfBaseAlgorithm</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the trained model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfBaseAlgorithm</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.base_class.BaseAlgorithm.load">
<em class="property"><span class="pre">classmethod</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_objects</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_system_info</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_reset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/base_class.html#BaseAlgorithm.load"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.base_class.BaseAlgorithm.load" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a zip-file.
Warning: <code class="docutils literal notranslate"><span class="pre">load</span></code> re-creates the model from scratch, it does not update it in-place!
For an in-place load use <code class="docutils literal notranslate"><span class="pre">set_parameters</span></code> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – path to the file (or a file-like) where to
load the agent from</p></li>
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a><em> | </em><em>None</em>) – the new environment to run the loaded model on
(can be None if you only need prediction from a trained model) has priority over any saved environment</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device on which the code should run.</p></li>
<li><p><strong>custom_objects</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Dictionary of objects to replace
upon loading. If a variable is present in this dictionary as a
key, it will not be deserialized and the corresponding item
will be used instead. Similar to custom_objects in
<code class="docutils literal notranslate"><span class="pre">keras.models.load_model</span></code>. Useful when you have an object in
file that can not be deserialized.</p></li>
<li><p><strong>print_system_info</strong> (<em>bool</em>) – Whether to print system info from the saved model
and the current system info (useful to debug loading issues)</p></li>
<li><p><strong>force_reset</strong> (<em>bool</em>) – Force call to <code class="docutils literal notranslate"><span class="pre">reset()</span></code> before training
to avoid unexpected behavior.
See <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/597">https://github.com/DLR-RM/stable-baselines3/issues/597</a></p></li>
<li><p><strong>kwargs</strong> – extra arguments to change the model when loading</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>new model instance with loaded parameters</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfBaseAlgorithm</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="stable_baselines3.common.base_class.BaseAlgorithm.logger">
<em class="property"><span class="pre">property</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">logger</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><a class="reference internal" href="index.html#stable_baselines3.common.logger.Logger" title="stable_baselines3.common.logger.Logger"><span class="pre">Logger</span></a></em><a class="headerlink" href="#stable_baselines3.common.base_class.BaseAlgorithm.logger" title="Permalink to this definition"></a></dt>
<dd><p>Getter for the logger object.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.base_class.BaseAlgorithm.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">episode_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/base_class.html#BaseAlgorithm.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.base_class.BaseAlgorithm.predict" title="Permalink to this definition"></a></dt>
<dd><p>Get the policy action from an observation (and optional hidden state).
Includes sugar-coating to handle different observations (e.g. normalizing images).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation</strong> (<em>ndarray</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>ndarray</em><em>]</em>) – the input observation</p></li>
<li><p><strong>state</strong> (<em>Tuple</em><em>[</em><em>ndarray</em><em>, </em><em>...</em><em>] </em><em>| </em><em>None</em>) – The last hidden states (can be None, used in recurrent policies)</p></li>
<li><p><strong>episode_start</strong> (<em>ndarray</em><em> | </em><em>None</em>) – The last masks (can be None, used in recurrent policies)
this correspond to beginning of episodes,
where the hidden states of the RNN must be reset.</p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – Whether or not to return deterministic actions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the model’s action and the next hidden state
(used in recurrent policies)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>ndarray</em>, <em>Tuple</em>[<em>ndarray</em>, …] | None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.base_class.BaseAlgorithm.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/base_class.html#BaseAlgorithm.save"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.base_class.BaseAlgorithm.save" title="Permalink to this definition"></a></dt>
<dd><p>Save all the attributes of the object and the model parameters in a zip-file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – path to the file where the rl agent should be saved</p></li>
<li><p><strong>exclude</strong> (<em>Iterable</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – name of parameters that should be excluded in addition to the default ones</p></li>
<li><p><strong>include</strong> (<em>Iterable</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – name of parameters that might be excluded but should be included anyway</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.base_class.BaseAlgorithm.set_env">
<span class="sig-name descname"><span class="pre">set_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_reset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/base_class.html#BaseAlgorithm.set_env"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.base_class.BaseAlgorithm.set_env" title="Permalink to this definition"></a></dt>
<dd><p>Checks the validity of the environment, and if it is coherent, set it as the current environment.
Furthermore wrap any non vectorized env into a vectorized
checked parameters:
- observation_space
- action_space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The environment for learning a policy</p></li>
<li><p><strong>force_reset</strong> (<em>bool</em>) – Force call to <code class="docutils literal notranslate"><span class="pre">reset()</span></code> before training
to avoid unexpected behavior.
See issue <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/597">https://github.com/DLR-RM/stable-baselines3/issues/597</a></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.base_class.BaseAlgorithm.set_logger">
<span class="sig-name descname"><span class="pre">set_logger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/base_class.html#BaseAlgorithm.set_logger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.base_class.BaseAlgorithm.set_logger" title="Permalink to this definition"></a></dt>
<dd><p>Setter for for logger object.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When passing a custom logger object,
this will overwrite <code class="docutils literal notranslate"><span class="pre">tensorboard_log</span></code> and <code class="docutils literal notranslate"><span class="pre">verbose</span></code> settings
passed to the constructor.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>logger</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.logger.Logger" title="stable_baselines3.common.logger.Logger"><em>Logger</em></a>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.base_class.BaseAlgorithm.set_parameters">
<span class="sig-name descname"><span class="pre">set_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">load_path_or_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exact_match</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/base_class.html#BaseAlgorithm.set_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.base_class.BaseAlgorithm.set_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Load parameters from a given zip-file or a nested dictionary containing parameters for
different modules (see <code class="docutils literal notranslate"><span class="pre">get_parameters</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>load_path_or_iter</strong> – Location of the saved data (path or file-like, see <code class="docutils literal notranslate"><span class="pre">save</span></code>), or a nested
dictionary containing nn.Module parameters used by the policy. The dictionary maps
object names to a state-dictionary returned by <code class="docutils literal notranslate"><span class="pre">torch.nn.Module.state_dict()</span></code>.</p></li>
<li><p><strong>exact_match</strong> (<em>bool</em>) – If True, the given parameters should include parameters for each
module and each of their parameters, otherwise raises an Exception. If set to False, this
can be used to update only specific parameters.</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device on which the code should run.</p></li>
<li><p><strong>load_path_or_dict</strong> (<em>str</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.base_class.BaseAlgorithm.set_random_seed">
<span class="sig-name descname"><span class="pre">set_random_seed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/base_class.html#BaseAlgorithm.set_random_seed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.base_class.BaseAlgorithm.set_random_seed" title="Permalink to this definition"></a></dt>
<dd><p>Set the seed of the pseudo-random generators
(python, numpy, pytorch, gym, action_space)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<span class="target" id="module-stable_baselines3.common.off_policy_algorithm"></span><section id="base-off-policy-class">
<h4>Base Off-Policy Class<a class="headerlink" href="#base-off-policy-class" title="Permalink to this heading"></a></h4>
<p>The base RL algorithm for Off-Policy algorithm (ex: SAC/TD3)</p>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.off_policy_algorithm.OffPolicyAlgorithm">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.off_policy_algorithm.</span></span><span class="sig-name descname"><span class="pre">OffPolicyAlgorithm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">policy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_starts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.005</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(1,</span> <span class="pre">'step')</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_buffer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_buffer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimize_memory_usage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stats_window_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensorboard_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">support_multi_env</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor_wrapper</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sde_sample_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde_at_warmup</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sde_support</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supported_action_spaces</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/off_policy_algorithm.html#OffPolicyAlgorithm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.off_policy_algorithm.OffPolicyAlgorithm" title="Permalink to this definition"></a></dt>
<dd><p>The base for Off-Policy algorithms (ex: SAC/TD3)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>policy</strong> (<em>BasePolicy</em>) – The policy model to use (MlpPolicy, CnnPolicy, …)</p></li>
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.VecEnv"><em>VecEnv</em></a><em> | </em><em>str</em>) – The environment to learn from
(if registered in Gym, can be str. Can be None for loading trained models)</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – learning rate for the optimizer,
it can be a function of the current progress remaining (from 1 to 0)</p></li>
<li><p><strong>buffer_size</strong> (<em>int</em>) – size of the replay buffer</p></li>
<li><p><strong>learning_starts</strong> (<em>int</em>) – how many steps of the model to collect transitions for before learning starts</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Minibatch size for each gradient update</p></li>
<li><p><strong>tau</strong> (<em>float</em>) – the soft update coefficient (“Polyak update”, between 0 and 1)</p></li>
<li><p><strong>gamma</strong> (<em>float</em>) – the discount factor</p></li>
<li><p><strong>train_freq</strong> (<em>int</em><em> | </em><em>Tuple</em><em>[</em><em>int</em><em>, </em><em>str</em><em>]</em>) – Update the model every <code class="docutils literal notranslate"><span class="pre">train_freq</span></code> steps. Alternatively pass a tuple of frequency and unit
like <code class="docutils literal notranslate"><span class="pre">(5,</span> <span class="pre">&quot;step&quot;)</span></code> or <code class="docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">&quot;episode&quot;)</span></code>.</p></li>
<li><p><strong>gradient_steps</strong> (<em>int</em>) – How many gradient steps to do after each rollout (see <code class="docutils literal notranslate"><span class="pre">train_freq</span></code>)
Set to <code class="docutils literal notranslate"><span class="pre">-1</span></code> means to do as many gradient steps as steps done in the environment
during the rollout.</p></li>
<li><p><strong>action_noise</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.noise.ActionNoise" title="stable_baselines3.common.noise.ActionNoise"><em>ActionNoise</em></a><em> | </em><em>None</em>) – the action noise type (None by default), this can help
for hard exploration problem. Cf common.noise for the different action noise type.</p></li>
<li><p><strong>replay_buffer_class</strong> (<em>Type</em><em>[</em><em>ReplayBuffer</em><em>] </em><em>| </em><em>None</em>) – Replay buffer class to use (for instance <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code>).
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, it will be automatically selected.</p></li>
<li><p><strong>replay_buffer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments to pass to the replay buffer on creation.</p></li>
<li><p><strong>optimize_memory_usage</strong> (<em>bool</em>) – Enable a memory efficient variant of the replay buffer
at a cost of more complexity.
See <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195">https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195</a></p></li>
<li><p><strong>policy_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional arguments to be passed to the policy on creation</p></li>
<li><p><strong>stats_window_size</strong> (<em>int</em>) – Window size for the rollout logging, specifying the number of episodes to average
the reported success rate, mean episode length, and mean reward over</p></li>
<li><p><strong>tensorboard_log</strong> (<em>str</em><em> | </em><em>None</em>) – the log location for tensorboard (if None, no logging)</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 1 for info messages (such as device or wrappers used), 2 for
debug messages</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device on which the code should run.
By default, it will try to use a Cuda compatible device and fallback to cpu
if it is not possible.</p></li>
<li><p><strong>support_multi_env</strong> (<em>bool</em>) – Whether the algorithm supports training
with multiple environments (as in A2C)</p></li>
<li><p><strong>monitor_wrapper</strong> (<em>bool</em>) – When creating an environment, whether to wrap it
or not in a Monitor wrapper.</p></li>
<li><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – Seed for the pseudo random generators</p></li>
<li><p><strong>use_sde</strong> (<em>bool</em>) – Whether to use State Dependent Exploration (SDE)
instead of action noise exploration (default: False)</p></li>
<li><p><strong>sde_sample_freq</strong> (<em>int</em>) – Sample a new noise matrix every n steps when using gSDE
Default: -1 (only sample at the beginning of the rollout)</p></li>
<li><p><strong>use_sde_at_warmup</strong> (<em>bool</em>) – Whether to use gSDE instead of uniform sampling
during the warm up phase (before learning starts)</p></li>
<li><p><strong>sde_support</strong> (<em>bool</em>) – Whether the model support gSDE or not</p></li>
<li><p><strong>supported_action_spaces</strong> (<em>Tuple</em><em>[</em><em>Type</em><em>[</em><em>Space</em><em>]</em><em>, </em><em>...</em><em>] </em><em>| </em><em>None</em>) – The action spaces supported by the algorithm.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.off_policy_algorithm.OffPolicyAlgorithm.collect_rollouts">
<span class="sig-name descname"><span class="pre">collect_rollouts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_freq</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_buffer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_starts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/off_policy_algorithm.html#OffPolicyAlgorithm.collect_rollouts"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.off_policy_algorithm.OffPolicyAlgorithm.collect_rollouts" title="Permalink to this definition"></a></dt>
<dd><p>Collect experiences and store them into a <code class="docutils literal notranslate"><span class="pre">ReplayBuffer</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The training environment</p></li>
<li><p><strong>callback</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – Callback that will be called at each step
(and at the beginning and end of the rollout)</p></li>
<li><p><strong>train_freq</strong> (<em>TrainFreq</em>) – How much experience to collect
by doing rollouts of current policy.
Either <code class="docutils literal notranslate"><span class="pre">TrainFreq(&lt;n&gt;,</span> <span class="pre">TrainFrequencyUnit.STEP)</span></code>
or <code class="docutils literal notranslate"><span class="pre">TrainFreq(&lt;n&gt;,</span> <span class="pre">TrainFrequencyUnit.EPISODE)</span></code>
with <code class="docutils literal notranslate"><span class="pre">&lt;n&gt;</span></code> being an integer greater than 0.</p></li>
<li><p><strong>action_noise</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.noise.ActionNoise" title="stable_baselines3.common.noise.ActionNoise"><em>ActionNoise</em></a><em> | </em><em>None</em>) – Action noise that will be used for exploration
Required for deterministic policy (e.g. TD3). This can also be used
in addition to the stochastic policy for SAC.</p></li>
<li><p><strong>learning_starts</strong> (<em>int</em>) – Number of steps before learning for the warm-up phase.</p></li>
<li><p><strong>replay_buffer</strong> (<em>ReplayBuffer</em>) – </p></li>
<li><p><strong>log_interval</strong> (<em>int</em><em> | </em><em>None</em>) – Log data every <code class="docutils literal notranslate"><span class="pre">log_interval</span></code> episodes</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>RolloutReturn</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.off_policy_algorithm.OffPolicyAlgorithm.learn">
<span class="sig-name descname"><span class="pre">learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">total_timesteps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tb_log_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'run'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_num_timesteps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">progress_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/off_policy_algorithm.html#OffPolicyAlgorithm.learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.off_policy_algorithm.OffPolicyAlgorithm.learn" title="Permalink to this definition"></a></dt>
<dd><p>Return a trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>total_timesteps</strong> (<em>int</em>) – The total number of samples (env steps) to train on</p></li>
<li><p><strong>callback</strong> (<em>None</em><em> | </em><em>Callable</em><em> | </em><em>List</em><em>[</em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a><em>] </em><em>| </em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – callback(s) called at every step with state of the algorithm.</p></li>
<li><p><strong>log_interval</strong> (<em>int</em>) – The number of episodes before logging.</p></li>
<li><p><strong>tb_log_name</strong> (<em>str</em>) – the name of the run for TensorBoard logging</p></li>
<li><p><strong>reset_num_timesteps</strong> (<em>bool</em>) – whether or not to reset the current timestep number (used in logging)</p></li>
<li><p><strong>progress_bar</strong> (<em>bool</em>) – Display a progress bar using tqdm and rich.</p></li>
<li><p><strong>self</strong> (<em>SelfOffPolicyAlgorithm</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the trained model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfOffPolicyAlgorithm</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.off_policy_algorithm.OffPolicyAlgorithm.load_replay_buffer">
<span class="sig-name descname"><span class="pre">load_replay_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truncate_last_traj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/off_policy_algorithm.html#OffPolicyAlgorithm.load_replay_buffer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.off_policy_algorithm.OffPolicyAlgorithm.load_replay_buffer" title="Permalink to this definition"></a></dt>
<dd><p>Load a replay buffer from a pickle file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – Path to the pickled replay buffer.</p></li>
<li><p><strong>truncate_last_traj</strong> (<em>bool</em>) – When using <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code> with online sampling:
If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, we assume that the last trajectory in the replay buffer was finished
(and truncate it).
If set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, we assume that we continue the same trajectory (same episode).</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.off_policy_algorithm.OffPolicyAlgorithm.save_replay_buffer">
<span class="sig-name descname"><span class="pre">save_replay_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/off_policy_algorithm.html#OffPolicyAlgorithm.save_replay_buffer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.off_policy_algorithm.OffPolicyAlgorithm.save_replay_buffer" title="Permalink to this definition"></a></dt>
<dd><p>Save the replay buffer as a pickle file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – Path to the file where the replay buffer should be saved.
if path is a str or pathlib.Path, the path is automatically created if necessary.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.off_policy_algorithm.OffPolicyAlgorithm.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradient_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/off_policy_algorithm.html#OffPolicyAlgorithm.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.off_policy_algorithm.OffPolicyAlgorithm.train" title="Permalink to this definition"></a></dt>
<dd><p>Sample the replay buffer and do the updates
(gradient descent and update target networks)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gradient_steps</strong> (<em>int</em>) – </p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<span class="target" id="module-stable_baselines3.common.on_policy_algorithm"></span></section>
<section id="base-on-policy-class">
<h4>Base On-Policy Class<a class="headerlink" href="#base-on-policy-class" title="Permalink to this heading"></a></h4>
<p>The base RL algorithm for On-Policy algorithm (ex: A2C/PPO)</p>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.on_policy_algorithm.OnPolicyAlgorithm">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.on_policy_algorithm.</span></span><span class="sig-name descname"><span class="pre">OnPolicyAlgorithm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">policy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gae_lambda</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ent_coef</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vf_coef</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_grad_norm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sde_sample_freq</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rollout_buffer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rollout_buffer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stats_window_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensorboard_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor_wrapper</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_init_setup_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">supported_action_spaces</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/on_policy_algorithm.html#OnPolicyAlgorithm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.on_policy_algorithm.OnPolicyAlgorithm" title="Permalink to this definition"></a></dt>
<dd><p>The base for On-Policy algorithms (ex: A2C/PPO).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>policy</strong> (<em>ActorCriticPolicy</em>) – The policy model to use (MlpPolicy, CnnPolicy, …)</p></li>
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.VecEnv"><em>VecEnv</em></a><em> | </em><em>str</em>) – The environment to learn from (if registered in Gym, can be str)</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – The learning rate, it can be a function
of the current progress remaining (from 1 to 0)</p></li>
<li><p><strong>n_steps</strong> (<em>int</em>) – The number of steps to run for each environment per update
(i.e. batch size is n_steps * n_env where n_env is number of environment copies running in parallel)</p></li>
<li><p><strong>gamma</strong> (<em>float</em>) – Discount factor</p></li>
<li><p><strong>gae_lambda</strong> (<em>float</em>) – Factor for trade-off of bias vs variance for Generalized Advantage Estimator.
Equivalent to classic advantage when set to 1.</p></li>
<li><p><strong>ent_coef</strong> (<em>float</em>) – Entropy coefficient for the loss calculation</p></li>
<li><p><strong>vf_coef</strong> (<em>float</em>) – Value function coefficient for the loss calculation</p></li>
<li><p><strong>max_grad_norm</strong> (<em>float</em>) – The maximum value for the gradient clipping</p></li>
<li><p><strong>use_sde</strong> (<em>bool</em>) – Whether to use generalized State Dependent Exploration (gSDE)
instead of action noise exploration (default: False)</p></li>
<li><p><strong>sde_sample_freq</strong> (<em>int</em>) – Sample a new noise matrix every n steps when using gSDE
Default: -1 (only sample at the beginning of the rollout)</p></li>
<li><p><strong>rollout_buffer_class</strong> (<em>Type</em><em>[</em><em>RolloutBuffer</em><em>] </em><em>| </em><em>None</em>) – Rollout buffer class to use. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, it will be automatically selected.</p></li>
<li><p><strong>rollout_buffer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments to pass to the rollout buffer on creation.</p></li>
<li><p><strong>stats_window_size</strong> (<em>int</em>) – Window size for the rollout logging, specifying the number of episodes to average
the reported success rate, mean episode length, and mean reward over</p></li>
<li><p><strong>tensorboard_log</strong> (<em>str</em><em> | </em><em>None</em>) – the log location for tensorboard (if None, no logging)</p></li>
<li><p><strong>monitor_wrapper</strong> (<em>bool</em>) – When creating an environment, whether to wrap it
or not in a Monitor wrapper.</p></li>
<li><p><strong>policy_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – additional arguments to be passed to the policy on creation</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 1 for info messages (such as device or wrappers used), 2 for
debug messages</p></li>
<li><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – Seed for the pseudo random generators</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device (cpu, cuda, …) on which the code should be run.
Setting it to auto, the code will be run on the GPU if possible.</p></li>
<li><p><strong>_init_setup_model</strong> (<em>bool</em>) – Whether or not to build the network at the creation of the instance</p></li>
<li><p><strong>supported_action_spaces</strong> (<em>Tuple</em><em>[</em><em>Type</em><em>[</em><em>Space</em><em>]</em><em>, </em><em>...</em><em>] </em><em>| </em><em>None</em>) – The action spaces supported by the algorithm.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.on_policy_algorithm.OnPolicyAlgorithm.collect_rollouts">
<span class="sig-name descname"><span class="pre">collect_rollouts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rollout_buffer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_rollout_steps</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/on_policy_algorithm.html#OnPolicyAlgorithm.collect_rollouts"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.on_policy_algorithm.OnPolicyAlgorithm.collect_rollouts" title="Permalink to this definition"></a></dt>
<dd><p>Collect experiences using the current policy and fill a <code class="docutils literal notranslate"><span class="pre">RolloutBuffer</span></code>.
The term rollout here refers to the model-free notion and should not
be used with the concept of rollout used in model-based RL or planning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The training environment</p></li>
<li><p><strong>callback</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – Callback that will be called at each step
(and at the beginning and end of the rollout)</p></li>
<li><p><strong>rollout_buffer</strong> (<em>RolloutBuffer</em>) – Buffer to fill with rollouts</p></li>
<li><p><strong>n_rollout_steps</strong> (<em>int</em>) – Number of experiences to collect per environment</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>True if function returned with at least <cite>n_rollout_steps</cite>
collected, False if callback terminated rollout prematurely.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.on_policy_algorithm.OnPolicyAlgorithm.learn">
<span class="sig-name descname"><span class="pre">learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">total_timesteps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tb_log_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'OnPolicyAlgorithm'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_num_timesteps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">progress_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/on_policy_algorithm.html#OnPolicyAlgorithm.learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.on_policy_algorithm.OnPolicyAlgorithm.learn" title="Permalink to this definition"></a></dt>
<dd><p>Return a trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>total_timesteps</strong> (<em>int</em>) – The total number of samples (env steps) to train on</p></li>
<li><p><strong>callback</strong> (<em>None</em><em> | </em><em>Callable</em><em> | </em><em>List</em><em>[</em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a><em>] </em><em>| </em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – callback(s) called at every step with state of the algorithm.</p></li>
<li><p><strong>log_interval</strong> (<em>int</em>) – The number of episodes before logging.</p></li>
<li><p><strong>tb_log_name</strong> (<em>str</em>) – the name of the run for TensorBoard logging</p></li>
<li><p><strong>reset_num_timesteps</strong> (<em>bool</em>) – whether or not to reset the current timestep number (used in logging)</p></li>
<li><p><strong>progress_bar</strong> (<em>bool</em>) – Display a progress bar using tqdm and rich.</p></li>
<li><p><strong>self</strong> (<em>SelfOnPolicyAlgorithm</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the trained model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfOnPolicyAlgorithm</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.on_policy_algorithm.OnPolicyAlgorithm.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/on_policy_algorithm.html#OnPolicyAlgorithm.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.on_policy_algorithm.OnPolicyAlgorithm.train" title="Permalink to this definition"></a></dt>
<dd><p>Consume current rollout data and update policy parameters.
Implemented by individual algorithms.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<span id="document-modules/a2c"></span><span class="target" id="module-stable_baselines3.a2c"><span id="a2c"></span></span><section id="id1">
<h3>A2C<a class="headerlink" href="#id1" title="Permalink to this heading"></a></h3>
<p>A synchronous, deterministic variant of <a class="reference external" href="https://arxiv.org/abs/1602.01783">Asynchronous Advantage Actor Critic (A3C)</a>.
It uses multiple workers to avoid the use of a replay buffer.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If you find training unstable or want to match performance of stable-baselines A2C, consider using
<code class="docutils literal notranslate"><span class="pre">RMSpropTFLike</span></code> optimizer from <code class="docutils literal notranslate"><span class="pre">stable_baselines3.common.sb2_compat.rmsprop_tf_like</span></code>.
You can change optimizer with <code class="docutils literal notranslate"><span class="pre">A2C(policy_kwargs=dict(optimizer_class=RMSpropTFLike,</span> <span class="pre">optimizer_kwargs=dict(eps=1e-5)))</span></code>.
Read more <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/pull/110#issuecomment-663255241">here</a>.</p>
</div>
<section id="notes">
<h4>Notes<a class="headerlink" href="#notes" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Original paper:  <a class="reference external" href="https://arxiv.org/abs/1602.01783">https://arxiv.org/abs/1602.01783</a></p></li>
<li><p>OpenAI blog post: <a class="reference external" href="https://openai.com/blog/baselines-acktr-a2c/">https://openai.com/blog/baselines-acktr-a2c/</a></p></li>
</ul>
</section>
<section id="can-i-use">
<h4>Can I use?<a class="headerlink" href="#can-i-use" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Recurrent policies: ❌</p></li>
<li><p>Multi processing: ✔️</p></li>
<li><p>Gym spaces:</p></li>
</ul>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Space</p></th>
<th class="head"><p>Action</p></th>
<th class="head"><p>Observation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Discrete</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>Box</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>MultiDiscrete</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>MultiBinary</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>Dict</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
</tbody>
</table>
</section>
<section id="example">
<h4>Example<a class="headerlink" href="#example" title="Permalink to this heading"></a></h4>
<p>This example is only to demonstrate the use of the library and its functions, and the trained agents may not solve the environments. Optimized hyperparameters can be found in RL Zoo <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">repository</a>.</p>
<p>Train a A2C agent on <code class="docutils literal notranslate"><span class="pre">CartPole-v1</span></code> using 4 environments.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">A2C</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.env_util</span> <span class="kn">import</span> <span class="n">make_vec_env</span>

<span class="c1"># Parallel environments</span>
<span class="n">vec_env</span> <span class="o">=</span> <span class="n">make_vec_env</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">n_envs</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">A2C</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">vec_env</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">25000</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;a2c_cartpole&quot;</span><span class="p">)</span>

<span class="k">del</span> <span class="n">model</span> <span class="c1"># remove to demonstrate saving and loading</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">A2C</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;a2c_cartpole&quot;</span><span class="p">)</span>

<span class="n">obs</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">_states</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">dones</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="n">vec_env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A2C is meant to be run primarily on the CPU, especially when you are not using a CNN. To improve CPU utilization, try turning off the GPU and using <code class="docutils literal notranslate"><span class="pre">SubprocVecEnv</span></code> instead of the default <code class="docutils literal notranslate"><span class="pre">DummyVecEnv</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">A2C</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.env_util</span> <span class="kn">import</span> <span class="n">make_vec_env</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.vec_env</span> <span class="kn">import</span> <span class="n">SubprocVecEnv</span>

<span class="k">if</span> <span class="vm">__name__</span><span class="o">==</span><span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">make_vec_env</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">n_envs</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">vec_env_cls</span><span class="o">=</span><span class="n">SubprocVecEnv</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">A2C</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">25_000</span><span class="p">)</span>
</pre></div>
</div>
<p>For more information, see <a class="reference internal" href="index.html#vec-env"><span class="std std-ref">Vectorized Environments</span></a>, <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/1245">Issue #1245</a> or the <a class="reference external" href="https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/multiprocessing_rl.ipynb">Multiprocessing notebook</a>.</p>
</div>
</section>
<section id="results">
<h4>Results<a class="headerlink" href="#results" title="Permalink to this heading"></a></h4>
<section id="atari-games">
<h5>Atari Games<a class="headerlink" href="#atari-games" title="Permalink to this heading"></a></h5>
<p>The complete learning curves are available in the <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/pull/110">associated PR #110</a>.</p>
</section>
<section id="pybullet-environments">
<h5>PyBullet Environments<a class="headerlink" href="#pybullet-environments" title="Permalink to this heading"></a></h5>
<p>Results on the PyBullet benchmark (2M steps) using 6 seeds.
The complete learning curves are available in the <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/48">associated issue #48</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Hyperparameters from the <a class="reference external" href="https://arxiv.org/abs/2005.05719">gSDE paper</a> were used (as they are tuned for PyBullet envs).</p>
</div>
<p><em>Gaussian</em> means that the unstructured Gaussian noise is used for exploration,
<em>gSDE</em> (generalized State-Dependent Exploration) is used otherwise.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Environments</p></th>
<th class="head"><p>A2C</p></th>
<th class="head"><p>A2C</p></th>
<th class="head"><p>PPO</p></th>
<th class="head"><p>PPO</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td></td>
<td><p>Gaussian</p></td>
<td><p>gSDE</p></td>
<td><p>Gaussian</p></td>
<td><p>gSDE</p></td>
</tr>
<tr class="row-odd"><td><p>HalfCheetah</p></td>
<td><p>2003 +/- 54</p></td>
<td><p>2032 +/- 122</p></td>
<td><p>1976 +/- 479</p></td>
<td><p>2826 +/- 45</p></td>
</tr>
<tr class="row-even"><td><p>Ant</p></td>
<td><p>2286 +/- 72</p></td>
<td><p>2443 +/- 89</p></td>
<td><p>2364 +/- 120</p></td>
<td><p>2782 +/- 76</p></td>
</tr>
<tr class="row-odd"><td><p>Hopper</p></td>
<td><p>1627 +/- 158</p></td>
<td><p>1561 +/- 220</p></td>
<td><p>1567 +/- 339</p></td>
<td><p>2512 +/- 21</p></td>
</tr>
<tr class="row-even"><td><p>Walker2D</p></td>
<td><p>577 +/- 65</p></td>
<td><p>839 +/- 56</p></td>
<td><p>1230 +/- 147</p></td>
<td><p>2019 +/- 64</p></td>
</tr>
</tbody>
</table>
</section>
<section id="how-to-replicate-the-results">
<h5>How to replicate the results?<a class="headerlink" href="#how-to-replicate-the-results" title="Permalink to this heading"></a></h5>
<p>Clone the <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">rl-zoo repo</a>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/DLR-RM/rl-baselines3-zoo
<span class="nb">cd</span><span class="w"> </span>rl-baselines3-zoo/
</pre></div>
</div>
<p>Run the benchmark (replace <code class="docutils literal notranslate"><span class="pre">$ENV_ID</span></code> by the envs mentioned above):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>train.py<span class="w"> </span>--algo<span class="w"> </span>a2c<span class="w"> </span>--env<span class="w"> </span><span class="nv">$ENV_ID</span><span class="w"> </span>--eval-episodes<span class="w"> </span><span class="m">10</span><span class="w"> </span>--eval-freq<span class="w"> </span><span class="m">10000</span>
</pre></div>
</div>
<p>Plot the results (here for PyBullet envs only):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>scripts/all_plots.py<span class="w"> </span>-a<span class="w"> </span>a2c<span class="w"> </span>-e<span class="w"> </span>HalfCheetah<span class="w"> </span>Ant<span class="w"> </span>Hopper<span class="w"> </span>Walker2D<span class="w"> </span>-f<span class="w"> </span>logs/<span class="w"> </span>-o<span class="w"> </span>logs/a2c_results
python<span class="w"> </span>scripts/plot_from_file.py<span class="w"> </span>-i<span class="w"> </span>logs/a2c_results.pkl<span class="w"> </span>-latex<span class="w"> </span>-l<span class="w"> </span>A2C
</pre></div>
</div>
</section>
</section>
<section id="parameters">
<h4>Parameters<a class="headerlink" href="#parameters" title="Permalink to this heading"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.a2c.A2C">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.a2c.</span></span><span class="sig-name descname"><span class="pre">A2C</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">policy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0007</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gae_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ent_coef</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vf_coef</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_grad_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rms_prop_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_rms_prop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sde_sample_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rollout_buffer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rollout_buffer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_advantage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stats_window_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensorboard_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_init_setup_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/a2c/a2c.html#A2C"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.a2c.A2C" title="Permalink to this definition"></a></dt>
<dd><p>Advantage Actor Critic (A2C)</p>
<p>Paper: <a class="reference external" href="https://arxiv.org/abs/1602.01783">https://arxiv.org/abs/1602.01783</a>
Code: This implementation borrows code from <a class="reference external" href="https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail">https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail</a> and
and Stable Baselines (<a class="reference external" href="https://github.com/hill-a/stable-baselines">https://github.com/hill-a/stable-baselines</a>)</p>
<p>Introduction to A2C: <a class="reference external" href="https://hackernoon.com/intuitive-rl-intro-to-advantage-actor-critic-a2c-4ff545978752">https://hackernoon.com/intuitive-rl-intro-to-advantage-actor-critic-a2c-4ff545978752</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>policy</strong> (<em>ActorCriticPolicy</em>) – The policy model to use (MlpPolicy, CnnPolicy, …)</p></li>
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.VecEnv"><em>VecEnv</em></a><em> | </em><em>str</em>) – The environment to learn from (if registered in Gym, can be str)</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – The learning rate, it can be a function
of the current progress remaining (from 1 to 0)</p></li>
<li><p><strong>n_steps</strong> (<em>int</em>) – The number of steps to run for each environment per update
(i.e. batch size is n_steps * n_env where n_env is number of environment copies running in parallel)</p></li>
<li><p><strong>gamma</strong> (<em>float</em>) – Discount factor</p></li>
<li><p><strong>gae_lambda</strong> (<em>float</em>) – Factor for trade-off of bias vs variance for Generalized Advantage Estimator.
Equivalent to classic advantage when set to 1.</p></li>
<li><p><strong>ent_coef</strong> (<em>float</em>) – Entropy coefficient for the loss calculation</p></li>
<li><p><strong>vf_coef</strong> (<em>float</em>) – Value function coefficient for the loss calculation</p></li>
<li><p><strong>max_grad_norm</strong> (<em>float</em>) – The maximum value for the gradient clipping</p></li>
<li><p><strong>rms_prop_eps</strong> (<em>float</em>) – RMSProp epsilon. It stabilizes square root computation in denominator
of RMSProp update</p></li>
<li><p><strong>use_rms_prop</strong> (<em>bool</em>) – Whether to use RMSprop (default) or Adam as optimizer</p></li>
<li><p><strong>use_sde</strong> (<em>bool</em>) – Whether to use generalized State Dependent Exploration (gSDE)
instead of action noise exploration (default: False)</p></li>
<li><p><strong>sde_sample_freq</strong> (<em>int</em>) – Sample a new noise matrix every n steps when using gSDE
Default: -1 (only sample at the beginning of the rollout)</p></li>
<li><p><strong>rollout_buffer_class</strong> (<em>Type</em><em>[</em><em>RolloutBuffer</em><em>] </em><em>| </em><em>None</em>) – Rollout buffer class to use. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, it will be automatically selected.</p></li>
<li><p><strong>rollout_buffer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments to pass to the rollout buffer on creation.</p></li>
<li><p><strong>normalize_advantage</strong> (<em>bool</em>) – Whether to normalize or not the advantage</p></li>
<li><p><strong>stats_window_size</strong> (<em>int</em>) – Window size for the rollout logging, specifying the number of episodes to average
the reported success rate, mean episode length, and mean reward over</p></li>
<li><p><strong>tensorboard_log</strong> (<em>str</em><em> | </em><em>None</em>) – the log location for tensorboard (if None, no logging)</p></li>
<li><p><strong>policy_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – additional arguments to be passed to the policy on creation</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 1 for info messages (such as device or wrappers used), 2 for
debug messages</p></li>
<li><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – Seed for the pseudo random generators</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device (cpu, cuda, …) on which the code should be run.
Setting it to auto, the code will be run on the GPU if possible.</p></li>
<li><p><strong>_init_setup_model</strong> (<em>bool</em>) – Whether or not to build the network at the creation of the instance</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.a2c.A2C.collect_rollouts">
<span class="sig-name descname"><span class="pre">collect_rollouts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rollout_buffer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_rollout_steps</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.a2c.A2C.collect_rollouts" title="Permalink to this definition"></a></dt>
<dd><p>Collect experiences using the current policy and fill a <code class="docutils literal notranslate"><span class="pre">RolloutBuffer</span></code>.
The term rollout here refers to the model-free notion and should not
be used with the concept of rollout used in model-based RL or planning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The training environment</p></li>
<li><p><strong>callback</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – Callback that will be called at each step
(and at the beginning and end of the rollout)</p></li>
<li><p><strong>rollout_buffer</strong> (<em>RolloutBuffer</em>) – Buffer to fill with rollouts</p></li>
<li><p><strong>n_rollout_steps</strong> (<em>int</em>) – Number of experiences to collect per environment</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>True if function returned with at least <cite>n_rollout_steps</cite>
collected, False if callback terminated rollout prematurely.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.a2c.A2C.get_env">
<span class="sig-name descname"><span class="pre">get_env</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.a2c.A2C.get_env" title="Permalink to this definition"></a></dt>
<dd><p>Returns the current environment (can be None if not defined).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The current environment</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.a2c.A2C.get_parameters">
<span class="sig-name descname"><span class="pre">get_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.a2c.A2C.get_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Return the parameters of the agent. This includes parameters from different networks, e.g.
critics (value functions) and policies (pi functions).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Mapping of from names of the objects to PyTorch state-dicts.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Dict</em>[str, <em>Dict</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.a2c.A2C.get_vec_normalize_env">
<span class="sig-name descname"><span class="pre">get_vec_normalize_env</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.a2c.A2C.get_vec_normalize_env" title="Permalink to this definition"></a></dt>
<dd><p>Return the <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> wrapper of the training env
if it exists.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> env.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecNormalize" title="stable_baselines3.common.vec_env.vec_normalize.VecNormalize"><em>VecNormalize</em></a> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.a2c.A2C.learn">
<span class="sig-name descname"><span class="pre">learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">total_timesteps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tb_log_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'A2C'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_num_timesteps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">progress_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/a2c/a2c.html#A2C.learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.a2c.A2C.learn" title="Permalink to this definition"></a></dt>
<dd><p>Return a trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>total_timesteps</strong> (<em>int</em>) – The total number of samples (env steps) to train on</p></li>
<li><p><strong>callback</strong> (<em>None</em><em> | </em><em>Callable</em><em> | </em><em>List</em><em>[</em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a><em>] </em><em>| </em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – callback(s) called at every step with state of the algorithm.</p></li>
<li><p><strong>log_interval</strong> (<em>int</em>) – The number of episodes before logging.</p></li>
<li><p><strong>tb_log_name</strong> (<em>str</em>) – the name of the run for TensorBoard logging</p></li>
<li><p><strong>reset_num_timesteps</strong> (<em>bool</em>) – whether or not to reset the current timestep number (used in logging)</p></li>
<li><p><strong>progress_bar</strong> (<em>bool</em>) – Display a progress bar using tqdm and rich.</p></li>
<li><p><strong>self</strong> (<em>SelfA2C</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the trained model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfA2C</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.a2c.A2C.load">
<em class="property"><span class="pre">classmethod</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_objects</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_system_info</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_reset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.a2c.A2C.load" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a zip-file.
Warning: <code class="docutils literal notranslate"><span class="pre">load</span></code> re-creates the model from scratch, it does not update it in-place!
For an in-place load use <code class="docutils literal notranslate"><span class="pre">set_parameters</span></code> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – path to the file (or a file-like) where to
load the agent from</p></li>
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a><em> | </em><em>None</em>) – the new environment to run the loaded model on
(can be None if you only need prediction from a trained model) has priority over any saved environment</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device on which the code should run.</p></li>
<li><p><strong>custom_objects</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Dictionary of objects to replace
upon loading. If a variable is present in this dictionary as a
key, it will not be deserialized and the corresponding item
will be used instead. Similar to custom_objects in
<code class="docutils literal notranslate"><span class="pre">keras.models.load_model</span></code>. Useful when you have an object in
file that can not be deserialized.</p></li>
<li><p><strong>print_system_info</strong> (<em>bool</em>) – Whether to print system info from the saved model
and the current system info (useful to debug loading issues)</p></li>
<li><p><strong>force_reset</strong> (<em>bool</em>) – Force call to <code class="docutils literal notranslate"><span class="pre">reset()</span></code> before training
to avoid unexpected behavior.
See <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/597">https://github.com/DLR-RM/stable-baselines3/issues/597</a></p></li>
<li><p><strong>kwargs</strong> – extra arguments to change the model when loading</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>new model instance with loaded parameters</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfBaseAlgorithm</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="stable_baselines3.a2c.A2C.logger">
<em class="property"><span class="pre">property</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">logger</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><a class="reference internal" href="index.html#stable_baselines3.common.logger.Logger" title="stable_baselines3.common.logger.Logger"><span class="pre">Logger</span></a></em><a class="headerlink" href="#stable_baselines3.a2c.A2C.logger" title="Permalink to this definition"></a></dt>
<dd><p>Getter for the logger object.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.a2c.A2C.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">episode_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.a2c.A2C.predict" title="Permalink to this definition"></a></dt>
<dd><p>Get the policy action from an observation (and optional hidden state).
Includes sugar-coating to handle different observations (e.g. normalizing images).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation</strong> (<em>ndarray</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>ndarray</em><em>]</em>) – the input observation</p></li>
<li><p><strong>state</strong> (<em>Tuple</em><em>[</em><em>ndarray</em><em>, </em><em>...</em><em>] </em><em>| </em><em>None</em>) – The last hidden states (can be None, used in recurrent policies)</p></li>
<li><p><strong>episode_start</strong> (<em>ndarray</em><em> | </em><em>None</em>) – The last masks (can be None, used in recurrent policies)
this correspond to beginning of episodes,
where the hidden states of the RNN must be reset.</p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – Whether or not to return deterministic actions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the model’s action and the next hidden state
(used in recurrent policies)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>ndarray</em>, <em>Tuple</em>[<em>ndarray</em>, …] | None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.a2c.A2C.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.a2c.A2C.save" title="Permalink to this definition"></a></dt>
<dd><p>Save all the attributes of the object and the model parameters in a zip-file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – path to the file where the rl agent should be saved</p></li>
<li><p><strong>exclude</strong> (<em>Iterable</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – name of parameters that should be excluded in addition to the default ones</p></li>
<li><p><strong>include</strong> (<em>Iterable</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – name of parameters that might be excluded but should be included anyway</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.a2c.A2C.set_env">
<span class="sig-name descname"><span class="pre">set_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_reset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.a2c.A2C.set_env" title="Permalink to this definition"></a></dt>
<dd><p>Checks the validity of the environment, and if it is coherent, set it as the current environment.
Furthermore wrap any non vectorized env into a vectorized
checked parameters:
- observation_space
- action_space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The environment for learning a policy</p></li>
<li><p><strong>force_reset</strong> (<em>bool</em>) – Force call to <code class="docutils literal notranslate"><span class="pre">reset()</span></code> before training
to avoid unexpected behavior.
See issue <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/597">https://github.com/DLR-RM/stable-baselines3/issues/597</a></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.a2c.A2C.set_logger">
<span class="sig-name descname"><span class="pre">set_logger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.a2c.A2C.set_logger" title="Permalink to this definition"></a></dt>
<dd><p>Setter for for logger object.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When passing a custom logger object,
this will overwrite <code class="docutils literal notranslate"><span class="pre">tensorboard_log</span></code> and <code class="docutils literal notranslate"><span class="pre">verbose</span></code> settings
passed to the constructor.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>logger</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.logger.Logger" title="stable_baselines3.common.logger.Logger"><em>Logger</em></a>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.a2c.A2C.set_parameters">
<span class="sig-name descname"><span class="pre">set_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">load_path_or_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exact_match</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.a2c.A2C.set_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Load parameters from a given zip-file or a nested dictionary containing parameters for
different modules (see <code class="docutils literal notranslate"><span class="pre">get_parameters</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>load_path_or_iter</strong> – Location of the saved data (path or file-like, see <code class="docutils literal notranslate"><span class="pre">save</span></code>), or a nested
dictionary containing nn.Module parameters used by the policy. The dictionary maps
object names to a state-dictionary returned by <code class="docutils literal notranslate"><span class="pre">torch.nn.Module.state_dict()</span></code>.</p></li>
<li><p><strong>exact_match</strong> (<em>bool</em>) – If True, the given parameters should include parameters for each
module and each of their parameters, otherwise raises an Exception. If set to False, this
can be used to update only specific parameters.</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device on which the code should run.</p></li>
<li><p><strong>load_path_or_dict</strong> (<em>str</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.a2c.A2C.set_random_seed">
<span class="sig-name descname"><span class="pre">set_random_seed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.a2c.A2C.set_random_seed" title="Permalink to this definition"></a></dt>
<dd><p>Set the seed of the pseudo-random generators
(python, numpy, pytorch, gym, action_space)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.a2c.A2C.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/a2c/a2c.html#A2C.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.a2c.A2C.train" title="Permalink to this definition"></a></dt>
<dd><p>Update policy using the currently gathered
rollout buffer (one gradient step over whole data).</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="a2c-policies">
<h4>A2C Policies<a class="headerlink" href="#a2c-policies" title="Permalink to this heading"></a></h4>
<dl class="py attribute">
<dt class="sig sig-object py" id="stable_baselines3.a2c.MlpPolicy">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.a2c.</span></span><span class="sig-name descname"><span class="pre">MlpPolicy</span></span><a class="headerlink" href="#stable_baselines3.a2c.MlpPolicy" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">ActorCriticPolicy</span></code></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.policies.</span></span><span class="sig-name descname"><span class="pre">ActorCriticPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.Tanh'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ortho_init=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std_init=0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_std=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_expln=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">squash_output=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.FlattenExtractor'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share_features_extractor=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#ActorCriticPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Policy class for actor-critic algorithms (has both policy and value prediction).
Used by A2C, PPO and the likes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Space</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Space</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>ortho_init</strong> (<em>bool</em>) – Whether to use or not orthogonal initialization</p></li>
<li><p><strong>use_sde</strong> (<em>bool</em>) – Whether to use State Dependent Exploration or not</p></li>
<li><p><strong>log_std_init</strong> (<em>float</em>) – Initial value for the log standard deviation</p></li>
<li><p><strong>full_std</strong> (<em>bool</em>) – Whether to use (n_features x n_actions) parameters
for the std instead of only (n_features,) when using gSDE</p></li>
<li><p><strong>use_expln</strong> (<em>bool</em>) – Use <code class="docutils literal notranslate"><span class="pre">expln()</span></code> function instead of <code class="docutils literal notranslate"><span class="pre">exp()</span></code> to ensure
a positive standard deviation (cf paper). It allows to keep variance
above zero and prevent it from growing too fast. In practice, <code class="docutils literal notranslate"><span class="pre">exp()</span></code> is usually enough.</p></li>
<li><p><strong>squash_output</strong> (<em>bool</em>) – Whether to squash the output using a tanh function,
this allows to ensure boundaries when using gSDE.</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Features extractor to use.</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments
to pass to the features extractor.</p></li>
<li><p><strong>share_features_extractor</strong> (<em>bool</em>) – If True, the features extractor is shared between the policy and value networks.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">evaluate_actions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">actions</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#ActorCriticPolicy.evaluate_actions"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Evaluate actions according to the current policy,
given the observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs</strong> (<em>Tensor</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – Observation</p></li>
<li><p><strong>actions</strong> (<em>Tensor</em>) – Actions</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>estimated value, log likelihood of taking those actions
and entropy of the action distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>, <em>Tensor</em> | None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">extract_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#ActorCriticPolicy.extract_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Preprocess the observation if needed and extract features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs</strong> (<em>Tensor</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – Observation</p></li>
<li><p><strong>features_extractor</strong> (<em>BaseFeaturesExtractor</em><em> | </em><em>None</em>) – The features extractor to use. If None, then <code class="docutils literal notranslate"><span class="pre">self.features_extractor</span></code> is used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The extracted features. If features extractor is not shared, returns a tuple with the
features for the actor and the features for the critic.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em> | <em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#ActorCriticPolicy.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Forward pass in all the networks (actor and critic)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs</strong> (<em>Tensor</em>) – Observation</p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – Whether to sample or use deterministic actions</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>action, value and log probability of the action</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">get_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#ActorCriticPolicy.get_distribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Get the current policy distribution given the observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>obs</strong> (<em>Tensor</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the action distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="index.html#stable_baselines3.common.distributions.Distribution" title="stable_baselines3.common.distributions.Distribution"><em>Distribution</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">predict_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#ActorCriticPolicy.predict_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Get the estimated values according to the current policy given the observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>obs</strong> (<em>Tensor</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – Observation</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the estimated values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">reset_noise</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_envs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#ActorCriticPolicy.reset_noise"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Sample new weights for the exploration matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>n_envs</strong> (<em>int</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="stable_baselines3.a2c.CnnPolicy">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.a2c.</span></span><span class="sig-name descname"><span class="pre">CnnPolicy</span></span><a class="headerlink" href="#stable_baselines3.a2c.CnnPolicy" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">ActorCriticCnnPolicy</span></code></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.policies.</span></span><span class="sig-name descname"><span class="pre">ActorCriticCnnPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.Tanh'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ortho_init=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std_init=0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_std=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_expln=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">squash_output=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.NatureCNN'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share_features_extractor=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#ActorCriticCnnPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>CNN policy class for actor-critic algorithms (has both policy and value prediction).
Used by A2C, PPO and the likes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Space</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Space</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>ortho_init</strong> (<em>bool</em>) – Whether to use or not orthogonal initialization</p></li>
<li><p><strong>use_sde</strong> (<em>bool</em>) – Whether to use State Dependent Exploration or not</p></li>
<li><p><strong>log_std_init</strong> (<em>float</em>) – Initial value for the log standard deviation</p></li>
<li><p><strong>full_std</strong> (<em>bool</em>) – Whether to use (n_features x n_actions) parameters
for the std instead of only (n_features,) when using gSDE</p></li>
<li><p><strong>use_expln</strong> (<em>bool</em>) – Use <code class="docutils literal notranslate"><span class="pre">expln()</span></code> function instead of <code class="docutils literal notranslate"><span class="pre">exp()</span></code> to ensure
a positive standard deviation (cf paper). It allows to keep variance
above zero and prevent it from growing too fast. In practice, <code class="docutils literal notranslate"><span class="pre">exp()</span></code> is usually enough.</p></li>
<li><p><strong>squash_output</strong> (<em>bool</em>) – Whether to squash the output using a tanh function,
this allows to ensure boundaries when using gSDE.</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Features extractor to use.</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments
to pass to the features extractor.</p></li>
<li><p><strong>share_features_extractor</strong> (<em>bool</em>) – If True, the features extractor is shared between the policy and value networks.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="stable_baselines3.a2c.MultiInputPolicy">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.a2c.</span></span><span class="sig-name descname"><span class="pre">MultiInputPolicy</span></span><a class="headerlink" href="#stable_baselines3.a2c.MultiInputPolicy" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">MultiInputActorCriticPolicy</span></code></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.policies.</span></span><span class="sig-name descname"><span class="pre">MultiInputActorCriticPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.Tanh'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ortho_init=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std_init=0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_std=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_expln=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">squash_output=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.CombinedExtractor'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share_features_extractor=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#MultiInputActorCriticPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>MultiInputActorClass policy class for actor-critic algorithms (has both policy and value prediction).
Used by A2C, PPO and the likes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Dict</em>) – Observation space (Tuple)</p></li>
<li><p><strong>action_space</strong> (<em>Space</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>ortho_init</strong> (<em>bool</em>) – Whether to use or not orthogonal initialization</p></li>
<li><p><strong>use_sde</strong> (<em>bool</em>) – Whether to use State Dependent Exploration or not</p></li>
<li><p><strong>log_std_init</strong> (<em>float</em>) – Initial value for the log standard deviation</p></li>
<li><p><strong>full_std</strong> (<em>bool</em>) – Whether to use (n_features x n_actions) parameters
for the std instead of only (n_features,) when using gSDE</p></li>
<li><p><strong>use_expln</strong> (<em>bool</em>) – Use <code class="docutils literal notranslate"><span class="pre">expln()</span></code> function instead of <code class="docutils literal notranslate"><span class="pre">exp()</span></code> to ensure
a positive standard deviation (cf paper). It allows to keep variance
above zero and prevent it from growing too fast. In practice, <code class="docutils literal notranslate"><span class="pre">exp()</span></code> is usually enough.</p></li>
<li><p><strong>squash_output</strong> (<em>bool</em>) – Whether to squash the output using a tanh function,
this allows to ensure boundaries when using gSDE.</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Uses the CombinedExtractor</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments
to pass to the features extractor.</p></li>
<li><p><strong>share_features_extractor</strong> (<em>bool</em>) – If True, the features extractor is shared between the policy and value networks.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
<span id="document-modules/ddpg"></span><span class="target" id="module-stable_baselines3.ddpg"><span id="ddpg"></span></span><section id="id1">
<h3>DDPG<a class="headerlink" href="#id1" title="Permalink to this heading"></a></h3>
<p><a class="reference external" href="https://spinningup.openai.com/en/latest/algorithms/ddpg.html">Deep Deterministic Policy Gradient (DDPG)</a> combines the
trick for DQN with the deterministic policy gradient, to obtain an algorithm for continuous actions.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As <code class="docutils literal notranslate"><span class="pre">DDPG</span></code> can be seen as a special case of its successor <a class="reference internal" href="index.html#td3"><span class="std std-ref">TD3</span></a>,
they share the same policies and same implementation.</p>
</div>
<p class="rubric">Available Policies</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#stable_baselines3.ddpg.MlpPolicy" title="stable_baselines3.ddpg.MlpPolicy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MlpPolicy</span></code></a></p></td>
<td><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">TD3Policy</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">CnnPolicy</span></code></p></td>
<td><p>Policy class (with both actor and critic) for TD3.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiInputPolicy</span></code></p></td>
<td><p>Policy class (with both actor and critic) for TD3 to be used with Dict observation spaces.</p></td>
</tr>
</tbody>
</table>
<section id="notes">
<h4>Notes<a class="headerlink" href="#notes" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Deterministic Policy Gradient: <a class="reference external" href="http://proceedings.mlr.press/v32/silver14.pdf">http://proceedings.mlr.press/v32/silver14.pdf</a></p></li>
<li><p>DDPG Paper: <a class="reference external" href="https://arxiv.org/abs/1509.02971">https://arxiv.org/abs/1509.02971</a></p></li>
<li><p>OpenAI Spinning Guide for DDPG: <a class="reference external" href="https://spinningup.openai.com/en/latest/algorithms/ddpg.html">https://spinningup.openai.com/en/latest/algorithms/ddpg.html</a></p></li>
</ul>
</section>
<section id="can-i-use">
<h4>Can I use?<a class="headerlink" href="#can-i-use" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Recurrent policies: ❌</p></li>
<li><p>Multi processing: ✔️</p></li>
<li><p>Gym spaces:</p></li>
</ul>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Space</p></th>
<th class="head"><p>Action</p></th>
<th class="head"><p>Observation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Discrete</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>Box</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>MultiDiscrete</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>MultiBinary</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>Dict</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
</tbody>
</table>
</section>
<section id="example">
<h4>Example<a class="headerlink" href="#example" title="Permalink to this heading"></a></h4>
<p>This example is only to demonstrate the use of the library and its functions, and the trained agents may not solve the environments. Optimized hyperparameters can be found in RL Zoo <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">repository</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">DDPG</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.noise</span> <span class="kn">import</span> <span class="n">NormalActionNoise</span><span class="p">,</span> <span class="n">OrnsteinUhlenbeckActionNoise</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">)</span>

<span class="c1"># The noise objects for DDPG</span>
<span class="n">n_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">action_noise</span> <span class="o">=</span> <span class="n">NormalActionNoise</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_actions</span><span class="p">),</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_actions</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">DDPG</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">action_noise</span><span class="o">=</span><span class="n">action_noise</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;ddpg_pendulum&quot;</span><span class="p">)</span>
<span class="n">vec_env</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_env</span><span class="p">()</span>

<span class="k">del</span> <span class="n">model</span> <span class="c1"># remove to demonstrate saving and loading</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">DDPG</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;ddpg_pendulum&quot;</span><span class="p">)</span>

<span class="n">obs</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">_states</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">dones</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="results">
<h4>Results<a class="headerlink" href="#results" title="Permalink to this heading"></a></h4>
<section id="pybullet-environments">
<h5>PyBullet Environments<a class="headerlink" href="#pybullet-environments" title="Permalink to this heading"></a></h5>
<p>Results on the PyBullet benchmark (1M steps) using 6 seeds.
The complete learning curves are available in the <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/48">associated issue #48</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Hyperparameters of <a class="reference internal" href="index.html#td3"><span class="std std-ref">TD3</span></a> from the <a class="reference external" href="https://arxiv.org/abs/2005.05719">gSDE paper</a> were used for <code class="docutils literal notranslate"><span class="pre">DDPG</span></code>.</p>
</div>
<p><em>Gaussian</em> means that the unstructured Gaussian noise is used for exploration,
<em>gSDE</em> (generalized State-Dependent Exploration) is used otherwise.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Environments</p></th>
<th class="head"><p>DDPG</p></th>
<th class="head"><p>TD3</p></th>
<th class="head"><p>SAC</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td></td>
<td><p>Gaussian</p></td>
<td><p>Gaussian</p></td>
<td><p>gSDE</p></td>
</tr>
<tr class="row-odd"><td><p>HalfCheetah</p></td>
<td><p>2272 +/- 69</p></td>
<td><p>2774 +/- 35</p></td>
<td><p>2984 +/- 202</p></td>
</tr>
<tr class="row-even"><td><p>Ant</p></td>
<td><p>1651 +/- 407</p></td>
<td><p>3305 +/- 43</p></td>
<td><p>3102 +/- 37</p></td>
</tr>
<tr class="row-odd"><td><p>Hopper</p></td>
<td><p>1201 +/- 211</p></td>
<td><p>2429 +/- 126</p></td>
<td><p>2262 +/- 1</p></td>
</tr>
<tr class="row-even"><td><p>Walker2D</p></td>
<td><p>882 +/- 186</p></td>
<td><p>2063 +/- 185</p></td>
<td><p>2136 +/- 67</p></td>
</tr>
</tbody>
</table>
</section>
<section id="how-to-replicate-the-results">
<h5>How to replicate the results?<a class="headerlink" href="#how-to-replicate-the-results" title="Permalink to this heading"></a></h5>
<p>Clone the <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">rl-zoo repo</a>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/DLR-RM/rl-baselines3-zoo
<span class="nb">cd</span><span class="w"> </span>rl-baselines3-zoo/
</pre></div>
</div>
<p>Run the benchmark (replace <code class="docutils literal notranslate"><span class="pre">$ENV_ID</span></code> by the envs mentioned above):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>train.py<span class="w"> </span>--algo<span class="w"> </span>ddpg<span class="w"> </span>--env<span class="w"> </span><span class="nv">$ENV_ID</span><span class="w"> </span>--eval-episodes<span class="w"> </span><span class="m">10</span><span class="w"> </span>--eval-freq<span class="w"> </span><span class="m">10000</span>
</pre></div>
</div>
<p>Plot the results:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>scripts/all_plots.py<span class="w"> </span>-a<span class="w"> </span>ddpg<span class="w"> </span>-e<span class="w"> </span>HalfCheetah<span class="w"> </span>Ant<span class="w"> </span>Hopper<span class="w"> </span>Walker2D<span class="w"> </span>-f<span class="w"> </span>logs/<span class="w"> </span>-o<span class="w"> </span>logs/ddpg_results
python<span class="w"> </span>scripts/plot_from_file.py<span class="w"> </span>-i<span class="w"> </span>logs/ddpg_results.pkl<span class="w"> </span>-latex<span class="w"> </span>-l<span class="w"> </span>DDPG
</pre></div>
</div>
</section>
</section>
<section id="parameters">
<h4>Parameters<a class="headerlink" href="#parameters" title="Permalink to this heading"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.DDPG">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.ddpg.</span></span><span class="sig-name descname"><span class="pre">DDPG</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">policy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_starts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.005</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(1,</span> <span class="pre">'episode')</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_buffer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_buffer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimize_memory_usage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensorboard_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_init_setup_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/ddpg/ddpg.html#DDPG"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.ddpg.DDPG" title="Permalink to this definition"></a></dt>
<dd><p>Deep Deterministic Policy Gradient (DDPG).</p>
<p>Deterministic Policy Gradient: <a class="reference external" href="http://proceedings.mlr.press/v32/silver14.pdf">http://proceedings.mlr.press/v32/silver14.pdf</a>
DDPG Paper: <a class="reference external" href="https://arxiv.org/abs/1509.02971">https://arxiv.org/abs/1509.02971</a>
Introduction to DDPG: <a class="reference external" href="https://spinningup.openai.com/en/latest/algorithms/ddpg.html">https://spinningup.openai.com/en/latest/algorithms/ddpg.html</a></p>
<p>Note: we treat DDPG as a special case of its successor TD3.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>policy</strong> (<em>TD3Policy</em>) – The policy model to use (MlpPolicy, CnnPolicy, …)</p></li>
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.VecEnv"><em>VecEnv</em></a><em> | </em><em>str</em>) – The environment to learn from (if registered in Gym, can be str)</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – learning rate for adam optimizer,
the same learning rate will be used for all networks (Q-Values, Actor and Value function)
it can be a function of the current progress remaining (from 1 to 0)</p></li>
<li><p><strong>buffer_size</strong> (<em>int</em>) – size of the replay buffer</p></li>
<li><p><strong>learning_starts</strong> (<em>int</em>) – how many steps of the model to collect transitions for before learning starts</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Minibatch size for each gradient update</p></li>
<li><p><strong>tau</strong> (<em>float</em>) – the soft update coefficient (“Polyak update”, between 0 and 1)</p></li>
<li><p><strong>gamma</strong> (<em>float</em>) – the discount factor</p></li>
<li><p><strong>train_freq</strong> (<em>int</em><em> | </em><em>Tuple</em><em>[</em><em>int</em><em>, </em><em>str</em><em>]</em>) – Update the model every <code class="docutils literal notranslate"><span class="pre">train_freq</span></code> steps. Alternatively pass a tuple of frequency and unit
like <code class="docutils literal notranslate"><span class="pre">(5,</span> <span class="pre">&quot;step&quot;)</span></code> or <code class="docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">&quot;episode&quot;)</span></code>.</p></li>
<li><p><strong>gradient_steps</strong> (<em>int</em>) – How many gradient steps to do after each rollout (see <code class="docutils literal notranslate"><span class="pre">train_freq</span></code>)
Set to <code class="docutils literal notranslate"><span class="pre">-1</span></code> means to do as many gradient steps as steps done in the environment
during the rollout.</p></li>
<li><p><strong>action_noise</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.noise.ActionNoise" title="stable_baselines3.common.noise.ActionNoise"><em>ActionNoise</em></a><em> | </em><em>None</em>) – the action noise type (None by default), this can help
for hard exploration problem. Cf common.noise for the different action noise type.</p></li>
<li><p><strong>replay_buffer_class</strong> (<em>Type</em><em>[</em><em>ReplayBuffer</em><em>] </em><em>| </em><em>None</em>) – Replay buffer class to use (for instance <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code>).
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, it will be automatically selected.</p></li>
<li><p><strong>replay_buffer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments to pass to the replay buffer on creation.</p></li>
<li><p><strong>optimize_memory_usage</strong> (<em>bool</em>) – Enable a memory efficient variant of the replay buffer
at a cost of more complexity.
See <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195">https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195</a></p></li>
<li><p><strong>policy_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – additional arguments to be passed to the policy on creation</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 1 for info messages (such as device or wrappers used), 2 for
debug messages</p></li>
<li><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – Seed for the pseudo random generators</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device (cpu, cuda, …) on which the code should be run.
Setting it to auto, the code will be run on the GPU if possible.</p></li>
<li><p><strong>_init_setup_model</strong> (<em>bool</em>) – Whether or not to build the network at the creation of the instance</p></li>
<li><p><strong>tensorboard_log</strong> (<em>str</em><em> | </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.DDPG.collect_rollouts">
<span class="sig-name descname"><span class="pre">collect_rollouts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_freq</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_buffer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_starts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ddpg.DDPG.collect_rollouts" title="Permalink to this definition"></a></dt>
<dd><p>Collect experiences and store them into a <code class="docutils literal notranslate"><span class="pre">ReplayBuffer</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The training environment</p></li>
<li><p><strong>callback</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – Callback that will be called at each step
(and at the beginning and end of the rollout)</p></li>
<li><p><strong>train_freq</strong> (<em>TrainFreq</em>) – How much experience to collect
by doing rollouts of current policy.
Either <code class="docutils literal notranslate"><span class="pre">TrainFreq(&lt;n&gt;,</span> <span class="pre">TrainFrequencyUnit.STEP)</span></code>
or <code class="docutils literal notranslate"><span class="pre">TrainFreq(&lt;n&gt;,</span> <span class="pre">TrainFrequencyUnit.EPISODE)</span></code>
with <code class="docutils literal notranslate"><span class="pre">&lt;n&gt;</span></code> being an integer greater than 0.</p></li>
<li><p><strong>action_noise</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.noise.ActionNoise" title="stable_baselines3.common.noise.ActionNoise"><em>ActionNoise</em></a><em> | </em><em>None</em>) – Action noise that will be used for exploration
Required for deterministic policy (e.g. TD3). This can also be used
in addition to the stochastic policy for SAC.</p></li>
<li><p><strong>learning_starts</strong> (<em>int</em>) – Number of steps before learning for the warm-up phase.</p></li>
<li><p><strong>replay_buffer</strong> (<em>ReplayBuffer</em>) – </p></li>
<li><p><strong>log_interval</strong> (<em>int</em><em> | </em><em>None</em>) – Log data every <code class="docutils literal notranslate"><span class="pre">log_interval</span></code> episodes</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>RolloutReturn</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.DDPG.get_env">
<span class="sig-name descname"><span class="pre">get_env</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ddpg.DDPG.get_env" title="Permalink to this definition"></a></dt>
<dd><p>Returns the current environment (can be None if not defined).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The current environment</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.DDPG.get_parameters">
<span class="sig-name descname"><span class="pre">get_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ddpg.DDPG.get_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Return the parameters of the agent. This includes parameters from different networks, e.g.
critics (value functions) and policies (pi functions).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Mapping of from names of the objects to PyTorch state-dicts.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Dict</em>[str, <em>Dict</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.DDPG.get_vec_normalize_env">
<span class="sig-name descname"><span class="pre">get_vec_normalize_env</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ddpg.DDPG.get_vec_normalize_env" title="Permalink to this definition"></a></dt>
<dd><p>Return the <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> wrapper of the training env
if it exists.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> env.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecNormalize" title="stable_baselines3.common.vec_env.vec_normalize.VecNormalize"><em>VecNormalize</em></a> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.DDPG.learn">
<span class="sig-name descname"><span class="pre">learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">total_timesteps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tb_log_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'DDPG'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_num_timesteps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">progress_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/ddpg/ddpg.html#DDPG.learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.ddpg.DDPG.learn" title="Permalink to this definition"></a></dt>
<dd><p>Return a trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>total_timesteps</strong> (<em>int</em>) – The total number of samples (env steps) to train on</p></li>
<li><p><strong>callback</strong> (<em>None</em><em> | </em><em>Callable</em><em> | </em><em>List</em><em>[</em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a><em>] </em><em>| </em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – callback(s) called at every step with state of the algorithm.</p></li>
<li><p><strong>log_interval</strong> (<em>int</em>) – The number of episodes before logging.</p></li>
<li><p><strong>tb_log_name</strong> (<em>str</em>) – the name of the run for TensorBoard logging</p></li>
<li><p><strong>reset_num_timesteps</strong> (<em>bool</em>) – whether or not to reset the current timestep number (used in logging)</p></li>
<li><p><strong>progress_bar</strong> (<em>bool</em>) – Display a progress bar using tqdm and rich.</p></li>
<li><p><strong>self</strong> (<em>SelfDDPG</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the trained model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfDDPG</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.DDPG.load">
<em class="property"><span class="pre">classmethod</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_objects</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_system_info</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_reset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ddpg.DDPG.load" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a zip-file.
Warning: <code class="docutils literal notranslate"><span class="pre">load</span></code> re-creates the model from scratch, it does not update it in-place!
For an in-place load use <code class="docutils literal notranslate"><span class="pre">set_parameters</span></code> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – path to the file (or a file-like) where to
load the agent from</p></li>
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a><em> | </em><em>None</em>) – the new environment to run the loaded model on
(can be None if you only need prediction from a trained model) has priority over any saved environment</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device on which the code should run.</p></li>
<li><p><strong>custom_objects</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Dictionary of objects to replace
upon loading. If a variable is present in this dictionary as a
key, it will not be deserialized and the corresponding item
will be used instead. Similar to custom_objects in
<code class="docutils literal notranslate"><span class="pre">keras.models.load_model</span></code>. Useful when you have an object in
file that can not be deserialized.</p></li>
<li><p><strong>print_system_info</strong> (<em>bool</em>) – Whether to print system info from the saved model
and the current system info (useful to debug loading issues)</p></li>
<li><p><strong>force_reset</strong> (<em>bool</em>) – Force call to <code class="docutils literal notranslate"><span class="pre">reset()</span></code> before training
to avoid unexpected behavior.
See <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/597">https://github.com/DLR-RM/stable-baselines3/issues/597</a></p></li>
<li><p><strong>kwargs</strong> – extra arguments to change the model when loading</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>new model instance with loaded parameters</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfBaseAlgorithm</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.DDPG.load_replay_buffer">
<span class="sig-name descname"><span class="pre">load_replay_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truncate_last_traj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ddpg.DDPG.load_replay_buffer" title="Permalink to this definition"></a></dt>
<dd><p>Load a replay buffer from a pickle file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – Path to the pickled replay buffer.</p></li>
<li><p><strong>truncate_last_traj</strong> (<em>bool</em>) – When using <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code> with online sampling:
If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, we assume that the last trajectory in the replay buffer was finished
(and truncate it).
If set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, we assume that we continue the same trajectory (same episode).</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.DDPG.logger">
<em class="property"><span class="pre">property</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">logger</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><a class="reference internal" href="index.html#stable_baselines3.common.logger.Logger" title="stable_baselines3.common.logger.Logger"><span class="pre">Logger</span></a></em><a class="headerlink" href="#stable_baselines3.ddpg.DDPG.logger" title="Permalink to this definition"></a></dt>
<dd><p>Getter for the logger object.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.DDPG.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">episode_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ddpg.DDPG.predict" title="Permalink to this definition"></a></dt>
<dd><p>Get the policy action from an observation (and optional hidden state).
Includes sugar-coating to handle different observations (e.g. normalizing images).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation</strong> (<em>ndarray</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>ndarray</em><em>]</em>) – the input observation</p></li>
<li><p><strong>state</strong> (<em>Tuple</em><em>[</em><em>ndarray</em><em>, </em><em>...</em><em>] </em><em>| </em><em>None</em>) – The last hidden states (can be None, used in recurrent policies)</p></li>
<li><p><strong>episode_start</strong> (<em>ndarray</em><em> | </em><em>None</em>) – The last masks (can be None, used in recurrent policies)
this correspond to beginning of episodes,
where the hidden states of the RNN must be reset.</p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – Whether or not to return deterministic actions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the model’s action and the next hidden state
(used in recurrent policies)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>ndarray</em>, <em>Tuple</em>[<em>ndarray</em>, …] | None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.DDPG.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ddpg.DDPG.save" title="Permalink to this definition"></a></dt>
<dd><p>Save all the attributes of the object and the model parameters in a zip-file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – path to the file where the rl agent should be saved</p></li>
<li><p><strong>exclude</strong> (<em>Iterable</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – name of parameters that should be excluded in addition to the default ones</p></li>
<li><p><strong>include</strong> (<em>Iterable</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – name of parameters that might be excluded but should be included anyway</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.DDPG.save_replay_buffer">
<span class="sig-name descname"><span class="pre">save_replay_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ddpg.DDPG.save_replay_buffer" title="Permalink to this definition"></a></dt>
<dd><p>Save the replay buffer as a pickle file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – Path to the file where the replay buffer should be saved.
if path is a str or pathlib.Path, the path is automatically created if necessary.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.DDPG.set_env">
<span class="sig-name descname"><span class="pre">set_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_reset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ddpg.DDPG.set_env" title="Permalink to this definition"></a></dt>
<dd><p>Checks the validity of the environment, and if it is coherent, set it as the current environment.
Furthermore wrap any non vectorized env into a vectorized
checked parameters:
- observation_space
- action_space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The environment for learning a policy</p></li>
<li><p><strong>force_reset</strong> (<em>bool</em>) – Force call to <code class="docutils literal notranslate"><span class="pre">reset()</span></code> before training
to avoid unexpected behavior.
See issue <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/597">https://github.com/DLR-RM/stable-baselines3/issues/597</a></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.DDPG.set_logger">
<span class="sig-name descname"><span class="pre">set_logger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ddpg.DDPG.set_logger" title="Permalink to this definition"></a></dt>
<dd><p>Setter for for logger object.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When passing a custom logger object,
this will overwrite <code class="docutils literal notranslate"><span class="pre">tensorboard_log</span></code> and <code class="docutils literal notranslate"><span class="pre">verbose</span></code> settings
passed to the constructor.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>logger</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.logger.Logger" title="stable_baselines3.common.logger.Logger"><em>Logger</em></a>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.DDPG.set_parameters">
<span class="sig-name descname"><span class="pre">set_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">load_path_or_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exact_match</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ddpg.DDPG.set_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Load parameters from a given zip-file or a nested dictionary containing parameters for
different modules (see <code class="docutils literal notranslate"><span class="pre">get_parameters</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>load_path_or_iter</strong> – Location of the saved data (path or file-like, see <code class="docutils literal notranslate"><span class="pre">save</span></code>), or a nested
dictionary containing nn.Module parameters used by the policy. The dictionary maps
object names to a state-dictionary returned by <code class="docutils literal notranslate"><span class="pre">torch.nn.Module.state_dict()</span></code>.</p></li>
<li><p><strong>exact_match</strong> (<em>bool</em>) – If True, the given parameters should include parameters for each
module and each of their parameters, otherwise raises an Exception. If set to False, this
can be used to update only specific parameters.</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device on which the code should run.</p></li>
<li><p><strong>load_path_or_dict</strong> (<em>str</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.DDPG.set_random_seed">
<span class="sig-name descname"><span class="pre">set_random_seed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ddpg.DDPG.set_random_seed" title="Permalink to this definition"></a></dt>
<dd><p>Set the seed of the pseudo-random generators
(python, numpy, pytorch, gym, action_space)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.DDPG.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradient_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ddpg.DDPG.train" title="Permalink to this definition"></a></dt>
<dd><p>Sample the replay buffer and do the updates
(gradient descent and update target networks)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gradient_steps</strong> (<em>int</em>) – </p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="ddpg-policies">
<span id="id2"></span><h4>DDPG Policies<a class="headerlink" href="#ddpg-policies" title="Permalink to this heading"></a></h4>
<dl class="py attribute">
<dt class="sig sig-object py" id="stable_baselines3.ddpg.MlpPolicy">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.ddpg.</span></span><span class="sig-name descname"><span class="pre">MlpPolicy</span></span><a class="headerlink" href="#stable_baselines3.ddpg.MlpPolicy" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">TD3Policy</span></code></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.td3.policies.</span></span><span class="sig-name descname"><span class="pre">TD3Policy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.FlattenExtractor'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_critics=2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share_features_extractor=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/td3/policies.html#TD3Policy"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Policy class (with both actor and critic) for TD3.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Space</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Box</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Features extractor to use.</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments
to pass to the features extractor.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
<li><p><strong>n_critics</strong> (<em>int</em>) – Number of critic networks to create.</p></li>
<li><p><strong>share_features_extractor</strong> (<em>bool</em>) – Whether to share or not the features extractor
between the actor and the critic (this saves computation time)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/td3/policies.html#TD3Policy.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation</strong> (<em>Tensor</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – </p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">set_training_mode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/td3/policies.html#TD3Policy.set_training_mode"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Put the policy in either training or evaluation mode.</p>
<p>This affects certain modules, such as batch normalisation and dropout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em>) – if true, set to training mode, else set to evaluation mode</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.ddpg.</span></span><span class="sig-name descname"><span class="pre">CnnPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.NatureCNN'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_critics=2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share_features_extractor=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/td3/policies.html#CnnPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Policy class (with both actor and critic) for TD3.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Space</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Box</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Features extractor to use.</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments
to pass to the features extractor.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
<li><p><strong>n_critics</strong> (<em>int</em>) – Number of critic networks to create.</p></li>
<li><p><strong>share_features_extractor</strong> (<em>bool</em>) – Whether to share or not the features extractor
between the actor and the critic (this saves computation time)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.ddpg.</span></span><span class="sig-name descname"><span class="pre">MultiInputPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.CombinedExtractor'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_critics=2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share_features_extractor=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/td3/policies.html#MultiInputPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Policy class (with both actor and critic) for TD3 to be used with Dict observation spaces.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Dict</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Box</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Features extractor to use.</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments
to pass to the features extractor.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
<li><p><strong>n_critics</strong> (<em>int</em>) – Number of critic networks to create.</p></li>
<li><p><strong>share_features_extractor</strong> (<em>bool</em>) – Whether to share or not the features extractor
between the actor and the critic (this saves computation time)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
<span id="document-modules/dqn"></span><span class="target" id="module-stable_baselines3.dqn"><span id="dqn"></span></span><section id="id1">
<h3>DQN<a class="headerlink" href="#id1" title="Permalink to this heading"></a></h3>
<p><a class="reference external" href="https://arxiv.org/abs/1312.5602">Deep Q Network (DQN)</a> builds on <a class="reference external" href="http://ml.informatik.uni-freiburg.de/former/_media/publications/rieecml05.pdf">Fitted Q-Iteration (FQI)</a>
and make use of different tricks to stabilize the learning with neural networks: it uses a replay buffer, a target network and gradient clipping.</p>
<p class="rubric">Available Policies</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#stable_baselines3.dqn.MlpPolicy" title="stable_baselines3.dqn.MlpPolicy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MlpPolicy</span></code></a></p></td>
<td><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">DQNPolicy</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#stable_baselines3.dqn.CnnPolicy" title="stable_baselines3.dqn.CnnPolicy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CnnPolicy</span></code></a></p></td>
<td><p>Policy class for DQN when using images as input.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#stable_baselines3.dqn.MultiInputPolicy" title="stable_baselines3.dqn.MultiInputPolicy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiInputPolicy</span></code></a></p></td>
<td><p>Policy class for DQN when using dict observations as input.</p></td>
</tr>
</tbody>
</table>
<section id="notes">
<h4>Notes<a class="headerlink" href="#notes" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Original paper: <a class="reference external" href="https://arxiv.org/abs/1312.5602">https://arxiv.org/abs/1312.5602</a></p></li>
<li><p>Further reference: <a class="reference external" href="https://www.nature.com/articles/nature14236">https://www.nature.com/articles/nature14236</a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This implementation provides only vanilla Deep Q-Learning and has no extensions such as Double-DQN, Dueling-DQN and Prioritized Experience Replay.</p>
</div>
</section>
<section id="can-i-use">
<h4>Can I use?<a class="headerlink" href="#can-i-use" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Recurrent policies: ❌</p></li>
<li><p>Multi processing: ✔️</p></li>
<li><p>Gym spaces:</p></li>
</ul>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Space</p></th>
<th class="head"><p>Action</p></th>
<th class="head"><p>Observation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Discrete</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>Box</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>MultiDiscrete</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>MultiBinary</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>Dict</p></td>
<td><p>❌</p></td>
<td><p>✔️️</p></td>
</tr>
</tbody>
</table>
</section>
<section id="example">
<h4>Example<a class="headerlink" href="#example" title="Permalink to this heading"></a></h4>
<p>This example is only to demonstrate the use of the library and its functions, and the trained agents may not solve the environments. Optimized hyperparameters can be found in RL Zoo <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">repository</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">DQN</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">&quot;human&quot;</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">DQN</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;dqn_cartpole&quot;</span><span class="p">)</span>

<span class="k">del</span> <span class="n">model</span> <span class="c1"># remove to demonstrate saving and loading</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">DQN</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;dqn_cartpole&quot;</span><span class="p">)</span>

<span class="n">obs</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">_states</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">:</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="results">
<h4>Results<a class="headerlink" href="#results" title="Permalink to this heading"></a></h4>
<section id="atari-games">
<h5>Atari Games<a class="headerlink" href="#atari-games" title="Permalink to this heading"></a></h5>
<p>The complete learning curves are available in the <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/pull/110">associated PR #110</a>.</p>
</section>
<section id="how-to-replicate-the-results">
<h5>How to replicate the results?<a class="headerlink" href="#how-to-replicate-the-results" title="Permalink to this heading"></a></h5>
<p>Clone the <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">rl-zoo repo</a>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/DLR-RM/rl-baselines3-zoo
<span class="nb">cd</span><span class="w"> </span>rl-baselines3-zoo/
</pre></div>
</div>
<p>Run the benchmark (replace <code class="docutils literal notranslate"><span class="pre">$ENV_ID</span></code> by the env id, for instance <code class="docutils literal notranslate"><span class="pre">BreakoutNoFrameskip-v4</span></code>):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>train.py<span class="w"> </span>--algo<span class="w"> </span>dqn<span class="w"> </span>--env<span class="w"> </span><span class="nv">$ENV_ID</span><span class="w"> </span>--eval-episodes<span class="w"> </span><span class="m">10</span><span class="w"> </span>--eval-freq<span class="w"> </span><span class="m">10000</span>
</pre></div>
</div>
<p>Plot the results:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>scripts/all_plots.py<span class="w"> </span>-a<span class="w"> </span>dqn<span class="w"> </span>-e<span class="w"> </span>Pong<span class="w"> </span>Breakout<span class="w"> </span>-f<span class="w"> </span>logs/<span class="w"> </span>-o<span class="w"> </span>logs/dqn_results
python<span class="w"> </span>scripts/plot_from_file.py<span class="w"> </span>-i<span class="w"> </span>logs/dqn_results.pkl<span class="w"> </span>-latex<span class="w"> </span>-l<span class="w"> </span>DQN
</pre></div>
</div>
</section>
</section>
<section id="parameters">
<h4>Parameters<a class="headerlink" href="#parameters" title="Permalink to this heading"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.dqn.DQN">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.dqn.</span></span><span class="sig-name descname"><span class="pre">DQN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">policy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_starts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_buffer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_buffer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimize_memory_usage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_update_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exploration_fraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exploration_initial_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exploration_final_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_grad_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stats_window_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensorboard_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_init_setup_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/dqn/dqn.html#DQN"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.dqn.DQN" title="Permalink to this definition"></a></dt>
<dd><p>Deep Q-Network (DQN)</p>
<p>Paper: <a class="reference external" href="https://arxiv.org/abs/1312.5602">https://arxiv.org/abs/1312.5602</a>, <a class="reference external" href="https://www.nature.com/articles/nature14236">https://www.nature.com/articles/nature14236</a>
Default hyperparameters are taken from the Nature paper,
except for the optimizer and learning rate that were taken from Stable Baselines defaults.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>policy</strong> (<em>DQNPolicy</em>) – The policy model to use (MlpPolicy, CnnPolicy, …)</p></li>
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.VecEnv"><em>VecEnv</em></a><em> | </em><em>str</em>) – The environment to learn from (if registered in Gym, can be str)</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – The learning rate, it can be a function
of the current progress remaining (from 1 to 0)</p></li>
<li><p><strong>buffer_size</strong> (<em>int</em>) – size of the replay buffer</p></li>
<li><p><strong>learning_starts</strong> (<em>int</em>) – how many steps of the model to collect transitions for before learning starts</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Minibatch size for each gradient update</p></li>
<li><p><strong>tau</strong> (<em>float</em>) – the soft update coefficient (“Polyak update”, between 0 and 1) default 1 for hard update</p></li>
<li><p><strong>gamma</strong> (<em>float</em>) – the discount factor</p></li>
<li><p><strong>train_freq</strong> (<em>int</em><em> | </em><em>Tuple</em><em>[</em><em>int</em><em>, </em><em>str</em><em>]</em>) – Update the model every <code class="docutils literal notranslate"><span class="pre">train_freq</span></code> steps. Alternatively pass a tuple of frequency and unit
like <code class="docutils literal notranslate"><span class="pre">(5,</span> <span class="pre">&quot;step&quot;)</span></code> or <code class="docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">&quot;episode&quot;)</span></code>.</p></li>
<li><p><strong>gradient_steps</strong> (<em>int</em>) – How many gradient steps to do after each rollout (see <code class="docutils literal notranslate"><span class="pre">train_freq</span></code>)
Set to <code class="docutils literal notranslate"><span class="pre">-1</span></code> means to do as many gradient steps as steps done in the environment
during the rollout.</p></li>
<li><p><strong>replay_buffer_class</strong> (<em>Type</em><em>[</em><em>ReplayBuffer</em><em>] </em><em>| </em><em>None</em>) – Replay buffer class to use (for instance <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code>).
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, it will be automatically selected.</p></li>
<li><p><strong>replay_buffer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments to pass to the replay buffer on creation.</p></li>
<li><p><strong>optimize_memory_usage</strong> (<em>bool</em>) – Enable a memory efficient variant of the replay buffer
at a cost of more complexity.
See <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195">https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195</a></p></li>
<li><p><strong>target_update_interval</strong> (<em>int</em>) – update the target network every <code class="docutils literal notranslate"><span class="pre">target_update_interval</span></code>
environment steps.</p></li>
<li><p><strong>exploration_fraction</strong> (<em>float</em>) – fraction of entire training period over which the exploration rate is reduced</p></li>
<li><p><strong>exploration_initial_eps</strong> (<em>float</em>) – initial value of random action probability</p></li>
<li><p><strong>exploration_final_eps</strong> (<em>float</em>) – final value of random action probability</p></li>
<li><p><strong>max_grad_norm</strong> (<em>float</em>) – The maximum value for the gradient clipping</p></li>
<li><p><strong>stats_window_size</strong> (<em>int</em>) – Window size for the rollout logging, specifying the number of episodes to average
the reported success rate, mean episode length, and mean reward over</p></li>
<li><p><strong>tensorboard_log</strong> (<em>str</em><em> | </em><em>None</em>) – the log location for tensorboard (if None, no logging)</p></li>
<li><p><strong>policy_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – additional arguments to be passed to the policy on creation</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 1 for info messages (such as device or wrappers used), 2 for
debug messages</p></li>
<li><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – Seed for the pseudo random generators</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device (cpu, cuda, …) on which the code should be run.
Setting it to auto, the code will be run on the GPU if possible.</p></li>
<li><p><strong>_init_setup_model</strong> (<em>bool</em>) – Whether or not to build the network at the creation of the instance</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.dqn.DQN.collect_rollouts">
<span class="sig-name descname"><span class="pre">collect_rollouts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_freq</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_buffer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_starts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.dqn.DQN.collect_rollouts" title="Permalink to this definition"></a></dt>
<dd><p>Collect experiences and store them into a <code class="docutils literal notranslate"><span class="pre">ReplayBuffer</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The training environment</p></li>
<li><p><strong>callback</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – Callback that will be called at each step
(and at the beginning and end of the rollout)</p></li>
<li><p><strong>train_freq</strong> (<em>TrainFreq</em>) – How much experience to collect
by doing rollouts of current policy.
Either <code class="docutils literal notranslate"><span class="pre">TrainFreq(&lt;n&gt;,</span> <span class="pre">TrainFrequencyUnit.STEP)</span></code>
or <code class="docutils literal notranslate"><span class="pre">TrainFreq(&lt;n&gt;,</span> <span class="pre">TrainFrequencyUnit.EPISODE)</span></code>
with <code class="docutils literal notranslate"><span class="pre">&lt;n&gt;</span></code> being an integer greater than 0.</p></li>
<li><p><strong>action_noise</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.noise.ActionNoise" title="stable_baselines3.common.noise.ActionNoise"><em>ActionNoise</em></a><em> | </em><em>None</em>) – Action noise that will be used for exploration
Required for deterministic policy (e.g. TD3). This can also be used
in addition to the stochastic policy for SAC.</p></li>
<li><p><strong>learning_starts</strong> (<em>int</em>) – Number of steps before learning for the warm-up phase.</p></li>
<li><p><strong>replay_buffer</strong> (<em>ReplayBuffer</em>) – </p></li>
<li><p><strong>log_interval</strong> (<em>int</em><em> | </em><em>None</em>) – Log data every <code class="docutils literal notranslate"><span class="pre">log_interval</span></code> episodes</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>RolloutReturn</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.dqn.DQN.get_env">
<span class="sig-name descname"><span class="pre">get_env</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.dqn.DQN.get_env" title="Permalink to this definition"></a></dt>
<dd><p>Returns the current environment (can be None if not defined).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The current environment</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.dqn.DQN.get_parameters">
<span class="sig-name descname"><span class="pre">get_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.dqn.DQN.get_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Return the parameters of the agent. This includes parameters from different networks, e.g.
critics (value functions) and policies (pi functions).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Mapping of from names of the objects to PyTorch state-dicts.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Dict</em>[str, <em>Dict</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.dqn.DQN.get_vec_normalize_env">
<span class="sig-name descname"><span class="pre">get_vec_normalize_env</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.dqn.DQN.get_vec_normalize_env" title="Permalink to this definition"></a></dt>
<dd><p>Return the <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> wrapper of the training env
if it exists.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> env.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecNormalize" title="stable_baselines3.common.vec_env.vec_normalize.VecNormalize"><em>VecNormalize</em></a> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.dqn.DQN.learn">
<span class="sig-name descname"><span class="pre">learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">total_timesteps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tb_log_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'DQN'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_num_timesteps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">progress_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/dqn/dqn.html#DQN.learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.dqn.DQN.learn" title="Permalink to this definition"></a></dt>
<dd><p>Return a trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>total_timesteps</strong> (<em>int</em>) – The total number of samples (env steps) to train on</p></li>
<li><p><strong>callback</strong> (<em>None</em><em> | </em><em>Callable</em><em> | </em><em>List</em><em>[</em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a><em>] </em><em>| </em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – callback(s) called at every step with state of the algorithm.</p></li>
<li><p><strong>log_interval</strong> (<em>int</em>) – The number of episodes before logging.</p></li>
<li><p><strong>tb_log_name</strong> (<em>str</em>) – the name of the run for TensorBoard logging</p></li>
<li><p><strong>reset_num_timesteps</strong> (<em>bool</em>) – whether or not to reset the current timestep number (used in logging)</p></li>
<li><p><strong>progress_bar</strong> (<em>bool</em>) – Display a progress bar using tqdm and rich.</p></li>
<li><p><strong>self</strong> (<em>SelfDQN</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the trained model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfDQN</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.dqn.DQN.load">
<em class="property"><span class="pre">classmethod</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_objects</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_system_info</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_reset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.dqn.DQN.load" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a zip-file.
Warning: <code class="docutils literal notranslate"><span class="pre">load</span></code> re-creates the model from scratch, it does not update it in-place!
For an in-place load use <code class="docutils literal notranslate"><span class="pre">set_parameters</span></code> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – path to the file (or a file-like) where to
load the agent from</p></li>
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a><em> | </em><em>None</em>) – the new environment to run the loaded model on
(can be None if you only need prediction from a trained model) has priority over any saved environment</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device on which the code should run.</p></li>
<li><p><strong>custom_objects</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Dictionary of objects to replace
upon loading. If a variable is present in this dictionary as a
key, it will not be deserialized and the corresponding item
will be used instead. Similar to custom_objects in
<code class="docutils literal notranslate"><span class="pre">keras.models.load_model</span></code>. Useful when you have an object in
file that can not be deserialized.</p></li>
<li><p><strong>print_system_info</strong> (<em>bool</em>) – Whether to print system info from the saved model
and the current system info (useful to debug loading issues)</p></li>
<li><p><strong>force_reset</strong> (<em>bool</em>) – Force call to <code class="docutils literal notranslate"><span class="pre">reset()</span></code> before training
to avoid unexpected behavior.
See <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/597">https://github.com/DLR-RM/stable-baselines3/issues/597</a></p></li>
<li><p><strong>kwargs</strong> – extra arguments to change the model when loading</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>new model instance with loaded parameters</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfBaseAlgorithm</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.dqn.DQN.load_replay_buffer">
<span class="sig-name descname"><span class="pre">load_replay_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truncate_last_traj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.dqn.DQN.load_replay_buffer" title="Permalink to this definition"></a></dt>
<dd><p>Load a replay buffer from a pickle file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – Path to the pickled replay buffer.</p></li>
<li><p><strong>truncate_last_traj</strong> (<em>bool</em>) – When using <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code> with online sampling:
If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, we assume that the last trajectory in the replay buffer was finished
(and truncate it).
If set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, we assume that we continue the same trajectory (same episode).</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="stable_baselines3.dqn.DQN.logger">
<em class="property"><span class="pre">property</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">logger</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><a class="reference internal" href="index.html#stable_baselines3.common.logger.Logger" title="stable_baselines3.common.logger.Logger"><span class="pre">Logger</span></a></em><a class="headerlink" href="#stable_baselines3.dqn.DQN.logger" title="Permalink to this definition"></a></dt>
<dd><p>Getter for the logger object.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.dqn.DQN.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">episode_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/dqn/dqn.html#DQN.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.dqn.DQN.predict" title="Permalink to this definition"></a></dt>
<dd><p>Overrides the base_class predict function to include epsilon-greedy exploration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation</strong> (<em>ndarray</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>ndarray</em><em>]</em>) – the input observation</p></li>
<li><p><strong>state</strong> (<em>Tuple</em><em>[</em><em>ndarray</em><em>, </em><em>...</em><em>] </em><em>| </em><em>None</em>) – The last states (can be None, used in recurrent policies)</p></li>
<li><p><strong>episode_start</strong> (<em>ndarray</em><em> | </em><em>None</em>) – The last masks (can be None, used in recurrent policies)</p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – Whether or not to return deterministic actions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the model’s action and the next state
(used in recurrent policies)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>ndarray</em>, <em>Tuple</em>[<em>ndarray</em>, …] | None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.dqn.DQN.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.dqn.DQN.save" title="Permalink to this definition"></a></dt>
<dd><p>Save all the attributes of the object and the model parameters in a zip-file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – path to the file where the rl agent should be saved</p></li>
<li><p><strong>exclude</strong> (<em>Iterable</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – name of parameters that should be excluded in addition to the default ones</p></li>
<li><p><strong>include</strong> (<em>Iterable</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – name of parameters that might be excluded but should be included anyway</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.dqn.DQN.save_replay_buffer">
<span class="sig-name descname"><span class="pre">save_replay_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.dqn.DQN.save_replay_buffer" title="Permalink to this definition"></a></dt>
<dd><p>Save the replay buffer as a pickle file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – Path to the file where the replay buffer should be saved.
if path is a str or pathlib.Path, the path is automatically created if necessary.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.dqn.DQN.set_env">
<span class="sig-name descname"><span class="pre">set_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_reset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.dqn.DQN.set_env" title="Permalink to this definition"></a></dt>
<dd><p>Checks the validity of the environment, and if it is coherent, set it as the current environment.
Furthermore wrap any non vectorized env into a vectorized
checked parameters:
- observation_space
- action_space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The environment for learning a policy</p></li>
<li><p><strong>force_reset</strong> (<em>bool</em>) – Force call to <code class="docutils literal notranslate"><span class="pre">reset()</span></code> before training
to avoid unexpected behavior.
See issue <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/597">https://github.com/DLR-RM/stable-baselines3/issues/597</a></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.dqn.DQN.set_logger">
<span class="sig-name descname"><span class="pre">set_logger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.dqn.DQN.set_logger" title="Permalink to this definition"></a></dt>
<dd><p>Setter for for logger object.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When passing a custom logger object,
this will overwrite <code class="docutils literal notranslate"><span class="pre">tensorboard_log</span></code> and <code class="docutils literal notranslate"><span class="pre">verbose</span></code> settings
passed to the constructor.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>logger</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.logger.Logger" title="stable_baselines3.common.logger.Logger"><em>Logger</em></a>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.dqn.DQN.set_parameters">
<span class="sig-name descname"><span class="pre">set_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">load_path_or_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exact_match</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.dqn.DQN.set_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Load parameters from a given zip-file or a nested dictionary containing parameters for
different modules (see <code class="docutils literal notranslate"><span class="pre">get_parameters</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>load_path_or_iter</strong> – Location of the saved data (path or file-like, see <code class="docutils literal notranslate"><span class="pre">save</span></code>), or a nested
dictionary containing nn.Module parameters used by the policy. The dictionary maps
object names to a state-dictionary returned by <code class="docutils literal notranslate"><span class="pre">torch.nn.Module.state_dict()</span></code>.</p></li>
<li><p><strong>exact_match</strong> (<em>bool</em>) – If True, the given parameters should include parameters for each
module and each of their parameters, otherwise raises an Exception. If set to False, this
can be used to update only specific parameters.</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device on which the code should run.</p></li>
<li><p><strong>load_path_or_dict</strong> (<em>str</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.dqn.DQN.set_random_seed">
<span class="sig-name descname"><span class="pre">set_random_seed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.dqn.DQN.set_random_seed" title="Permalink to this definition"></a></dt>
<dd><p>Set the seed of the pseudo-random generators
(python, numpy, pytorch, gym, action_space)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.dqn.DQN.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradient_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/dqn/dqn.html#DQN.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.dqn.DQN.train" title="Permalink to this definition"></a></dt>
<dd><p>Sample the replay buffer and do the updates
(gradient descent and update target networks)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gradient_steps</strong> (<em>int</em>) – </p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="dqn-policies">
<span id="id2"></span><h4>DQN Policies<a class="headerlink" href="#dqn-policies" title="Permalink to this heading"></a></h4>
<dl class="py attribute">
<dt class="sig sig-object py" id="stable_baselines3.dqn.MlpPolicy">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.dqn.</span></span><span class="sig-name descname"><span class="pre">MlpPolicy</span></span><a class="headerlink" href="#stable_baselines3.dqn.MlpPolicy" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">DQNPolicy</span></code></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.dqn.policies.</span></span><span class="sig-name descname"><span class="pre">DQNPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.FlattenExtractor'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/dqn/policies.html#DQNPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Policy class with Q-Value Net and target net for DQN</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Space</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Discrete</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Features extractor to use.</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments
to pass to the features extractor.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/dqn/policies.html#DQNPolicy.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs</strong> (<em>Tensor</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – </p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">set_training_mode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/dqn/policies.html#DQNPolicy.set_training_mode"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Put the policy in either training or evaluation mode.</p>
<p>This affects certain modules, such as batch normalisation and dropout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em>) – if true, set to training mode, else set to evaluation mode</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.dqn.CnnPolicy">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.dqn.</span></span><span class="sig-name descname"><span class="pre">CnnPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.NatureCNN'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/dqn/policies.html#CnnPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.dqn.CnnPolicy" title="Permalink to this definition"></a></dt>
<dd><p>Policy class for DQN when using images as input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Space</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Discrete</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Features extractor to use.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.dqn.MultiInputPolicy">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.dqn.</span></span><span class="sig-name descname"><span class="pre">MultiInputPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.CombinedExtractor'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/dqn/policies.html#MultiInputPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.dqn.MultiInputPolicy" title="Permalink to this definition"></a></dt>
<dd><p>Policy class for DQN when using dict observations as input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Dict</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Discrete</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Features extractor to use.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
<span id="document-modules/her"></span><span class="target" id="module-stable_baselines3.her"><span id="her"></span></span><section id="id1">
<h3>HER<a class="headerlink" href="#id1" title="Permalink to this heading"></a></h3>
<p><a class="reference external" href="https://arxiv.org/abs/1707.01495">Hindsight Experience Replay (HER)</a></p>
<p>HER is an algorithm that works with off-policy methods (DQN, SAC, TD3 and DDPG for example).
HER uses the fact that even if a desired goal was not achieved, other goal may have been achieved during a rollout.
It creates “virtual” transitions by relabeling transitions (changing the desired goal) from past episodes.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Starting from Stable Baselines3 v1.1.0, <code class="docutils literal notranslate"><span class="pre">HER</span></code> is no longer a separate algorithm
but a replay buffer class <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code> that must be passed to an off-policy algorithm
when using <code class="docutils literal notranslate"><span class="pre">MultiInputPolicy</span></code> (to have Dict observation support).</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>HER requires the environment to follow the legacy <a class="reference external" href="https://github.com/Farama-Foundation/Gymnasium-Robotics/blob/a35b1c1fa669428bf640a2c7101e66eb1627ac3a/gym_robotics/core.py#L8">gym_robotics.GoalEnv interface</a>
In short, the <code class="docutils literal notranslate"><span class="pre">gym.Env</span></code> must have:
- a vectorized implementation of <code class="docutils literal notranslate"><span class="pre">compute_reward()</span></code>
- a dictionary observation space with three keys: <code class="docutils literal notranslate"><span class="pre">observation</span></code>, <code class="docutils literal notranslate"><span class="pre">achieved_goal</span></code> and <code class="docutils literal notranslate"><span class="pre">desired_goal</span></code></p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Because it needs access to <code class="docutils literal notranslate"><span class="pre">env.compute_reward()</span></code>
<code class="docutils literal notranslate"><span class="pre">HER</span></code> must be loaded with the env. If you just want to use the trained policy
without instantiating the environment, we recommend saving the policy only.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Compared to other implementations, the <code class="docutils literal notranslate"><span class="pre">future</span></code> goal sampling strategy is inclusive:
the current transition can be used when re-sampling.</p>
</div>
<section id="notes">
<h4>Notes<a class="headerlink" href="#notes" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Original paper: <a class="reference external" href="https://arxiv.org/abs/1707.01495">https://arxiv.org/abs/1707.01495</a></p></li>
<li><p>OpenAI paper: <a class="reference external" href="https://arxiv.org/abs/1802.09464">Plappert et al. (2018)</a></p></li>
<li><p>OpenAI blog post: <a class="reference external" href="https://openai.com/blog/ingredients-for-robotics-research/">https://openai.com/blog/ingredients-for-robotics-research/</a></p></li>
</ul>
</section>
<section id="can-i-use">
<h4>Can I use?<a class="headerlink" href="#can-i-use" title="Permalink to this heading"></a></h4>
<p>Please refer to the used model (DQN, QR-DQN, SAC, TQC, TD3, or DDPG) for that section.</p>
</section>
<section id="example">
<h4>Example<a class="headerlink" href="#example" title="Permalink to this heading"></a></h4>
<p>This example is only to demonstrate the use of the library and its functions, and the trained agents may not solve the environments. Optimized hyperparameters can be found in RL Zoo <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">repository</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">HerReplayBuffer</span><span class="p">,</span> <span class="n">DDPG</span><span class="p">,</span> <span class="n">DQN</span><span class="p">,</span> <span class="n">SAC</span><span class="p">,</span> <span class="n">TD3</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.her.goal_selection_strategy</span> <span class="kn">import</span> <span class="n">GoalSelectionStrategy</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.envs</span> <span class="kn">import</span> <span class="n">BitFlippingEnv</span>

<span class="n">model_class</span> <span class="o">=</span> <span class="n">DQN</span>  <span class="c1"># works also with SAC, DDPG and TD3</span>
<span class="n">N_BITS</span> <span class="o">=</span> <span class="mi">15</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">BitFlippingEnv</span><span class="p">(</span><span class="n">n_bits</span><span class="o">=</span><span class="n">N_BITS</span><span class="p">,</span> <span class="n">continuous</span><span class="o">=</span><span class="n">model_class</span> <span class="ow">in</span> <span class="p">[</span><span class="n">DDPG</span><span class="p">,</span> <span class="n">SAC</span><span class="p">,</span> <span class="n">TD3</span><span class="p">],</span> <span class="n">max_steps</span><span class="o">=</span><span class="n">N_BITS</span><span class="p">)</span>

<span class="c1"># Available strategies (cf paper): future, final, episode</span>
<span class="n">goal_selection_strategy</span> <span class="o">=</span> <span class="s2">&quot;future&quot;</span> <span class="c1"># equivalent to GoalSelectionStrategy.FUTURE</span>

<span class="c1"># Initialize the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model_class</span><span class="p">(</span>
    <span class="s2">&quot;MultiInputPolicy&quot;</span><span class="p">,</span>
    <span class="n">env</span><span class="p">,</span>
    <span class="n">replay_buffer_class</span><span class="o">=</span><span class="n">HerReplayBuffer</span><span class="p">,</span>
    <span class="c1"># Parameters for HER</span>
    <span class="n">replay_buffer_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="n">n_sampled_goal</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">goal_selection_strategy</span><span class="o">=</span><span class="n">goal_selection_strategy</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;./her_bit_env&quot;</span><span class="p">)</span>
<span class="c1"># Because it needs access to `env.compute_reward()`</span>
<span class="c1"># HER must be loaded with the env</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model_class</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;./her_bit_env&quot;</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env</span><span class="p">)</span>

<span class="n">obs</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">:</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="results">
<h4>Results<a class="headerlink" href="#results" title="Permalink to this heading"></a></h4>
<p>This implementation was tested on the <a class="reference external" href="https://github.com/eleurent/highway-env">parking env</a>
using 3 seeds.</p>
<p>The complete learning curves are available in the <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/pull/120">associated PR #120</a>.</p>
<section id="how-to-replicate-the-results">
<h5>How to replicate the results?<a class="headerlink" href="#how-to-replicate-the-results" title="Permalink to this heading"></a></h5>
<p>Clone the <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">rl-zoo repo</a>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/DLR-RM/rl-baselines3-zoo
<span class="nb">cd</span><span class="w"> </span>rl-baselines3-zoo/
</pre></div>
</div>
<p>Run the benchmark:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>train.py<span class="w"> </span>--algo<span class="w"> </span>tqc<span class="w"> </span>--env<span class="w"> </span>parking-v0<span class="w"> </span>--eval-episodes<span class="w"> </span><span class="m">10</span><span class="w"> </span>--eval-freq<span class="w"> </span><span class="m">10000</span>
</pre></div>
</div>
<p>Plot the results:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>scripts/all_plots.py<span class="w"> </span>-a<span class="w"> </span>tqc<span class="w"> </span>-e<span class="w"> </span>parking-v0<span class="w"> </span>-f<span class="w"> </span>logs/<span class="w"> </span>--no-million
</pre></div>
</div>
</section>
</section>
<section id="parameters">
<h4>Parameters<a class="headerlink" href="#parameters" title="Permalink to this heading"></a></h4>
</section>
<section id="her-replay-buffer">
<h4>HER Replay Buffer<a class="headerlink" href="#her-replay-buffer" title="Permalink to this heading"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.her.HerReplayBuffer">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.her.</span></span><span class="sig-name descname"><span class="pre">HerReplayBuffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">buffer_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_envs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimize_memory_usage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">handle_timeout_termination</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_sampled_goal</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">goal_selection_strategy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'future'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy_info_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/her/her_replay_buffer.html#HerReplayBuffer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.her.HerReplayBuffer" title="Permalink to this definition"></a></dt>
<dd><p>Hindsight Experience Replay (HER) buffer.
Paper: <a class="reference external" href="https://arxiv.org/abs/1707.01495">https://arxiv.org/abs/1707.01495</a></p>
<p>Replay buffer for sampling HER (Hindsight Experience Replay) transitions.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Compared to other implementations, the <code class="docutils literal notranslate"><span class="pre">future</span></code> goal sampling strategy is inclusive:
the current transition can be used when re-sampling.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>buffer_size</strong> (<em>int</em>) – Max number of element in the buffer</p></li>
<li><p><strong>observation_space</strong> (<em>Dict</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Space</em>) – Action space</p></li>
<li><p><strong>env</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a><em> | </em><em>None</em>) – The training environment</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – PyTorch device</p></li>
<li><p><strong>n_envs</strong> (<em>int</em>) – Number of parallel environments</p></li>
<li><p><strong>optimize_memory_usage</strong> (<em>bool</em>) – Enable a memory efficient variant
Disabled for now (see <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/pull/243#discussion_r531535702">https://github.com/DLR-RM/stable-baselines3/pull/243#discussion_r531535702</a>)</p></li>
<li><p><strong>handle_timeout_termination</strong> (<em>bool</em>) – Handle timeout termination (due to timelimit)
separately and treat the task as infinite horizon task.
<a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/284">https://github.com/DLR-RM/stable-baselines3/issues/284</a></p></li>
<li><p><strong>n_sampled_goal</strong> (<em>int</em>) – Number of virtual transitions to create per real transition,
by sampling new goals.</p></li>
<li><p><strong>goal_selection_strategy</strong> (<a class="reference internal" href="index.html#stable_baselines3.her.GoalSelectionStrategy" title="stable_baselines3.her.goal_selection_strategy.GoalSelectionStrategy"><em>GoalSelectionStrategy</em></a><em> | </em><em>str</em>) – Strategy for sampling goals for replay.
One of [‘episode’, ‘final’, ‘future’]</p></li>
<li><p><strong>copy_info_dict</strong> (<em>bool</em>) – Whether to copy the info dictionary and pass it to
<code class="docutils literal notranslate"><span class="pre">compute_reward()</span></code> method.
Please note that the copy may cause a slowdown.
False by default.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.her.HerReplayBuffer.add">
<span class="sig-name descname"><span class="pre">add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">next_obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">done</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">infos</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/her/her_replay_buffer.html#HerReplayBuffer.add"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.her.HerReplayBuffer.add" title="Permalink to this definition"></a></dt>
<dd><p>Add elements to the buffer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>ndarray</em><em>]</em>) – </p></li>
<li><p><strong>next_obs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>ndarray</em><em>]</em>) – </p></li>
<li><p><strong>action</strong> (<em>ndarray</em>) – </p></li>
<li><p><strong>reward</strong> (<em>ndarray</em>) – </p></li>
<li><p><strong>done</strong> (<em>ndarray</em>) – </p></li>
<li><p><strong>infos</strong> (<em>List</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.her.HerReplayBuffer.extend">
<span class="sig-name descname"><span class="pre">extend</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.her.HerReplayBuffer.extend" title="Permalink to this definition"></a></dt>
<dd><p>Add a new batch of transitions to the buffer</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.her.HerReplayBuffer.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.her.HerReplayBuffer.reset" title="Permalink to this definition"></a></dt>
<dd><p>Reset the buffer.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.her.HerReplayBuffer.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/her/her_replay_buffer.html#HerReplayBuffer.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.her.HerReplayBuffer.sample" title="Permalink to this definition"></a></dt>
<dd><p>Sample elements from the replay buffer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<em>int</em>) – Number of element to sample</p></li>
<li><p><strong>env</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecNormalize" title="stable_baselines3.common.vec_env.vec_normalize.VecNormalize"><em>VecNormalize</em></a><em> | </em><em>None</em>) – Associated VecEnv to normalize the observations/rewards when sampling</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Samples</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>DictReplayBufferSamples</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.her.HerReplayBuffer.set_env">
<span class="sig-name descname"><span class="pre">set_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/her/her_replay_buffer.html#HerReplayBuffer.set_env"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.her.HerReplayBuffer.set_env" title="Permalink to this definition"></a></dt>
<dd><p>Sets the environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>env</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.her.HerReplayBuffer.size">
<span class="sig-name descname"><span class="pre">size</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.her.HerReplayBuffer.size" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The current size of the buffer</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.her.HerReplayBuffer.swap_and_flatten">
<em class="property"><span class="pre">static</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">swap_and_flatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arr</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.her.HerReplayBuffer.swap_and_flatten" title="Permalink to this definition"></a></dt>
<dd><p>Swap and then flatten axes 0 (buffer_size) and 1 (n_envs)
to convert shape from [n_steps, n_envs, …] (when … is the shape of the features)
to [n_steps * n_envs, …] (which maintain the order)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>arr</strong> (<em>ndarray</em>) – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.her.HerReplayBuffer.to_torch">
<span class="sig-name descname"><span class="pre">to_torch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.her.HerReplayBuffer.to_torch" title="Permalink to this definition"></a></dt>
<dd><p>Convert a numpy array to a PyTorch tensor.
Note: it copies the data by default</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>array</strong> (<em>ndarray</em>) – </p></li>
<li><p><strong>copy</strong> (<em>bool</em>) – Whether to copy or not the data (may be useful to avoid changing things
by reference). This argument is inoperative if the device is not the CPU.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.her.HerReplayBuffer.truncate_last_trajectory">
<span class="sig-name descname"><span class="pre">truncate_last_trajectory</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/her/her_replay_buffer.html#HerReplayBuffer.truncate_last_trajectory"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.her.HerReplayBuffer.truncate_last_trajectory" title="Permalink to this definition"></a></dt>
<dd><p>If called, we assume that the last trajectory in the replay buffer was finished
(and truncate it).
If not called, we assume that we continue the same trajectory (same episode).</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="goal-selection-strategies">
<h4>Goal Selection Strategies<a class="headerlink" href="#goal-selection-strategies" title="Permalink to this heading"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.her.GoalSelectionStrategy">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.her.</span></span><span class="sig-name descname"><span class="pre">GoalSelectionStrategy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/her/goal_selection_strategy.html#GoalSelectionStrategy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.her.GoalSelectionStrategy" title="Permalink to this definition"></a></dt>
<dd><p>The strategies for selecting new goals when
creating artificial transitions.</p>
</dd></dl>

</section>
</section>
<span id="document-modules/ppo"></span><span class="target" id="module-stable_baselines3.ppo"><span id="ppo2"></span></span><section id="ppo">
<h3>PPO<a class="headerlink" href="#ppo" title="Permalink to this heading"></a></h3>
<p>The <a class="reference external" href="https://arxiv.org/abs/1707.06347">Proximal Policy Optimization</a> algorithm combines ideas from A2C (having multiple workers)
and TRPO (it uses a trust region to improve the actor).</p>
<p>The main idea is that after an update, the new policy should be not too far from the old policy.
For that, ppo uses clipping to avoid too large update.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>PPO contains several modifications from the original algorithm not documented
by OpenAI: advantages are normalized and value function can be also clipped.</p>
</div>
<section id="notes">
<h4>Notes<a class="headerlink" href="#notes" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Original paper: <a class="reference external" href="https://arxiv.org/abs/1707.06347">https://arxiv.org/abs/1707.06347</a></p></li>
<li><p>Clear explanation of PPO on Arxiv Insights channel: <a class="reference external" href="https://www.youtube.com/watch?v=5P7I-xPq8u8">https://www.youtube.com/watch?v=5P7I-xPq8u8</a></p></li>
<li><p>OpenAI blog post: <a class="reference external" href="https://blog.openai.com/openai-baselines-ppo/">https://blog.openai.com/openai-baselines-ppo/</a></p></li>
<li><p>Spinning Up guide: <a class="reference external" href="https://spinningup.openai.com/en/latest/algorithms/ppo.html">https://spinningup.openai.com/en/latest/algorithms/ppo.html</a></p></li>
<li><p>37 implementation details blog: <a class="reference external" href="https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/">https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/</a></p></li>
</ul>
</section>
<section id="can-i-use">
<h4>Can I use?<a class="headerlink" href="#can-i-use" title="Permalink to this heading"></a></h4>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A recurrent version of PPO is available in our contrib repo: <a class="reference external" href="https://sb3-contrib.readthedocs.io/en/master/modules/ppo_recurrent.html">https://sb3-contrib.readthedocs.io/en/master/modules/ppo_recurrent.html</a></p>
<p>However we advise users to start with simple frame-stacking as a simpler, faster
and usually competitive alternative, more info in our report: <a class="reference external" href="https://wandb.ai/sb3/no-vel-envs/reports/PPO-vs-RecurrentPPO-aka-PPO-LSTM-on-environments-with-masked-velocity--VmlldzoxOTI4NjE4">https://wandb.ai/sb3/no-vel-envs/reports/PPO-vs-RecurrentPPO-aka-PPO-LSTM-on-environments-with-masked-velocity–VmlldzoxOTI4NjE4</a>
See also <a class="reference external" href="https://arxiv.org/abs/1912.01588">Procgen paper appendix Fig 11.</a>.
In practice, you can stack multiple observations using <code class="docutils literal notranslate"><span class="pre">VecFrameStack</span></code>.</p>
</div>
<ul class="simple">
<li><p>Recurrent policies: ❌</p></li>
<li><p>Multi processing: ✔️</p></li>
<li><p>Gym spaces:</p></li>
</ul>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Space</p></th>
<th class="head"><p>Action</p></th>
<th class="head"><p>Observation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Discrete</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>Box</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>MultiDiscrete</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>MultiBinary</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>Dict</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
</tbody>
</table>
</section>
<section id="example">
<h4>Example<a class="headerlink" href="#example" title="Permalink to this heading"></a></h4>
<p>This example is only to demonstrate the use of the library and its functions, and the trained agents may not solve the environments. Optimized hyperparameters can be found in RL Zoo <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">repository</a>.</p>
<p>Train a PPO agent on <code class="docutils literal notranslate"><span class="pre">CartPole-v1</span></code> using 4 environments.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">PPO</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.env_util</span> <span class="kn">import</span> <span class="n">make_vec_env</span>

<span class="c1"># Parallel environments</span>
<span class="n">vec_env</span> <span class="o">=</span> <span class="n">make_vec_env</span><span class="p">(</span><span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">n_envs</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">vec_env</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">25000</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;ppo_cartpole&quot;</span><span class="p">)</span>

<span class="k">del</span> <span class="n">model</span> <span class="c1"># remove to demonstrate saving and loading</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">PPO</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;ppo_cartpole&quot;</span><span class="p">)</span>

<span class="n">obs</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">_states</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">dones</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="n">vec_env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="results">
<h4>Results<a class="headerlink" href="#results" title="Permalink to this heading"></a></h4>
<section id="atari-games">
<h5>Atari Games<a class="headerlink" href="#atari-games" title="Permalink to this heading"></a></h5>
<p>The complete learning curves are available in the <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/pull/110">associated PR #110</a>.</p>
</section>
<section id="pybullet-environments">
<h5>PyBullet Environments<a class="headerlink" href="#pybullet-environments" title="Permalink to this heading"></a></h5>
<p>Results on the PyBullet benchmark (2M steps) using 6 seeds.
The complete learning curves are available in the <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/48">associated issue #48</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Hyperparameters from the <a class="reference external" href="https://arxiv.org/abs/2005.05719">gSDE paper</a> were used (as they are tuned for PyBullet envs).</p>
</div>
<p><em>Gaussian</em> means that the unstructured Gaussian noise is used for exploration,
<em>gSDE</em> (generalized State-Dependent Exploration) is used otherwise.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Environments</p></th>
<th class="head"><p>A2C</p></th>
<th class="head"><p>A2C</p></th>
<th class="head"><p>PPO</p></th>
<th class="head"><p>PPO</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td></td>
<td><p>Gaussian</p></td>
<td><p>gSDE</p></td>
<td><p>Gaussian</p></td>
<td><p>gSDE</p></td>
</tr>
<tr class="row-odd"><td><p>HalfCheetah</p></td>
<td><p>2003 +/- 54</p></td>
<td><p>2032 +/- 122</p></td>
<td><p>1976 +/- 479</p></td>
<td><p>2826 +/- 45</p></td>
</tr>
<tr class="row-even"><td><p>Ant</p></td>
<td><p>2286 +/- 72</p></td>
<td><p>2443 +/- 89</p></td>
<td><p>2364 +/- 120</p></td>
<td><p>2782 +/- 76</p></td>
</tr>
<tr class="row-odd"><td><p>Hopper</p></td>
<td><p>1627 +/- 158</p></td>
<td><p>1561 +/- 220</p></td>
<td><p>1567 +/- 339</p></td>
<td><p>2512 +/- 21</p></td>
</tr>
<tr class="row-even"><td><p>Walker2D</p></td>
<td><p>577 +/- 65</p></td>
<td><p>839 +/- 56</p></td>
<td><p>1230 +/- 147</p></td>
<td><p>2019 +/- 64</p></td>
</tr>
</tbody>
</table>
</section>
<section id="how-to-replicate-the-results">
<h5>How to replicate the results?<a class="headerlink" href="#how-to-replicate-the-results" title="Permalink to this heading"></a></h5>
<p>Clone the <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">rl-zoo repo</a>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/DLR-RM/rl-baselines3-zoo
<span class="nb">cd</span><span class="w"> </span>rl-baselines3-zoo/
</pre></div>
</div>
<p>Run the benchmark (replace <code class="docutils literal notranslate"><span class="pre">$ENV_ID</span></code> by the envs mentioned above):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>train.py<span class="w"> </span>--algo<span class="w"> </span>ppo<span class="w"> </span>--env<span class="w"> </span><span class="nv">$ENV_ID</span><span class="w"> </span>--eval-episodes<span class="w"> </span><span class="m">10</span><span class="w"> </span>--eval-freq<span class="w"> </span><span class="m">10000</span>
</pre></div>
</div>
<p>Plot the results (here for PyBullet envs only):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>scripts/all_plots.py<span class="w"> </span>-a<span class="w"> </span>ppo<span class="w"> </span>-e<span class="w"> </span>HalfCheetah<span class="w"> </span>Ant<span class="w"> </span>Hopper<span class="w"> </span>Walker2D<span class="w"> </span>-f<span class="w"> </span>logs/<span class="w"> </span>-o<span class="w"> </span>logs/ppo_results
python<span class="w"> </span>scripts/plot_from_file.py<span class="w"> </span>-i<span class="w"> </span>logs/ppo_results.pkl<span class="w"> </span>-latex<span class="w"> </span>-l<span class="w"> </span>PPO
</pre></div>
</div>
</section>
</section>
<section id="parameters">
<h4>Parameters<a class="headerlink" href="#parameters" title="Permalink to this heading"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.ppo.PPO">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.ppo.</span></span><span class="sig-name descname"><span class="pre">PPO</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">policy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0003</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2048</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gae_lambda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_range</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_range_vf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_advantage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ent_coef</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vf_coef</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_grad_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sde_sample_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rollout_buffer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rollout_buffer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_kl</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stats_window_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensorboard_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_init_setup_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/ppo/ppo.html#PPO"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.ppo.PPO" title="Permalink to this definition"></a></dt>
<dd><p>Proximal Policy Optimization algorithm (PPO) (clip version)</p>
<p>Paper: <a class="reference external" href="https://arxiv.org/abs/1707.06347">https://arxiv.org/abs/1707.06347</a>
Code: This implementation borrows code from OpenAI Spinning Up (<a class="reference external" href="https://github.com/openai/spinningup/">https://github.com/openai/spinningup/</a>)
<a class="reference external" href="https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail">https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail</a> and
Stable Baselines (PPO2 from <a class="reference external" href="https://github.com/hill-a/stable-baselines">https://github.com/hill-a/stable-baselines</a>)</p>
<p>Introduction to PPO: <a class="reference external" href="https://spinningup.openai.com/en/latest/algorithms/ppo.html">https://spinningup.openai.com/en/latest/algorithms/ppo.html</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>policy</strong> (<em>ActorCriticPolicy</em>) – The policy model to use (MlpPolicy, CnnPolicy, …)</p></li>
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.VecEnv"><em>VecEnv</em></a><em> | </em><em>str</em>) – The environment to learn from (if registered in Gym, can be str)</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – The learning rate, it can be a function
of the current progress remaining (from 1 to 0)</p></li>
<li><p><strong>n_steps</strong> (<em>int</em>) – The number of steps to run for each environment per update
(i.e. rollout buffer size is n_steps * n_envs where n_envs is number of environment copies running in parallel)
NOTE: n_steps * n_envs must be greater than 1 (because of the advantage normalization)
See <a class="reference external" href="https://github.com/pytorch/pytorch/issues/29372">https://github.com/pytorch/pytorch/issues/29372</a></p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Minibatch size</p></li>
<li><p><strong>n_epochs</strong> (<em>int</em>) – Number of epoch when optimizing the surrogate loss</p></li>
<li><p><strong>gamma</strong> (<em>float</em>) – Discount factor</p></li>
<li><p><strong>gae_lambda</strong> (<em>float</em>) – Factor for trade-off of bias vs variance for Generalized Advantage Estimator</p></li>
<li><p><strong>clip_range</strong> (<em>float</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Clipping parameter, it can be a function of the current progress
remaining (from 1 to 0).</p></li>
<li><p><strong>clip_range_vf</strong> (<em>None</em><em> | </em><em>float</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Clipping parameter for the value function,
it can be a function of the current progress remaining (from 1 to 0).
This is a parameter specific to the OpenAI implementation. If None is passed (default),
no clipping will be done on the value function.
IMPORTANT: this clipping depends on the reward scaling.</p></li>
<li><p><strong>normalize_advantage</strong> (<em>bool</em>) – Whether to normalize or not the advantage</p></li>
<li><p><strong>ent_coef</strong> (<em>float</em>) – Entropy coefficient for the loss calculation</p></li>
<li><p><strong>vf_coef</strong> (<em>float</em>) – Value function coefficient for the loss calculation</p></li>
<li><p><strong>max_grad_norm</strong> (<em>float</em>) – The maximum value for the gradient clipping</p></li>
<li><p><strong>use_sde</strong> (<em>bool</em>) – Whether to use generalized State Dependent Exploration (gSDE)
instead of action noise exploration (default: False)</p></li>
<li><p><strong>sde_sample_freq</strong> (<em>int</em>) – Sample a new noise matrix every n steps when using gSDE
Default: -1 (only sample at the beginning of the rollout)</p></li>
<li><p><strong>rollout_buffer_class</strong> (<em>Type</em><em>[</em><em>RolloutBuffer</em><em>] </em><em>| </em><em>None</em>) – Rollout buffer class to use. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, it will be automatically selected.</p></li>
<li><p><strong>rollout_buffer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments to pass to the rollout buffer on creation</p></li>
<li><p><strong>target_kl</strong> (<em>float</em><em> | </em><em>None</em>) – Limit the KL divergence between updates,
because the clipping is not enough to prevent large update
see issue #213 (cf <a class="reference external" href="https://github.com/hill-a/stable-baselines/issues/213">https://github.com/hill-a/stable-baselines/issues/213</a>)
By default, there is no limit on the kl div.</p></li>
<li><p><strong>stats_window_size</strong> (<em>int</em>) – Window size for the rollout logging, specifying the number of episodes to average
the reported success rate, mean episode length, and mean reward over</p></li>
<li><p><strong>tensorboard_log</strong> (<em>str</em><em> | </em><em>None</em>) – the log location for tensorboard (if None, no logging)</p></li>
<li><p><strong>policy_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – additional arguments to be passed to the policy on creation</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 1 for info messages (such as device or wrappers used), 2 for
debug messages</p></li>
<li><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – Seed for the pseudo random generators</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device (cpu, cuda, …) on which the code should be run.
Setting it to auto, the code will be run on the GPU if possible.</p></li>
<li><p><strong>_init_setup_model</strong> (<em>bool</em>) – Whether or not to build the network at the creation of the instance</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ppo.PPO.collect_rollouts">
<span class="sig-name descname"><span class="pre">collect_rollouts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rollout_buffer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_rollout_steps</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ppo.PPO.collect_rollouts" title="Permalink to this definition"></a></dt>
<dd><p>Collect experiences using the current policy and fill a <code class="docutils literal notranslate"><span class="pre">RolloutBuffer</span></code>.
The term rollout here refers to the model-free notion and should not
be used with the concept of rollout used in model-based RL or planning.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The training environment</p></li>
<li><p><strong>callback</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – Callback that will be called at each step
(and at the beginning and end of the rollout)</p></li>
<li><p><strong>rollout_buffer</strong> (<em>RolloutBuffer</em>) – Buffer to fill with rollouts</p></li>
<li><p><strong>n_rollout_steps</strong> (<em>int</em>) – Number of experiences to collect per environment</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>True if function returned with at least <cite>n_rollout_steps</cite>
collected, False if callback terminated rollout prematurely.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ppo.PPO.get_env">
<span class="sig-name descname"><span class="pre">get_env</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ppo.PPO.get_env" title="Permalink to this definition"></a></dt>
<dd><p>Returns the current environment (can be None if not defined).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The current environment</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ppo.PPO.get_parameters">
<span class="sig-name descname"><span class="pre">get_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ppo.PPO.get_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Return the parameters of the agent. This includes parameters from different networks, e.g.
critics (value functions) and policies (pi functions).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Mapping of from names of the objects to PyTorch state-dicts.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Dict</em>[str, <em>Dict</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ppo.PPO.get_vec_normalize_env">
<span class="sig-name descname"><span class="pre">get_vec_normalize_env</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ppo.PPO.get_vec_normalize_env" title="Permalink to this definition"></a></dt>
<dd><p>Return the <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> wrapper of the training env
if it exists.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> env.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecNormalize" title="stable_baselines3.common.vec_env.vec_normalize.VecNormalize"><em>VecNormalize</em></a> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ppo.PPO.learn">
<span class="sig-name descname"><span class="pre">learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">total_timesteps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tb_log_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'PPO'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_num_timesteps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">progress_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/ppo/ppo.html#PPO.learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.ppo.PPO.learn" title="Permalink to this definition"></a></dt>
<dd><p>Return a trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>total_timesteps</strong> (<em>int</em>) – The total number of samples (env steps) to train on</p></li>
<li><p><strong>callback</strong> (<em>None</em><em> | </em><em>Callable</em><em> | </em><em>List</em><em>[</em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a><em>] </em><em>| </em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – callback(s) called at every step with state of the algorithm.</p></li>
<li><p><strong>log_interval</strong> (<em>int</em>) – The number of episodes before logging.</p></li>
<li><p><strong>tb_log_name</strong> (<em>str</em>) – the name of the run for TensorBoard logging</p></li>
<li><p><strong>reset_num_timesteps</strong> (<em>bool</em>) – whether or not to reset the current timestep number (used in logging)</p></li>
<li><p><strong>progress_bar</strong> (<em>bool</em>) – Display a progress bar using tqdm and rich.</p></li>
<li><p><strong>self</strong> (<em>SelfPPO</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the trained model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfPPO</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ppo.PPO.load">
<em class="property"><span class="pre">classmethod</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_objects</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_system_info</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_reset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ppo.PPO.load" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a zip-file.
Warning: <code class="docutils literal notranslate"><span class="pre">load</span></code> re-creates the model from scratch, it does not update it in-place!
For an in-place load use <code class="docutils literal notranslate"><span class="pre">set_parameters</span></code> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – path to the file (or a file-like) where to
load the agent from</p></li>
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a><em> | </em><em>None</em>) – the new environment to run the loaded model on
(can be None if you only need prediction from a trained model) has priority over any saved environment</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device on which the code should run.</p></li>
<li><p><strong>custom_objects</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Dictionary of objects to replace
upon loading. If a variable is present in this dictionary as a
key, it will not be deserialized and the corresponding item
will be used instead. Similar to custom_objects in
<code class="docutils literal notranslate"><span class="pre">keras.models.load_model</span></code>. Useful when you have an object in
file that can not be deserialized.</p></li>
<li><p><strong>print_system_info</strong> (<em>bool</em>) – Whether to print system info from the saved model
and the current system info (useful to debug loading issues)</p></li>
<li><p><strong>force_reset</strong> (<em>bool</em>) – Force call to <code class="docutils literal notranslate"><span class="pre">reset()</span></code> before training
to avoid unexpected behavior.
See <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/597">https://github.com/DLR-RM/stable-baselines3/issues/597</a></p></li>
<li><p><strong>kwargs</strong> – extra arguments to change the model when loading</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>new model instance with loaded parameters</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfBaseAlgorithm</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="stable_baselines3.ppo.PPO.logger">
<em class="property"><span class="pre">property</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">logger</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><a class="reference internal" href="index.html#stable_baselines3.common.logger.Logger" title="stable_baselines3.common.logger.Logger"><span class="pre">Logger</span></a></em><a class="headerlink" href="#stable_baselines3.ppo.PPO.logger" title="Permalink to this definition"></a></dt>
<dd><p>Getter for the logger object.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ppo.PPO.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">episode_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ppo.PPO.predict" title="Permalink to this definition"></a></dt>
<dd><p>Get the policy action from an observation (and optional hidden state).
Includes sugar-coating to handle different observations (e.g. normalizing images).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation</strong> (<em>ndarray</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>ndarray</em><em>]</em>) – the input observation</p></li>
<li><p><strong>state</strong> (<em>Tuple</em><em>[</em><em>ndarray</em><em>, </em><em>...</em><em>] </em><em>| </em><em>None</em>) – The last hidden states (can be None, used in recurrent policies)</p></li>
<li><p><strong>episode_start</strong> (<em>ndarray</em><em> | </em><em>None</em>) – The last masks (can be None, used in recurrent policies)
this correspond to beginning of episodes,
where the hidden states of the RNN must be reset.</p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – Whether or not to return deterministic actions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the model’s action and the next hidden state
(used in recurrent policies)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>ndarray</em>, <em>Tuple</em>[<em>ndarray</em>, …] | None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ppo.PPO.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ppo.PPO.save" title="Permalink to this definition"></a></dt>
<dd><p>Save all the attributes of the object and the model parameters in a zip-file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – path to the file where the rl agent should be saved</p></li>
<li><p><strong>exclude</strong> (<em>Iterable</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – name of parameters that should be excluded in addition to the default ones</p></li>
<li><p><strong>include</strong> (<em>Iterable</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – name of parameters that might be excluded but should be included anyway</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ppo.PPO.set_env">
<span class="sig-name descname"><span class="pre">set_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_reset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ppo.PPO.set_env" title="Permalink to this definition"></a></dt>
<dd><p>Checks the validity of the environment, and if it is coherent, set it as the current environment.
Furthermore wrap any non vectorized env into a vectorized
checked parameters:
- observation_space
- action_space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The environment for learning a policy</p></li>
<li><p><strong>force_reset</strong> (<em>bool</em>) – Force call to <code class="docutils literal notranslate"><span class="pre">reset()</span></code> before training
to avoid unexpected behavior.
See issue <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/597">https://github.com/DLR-RM/stable-baselines3/issues/597</a></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ppo.PPO.set_logger">
<span class="sig-name descname"><span class="pre">set_logger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ppo.PPO.set_logger" title="Permalink to this definition"></a></dt>
<dd><p>Setter for for logger object.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When passing a custom logger object,
this will overwrite <code class="docutils literal notranslate"><span class="pre">tensorboard_log</span></code> and <code class="docutils literal notranslate"><span class="pre">verbose</span></code> settings
passed to the constructor.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>logger</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.logger.Logger" title="stable_baselines3.common.logger.Logger"><em>Logger</em></a>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ppo.PPO.set_parameters">
<span class="sig-name descname"><span class="pre">set_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">load_path_or_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exact_match</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ppo.PPO.set_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Load parameters from a given zip-file or a nested dictionary containing parameters for
different modules (see <code class="docutils literal notranslate"><span class="pre">get_parameters</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>load_path_or_iter</strong> – Location of the saved data (path or file-like, see <code class="docutils literal notranslate"><span class="pre">save</span></code>), or a nested
dictionary containing nn.Module parameters used by the policy. The dictionary maps
object names to a state-dictionary returned by <code class="docutils literal notranslate"><span class="pre">torch.nn.Module.state_dict()</span></code>.</p></li>
<li><p><strong>exact_match</strong> (<em>bool</em>) – If True, the given parameters should include parameters for each
module and each of their parameters, otherwise raises an Exception. If set to False, this
can be used to update only specific parameters.</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device on which the code should run.</p></li>
<li><p><strong>load_path_or_dict</strong> (<em>str</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ppo.PPO.set_random_seed">
<span class="sig-name descname"><span class="pre">set_random_seed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.ppo.PPO.set_random_seed" title="Permalink to this definition"></a></dt>
<dd><p>Set the seed of the pseudo-random generators
(python, numpy, pytorch, gym, action_space)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.ppo.PPO.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/ppo/ppo.html#PPO.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.ppo.PPO.train" title="Permalink to this definition"></a></dt>
<dd><p>Update policy using the currently gathered rollout buffer.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="ppo-policies">
<h4>PPO Policies<a class="headerlink" href="#ppo-policies" title="Permalink to this heading"></a></h4>
<dl class="py attribute">
<dt class="sig sig-object py" id="stable_baselines3.ppo.MlpPolicy">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.ppo.</span></span><span class="sig-name descname"><span class="pre">MlpPolicy</span></span><a class="headerlink" href="#stable_baselines3.ppo.MlpPolicy" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">ActorCriticPolicy</span></code></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.policies.</span></span><span class="sig-name descname"><span class="pre">ActorCriticPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.Tanh'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ortho_init=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std_init=0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_std=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_expln=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">squash_output=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.FlattenExtractor'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share_features_extractor=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#ActorCriticPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Policy class for actor-critic algorithms (has both policy and value prediction).
Used by A2C, PPO and the likes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Space</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Space</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>ortho_init</strong> (<em>bool</em>) – Whether to use or not orthogonal initialization</p></li>
<li><p><strong>use_sde</strong> (<em>bool</em>) – Whether to use State Dependent Exploration or not</p></li>
<li><p><strong>log_std_init</strong> (<em>float</em>) – Initial value for the log standard deviation</p></li>
<li><p><strong>full_std</strong> (<em>bool</em>) – Whether to use (n_features x n_actions) parameters
for the std instead of only (n_features,) when using gSDE</p></li>
<li><p><strong>use_expln</strong> (<em>bool</em>) – Use <code class="docutils literal notranslate"><span class="pre">expln()</span></code> function instead of <code class="docutils literal notranslate"><span class="pre">exp()</span></code> to ensure
a positive standard deviation (cf paper). It allows to keep variance
above zero and prevent it from growing too fast. In practice, <code class="docutils literal notranslate"><span class="pre">exp()</span></code> is usually enough.</p></li>
<li><p><strong>squash_output</strong> (<em>bool</em>) – Whether to squash the output using a tanh function,
this allows to ensure boundaries when using gSDE.</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Features extractor to use.</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments
to pass to the features extractor.</p></li>
<li><p><strong>share_features_extractor</strong> (<em>bool</em>) – If True, the features extractor is shared between the policy and value networks.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">evaluate_actions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">actions</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#ActorCriticPolicy.evaluate_actions"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Evaluate actions according to the current policy,
given the observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs</strong> (<em>Tensor</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – Observation</p></li>
<li><p><strong>actions</strong> (<em>Tensor</em>) – Actions</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>estimated value, log likelihood of taking those actions
and entropy of the action distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>, <em>Tensor</em> | None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">extract_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#ActorCriticPolicy.extract_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Preprocess the observation if needed and extract features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs</strong> (<em>Tensor</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – Observation</p></li>
<li><p><strong>features_extractor</strong> (<em>BaseFeaturesExtractor</em><em> | </em><em>None</em>) – The features extractor to use. If None, then <code class="docutils literal notranslate"><span class="pre">self.features_extractor</span></code> is used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The extracted features. If features extractor is not shared, returns a tuple with the
features for the actor and the features for the critic.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em> | <em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#ActorCriticPolicy.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Forward pass in all the networks (actor and critic)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs</strong> (<em>Tensor</em>) – Observation</p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – Whether to sample or use deterministic actions</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>action, value and log probability of the action</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">get_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#ActorCriticPolicy.get_distribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Get the current policy distribution given the observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>obs</strong> (<em>Tensor</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the action distribution.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="index.html#stable_baselines3.common.distributions.Distribution" title="stable_baselines3.common.distributions.Distribution"><em>Distribution</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">predict_values</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#ActorCriticPolicy.predict_values"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Get the estimated values according to the current policy given the observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>obs</strong> (<em>Tensor</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – Observation</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the estimated values.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">reset_noise</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_envs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#ActorCriticPolicy.reset_noise"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Sample new weights for the exploration matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>n_envs</strong> (<em>int</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="stable_baselines3.ppo.CnnPolicy">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.ppo.</span></span><span class="sig-name descname"><span class="pre">CnnPolicy</span></span><a class="headerlink" href="#stable_baselines3.ppo.CnnPolicy" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">ActorCriticCnnPolicy</span></code></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.policies.</span></span><span class="sig-name descname"><span class="pre">ActorCriticCnnPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.Tanh'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ortho_init=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std_init=0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_std=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_expln=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">squash_output=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.NatureCNN'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share_features_extractor=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#ActorCriticCnnPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>CNN policy class for actor-critic algorithms (has both policy and value prediction).
Used by A2C, PPO and the likes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Space</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Space</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>ortho_init</strong> (<em>bool</em>) – Whether to use or not orthogonal initialization</p></li>
<li><p><strong>use_sde</strong> (<em>bool</em>) – Whether to use State Dependent Exploration or not</p></li>
<li><p><strong>log_std_init</strong> (<em>float</em>) – Initial value for the log standard deviation</p></li>
<li><p><strong>full_std</strong> (<em>bool</em>) – Whether to use (n_features x n_actions) parameters
for the std instead of only (n_features,) when using gSDE</p></li>
<li><p><strong>use_expln</strong> (<em>bool</em>) – Use <code class="docutils literal notranslate"><span class="pre">expln()</span></code> function instead of <code class="docutils literal notranslate"><span class="pre">exp()</span></code> to ensure
a positive standard deviation (cf paper). It allows to keep variance
above zero and prevent it from growing too fast. In practice, <code class="docutils literal notranslate"><span class="pre">exp()</span></code> is usually enough.</p></li>
<li><p><strong>squash_output</strong> (<em>bool</em>) – Whether to squash the output using a tanh function,
this allows to ensure boundaries when using gSDE.</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Features extractor to use.</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments
to pass to the features extractor.</p></li>
<li><p><strong>share_features_extractor</strong> (<em>bool</em>) – If True, the features extractor is shared between the policy and value networks.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="stable_baselines3.ppo.MultiInputPolicy">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.ppo.</span></span><span class="sig-name descname"><span class="pre">MultiInputPolicy</span></span><a class="headerlink" href="#stable_baselines3.ppo.MultiInputPolicy" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">MultiInputActorCriticPolicy</span></code></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.policies.</span></span><span class="sig-name descname"><span class="pre">MultiInputActorCriticPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.Tanh'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ortho_init=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std_init=0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_std=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_expln=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">squash_output=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.CombinedExtractor'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share_features_extractor=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/policies.html#MultiInputActorCriticPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>MultiInputActorClass policy class for actor-critic algorithms (has both policy and value prediction).
Used by A2C, PPO and the likes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Dict</em>) – Observation space (Tuple)</p></li>
<li><p><strong>action_space</strong> (<em>Space</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>ortho_init</strong> (<em>bool</em>) – Whether to use or not orthogonal initialization</p></li>
<li><p><strong>use_sde</strong> (<em>bool</em>) – Whether to use State Dependent Exploration or not</p></li>
<li><p><strong>log_std_init</strong> (<em>float</em>) – Initial value for the log standard deviation</p></li>
<li><p><strong>full_std</strong> (<em>bool</em>) – Whether to use (n_features x n_actions) parameters
for the std instead of only (n_features,) when using gSDE</p></li>
<li><p><strong>use_expln</strong> (<em>bool</em>) – Use <code class="docutils literal notranslate"><span class="pre">expln()</span></code> function instead of <code class="docutils literal notranslate"><span class="pre">exp()</span></code> to ensure
a positive standard deviation (cf paper). It allows to keep variance
above zero and prevent it from growing too fast. In practice, <code class="docutils literal notranslate"><span class="pre">exp()</span></code> is usually enough.</p></li>
<li><p><strong>squash_output</strong> (<em>bool</em>) – Whether to squash the output using a tanh function,
this allows to ensure boundaries when using gSDE.</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Uses the CombinedExtractor</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments
to pass to the features extractor.</p></li>
<li><p><strong>share_features_extractor</strong> (<em>bool</em>) – If True, the features extractor is shared between the policy and value networks.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
<span id="document-modules/sac"></span><span class="target" id="module-stable_baselines3.sac"><span id="sac"></span></span><section id="id1">
<h3>SAC<a class="headerlink" href="#id1" title="Permalink to this heading"></a></h3>
<p><a class="reference external" href="https://spinningup.openai.com/en/latest/algorithms/sac.html">Soft Actor Critic (SAC)</a> Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor.</p>
<p>SAC is the successor of <a class="reference external" href="https://arxiv.org/abs/1702.08165">Soft Q-Learning SQL</a> and incorporates the double Q-learning trick from TD3.
A key feature of SAC, and a major difference with common RL algorithms, is that it is trained to maximize a trade-off between expected return and entropy, a measure of randomness in the policy.</p>
<p class="rubric">Available Policies</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#stable_baselines3.sac.MlpPolicy" title="stable_baselines3.sac.MlpPolicy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MlpPolicy</span></code></a></p></td>
<td><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">SACPolicy</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#stable_baselines3.sac.CnnPolicy" title="stable_baselines3.sac.CnnPolicy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CnnPolicy</span></code></a></p></td>
<td><p>Policy class (with both actor and critic) for SAC.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#stable_baselines3.sac.MultiInputPolicy" title="stable_baselines3.sac.MultiInputPolicy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiInputPolicy</span></code></a></p></td>
<td><p>Policy class (with both actor and critic) for SAC.</p></td>
</tr>
</tbody>
</table>
<section id="notes">
<h4>Notes<a class="headerlink" href="#notes" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Original paper: <a class="reference external" href="https://arxiv.org/abs/1801.01290">https://arxiv.org/abs/1801.01290</a></p></li>
<li><p>OpenAI Spinning Guide for SAC: <a class="reference external" href="https://spinningup.openai.com/en/latest/algorithms/sac.html">https://spinningup.openai.com/en/latest/algorithms/sac.html</a></p></li>
<li><p>Original Implementation: <a class="reference external" href="https://github.com/haarnoja/sac">https://github.com/haarnoja/sac</a></p></li>
<li><p>Blog post on using SAC with real robots: <a class="reference external" href="https://bair.berkeley.edu/blog/2018/12/14/sac/">https://bair.berkeley.edu/blog/2018/12/14/sac/</a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In our implementation, we use an entropy coefficient (as in OpenAI Spinning or Facebook Horizon),
which is the equivalent to the inverse of reward scale in the original SAC paper.
The main reason is that it avoids having too high errors when updating the Q functions.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The default policies for SAC differ a bit from others MlpPolicy: it uses ReLU instead of tanh activation,
to match the original paper</p>
</div>
</section>
<section id="can-i-use">
<h4>Can I use?<a class="headerlink" href="#can-i-use" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Recurrent policies: ❌</p></li>
<li><p>Multi processing: ✔️</p></li>
<li><p>Gym spaces:</p></li>
</ul>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Space</p></th>
<th class="head"><p>Action</p></th>
<th class="head"><p>Observation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Discrete</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>Box</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>MultiDiscrete</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>MultiBinary</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>Dict</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
</tbody>
</table>
</section>
<section id="example">
<h4>Example<a class="headerlink" href="#example" title="Permalink to this heading"></a></h4>
<p>This example is only to demonstrate the use of the library and its functions, and the trained agents may not solve the environments. Optimized hyperparameters can be found in RL Zoo <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">repository</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">SAC</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">&quot;human&quot;</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;sac_pendulum&quot;</span><span class="p">)</span>

<span class="k">del</span> <span class="n">model</span> <span class="c1"># remove to demonstrate saving and loading</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;sac_pendulum&quot;</span><span class="p">)</span>

<span class="n">obs</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">_states</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span><span class="p">:</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="results">
<h4>Results<a class="headerlink" href="#results" title="Permalink to this heading"></a></h4>
<section id="pybullet-environments">
<h5>PyBullet Environments<a class="headerlink" href="#pybullet-environments" title="Permalink to this heading"></a></h5>
<p>Results on the PyBullet benchmark (1M steps) using 3 seeds.
The complete learning curves are available in the <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/48">associated issue #48</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Hyperparameters from the <a class="reference external" href="https://arxiv.org/abs/2005.05719">gSDE paper</a> were used (as they are tuned for PyBullet envs).</p>
</div>
<p><em>Gaussian</em> means that the unstructured Gaussian noise is used for exploration,
<em>gSDE</em> (generalized State-Dependent Exploration) is used otherwise.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Environments</p></th>
<th class="head"><p>SAC</p></th>
<th class="head"><p>SAC</p></th>
<th class="head"><p>TD3</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td></td>
<td><p>Gaussian</p></td>
<td><p>gSDE</p></td>
<td><p>Gaussian</p></td>
</tr>
<tr class="row-odd"><td><p>HalfCheetah</p></td>
<td><p>2757 +/- 53</p></td>
<td><p>2984 +/- 202</p></td>
<td><p>2774 +/- 35</p></td>
</tr>
<tr class="row-even"><td><p>Ant</p></td>
<td><p>3146 +/- 35</p></td>
<td><p>3102 +/- 37</p></td>
<td><p>3305 +/- 43</p></td>
</tr>
<tr class="row-odd"><td><p>Hopper</p></td>
<td><p>2422 +/- 168</p></td>
<td><p>2262 +/- 1</p></td>
<td><p>2429 +/- 126</p></td>
</tr>
<tr class="row-even"><td><p>Walker2D</p></td>
<td><p>2184 +/- 54</p></td>
<td><p>2136 +/- 67</p></td>
<td><p>2063 +/- 185</p></td>
</tr>
</tbody>
</table>
</section>
<section id="how-to-replicate-the-results">
<h5>How to replicate the results?<a class="headerlink" href="#how-to-replicate-the-results" title="Permalink to this heading"></a></h5>
<p>Clone the <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">rl-zoo repo</a>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/DLR-RM/rl-baselines3-zoo
<span class="nb">cd</span><span class="w"> </span>rl-baselines3-zoo/
</pre></div>
</div>
<p>Run the benchmark (replace <code class="docutils literal notranslate"><span class="pre">$ENV_ID</span></code> by the envs mentioned above):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>train.py<span class="w"> </span>--algo<span class="w"> </span>sac<span class="w"> </span>--env<span class="w"> </span><span class="nv">$ENV_ID</span><span class="w"> </span>--eval-episodes<span class="w"> </span><span class="m">10</span><span class="w"> </span>--eval-freq<span class="w"> </span><span class="m">10000</span>
</pre></div>
</div>
<p>Plot the results:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>scripts/all_plots.py<span class="w"> </span>-a<span class="w"> </span>sac<span class="w"> </span>-e<span class="w"> </span>HalfCheetah<span class="w"> </span>Ant<span class="w"> </span>Hopper<span class="w"> </span>Walker2D<span class="w"> </span>-f<span class="w"> </span>logs/<span class="w"> </span>-o<span class="w"> </span>logs/sac_results
python<span class="w"> </span>scripts/plot_from_file.py<span class="w"> </span>-i<span class="w"> </span>logs/sac_results.pkl<span class="w"> </span>-latex<span class="w"> </span>-l<span class="w"> </span>SAC
</pre></div>
</div>
</section>
</section>
<section id="parameters">
<h4>Parameters<a class="headerlink" href="#parameters" title="Permalink to this heading"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.sac.SAC">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.sac.</span></span><span class="sig-name descname"><span class="pre">SAC</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">policy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0003</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_starts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.005</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_buffer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_buffer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimize_memory_usage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ent_coef</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_update_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_entropy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sde_sample_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde_at_warmup</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stats_window_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensorboard_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_init_setup_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/sac/sac.html#SAC"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.sac.SAC" title="Permalink to this definition"></a></dt>
<dd><p>Soft Actor-Critic (SAC)
Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor,
This implementation borrows code from original implementation (<a class="reference external" href="https://github.com/haarnoja/sac">https://github.com/haarnoja/sac</a>)
from OpenAI Spinning Up (<a class="reference external" href="https://github.com/openai/spinningup">https://github.com/openai/spinningup</a>), from the softlearning repo
(<a class="reference external" href="https://github.com/rail-berkeley/softlearning/">https://github.com/rail-berkeley/softlearning/</a>)
and from Stable Baselines (<a class="reference external" href="https://github.com/hill-a/stable-baselines">https://github.com/hill-a/stable-baselines</a>)
Paper: <a class="reference external" href="https://arxiv.org/abs/1801.01290">https://arxiv.org/abs/1801.01290</a>
Introduction to SAC: <a class="reference external" href="https://spinningup.openai.com/en/latest/algorithms/sac.html">https://spinningup.openai.com/en/latest/algorithms/sac.html</a></p>
<p>Note: we use double q target and not value target as discussed
in <a class="reference external" href="https://github.com/hill-a/stable-baselines/issues/270">https://github.com/hill-a/stable-baselines/issues/270</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>policy</strong> (<em>SACPolicy</em>) – The policy model to use (MlpPolicy, CnnPolicy, …)</p></li>
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.VecEnv"><em>VecEnv</em></a><em> | </em><em>str</em>) – The environment to learn from (if registered in Gym, can be str)</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – learning rate for adam optimizer,
the same learning rate will be used for all networks (Q-Values, Actor and Value function)
it can be a function of the current progress remaining (from 1 to 0)</p></li>
<li><p><strong>buffer_size</strong> (<em>int</em>) – size of the replay buffer</p></li>
<li><p><strong>learning_starts</strong> (<em>int</em>) – how many steps of the model to collect transitions for before learning starts</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Minibatch size for each gradient update</p></li>
<li><p><strong>tau</strong> (<em>float</em>) – the soft update coefficient (“Polyak update”, between 0 and 1)</p></li>
<li><p><strong>gamma</strong> (<em>float</em>) – the discount factor</p></li>
<li><p><strong>train_freq</strong> (<em>int</em><em> | </em><em>Tuple</em><em>[</em><em>int</em><em>, </em><em>str</em><em>]</em>) – Update the model every <code class="docutils literal notranslate"><span class="pre">train_freq</span></code> steps. Alternatively pass a tuple of frequency and unit
like <code class="docutils literal notranslate"><span class="pre">(5,</span> <span class="pre">&quot;step&quot;)</span></code> or <code class="docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">&quot;episode&quot;)</span></code>.</p></li>
<li><p><strong>gradient_steps</strong> (<em>int</em>) – How many gradient steps to do after each rollout (see <code class="docutils literal notranslate"><span class="pre">train_freq</span></code>)
Set to <code class="docutils literal notranslate"><span class="pre">-1</span></code> means to do as many gradient steps as steps done in the environment
during the rollout.</p></li>
<li><p><strong>action_noise</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.noise.ActionNoise" title="stable_baselines3.common.noise.ActionNoise"><em>ActionNoise</em></a><em> | </em><em>None</em>) – the action noise type (None by default), this can help
for hard exploration problem. Cf common.noise for the different action noise type.</p></li>
<li><p><strong>replay_buffer_class</strong> (<em>Type</em><em>[</em><em>ReplayBuffer</em><em>] </em><em>| </em><em>None</em>) – Replay buffer class to use (for instance <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code>).
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, it will be automatically selected.</p></li>
<li><p><strong>replay_buffer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments to pass to the replay buffer on creation.</p></li>
<li><p><strong>optimize_memory_usage</strong> (<em>bool</em>) – Enable a memory efficient variant of the replay buffer
at a cost of more complexity.
See <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195">https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195</a></p></li>
<li><p><strong>ent_coef</strong> (<em>str</em><em> | </em><em>float</em>) – Entropy regularization coefficient. (Equivalent to
inverse of reward scale in the original SAC paper.)  Controlling exploration/exploitation trade-off.
Set it to ‘auto’ to learn it automatically (and ‘auto_0.1’ for using 0.1 as initial value)</p></li>
<li><p><strong>target_update_interval</strong> (<em>int</em>) – update the target network every <code class="docutils literal notranslate"><span class="pre">target_network_update_freq</span></code>
gradient steps.</p></li>
<li><p><strong>target_entropy</strong> (<em>str</em><em> | </em><em>float</em>) – target entropy when learning <code class="docutils literal notranslate"><span class="pre">ent_coef</span></code> (<code class="docutils literal notranslate"><span class="pre">ent_coef</span> <span class="pre">=</span> <span class="pre">'auto'</span></code>)</p></li>
<li><p><strong>use_sde</strong> (<em>bool</em>) – Whether to use generalized State Dependent Exploration (gSDE)
instead of action noise exploration (default: False)</p></li>
<li><p><strong>sde_sample_freq</strong> (<em>int</em>) – Sample a new noise matrix every n steps when using gSDE
Default: -1 (only sample at the beginning of the rollout)</p></li>
<li><p><strong>use_sde_at_warmup</strong> (<em>bool</em>) – Whether to use gSDE instead of uniform sampling
during the warm up phase (before learning starts)</p></li>
<li><p><strong>stats_window_size</strong> (<em>int</em>) – Window size for the rollout logging, specifying the number of episodes to average
the reported success rate, mean episode length, and mean reward over</p></li>
<li><p><strong>tensorboard_log</strong> (<em>str</em><em> | </em><em>None</em>) – the log location for tensorboard (if None, no logging)</p></li>
<li><p><strong>policy_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – additional arguments to be passed to the policy on creation</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 1 for info messages (such as device or wrappers used), 2 for
debug messages</p></li>
<li><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – Seed for the pseudo random generators</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device (cpu, cuda, …) on which the code should be run.
Setting it to auto, the code will be run on the GPU if possible.</p></li>
<li><p><strong>_init_setup_model</strong> (<em>bool</em>) – Whether or not to build the network at the creation of the instance</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.sac.SAC.collect_rollouts">
<span class="sig-name descname"><span class="pre">collect_rollouts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_freq</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_buffer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_starts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.sac.SAC.collect_rollouts" title="Permalink to this definition"></a></dt>
<dd><p>Collect experiences and store them into a <code class="docutils literal notranslate"><span class="pre">ReplayBuffer</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The training environment</p></li>
<li><p><strong>callback</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – Callback that will be called at each step
(and at the beginning and end of the rollout)</p></li>
<li><p><strong>train_freq</strong> (<em>TrainFreq</em>) – How much experience to collect
by doing rollouts of current policy.
Either <code class="docutils literal notranslate"><span class="pre">TrainFreq(&lt;n&gt;,</span> <span class="pre">TrainFrequencyUnit.STEP)</span></code>
or <code class="docutils literal notranslate"><span class="pre">TrainFreq(&lt;n&gt;,</span> <span class="pre">TrainFrequencyUnit.EPISODE)</span></code>
with <code class="docutils literal notranslate"><span class="pre">&lt;n&gt;</span></code> being an integer greater than 0.</p></li>
<li><p><strong>action_noise</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.noise.ActionNoise" title="stable_baselines3.common.noise.ActionNoise"><em>ActionNoise</em></a><em> | </em><em>None</em>) – Action noise that will be used for exploration
Required for deterministic policy (e.g. TD3). This can also be used
in addition to the stochastic policy for SAC.</p></li>
<li><p><strong>learning_starts</strong> (<em>int</em>) – Number of steps before learning for the warm-up phase.</p></li>
<li><p><strong>replay_buffer</strong> (<em>ReplayBuffer</em>) – </p></li>
<li><p><strong>log_interval</strong> (<em>int</em><em> | </em><em>None</em>) – Log data every <code class="docutils literal notranslate"><span class="pre">log_interval</span></code> episodes</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>RolloutReturn</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.sac.SAC.get_env">
<span class="sig-name descname"><span class="pre">get_env</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.sac.SAC.get_env" title="Permalink to this definition"></a></dt>
<dd><p>Returns the current environment (can be None if not defined).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The current environment</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.sac.SAC.get_parameters">
<span class="sig-name descname"><span class="pre">get_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.sac.SAC.get_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Return the parameters of the agent. This includes parameters from different networks, e.g.
critics (value functions) and policies (pi functions).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Mapping of from names of the objects to PyTorch state-dicts.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Dict</em>[str, <em>Dict</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.sac.SAC.get_vec_normalize_env">
<span class="sig-name descname"><span class="pre">get_vec_normalize_env</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.sac.SAC.get_vec_normalize_env" title="Permalink to this definition"></a></dt>
<dd><p>Return the <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> wrapper of the training env
if it exists.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> env.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecNormalize" title="stable_baselines3.common.vec_env.vec_normalize.VecNormalize"><em>VecNormalize</em></a> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.sac.SAC.learn">
<span class="sig-name descname"><span class="pre">learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">total_timesteps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tb_log_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'SAC'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_num_timesteps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">progress_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/sac/sac.html#SAC.learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.sac.SAC.learn" title="Permalink to this definition"></a></dt>
<dd><p>Return a trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>total_timesteps</strong> (<em>int</em>) – The total number of samples (env steps) to train on</p></li>
<li><p><strong>callback</strong> (<em>None</em><em> | </em><em>Callable</em><em> | </em><em>List</em><em>[</em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a><em>] </em><em>| </em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – callback(s) called at every step with state of the algorithm.</p></li>
<li><p><strong>log_interval</strong> (<em>int</em>) – The number of episodes before logging.</p></li>
<li><p><strong>tb_log_name</strong> (<em>str</em>) – the name of the run for TensorBoard logging</p></li>
<li><p><strong>reset_num_timesteps</strong> (<em>bool</em>) – whether or not to reset the current timestep number (used in logging)</p></li>
<li><p><strong>progress_bar</strong> (<em>bool</em>) – Display a progress bar using tqdm and rich.</p></li>
<li><p><strong>self</strong> (<em>SelfSAC</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the trained model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfSAC</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.sac.SAC.load">
<em class="property"><span class="pre">classmethod</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_objects</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_system_info</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_reset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.sac.SAC.load" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a zip-file.
Warning: <code class="docutils literal notranslate"><span class="pre">load</span></code> re-creates the model from scratch, it does not update it in-place!
For an in-place load use <code class="docutils literal notranslate"><span class="pre">set_parameters</span></code> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – path to the file (or a file-like) where to
load the agent from</p></li>
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a><em> | </em><em>None</em>) – the new environment to run the loaded model on
(can be None if you only need prediction from a trained model) has priority over any saved environment</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device on which the code should run.</p></li>
<li><p><strong>custom_objects</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Dictionary of objects to replace
upon loading. If a variable is present in this dictionary as a
key, it will not be deserialized and the corresponding item
will be used instead. Similar to custom_objects in
<code class="docutils literal notranslate"><span class="pre">keras.models.load_model</span></code>. Useful when you have an object in
file that can not be deserialized.</p></li>
<li><p><strong>print_system_info</strong> (<em>bool</em>) – Whether to print system info from the saved model
and the current system info (useful to debug loading issues)</p></li>
<li><p><strong>force_reset</strong> (<em>bool</em>) – Force call to <code class="docutils literal notranslate"><span class="pre">reset()</span></code> before training
to avoid unexpected behavior.
See <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/597">https://github.com/DLR-RM/stable-baselines3/issues/597</a></p></li>
<li><p><strong>kwargs</strong> – extra arguments to change the model when loading</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>new model instance with loaded parameters</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfBaseAlgorithm</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.sac.SAC.load_replay_buffer">
<span class="sig-name descname"><span class="pre">load_replay_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truncate_last_traj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.sac.SAC.load_replay_buffer" title="Permalink to this definition"></a></dt>
<dd><p>Load a replay buffer from a pickle file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – Path to the pickled replay buffer.</p></li>
<li><p><strong>truncate_last_traj</strong> (<em>bool</em>) – When using <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code> with online sampling:
If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, we assume that the last trajectory in the replay buffer was finished
(and truncate it).
If set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, we assume that we continue the same trajectory (same episode).</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="stable_baselines3.sac.SAC.logger">
<em class="property"><span class="pre">property</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">logger</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><a class="reference internal" href="index.html#stable_baselines3.common.logger.Logger" title="stable_baselines3.common.logger.Logger"><span class="pre">Logger</span></a></em><a class="headerlink" href="#stable_baselines3.sac.SAC.logger" title="Permalink to this definition"></a></dt>
<dd><p>Getter for the logger object.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.sac.SAC.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">episode_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.sac.SAC.predict" title="Permalink to this definition"></a></dt>
<dd><p>Get the policy action from an observation (and optional hidden state).
Includes sugar-coating to handle different observations (e.g. normalizing images).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation</strong> (<em>ndarray</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>ndarray</em><em>]</em>) – the input observation</p></li>
<li><p><strong>state</strong> (<em>Tuple</em><em>[</em><em>ndarray</em><em>, </em><em>...</em><em>] </em><em>| </em><em>None</em>) – The last hidden states (can be None, used in recurrent policies)</p></li>
<li><p><strong>episode_start</strong> (<em>ndarray</em><em> | </em><em>None</em>) – The last masks (can be None, used in recurrent policies)
this correspond to beginning of episodes,
where the hidden states of the RNN must be reset.</p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – Whether or not to return deterministic actions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the model’s action and the next hidden state
(used in recurrent policies)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>ndarray</em>, <em>Tuple</em>[<em>ndarray</em>, …] | None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.sac.SAC.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.sac.SAC.save" title="Permalink to this definition"></a></dt>
<dd><p>Save all the attributes of the object and the model parameters in a zip-file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – path to the file where the rl agent should be saved</p></li>
<li><p><strong>exclude</strong> (<em>Iterable</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – name of parameters that should be excluded in addition to the default ones</p></li>
<li><p><strong>include</strong> (<em>Iterable</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – name of parameters that might be excluded but should be included anyway</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.sac.SAC.save_replay_buffer">
<span class="sig-name descname"><span class="pre">save_replay_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.sac.SAC.save_replay_buffer" title="Permalink to this definition"></a></dt>
<dd><p>Save the replay buffer as a pickle file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – Path to the file where the replay buffer should be saved.
if path is a str or pathlib.Path, the path is automatically created if necessary.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.sac.SAC.set_env">
<span class="sig-name descname"><span class="pre">set_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_reset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.sac.SAC.set_env" title="Permalink to this definition"></a></dt>
<dd><p>Checks the validity of the environment, and if it is coherent, set it as the current environment.
Furthermore wrap any non vectorized env into a vectorized
checked parameters:
- observation_space
- action_space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The environment for learning a policy</p></li>
<li><p><strong>force_reset</strong> (<em>bool</em>) – Force call to <code class="docutils literal notranslate"><span class="pre">reset()</span></code> before training
to avoid unexpected behavior.
See issue <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/597">https://github.com/DLR-RM/stable-baselines3/issues/597</a></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.sac.SAC.set_logger">
<span class="sig-name descname"><span class="pre">set_logger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.sac.SAC.set_logger" title="Permalink to this definition"></a></dt>
<dd><p>Setter for for logger object.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When passing a custom logger object,
this will overwrite <code class="docutils literal notranslate"><span class="pre">tensorboard_log</span></code> and <code class="docutils literal notranslate"><span class="pre">verbose</span></code> settings
passed to the constructor.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>logger</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.logger.Logger" title="stable_baselines3.common.logger.Logger"><em>Logger</em></a>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.sac.SAC.set_parameters">
<span class="sig-name descname"><span class="pre">set_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">load_path_or_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exact_match</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.sac.SAC.set_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Load parameters from a given zip-file or a nested dictionary containing parameters for
different modules (see <code class="docutils literal notranslate"><span class="pre">get_parameters</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>load_path_or_iter</strong> – Location of the saved data (path or file-like, see <code class="docutils literal notranslate"><span class="pre">save</span></code>), or a nested
dictionary containing nn.Module parameters used by the policy. The dictionary maps
object names to a state-dictionary returned by <code class="docutils literal notranslate"><span class="pre">torch.nn.Module.state_dict()</span></code>.</p></li>
<li><p><strong>exact_match</strong> (<em>bool</em>) – If True, the given parameters should include parameters for each
module and each of their parameters, otherwise raises an Exception. If set to False, this
can be used to update only specific parameters.</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device on which the code should run.</p></li>
<li><p><strong>load_path_or_dict</strong> (<em>str</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.sac.SAC.set_random_seed">
<span class="sig-name descname"><span class="pre">set_random_seed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.sac.SAC.set_random_seed" title="Permalink to this definition"></a></dt>
<dd><p>Set the seed of the pseudo-random generators
(python, numpy, pytorch, gym, action_space)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.sac.SAC.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradient_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/sac/sac.html#SAC.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.sac.SAC.train" title="Permalink to this definition"></a></dt>
<dd><p>Sample the replay buffer and do the updates
(gradient descent and update target networks)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gradient_steps</strong> (<em>int</em>) – </p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="sac-policies">
<span id="id2"></span><h4>SAC Policies<a class="headerlink" href="#sac-policies" title="Permalink to this heading"></a></h4>
<dl class="py attribute">
<dt class="sig sig-object py" id="stable_baselines3.sac.MlpPolicy">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.sac.</span></span><span class="sig-name descname"><span class="pre">MlpPolicy</span></span><a class="headerlink" href="#stable_baselines3.sac.MlpPolicy" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">SACPolicy</span></code></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.sac.policies.</span></span><span class="sig-name descname"><span class="pre">SACPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std_init=-3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_expln=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_mean=2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.FlattenExtractor'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_critics=2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share_features_extractor=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/sac/policies.html#SACPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Policy class (with both actor and critic) for SAC.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Space</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Box</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>use_sde</strong> (<em>bool</em>) – Whether to use State Dependent Exploration or not</p></li>
<li><p><strong>log_std_init</strong> (<em>float</em>) – Initial value for the log standard deviation</p></li>
<li><p><strong>use_expln</strong> (<em>bool</em>) – Use <code class="docutils literal notranslate"><span class="pre">expln()</span></code> function instead of <code class="docutils literal notranslate"><span class="pre">exp()</span></code> when using gSDE to ensure
a positive standard deviation (cf paper). It allows to keep variance
above zero and prevent it from growing too fast. In practice, <code class="docutils literal notranslate"><span class="pre">exp()</span></code> is usually enough.</p></li>
<li><p><strong>clip_mean</strong> (<em>float</em>) – Clip the mean output when using gSDE to avoid numerical instability.</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Features extractor to use.</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments
to pass to the features extractor.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
<li><p><strong>n_critics</strong> (<em>int</em>) – Number of critic networks to create.</p></li>
<li><p><strong>share_features_extractor</strong> (<em>bool</em>) – Whether to share or not the features extractor
between the actor and the critic (this saves computation time)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/sac/policies.html#SACPolicy.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs</strong> (<em>Tensor</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – </p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">reset_noise</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/sac/policies.html#SACPolicy.reset_noise"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Sample new weights for the exploration matrix, when using gSDE.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch_size</strong> (<em>int</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">set_training_mode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/sac/policies.html#SACPolicy.set_training_mode"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Put the policy in either training or evaluation mode.</p>
<p>This affects certain modules, such as batch normalisation and dropout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em>) – if true, set to training mode, else set to evaluation mode</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.sac.CnnPolicy">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.sac.</span></span><span class="sig-name descname"><span class="pre">CnnPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std_init=-3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_expln=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_mean=2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.NatureCNN'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_critics=2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share_features_extractor=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/sac/policies.html#CnnPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.sac.CnnPolicy" title="Permalink to this definition"></a></dt>
<dd><p>Policy class (with both actor and critic) for SAC.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Space</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Box</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>use_sde</strong> (<em>bool</em>) – Whether to use State Dependent Exploration or not</p></li>
<li><p><strong>log_std_init</strong> (<em>float</em>) – Initial value for the log standard deviation</p></li>
<li><p><strong>use_expln</strong> (<em>bool</em>) – Use <code class="docutils literal notranslate"><span class="pre">expln()</span></code> function instead of <code class="docutils literal notranslate"><span class="pre">exp()</span></code> when using gSDE to ensure
a positive standard deviation (cf paper). It allows to keep variance
above zero and prevent it from growing too fast. In practice, <code class="docutils literal notranslate"><span class="pre">exp()</span></code> is usually enough.</p></li>
<li><p><strong>clip_mean</strong> (<em>float</em>) – Clip the mean output when using gSDE to avoid numerical instability.</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Features extractor to use.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
<li><p><strong>n_critics</strong> (<em>int</em>) – Number of critic networks to create.</p></li>
<li><p><strong>share_features_extractor</strong> (<em>bool</em>) – Whether to share or not the features extractor
between the actor and the critic (this saves computation time)</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.sac.MultiInputPolicy">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.sac.</span></span><span class="sig-name descname"><span class="pre">MultiInputPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std_init=-3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_expln=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_mean=2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.CombinedExtractor'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_critics=2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share_features_extractor=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/sac/policies.html#MultiInputPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.sac.MultiInputPolicy" title="Permalink to this definition"></a></dt>
<dd><p>Policy class (with both actor and critic) for SAC.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Space</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Box</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>use_sde</strong> (<em>bool</em>) – Whether to use State Dependent Exploration or not</p></li>
<li><p><strong>log_std_init</strong> (<em>float</em>) – Initial value for the log standard deviation</p></li>
<li><p><strong>use_expln</strong> (<em>bool</em>) – Use <code class="docutils literal notranslate"><span class="pre">expln()</span></code> function instead of <code class="docutils literal notranslate"><span class="pre">exp()</span></code> when using gSDE to ensure
a positive standard deviation (cf paper). It allows to keep variance
above zero and prevent it from growing too fast. In practice, <code class="docutils literal notranslate"><span class="pre">exp()</span></code> is usually enough.</p></li>
<li><p><strong>clip_mean</strong> (<em>float</em>) – Clip the mean output when using gSDE to avoid numerical instability.</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Features extractor to use.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
<li><p><strong>n_critics</strong> (<em>int</em>) – Number of critic networks to create.</p></li>
<li><p><strong>share_features_extractor</strong> (<em>bool</em>) – Whether to share or not the features extractor
between the actor and the critic (this saves computation time)</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
<span id="document-modules/td3"></span><span class="target" id="module-stable_baselines3.td3"><span id="td3"></span></span><section id="id1">
<h3>TD3<a class="headerlink" href="#id1" title="Permalink to this heading"></a></h3>
<p><a class="reference external" href="https://spinningup.openai.com/en/latest/algorithms/td3.html">Twin Delayed DDPG (TD3)</a> Addressing Function Approximation Error in Actor-Critic Methods.</p>
<p>TD3 is a direct successor of <a class="reference internal" href="index.html#ddpg"><span class="std std-ref">DDPG</span></a> and improves it using three major tricks: clipped double Q-Learning, delayed policy update and target policy smoothing.
We recommend reading <a class="reference external" href="https://spinningup.openai.com/en/latest/algorithms/td3.html">OpenAI Spinning guide on TD3</a> to learn more about those.</p>
<p class="rubric">Available Policies</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#stable_baselines3.td3.MlpPolicy" title="stable_baselines3.td3.MlpPolicy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MlpPolicy</span></code></a></p></td>
<td><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">TD3Policy</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#stable_baselines3.td3.CnnPolicy" title="stable_baselines3.td3.CnnPolicy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CnnPolicy</span></code></a></p></td>
<td><p>Policy class (with both actor and critic) for TD3.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#stable_baselines3.td3.MultiInputPolicy" title="stable_baselines3.td3.MultiInputPolicy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiInputPolicy</span></code></a></p></td>
<td><p>Policy class (with both actor and critic) for TD3 to be used with Dict observation spaces.</p></td>
</tr>
</tbody>
</table>
<section id="notes">
<h4>Notes<a class="headerlink" href="#notes" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Original paper: <a class="reference external" href="https://arxiv.org/pdf/1802.09477.pdf">https://arxiv.org/pdf/1802.09477.pdf</a></p></li>
<li><p>OpenAI Spinning Guide for TD3: <a class="reference external" href="https://spinningup.openai.com/en/latest/algorithms/td3.html">https://spinningup.openai.com/en/latest/algorithms/td3.html</a></p></li>
<li><p>Original Implementation: <a class="reference external" href="https://github.com/sfujim/TD3">https://github.com/sfujim/TD3</a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The default policies for TD3 differ a bit from others MlpPolicy: it uses ReLU instead of tanh activation,
to match the original paper</p>
</div>
</section>
<section id="can-i-use">
<h4>Can I use?<a class="headerlink" href="#can-i-use" title="Permalink to this heading"></a></h4>
<ul class="simple">
<li><p>Recurrent policies: ❌</p></li>
<li><p>Multi processing: ✔️</p></li>
<li><p>Gym spaces:</p></li>
</ul>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Space</p></th>
<th class="head"><p>Action</p></th>
<th class="head"><p>Observation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Discrete</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>Box</p></td>
<td><p>✔️</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>MultiDiscrete</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-odd"><td><p>MultiBinary</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
<tr class="row-even"><td><p>Dict</p></td>
<td><p>❌</p></td>
<td><p>✔️</p></td>
</tr>
</tbody>
</table>
</section>
<section id="example">
<h4>Example<a class="headerlink" href="#example" title="Permalink to this heading"></a></h4>
<p>This example is only to demonstrate the use of the library and its functions, and the trained agents may not solve the environments. Optimized hyperparameters can be found in RL Zoo <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">repository</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gymnasium</span> <span class="k">as</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">TD3</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.noise</span> <span class="kn">import</span> <span class="n">NormalActionNoise</span><span class="p">,</span> <span class="n">OrnsteinUhlenbeckActionNoise</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;Pendulum-v1&quot;</span><span class="p">,</span> <span class="n">render_mode</span><span class="o">=</span><span class="s2">&quot;rgb_array&quot;</span><span class="p">)</span>

<span class="c1"># The noise objects for TD3</span>
<span class="n">n_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">action_noise</span> <span class="o">=</span> <span class="n">NormalActionNoise</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_actions</span><span class="p">),</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_actions</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">TD3</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">action_noise</span><span class="o">=</span><span class="n">action_noise</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">total_timesteps</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">log_interval</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;td3_pendulum&quot;</span><span class="p">)</span>
<span class="n">vec_env</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_env</span><span class="p">()</span>

<span class="k">del</span> <span class="n">model</span> <span class="c1"># remove to demonstrate saving and loading</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">TD3</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;td3_pendulum&quot;</span><span class="p">)</span>

<span class="n">obs</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">action</span><span class="p">,</span> <span class="n">_states</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
    <span class="n">obs</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">dones</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">vec_env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
    <span class="n">vec_env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s2">&quot;human&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="results">
<h4>Results<a class="headerlink" href="#results" title="Permalink to this heading"></a></h4>
<section id="pybullet-environments">
<h5>PyBullet Environments<a class="headerlink" href="#pybullet-environments" title="Permalink to this heading"></a></h5>
<p>Results on the PyBullet benchmark (1M steps) using 3 seeds.
The complete learning curves are available in the <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/48">associated issue #48</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Hyperparameters from the <a class="reference external" href="https://arxiv.org/abs/2005.05719">gSDE paper</a> were used (as they are tuned for PyBullet envs).</p>
</div>
<p><em>Gaussian</em> means that the unstructured Gaussian noise is used for exploration,
<em>gSDE</em> (generalized State-Dependent Exploration) is used otherwise.</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Environments</p></th>
<th class="head"><p>SAC</p></th>
<th class="head"><p>SAC</p></th>
<th class="head"><p>TD3</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td></td>
<td><p>Gaussian</p></td>
<td><p>gSDE</p></td>
<td><p>Gaussian</p></td>
</tr>
<tr class="row-odd"><td><p>HalfCheetah</p></td>
<td><p>2757 +/- 53</p></td>
<td><p>2984 +/- 202</p></td>
<td><p>2774 +/- 35</p></td>
</tr>
<tr class="row-even"><td><p>Ant</p></td>
<td><p>3146 +/- 35</p></td>
<td><p>3102 +/- 37</p></td>
<td><p>3305 +/- 43</p></td>
</tr>
<tr class="row-odd"><td><p>Hopper</p></td>
<td><p>2422 +/- 168</p></td>
<td><p>2262 +/- 1</p></td>
<td><p>2429 +/- 126</p></td>
</tr>
<tr class="row-even"><td><p>Walker2D</p></td>
<td><p>2184 +/- 54</p></td>
<td><p>2136 +/- 67</p></td>
<td><p>2063 +/- 185</p></td>
</tr>
</tbody>
</table>
</section>
<section id="how-to-replicate-the-results">
<h5>How to replicate the results?<a class="headerlink" href="#how-to-replicate-the-results" title="Permalink to this heading"></a></h5>
<p>Clone the <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">rl-zoo repo</a>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/DLR-RM/rl-baselines3-zoo
<span class="nb">cd</span><span class="w"> </span>rl-baselines3-zoo/
</pre></div>
</div>
<p>Run the benchmark (replace <code class="docutils literal notranslate"><span class="pre">$ENV_ID</span></code> by the envs mentioned above):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>train.py<span class="w"> </span>--algo<span class="w"> </span>td3<span class="w"> </span>--env<span class="w"> </span><span class="nv">$ENV_ID</span><span class="w"> </span>--eval-episodes<span class="w"> </span><span class="m">10</span><span class="w"> </span>--eval-freq<span class="w"> </span><span class="m">10000</span>
</pre></div>
</div>
<p>Plot the results:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>scripts/all_plots.py<span class="w"> </span>-a<span class="w"> </span>td3<span class="w"> </span>-e<span class="w"> </span>HalfCheetah<span class="w"> </span>Ant<span class="w"> </span>Hopper<span class="w"> </span>Walker2D<span class="w"> </span>-f<span class="w"> </span>logs/<span class="w"> </span>-o<span class="w"> </span>logs/td3_results
python<span class="w"> </span>scripts/plot_from_file.py<span class="w"> </span>-i<span class="w"> </span>logs/td3_results.pkl<span class="w"> </span>-latex<span class="w"> </span>-l<span class="w"> </span>TD3
</pre></div>
</div>
</section>
</section>
<section id="parameters">
<h4>Parameters<a class="headerlink" href="#parameters" title="Permalink to this heading"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.td3.TD3">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.td3.</span></span><span class="sig-name descname"><span class="pre">TD3</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">policy</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffer_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_starts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.005</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.99</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(1,</span> <span class="pre">'episode')</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_buffer_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_buffer_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimize_memory_usage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_delay</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_policy_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_noise_clip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stats_window_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensorboard_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">policy_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_init_setup_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/td3/td3.html#TD3"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.td3.TD3" title="Permalink to this definition"></a></dt>
<dd><p>Twin Delayed DDPG (TD3)
Addressing Function Approximation Error in Actor-Critic Methods.</p>
<p>Original implementation: <a class="reference external" href="https://github.com/sfujim/TD3">https://github.com/sfujim/TD3</a>
Paper: <a class="reference external" href="https://arxiv.org/abs/1802.09477">https://arxiv.org/abs/1802.09477</a>
Introduction to TD3: <a class="reference external" href="https://spinningup.openai.com/en/latest/algorithms/td3.html">https://spinningup.openai.com/en/latest/algorithms/td3.html</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>policy</strong> (<em>TD3Policy</em>) – The policy model to use (MlpPolicy, CnnPolicy, …)</p></li>
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.VecEnv"><em>VecEnv</em></a><em> | </em><em>str</em>) – The environment to learn from (if registered in Gym, can be str)</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – learning rate for adam optimizer,
the same learning rate will be used for all networks (Q-Values, Actor and Value function)
it can be a function of the current progress remaining (from 1 to 0)</p></li>
<li><p><strong>buffer_size</strong> (<em>int</em>) – size of the replay buffer</p></li>
<li><p><strong>learning_starts</strong> (<em>int</em>) – how many steps of the model to collect transitions for before learning starts</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – Minibatch size for each gradient update</p></li>
<li><p><strong>tau</strong> (<em>float</em>) – the soft update coefficient (“Polyak update”, between 0 and 1)</p></li>
<li><p><strong>gamma</strong> (<em>float</em>) – the discount factor</p></li>
<li><p><strong>train_freq</strong> (<em>int</em><em> | </em><em>Tuple</em><em>[</em><em>int</em><em>, </em><em>str</em><em>]</em>) – Update the model every <code class="docutils literal notranslate"><span class="pre">train_freq</span></code> steps. Alternatively pass a tuple of frequency and unit
like <code class="docutils literal notranslate"><span class="pre">(5,</span> <span class="pre">&quot;step&quot;)</span></code> or <code class="docutils literal notranslate"><span class="pre">(2,</span> <span class="pre">&quot;episode&quot;)</span></code>.</p></li>
<li><p><strong>gradient_steps</strong> (<em>int</em>) – How many gradient steps to do after each rollout (see <code class="docutils literal notranslate"><span class="pre">train_freq</span></code>)
Set to <code class="docutils literal notranslate"><span class="pre">-1</span></code> means to do as many gradient steps as steps done in the environment
during the rollout.</p></li>
<li><p><strong>action_noise</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.noise.ActionNoise" title="stable_baselines3.common.noise.ActionNoise"><em>ActionNoise</em></a><em> | </em><em>None</em>) – the action noise type (None by default), this can help
for hard exploration problem. Cf common.noise for the different action noise type.</p></li>
<li><p><strong>replay_buffer_class</strong> (<em>Type</em><em>[</em><em>ReplayBuffer</em><em>] </em><em>| </em><em>None</em>) – Replay buffer class to use (for instance <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code>).
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, it will be automatically selected.</p></li>
<li><p><strong>replay_buffer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments to pass to the replay buffer on creation.</p></li>
<li><p><strong>optimize_memory_usage</strong> (<em>bool</em>) – Enable a memory efficient variant of the replay buffer
at a cost of more complexity.
See <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195">https://github.com/DLR-RM/stable-baselines3/issues/37#issuecomment-637501195</a></p></li>
<li><p><strong>policy_delay</strong> (<em>int</em>) – Policy and target networks will only be updated once every policy_delay steps
per training steps. The Q values will be updated policy_delay more often (update every training step).</p></li>
<li><p><strong>target_policy_noise</strong> (<em>float</em>) – Standard deviation of Gaussian noise added to target policy
(smoothing noise)</p></li>
<li><p><strong>target_noise_clip</strong> (<em>float</em>) – Limit for absolute value of target policy smoothing noise.</p></li>
<li><p><strong>stats_window_size</strong> (<em>int</em>) – Window size for the rollout logging, specifying the number of episodes to average
the reported success rate, mean episode length, and mean reward over</p></li>
<li><p><strong>tensorboard_log</strong> (<em>str</em><em> | </em><em>None</em>) – the log location for tensorboard (if None, no logging)</p></li>
<li><p><strong>policy_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – additional arguments to be passed to the policy on creation</p></li>
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 1 for info messages (such as device or wrappers used), 2 for
debug messages</p></li>
<li><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – Seed for the pseudo random generators</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device (cpu, cuda, …) on which the code should be run.
Setting it to auto, the code will be run on the GPU if possible.</p></li>
<li><p><strong>_init_setup_model</strong> (<em>bool</em>) – Whether or not to build the network at the creation of the instance</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.td3.TD3.collect_rollouts">
<span class="sig-name descname"><span class="pre">collect_rollouts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_freq</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replay_buffer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_noise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_starts</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.td3.TD3.collect_rollouts" title="Permalink to this definition"></a></dt>
<dd><p>Collect experiences and store them into a <code class="docutils literal notranslate"><span class="pre">ReplayBuffer</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The training environment</p></li>
<li><p><strong>callback</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – Callback that will be called at each step
(and at the beginning and end of the rollout)</p></li>
<li><p><strong>train_freq</strong> (<em>TrainFreq</em>) – How much experience to collect
by doing rollouts of current policy.
Either <code class="docutils literal notranslate"><span class="pre">TrainFreq(&lt;n&gt;,</span> <span class="pre">TrainFrequencyUnit.STEP)</span></code>
or <code class="docutils literal notranslate"><span class="pre">TrainFreq(&lt;n&gt;,</span> <span class="pre">TrainFrequencyUnit.EPISODE)</span></code>
with <code class="docutils literal notranslate"><span class="pre">&lt;n&gt;</span></code> being an integer greater than 0.</p></li>
<li><p><strong>action_noise</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.noise.ActionNoise" title="stable_baselines3.common.noise.ActionNoise"><em>ActionNoise</em></a><em> | </em><em>None</em>) – Action noise that will be used for exploration
Required for deterministic policy (e.g. TD3). This can also be used
in addition to the stochastic policy for SAC.</p></li>
<li><p><strong>learning_starts</strong> (<em>int</em>) – Number of steps before learning for the warm-up phase.</p></li>
<li><p><strong>replay_buffer</strong> (<em>ReplayBuffer</em>) – </p></li>
<li><p><strong>log_interval</strong> (<em>int</em><em> | </em><em>None</em>) – Log data every <code class="docutils literal notranslate"><span class="pre">log_interval</span></code> episodes</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>RolloutReturn</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.td3.TD3.get_env">
<span class="sig-name descname"><span class="pre">get_env</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.td3.TD3.get_env" title="Permalink to this definition"></a></dt>
<dd><p>Returns the current environment (can be None if not defined).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The current environment</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.td3.TD3.get_parameters">
<span class="sig-name descname"><span class="pre">get_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.td3.TD3.get_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Return the parameters of the agent. This includes parameters from different networks, e.g.
critics (value functions) and policies (pi functions).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Mapping of from names of the objects to PyTorch state-dicts.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Dict</em>[str, <em>Dict</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.td3.TD3.get_vec_normalize_env">
<span class="sig-name descname"><span class="pre">get_vec_normalize_env</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.td3.TD3.get_vec_normalize_env" title="Permalink to this definition"></a></dt>
<dd><p>Return the <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> wrapper of the training env
if it exists.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> env.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecNormalize" title="stable_baselines3.common.vec_env.vec_normalize.VecNormalize"><em>VecNormalize</em></a> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.td3.TD3.learn">
<span class="sig-name descname"><span class="pre">learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">total_timesteps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tb_log_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'TD3'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_num_timesteps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">progress_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/td3/td3.html#TD3.learn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.td3.TD3.learn" title="Permalink to this definition"></a></dt>
<dd><p>Return a trained model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>total_timesteps</strong> (<em>int</em>) – The total number of samples (env steps) to train on</p></li>
<li><p><strong>callback</strong> (<em>None</em><em> | </em><em>Callable</em><em> | </em><em>List</em><em>[</em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a><em>] </em><em>| </em><a class="reference internal" href="index.html#stable_baselines3.common.callbacks.BaseCallback" title="stable_baselines3.common.callbacks.BaseCallback"><em>BaseCallback</em></a>) – callback(s) called at every step with state of the algorithm.</p></li>
<li><p><strong>log_interval</strong> (<em>int</em>) – The number of episodes before logging.</p></li>
<li><p><strong>tb_log_name</strong> (<em>str</em>) – the name of the run for TensorBoard logging</p></li>
<li><p><strong>reset_num_timesteps</strong> (<em>bool</em>) – whether or not to reset the current timestep number (used in logging)</p></li>
<li><p><strong>progress_bar</strong> (<em>bool</em>) – Display a progress bar using tqdm and rich.</p></li>
<li><p><strong>self</strong> (<em>SelfTD3</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the trained model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfTD3</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.td3.TD3.load">
<em class="property"><span class="pre">classmethod</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">load</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_objects</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_system_info</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_reset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.td3.TD3.load" title="Permalink to this definition"></a></dt>
<dd><p>Load the model from a zip-file.
Warning: <code class="docutils literal notranslate"><span class="pre">load</span></code> re-creates the model from scratch, it does not update it in-place!
For an in-place load use <code class="docutils literal notranslate"><span class="pre">set_parameters</span></code> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – path to the file (or a file-like) where to
load the agent from</p></li>
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a><em> | </em><em>None</em>) – the new environment to run the loaded model on
(can be None if you only need prediction from a trained model) has priority over any saved environment</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device on which the code should run.</p></li>
<li><p><strong>custom_objects</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Dictionary of objects to replace
upon loading. If a variable is present in this dictionary as a
key, it will not be deserialized and the corresponding item
will be used instead. Similar to custom_objects in
<code class="docutils literal notranslate"><span class="pre">keras.models.load_model</span></code>. Useful when you have an object in
file that can not be deserialized.</p></li>
<li><p><strong>print_system_info</strong> (<em>bool</em>) – Whether to print system info from the saved model
and the current system info (useful to debug loading issues)</p></li>
<li><p><strong>force_reset</strong> (<em>bool</em>) – Force call to <code class="docutils literal notranslate"><span class="pre">reset()</span></code> before training
to avoid unexpected behavior.
See <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/597">https://github.com/DLR-RM/stable-baselines3/issues/597</a></p></li>
<li><p><strong>kwargs</strong> – extra arguments to change the model when loading</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>new model instance with loaded parameters</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfBaseAlgorithm</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.td3.TD3.load_replay_buffer">
<span class="sig-name descname"><span class="pre">load_replay_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truncate_last_traj</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.td3.TD3.load_replay_buffer" title="Permalink to this definition"></a></dt>
<dd><p>Load a replay buffer from a pickle file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – Path to the pickled replay buffer.</p></li>
<li><p><strong>truncate_last_traj</strong> (<em>bool</em>) – When using <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code> with online sampling:
If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, we assume that the last trajectory in the replay buffer was finished
(and truncate it).
If set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, we assume that we continue the same trajectory (same episode).</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="stable_baselines3.td3.TD3.logger">
<em class="property"><span class="pre">property</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">logger</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w">  </span><a class="reference internal" href="index.html#stable_baselines3.common.logger.Logger" title="stable_baselines3.common.logger.Logger"><span class="pre">Logger</span></a></em><a class="headerlink" href="#stable_baselines3.td3.TD3.logger" title="Permalink to this definition"></a></dt>
<dd><p>Getter for the logger object.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.td3.TD3.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">episode_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.td3.TD3.predict" title="Permalink to this definition"></a></dt>
<dd><p>Get the policy action from an observation (and optional hidden state).
Includes sugar-coating to handle different observations (e.g. normalizing images).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation</strong> (<em>ndarray</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>ndarray</em><em>]</em>) – the input observation</p></li>
<li><p><strong>state</strong> (<em>Tuple</em><em>[</em><em>ndarray</em><em>, </em><em>...</em><em>] </em><em>| </em><em>None</em>) – The last hidden states (can be None, used in recurrent policies)</p></li>
<li><p><strong>episode_start</strong> (<em>ndarray</em><em> | </em><em>None</em>) – The last masks (can be None, used in recurrent policies)
this correspond to beginning of episodes,
where the hidden states of the RNN must be reset.</p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – Whether or not to return deterministic actions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the model’s action and the next hidden state
(used in recurrent policies)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>ndarray</em>, <em>Tuple</em>[<em>ndarray</em>, …] | None]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.td3.TD3.save">
<span class="sig-name descname"><span class="pre">save</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.td3.TD3.save" title="Permalink to this definition"></a></dt>
<dd><p>Save all the attributes of the object and the model parameters in a zip-file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – path to the file where the rl agent should be saved</p></li>
<li><p><strong>exclude</strong> (<em>Iterable</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – name of parameters that should be excluded in addition to the default ones</p></li>
<li><p><strong>include</strong> (<em>Iterable</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – name of parameters that might be excluded but should be included anyway</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.td3.TD3.save_replay_buffer">
<span class="sig-name descname"><span class="pre">save_replay_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.td3.TD3.save_replay_buffer" title="Permalink to this definition"></a></dt>
<dd><p>Save the replay buffer as a pickle file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>path</strong> (<em>str</em><em> | </em><em>Path</em><em> | </em><em>BufferedIOBase</em>) – Path to the file where the replay buffer should be saved.
if path is a str or pathlib.Path, the path is automatically created if necessary.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.td3.TD3.set_env">
<span class="sig-name descname"><span class="pre">set_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">force_reset</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.td3.TD3.set_env" title="Permalink to this definition"></a></dt>
<dd><p>Checks the validity of the environment, and if it is coherent, set it as the current environment.
Furthermore wrap any non vectorized env into a vectorized
checked parameters:
- observation_space
- action_space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The environment for learning a policy</p></li>
<li><p><strong>force_reset</strong> (<em>bool</em>) – Force call to <code class="docutils literal notranslate"><span class="pre">reset()</span></code> before training
to avoid unexpected behavior.
See issue <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/597">https://github.com/DLR-RM/stable-baselines3/issues/597</a></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.td3.TD3.set_logger">
<span class="sig-name descname"><span class="pre">set_logger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.td3.TD3.set_logger" title="Permalink to this definition"></a></dt>
<dd><p>Setter for for logger object.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When passing a custom logger object,
this will overwrite <code class="docutils literal notranslate"><span class="pre">tensorboard_log</span></code> and <code class="docutils literal notranslate"><span class="pre">verbose</span></code> settings
passed to the constructor.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>logger</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.logger.Logger" title="stable_baselines3.common.logger.Logger"><em>Logger</em></a>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.td3.TD3.set_parameters">
<span class="sig-name descname"><span class="pre">set_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">load_path_or_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exact_match</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.td3.TD3.set_parameters" title="Permalink to this definition"></a></dt>
<dd><p>Load parameters from a given zip-file or a nested dictionary containing parameters for
different modules (see <code class="docutils literal notranslate"><span class="pre">get_parameters</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>load_path_or_iter</strong> – Location of the saved data (path or file-like, see <code class="docutils literal notranslate"><span class="pre">save</span></code>), or a nested
dictionary containing nn.Module parameters used by the policy. The dictionary maps
object names to a state-dictionary returned by <code class="docutils literal notranslate"><span class="pre">torch.nn.Module.state_dict()</span></code>.</p></li>
<li><p><strong>exact_match</strong> (<em>bool</em>) – If True, the given parameters should include parameters for each
module and each of their parameters, otherwise raises an Exception. If set to False, this
can be used to update only specific parameters.</p></li>
<li><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – Device on which the code should run.</p></li>
<li><p><strong>load_path_or_dict</strong> (<em>str</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.td3.TD3.set_random_seed">
<span class="sig-name descname"><span class="pre">set_random_seed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#stable_baselines3.td3.TD3.set_random_seed" title="Permalink to this definition"></a></dt>
<dd><p>Set the seed of the pseudo-random generators
(python, numpy, pytorch, gym, action_space)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.td3.TD3.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gradient_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/td3/td3.html#TD3.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.td3.TD3.train" title="Permalink to this definition"></a></dt>
<dd><p>Sample the replay buffer and do the updates
(gradient descent and update target networks)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>gradient_steps</strong> (<em>int</em>) – </p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="td3-policies">
<span id="id2"></span><h4>TD3 Policies<a class="headerlink" href="#td3-policies" title="Permalink to this heading"></a></h4>
<dl class="py attribute">
<dt class="sig sig-object py" id="stable_baselines3.td3.MlpPolicy">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.td3.</span></span><span class="sig-name descname"><span class="pre">MlpPolicy</span></span><a class="headerlink" href="#stable_baselines3.td3.MlpPolicy" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">TD3Policy</span></code></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.td3.policies.</span></span><span class="sig-name descname"><span class="pre">TD3Policy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.FlattenExtractor'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_critics=2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share_features_extractor=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/td3/policies.html#TD3Policy"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Policy class (with both actor and critic) for TD3.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Space</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Box</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Features extractor to use.</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments
to pass to the features extractor.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
<li><p><strong>n_critics</strong> (<em>int</em>) – Number of critic networks to create.</p></li>
<li><p><strong>share_features_extractor</strong> (<em>bool</em>) – Whether to share or not the features extractor
between the actor and the critic (this saves computation time)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/td3/policies.html#TD3Policy.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation</strong> (<em>Tensor</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tensor</em><em>]</em>) – </p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">set_training_mode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/td3/policies.html#TD3Policy.set_training_mode"><span class="viewcode-link"><span class="pre">[source]</span></span></a></dt>
<dd><p>Put the policy in either training or evaluation mode.</p>
<p>This affects certain modules, such as batch normalisation and dropout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>bool</em>) – if true, set to training mode, else set to evaluation mode</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.td3.CnnPolicy">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.td3.</span></span><span class="sig-name descname"><span class="pre">CnnPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.NatureCNN'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_critics=2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share_features_extractor=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/td3/policies.html#CnnPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.td3.CnnPolicy" title="Permalink to this definition"></a></dt>
<dd><p>Policy class (with both actor and critic) for TD3.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Space</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Box</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Features extractor to use.</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments
to pass to the features extractor.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
<li><p><strong>n_critics</strong> (<em>int</em>) – Number of critic networks to create.</p></li>
<li><p><strong>share_features_extractor</strong> (<em>bool</em>) – Whether to share or not the features extractor
between the actor and the critic (this saves computation time)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.td3.MultiInputPolicy">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.td3.</span></span><span class="sig-name descname"><span class="pre">MultiInputPolicy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_arch=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_fn=&lt;class</span> <span class="pre">'torch.nn.modules.activation.ReLU'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_class=&lt;class</span> <span class="pre">'stable_baselines3.common.torch_layers.CombinedExtractor'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features_extractor_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_images=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_class=&lt;class</span> <span class="pre">'torch.optim.adam.Adam'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_critics=2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">share_features_extractor=False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/td3/policies.html#MultiInputPolicy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.td3.MultiInputPolicy" title="Permalink to this definition"></a></dt>
<dd><p>Policy class (with both actor and critic) for TD3 to be used with Dict observation spaces.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation_space</strong> (<em>Dict</em>) – Observation space</p></li>
<li><p><strong>action_space</strong> (<em>Box</em>) – Action space</p></li>
<li><p><strong>lr_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>]</em>) – Learning rate schedule (could be constant)</p></li>
<li><p><strong>net_arch</strong> (<em>List</em><em>[</em><em>int</em><em>] </em><em>| </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>] </em><em>| </em><em>None</em>) – The specification of the policy and value networks.</p></li>
<li><p><strong>activation_fn</strong> (<em>Type</em><em>[</em><em>Module</em><em>]</em>) – Activation function</p></li>
<li><p><strong>features_extractor_class</strong> (<em>Type</em><em>[</em><em>BaseFeaturesExtractor</em><em>]</em>) – Features extractor to use.</p></li>
<li><p><strong>features_extractor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments
to pass to the features extractor.</p></li>
<li><p><strong>normalize_images</strong> (<em>bool</em>) – Whether to normalize images or not,
dividing by 255.0 (True by default)</p></li>
<li><p><strong>optimizer_class</strong> (<em>Type</em><em>[</em><em>Optimizer</em><em>]</em>) – The optimizer to use,
<code class="docutils literal notranslate"><span class="pre">th.optim.Adam</span></code> by default</p></li>
<li><p><strong>optimizer_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Additional keyword arguments,
excluding the learning rate, to pass to the optimizer</p></li>
<li><p><strong>n_critics</strong> (<em>int</em>) – Number of critic networks to create.</p></li>
<li><p><strong>share_features_extractor</strong> (<em>bool</em>) – Whether to share or not the features extractor
between the actor and the critic (this saves computation time)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
</div>
<div class="toctree-wrapper compound">
<span id="document-common/atari_wrappers"></span><section id="module-stable_baselines3.common.atari_wrappers">
<span id="atari-wrappers"></span><span id="atari-wrapper"></span><h3>Atari Wrappers<a class="headerlink" href="#module-stable_baselines3.common.atari_wrappers" title="Permalink to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.atari_wrappers.AtariWrapper">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.atari_wrappers.</span></span><span class="sig-name descname"><span class="pre">AtariWrapper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noop_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">30</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frame_skip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">screen_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">84</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">terminal_on_life_loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clip_reward</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_repeat_probability</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/atari_wrappers.html#AtariWrapper"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.atari_wrappers.AtariWrapper" title="Permalink to this definition"></a></dt>
<dd><p>Atari 2600 preprocessings</p>
<p>Specifically:</p>
<ul class="simple">
<li><p>Noop reset: obtain initial state by taking random number of no-ops on reset.</p></li>
<li><p>Frame skipping: 4 by default</p></li>
<li><p>Max-pooling: most recent two observations</p></li>
<li><p>Termination signal when a life is lost.</p></li>
<li><p>Resize to a square image: 84x84 by default</p></li>
<li><p>Grayscale observation</p></li>
<li><p>Clip reward to {-1, 0, 1}</p></li>
<li><p>Sticky actions: disabled by default</p></li>
</ul>
<p>See <a class="reference external" href="https://danieltakeshi.github.io/2016/11/25/frame-skipping-and-preprocessing-for-deep-q-networks-on-atari-2600-games/">https://danieltakeshi.github.io/2016/11/25/frame-skipping-and-preprocessing-for-deep-q-networks-on-atari-2600-games/</a>
for a visual explanation.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Use this wrapper only with Atari v4 without frame skip: <code class="docutils literal notranslate"><span class="pre">env_id</span> <span class="pre">=</span> <span class="pre">&quot;*NoFrameskip-v4&quot;</span></code>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> – Environment to wrap</p></li>
<li><p><strong>noop_max</strong> – Max number of no-ops</p></li>
<li><p><strong>frame_skip</strong> – Frequency at which the agent experiences the game.
This correspond to repeating the action <code class="docutils literal notranslate"><span class="pre">frame_skip</span></code> times.</p></li>
<li><p><strong>screen_size</strong> – Resize Atari frame</p></li>
<li><p><strong>terminal_on_life_loss</strong> – If True, then step() returns done=True whenever a life is lost.</p></li>
<li><p><strong>clip_reward</strong> – If True (default), the reward is clip to {-1, 0, 1} depending on its sign.</p></li>
<li><p><strong>action_repeat_probability</strong> – Probability of repeating the last action</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.atari_wrappers.ClipRewardEnv">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.atari_wrappers.</span></span><span class="sig-name descname"><span class="pre">ClipRewardEnv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/atari_wrappers.html#ClipRewardEnv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.atari_wrappers.ClipRewardEnv" title="Permalink to this definition"></a></dt>
<dd><p>Clip the reward to {+1, 0, -1} by its sign.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>env</strong> – Environment to wrap</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.atari_wrappers.ClipRewardEnv.reward">
<span class="sig-name descname"><span class="pre">reward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reward</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/atari_wrappers.html#ClipRewardEnv.reward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.atari_wrappers.ClipRewardEnv.reward" title="Permalink to this definition"></a></dt>
<dd><p>Bin reward to {+1, 0, -1} by its sign.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>reward</strong> (<em>SupportsFloat</em>) – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.atari_wrappers.EpisodicLifeEnv">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.atari_wrappers.</span></span><span class="sig-name descname"><span class="pre">EpisodicLifeEnv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/atari_wrappers.html#EpisodicLifeEnv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.atari_wrappers.EpisodicLifeEnv" title="Permalink to this definition"></a></dt>
<dd><p>Make end-of-life == end-of-episode, but only reset on true game over.
Done by DeepMind for the DQN and co. since it helps value estimation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>env</strong> – Environment to wrap</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.atari_wrappers.EpisodicLifeEnv.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/atari_wrappers.html#EpisodicLifeEnv.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.atari_wrappers.EpisodicLifeEnv.reset" title="Permalink to this definition"></a></dt>
<dd><p>Calls the Gym environment reset, only when lives are exhausted.
This way all states are still reachable even though lives are episodic,
and the learner need not know about any of this behind-the-scenes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>kwargs</strong> – Extra keywords passed to env.reset() call</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the first observation of the environment</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>ndarray</em>, <em>Dict</em>[str, <em>Any</em>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.atari_wrappers.EpisodicLifeEnv.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/atari_wrappers.html#EpisodicLifeEnv.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.atari_wrappers.EpisodicLifeEnv.step" title="Permalink to this definition"></a></dt>
<dd><p>Uses the <a class="reference internal" href="#stable_baselines3.common.atari_wrappers.EpisodicLifeEnv.step" title="stable_baselines3.common.atari_wrappers.EpisodicLifeEnv.step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">step()</span></code></a> of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">env</span></code> that can be overwritten to change the returned data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action</strong> (<em>int</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<em>ndarray</em>, <em>SupportsFloat</em>, bool, bool, <em>Dict</em>[str, <em>Any</em>]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.atari_wrappers.FireResetEnv">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.atari_wrappers.</span></span><span class="sig-name descname"><span class="pre">FireResetEnv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/atari_wrappers.html#FireResetEnv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.atari_wrappers.FireResetEnv" title="Permalink to this definition"></a></dt>
<dd><p>Take action on reset for environments that are fixed until firing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>env</strong> – Environment to wrap</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.atari_wrappers.FireResetEnv.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/atari_wrappers.html#FireResetEnv.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.atari_wrappers.FireResetEnv.reset" title="Permalink to this definition"></a></dt>
<dd><p>Uses the <a class="reference internal" href="#stable_baselines3.common.atari_wrappers.FireResetEnv.reset" title="stable_baselines3.common.atari_wrappers.FireResetEnv.reset"><code class="xref py py-meth docutils literal notranslate"><span class="pre">reset()</span></code></a> of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">env</span></code> that can be overwritten to change the returned data.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>ndarray</em>, <em>Dict</em>[str, <em>Any</em>]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.atari_wrappers.MaxAndSkipEnv">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.atari_wrappers.</span></span><span class="sig-name descname"><span class="pre">MaxAndSkipEnv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/atari_wrappers.html#MaxAndSkipEnv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.atari_wrappers.MaxAndSkipEnv" title="Permalink to this definition"></a></dt>
<dd><p>Return only every <code class="docutils literal notranslate"><span class="pre">skip</span></code>-th frame (frameskipping)
and return the max between the two last frames.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> – Environment to wrap</p></li>
<li><p><strong>skip</strong> – Number of <code class="docutils literal notranslate"><span class="pre">skip</span></code>-th frame
The same action will be taken <code class="docutils literal notranslate"><span class="pre">skip</span></code> times.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.atari_wrappers.MaxAndSkipEnv.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/atari_wrappers.html#MaxAndSkipEnv.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.atari_wrappers.MaxAndSkipEnv.step" title="Permalink to this definition"></a></dt>
<dd><p>Step the environment with the given action
Repeat action, sum reward, and max over last observations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action</strong> (<em>int</em>) – the action</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>observation, reward, terminated, truncated, information</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>ndarray</em>, <em>SupportsFloat</em>, bool, bool, <em>Dict</em>[str, <em>Any</em>]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.atari_wrappers.NoopResetEnv">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.atari_wrappers.</span></span><span class="sig-name descname"><span class="pre">NoopResetEnv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">noop_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">30</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/atari_wrappers.html#NoopResetEnv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.atari_wrappers.NoopResetEnv" title="Permalink to this definition"></a></dt>
<dd><p>Sample initial states by taking random number of no-ops on reset.
No-op is assumed to be action 0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> – Environment to wrap</p></li>
<li><p><strong>noop_max</strong> – Maximum value of no-ops to run</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.atari_wrappers.NoopResetEnv.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/atari_wrappers.html#NoopResetEnv.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.atari_wrappers.NoopResetEnv.reset" title="Permalink to this definition"></a></dt>
<dd><p>Uses the <a class="reference internal" href="#stable_baselines3.common.atari_wrappers.NoopResetEnv.reset" title="stable_baselines3.common.atari_wrappers.NoopResetEnv.reset"><code class="xref py py-meth docutils literal notranslate"><span class="pre">reset()</span></code></a> of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">env</span></code> that can be overwritten to change the returned data.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>ndarray</em>, <em>Dict</em>[str, <em>Any</em>]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.atari_wrappers.StickyActionEnv">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.atari_wrappers.</span></span><span class="sig-name descname"><span class="pre">StickyActionEnv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_repeat_probability</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/atari_wrappers.html#StickyActionEnv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.atari_wrappers.StickyActionEnv" title="Permalink to this definition"></a></dt>
<dd><p>Sticky action.</p>
<p>Paper: <a class="reference external" href="https://arxiv.org/abs/1709.06009">https://arxiv.org/abs/1709.06009</a>
Official implementation: <a class="reference external" href="https://github.com/mgbellemare/Arcade-Learning-Environment">https://github.com/mgbellemare/Arcade-Learning-Environment</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> – Environment to wrap</p></li>
<li><p><strong>action_repeat_probability</strong> – Probability of repeating the last action</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.atari_wrappers.StickyActionEnv.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/atari_wrappers.html#StickyActionEnv.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.atari_wrappers.StickyActionEnv.reset" title="Permalink to this definition"></a></dt>
<dd><p>Uses the <a class="reference internal" href="#stable_baselines3.common.atari_wrappers.StickyActionEnv.reset" title="stable_baselines3.common.atari_wrappers.StickyActionEnv.reset"><code class="xref py py-meth docutils literal notranslate"><span class="pre">reset()</span></code></a> of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">env</span></code> that can be overwritten to change the returned data.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>ndarray</em>, <em>Dict</em>[str, <em>Any</em>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.atari_wrappers.StickyActionEnv.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/atari_wrappers.html#StickyActionEnv.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.atari_wrappers.StickyActionEnv.step" title="Permalink to this definition"></a></dt>
<dd><p>Uses the <a class="reference internal" href="#stable_baselines3.common.atari_wrappers.StickyActionEnv.step" title="stable_baselines3.common.atari_wrappers.StickyActionEnv.step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">step()</span></code></a> of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">env</span></code> that can be overwritten to change the returned data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action</strong> (<em>int</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<em>ndarray</em>, <em>SupportsFloat</em>, bool, bool, <em>Dict</em>[str, <em>Any</em>]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.atari_wrappers.WarpFrame">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.atari_wrappers.</span></span><span class="sig-name descname"><span class="pre">WarpFrame</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">84</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">height</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">84</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/atari_wrappers.html#WarpFrame"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.atari_wrappers.WarpFrame" title="Permalink to this definition"></a></dt>
<dd><p>Convert to grayscale and warp frames to 84x84 (default)
as done in the Nature paper and later work.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> – Environment to wrap</p></li>
<li><p><strong>width</strong> – New frame width</p></li>
<li><p><strong>height</strong> – New frame height</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.atari_wrappers.WarpFrame.observation">
<span class="sig-name descname"><span class="pre">observation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">frame</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/atari_wrappers.html#WarpFrame.observation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.atari_wrappers.WarpFrame.observation" title="Permalink to this definition"></a></dt>
<dd><p>returns the current observation from a frame</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>frame</strong> (<em>ndarray</em>) – environment frame</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the observation</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<span id="document-common/env_util"></span><section id="module-stable_baselines3.common.env_util">
<span id="environments-utils"></span><span id="env-util"></span><h3>Environments Utils<a class="headerlink" href="#module-stable_baselines3.common.env_util" title="Permalink to this heading"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.env_util.is_wrapped">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.env_util.</span></span><span class="sig-name descname"><span class="pre">is_wrapped</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wrapper_class</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/env_util.html#is_wrapped"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.env_util.is_wrapped" title="Permalink to this definition"></a></dt>
<dd><p>Check if a given environment has been wrapped with a given wrapper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<em>Env</em>) – Environment to check</p></li>
<li><p><strong>wrapper_class</strong> (<em>Type</em><em>[</em><em>Wrapper</em><em>]</em>) – Wrapper class to look for</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>True if environment has been wrapped with <code class="docutils literal notranslate"><span class="pre">wrapper_class</span></code>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.env_util.make_atari_env">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.env_util.</span></span><span class="sig-name descname"><span class="pre">make_atari_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_envs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wrapper_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vec_env_cls</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vec_env_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/env_util.html#make_atari_env"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.env_util.make_atari_env" title="Permalink to this definition"></a></dt>
<dd><p>Create a wrapped, monitored VecEnv for Atari.
It is a wrapper around <code class="docutils literal notranslate"><span class="pre">make_vec_env</span></code> that includes common preprocessing for Atari games.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env_id</strong> (<em>str</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>...</em><em>]</em><em>, </em><em>Env</em><em>]</em>) – either the env ID, the env class or a callable returning an env</p></li>
<li><p><strong>n_envs</strong> (<em>int</em>) – the number of environments you wish to have in parallel</p></li>
<li><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – the initial seed for the random number generator</p></li>
<li><p><strong>start_index</strong> (<em>int</em>) – start rank index</p></li>
<li><p><strong>monitor_dir</strong> (<em>str</em><em> | </em><em>None</em>) – Path to a folder where the monitor files will be saved.
If None, no file will be written, however, the env will still be wrapped
in a Monitor wrapper to provide additional information about training.</p></li>
<li><p><strong>wrapper_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Optional keyword argument to pass to the <code class="docutils literal notranslate"><span class="pre">AtariWrapper</span></code></p></li>
<li><p><strong>env_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Optional keyword argument to pass to the env constructor</p></li>
<li><p><strong>vec_env_cls</strong> (<em>Type</em><em>[</em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.DummyVecEnv" title="stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv"><em>DummyVecEnv</em></a><em>] </em><em>| </em><em>Type</em><em>[</em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.SubprocVecEnv" title="stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv"><em>SubprocVecEnv</em></a><em>] </em><em>| </em><em>None</em>) – A custom <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code> class constructor. Default: None.</p></li>
<li><p><strong>vec_env_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments to pass to the <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code> class constructor.</p></li>
<li><p><strong>monitor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments to pass to the <code class="docutils literal notranslate"><span class="pre">Monitor</span></code> class constructor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The wrapped environment</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.env_util.make_vec_env">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.env_util.</span></span><span class="sig-name descname"><span class="pre">make_vec_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_envs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wrapper_class</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vec_env_cls</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vec_env_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wrapper_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/env_util.html#make_vec_env"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.env_util.make_vec_env" title="Permalink to this definition"></a></dt>
<dd><p>Create a wrapped, monitored <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code>.
By default it uses a <code class="docutils literal notranslate"><span class="pre">DummyVecEnv</span></code> which is usually faster
than a <code class="docutils literal notranslate"><span class="pre">SubprocVecEnv</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env_id</strong> (<em>str</em><em> | </em><em>Callable</em><em>[</em><em>[</em><em>...</em><em>]</em><em>, </em><em>Env</em><em>]</em>) – either the env ID, the env class or a callable returning an env</p></li>
<li><p><strong>n_envs</strong> (<em>int</em>) – the number of environments you wish to have in parallel</p></li>
<li><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – the initial seed for the random number generator</p></li>
<li><p><strong>start_index</strong> (<em>int</em>) – start rank index</p></li>
<li><p><strong>monitor_dir</strong> (<em>str</em><em> | </em><em>None</em>) – Path to a folder where the monitor files will be saved.
If None, no file will be written, however, the env will still be wrapped
in a Monitor wrapper to provide additional information about training.</p></li>
<li><p><strong>wrapper_class</strong> (<em>Callable</em><em>[</em><em>[</em><em>Env</em><em>]</em><em>, </em><em>Env</em><em>] </em><em>| </em><em>None</em>) – Additional wrapper to use on the environment.
This can also be a function with single argument that wraps the environment in many things.
Note: the wrapper specified by this parameter will be applied after the <code class="docutils literal notranslate"><span class="pre">Monitor</span></code> wrapper.
if some cases (e.g. with TimeLimit wrapper) this can lead to undesired behavior.
See here for more details: <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/894">https://github.com/DLR-RM/stable-baselines3/issues/894</a></p></li>
<li><p><strong>env_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Optional keyword argument to pass to the env constructor</p></li>
<li><p><strong>vec_env_cls</strong> (<em>Type</em><em>[</em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.DummyVecEnv" title="stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv"><em>DummyVecEnv</em></a><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.SubprocVecEnv" title="stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv"><em>SubprocVecEnv</em></a><em>] </em><em>| </em><em>None</em>) – A custom <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code> class constructor. Default: None.</p></li>
<li><p><strong>vec_env_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments to pass to the <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code> class constructor.</p></li>
<li><p><strong>monitor_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments to pass to the <code class="docutils literal notranslate"><span class="pre">Monitor</span></code> class constructor.</p></li>
<li><p><strong>wrapper_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments to pass to the <code class="docutils literal notranslate"><span class="pre">Wrapper</span></code> class constructor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The wrapped environment</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.env_util.unwrap_wrapper">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.env_util.</span></span><span class="sig-name descname"><span class="pre">unwrap_wrapper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wrapper_class</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/env_util.html#unwrap_wrapper"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.env_util.unwrap_wrapper" title="Permalink to this definition"></a></dt>
<dd><p>Retrieve a <code class="docutils literal notranslate"><span class="pre">VecEnvWrapper</span></code> object by recursively searching.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<em>Env</em>) – Environment to unwrap</p></li>
<li><p><strong>wrapper_class</strong> (<em>Type</em><em>[</em><em>Wrapper</em><em>]</em>) – Wrapper to look for</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Environment unwrapped till <code class="docutils literal notranslate"><span class="pre">wrapper_class</span></code> if it has been wrapped with it</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Wrapper</em> | None</p>
</dd>
</dl>
</dd></dl>

</section>
<span id="document-common/envs"></span><span class="target" id="module-stable_baselines3.common.envs"><span id="envs"></span></span><section id="custom-environments">
<h3>Custom Environments<a class="headerlink" href="#custom-environments" title="Permalink to this heading"></a></h3>
<p>Those environments were created for testing purposes.</p>
<section id="bitflippingenv">
<h4>BitFlippingEnv<a class="headerlink" href="#bitflippingenv" title="Permalink to this heading"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.envs.BitFlippingEnv">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.envs.</span></span><span class="sig-name descname"><span class="pre">BitFlippingEnv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_bits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">continuous</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discrete_obs_space</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_obs_space</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">render_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'human'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/envs/bit_flipping_env.html#BitFlippingEnv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.envs.BitFlippingEnv" title="Permalink to this definition"></a></dt>
<dd><p>Simple bit flipping env, useful to test HER.
The goal is to flip all the bits to get a vector of ones.
In the continuous variant, if the ith action component has a value &gt; 0,
then the ith bit will be flipped. Uses a <code class="docutils literal notranslate"><span class="pre">MultiBinary</span></code> observation space
by default.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_bits</strong> – Number of bits to flip</p></li>
<li><p><strong>continuous</strong> – Whether to use the continuous actions version or not,
by default, it uses the discrete one</p></li>
<li><p><strong>max_steps</strong> – Max number of steps, by default, equal to n_bits</p></li>
<li><p><strong>discrete_obs_space</strong> – Whether to use the discrete observation
version or not, ie a one-hot encoding of all possible states</p></li>
<li><p><strong>image_obs_space</strong> – Whether to use an image observation version
or not, ie a greyscale image of the state</p></li>
<li><p><strong>channel_first</strong> – Whether to use channel-first or last image.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.envs.BitFlippingEnv.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/envs/bit_flipping_env.html#BitFlippingEnv.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.envs.BitFlippingEnv.close" title="Permalink to this definition"></a></dt>
<dd><p>After the user has finished using the environment, close contains the code necessary to “clean up” the environment.</p>
<p>This is critical for closing rendering windows, database or HTTP connections.
Calling <code class="docutils literal notranslate"><span class="pre">close</span></code> on an already closed environment has no effect and won’t raise an error.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.envs.BitFlippingEnv.convert_if_needed">
<span class="sig-name descname"><span class="pre">convert_if_needed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/envs/bit_flipping_env.html#BitFlippingEnv.convert_if_needed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.envs.BitFlippingEnv.convert_if_needed" title="Permalink to this definition"></a></dt>
<dd><p>Convert to discrete space if needed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>state</strong> (<em>ndarray</em>) – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int | <em>ndarray</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.envs.BitFlippingEnv.convert_to_bit_vector">
<span class="sig-name descname"><span class="pre">convert_to_bit_vector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/envs/bit_flipping_env.html#BitFlippingEnv.convert_to_bit_vector"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.envs.BitFlippingEnv.convert_to_bit_vector" title="Permalink to this definition"></a></dt>
<dd><p>Convert to bit vector if needed.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state</strong> (<em>int</em><em> | </em><em>ndarray</em>) – The state to be converted, which can be either an integer or a numpy array.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – The batch size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The state converted into a bit vector.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.envs.BitFlippingEnv.render">
<span class="sig-name descname"><span class="pre">render</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/envs/bit_flipping_env.html#BitFlippingEnv.render"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.envs.BitFlippingEnv.render" title="Permalink to this definition"></a></dt>
<dd><p>Compute the render frames as specified by <code class="xref py py-attr docutils literal notranslate"><span class="pre">render_mode</span></code> during the initialization of the environment.</p>
<p>The environment’s <code class="xref py py-attr docutils literal notranslate"><span class="pre">metadata</span></code> render modes (<cite>env.metadata[“render_modes”]</cite>) should contain the possible
ways to implement the render modes. In addition, list versions for most render modes is achieved through
<cite>gymnasium.make</cite> which automatically applies a wrapper to collect rendered frames.</p>
<dl class="simple">
<dt>Note:</dt><dd><p>As the <code class="xref py py-attr docutils literal notranslate"><span class="pre">render_mode</span></code> is known during <code class="docutils literal notranslate"><span class="pre">__init__</span></code>, the objects used to render the environment state
should be initialised in <code class="docutils literal notranslate"><span class="pre">__init__</span></code>.</p>
</dd>
</dl>
<p>By convention, if the <code class="xref py py-attr docutils literal notranslate"><span class="pre">render_mode</span></code> is:</p>
<ul class="simple">
<li><p>None (default): no render is computed.</p></li>
<li><p>“human”: The environment is continuously rendered in the current display or terminal, usually for human consumption.
This rendering should occur during <a class="reference internal" href="#stable_baselines3.common.envs.BitFlippingEnv.step" title="stable_baselines3.common.envs.BitFlippingEnv.step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">step()</span></code></a> and <a class="reference internal" href="#stable_baselines3.common.envs.BitFlippingEnv.render" title="stable_baselines3.common.envs.BitFlippingEnv.render"><code class="xref py py-meth docutils literal notranslate"><span class="pre">render()</span></code></a> doesn’t need to be called. Returns <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p>“rgb_array”: Return a single frame representing the current state of the environment.
A frame is a <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> with shape <code class="docutils literal notranslate"><span class="pre">(x,</span> <span class="pre">y,</span> <span class="pre">3)</span></code> representing RGB values for an x-by-y pixel image.</p></li>
<li><p>“ansi”: Return a strings (<code class="docutils literal notranslate"><span class="pre">str</span></code>) or <code class="docutils literal notranslate"><span class="pre">StringIO.StringIO</span></code> containing a terminal-style text representation
for each time step. The text can include newlines and ANSI escape sequences (e.g. for colors).</p></li>
<li><p>“rgb_array_list” and “ansi_list”: List based version of render modes are possible (except Human) through the
wrapper, <code class="xref py py-class docutils literal notranslate"><span class="pre">gymnasium.wrappers.RenderCollection</span></code> that is automatically applied during <code class="docutils literal notranslate"><span class="pre">gymnasium.make(...,</span> <span class="pre">render_mode=&quot;rgb_array_list&quot;)</span></code>.
The frames collected are popped after <a class="reference internal" href="#stable_baselines3.common.envs.BitFlippingEnv.render" title="stable_baselines3.common.envs.BitFlippingEnv.render"><code class="xref py py-meth docutils literal notranslate"><span class="pre">render()</span></code></a> is called or <a class="reference internal" href="#stable_baselines3.common.envs.BitFlippingEnv.reset" title="stable_baselines3.common.envs.BitFlippingEnv.reset"><code class="xref py py-meth docutils literal notranslate"><span class="pre">reset()</span></code></a>.</p></li>
</ul>
<dl class="simple">
<dt>Note:</dt><dd><p>Make sure that your class’s <code class="xref py py-attr docutils literal notranslate"><span class="pre">metadata</span></code> <code class="docutils literal notranslate"><span class="pre">&quot;render_modes&quot;</span></code> key includes the list of supported modes.</p>
</dd>
</dl>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.25.0: </span>The render function was changed to no longer accept parameters, rather these parameters should be specified
in the environment initialised, i.e., <code class="docutils literal notranslate"><span class="pre">gymnasium.make(&quot;CartPole-v1&quot;,</span> <span class="pre">render_mode=&quot;human&quot;)</span></code></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.envs.BitFlippingEnv.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/envs/bit_flipping_env.html#BitFlippingEnv.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.envs.BitFlippingEnv.reset" title="Permalink to this definition"></a></dt>
<dd><p>Resets the environment to an initial internal state, returning an initial observation and info.</p>
<p>This method generates a new starting state often with some randomness to ensure that the agent explores the
state space and learns a generalised policy about the environment. This randomness can be controlled
with the <code class="docutils literal notranslate"><span class="pre">seed</span></code> parameter otherwise if the environment already has a random number generator and
<a class="reference internal" href="#stable_baselines3.common.envs.BitFlippingEnv.reset" title="stable_baselines3.common.envs.BitFlippingEnv.reset"><code class="xref py py-meth docutils literal notranslate"><span class="pre">reset()</span></code></a> is called with <code class="docutils literal notranslate"><span class="pre">seed=None</span></code>, the RNG is not reset.</p>
<p>Therefore, <a class="reference internal" href="#stable_baselines3.common.envs.BitFlippingEnv.reset" title="stable_baselines3.common.envs.BitFlippingEnv.reset"><code class="xref py py-meth docutils literal notranslate"><span class="pre">reset()</span></code></a> should (in the typical use case) be called with a seed right after initialization and then never again.</p>
<p>For Custom environments, the first line of <a class="reference internal" href="#stable_baselines3.common.envs.BitFlippingEnv.reset" title="stable_baselines3.common.envs.BitFlippingEnv.reset"><code class="xref py py-meth docutils literal notranslate"><span class="pre">reset()</span></code></a> should be <code class="docutils literal notranslate"><span class="pre">super().reset(seed=seed)</span></code> which implements
the seeding correctly.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version v0.25: </span>The <code class="docutils literal notranslate"><span class="pre">return_info</span></code> parameter was removed and now info is expected to be returned.</p>
</div>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>seed (optional int): The seed that is used to initialize the environment’s PRNG (<cite>np_random</cite>).</dt><dd><p>If the environment does not already have a PRNG and <code class="docutils literal notranslate"><span class="pre">seed=None</span></code> (the default option) is passed,
a seed will be chosen from some source of entropy (e.g. timestamp or /dev/urandom).
However, if the environment already has a PRNG and <code class="docutils literal notranslate"><span class="pre">seed=None</span></code> is passed, the PRNG will <em>not</em> be reset.
If you pass an integer, the PRNG will be reset even if it already exists.
Usually, you want to pass an integer <em>right after the environment has been initialized and then never again</em>.
Please refer to the minimal example above to see this paradigm in action.</p>
</dd>
<dt>options (optional dict): Additional information to specify how the environment is reset (optional,</dt><dd><p>depending on the specific environment)</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt>observation (ObsType): Observation of the initial state. This will be an element of <code class="xref py py-attr docutils literal notranslate"><span class="pre">observation_space</span></code></dt><dd><p>(typically a numpy array) and is analogous to the observation returned by <a class="reference internal" href="#stable_baselines3.common.envs.BitFlippingEnv.step" title="stable_baselines3.common.envs.BitFlippingEnv.step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">step()</span></code></a>.</p>
</dd>
<dt>info (dictionary):  This dictionary contains auxiliary information complementing <code class="docutils literal notranslate"><span class="pre">observation</span></code>. It should be analogous to</dt><dd><p>the <code class="docutils literal notranslate"><span class="pre">info</span></code> returned by <a class="reference internal" href="#stable_baselines3.common.envs.BitFlippingEnv.step" title="stable_baselines3.common.envs.BitFlippingEnv.step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">step()</span></code></a>.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – </p></li>
<li><p><strong>options</strong> (<em>Dict</em><em> | </em><em>None</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<em>Dict</em>[str, int | <em>ndarray</em>], <em>Dict</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.envs.BitFlippingEnv.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/envs/bit_flipping_env.html#BitFlippingEnv.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.envs.BitFlippingEnv.step" title="Permalink to this definition"></a></dt>
<dd><p>Step into the env.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action</strong> (<em>ndarray</em><em> | </em><em>int</em>) – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tuple</em> | <em>Dict</em>[str, <em>Any</em>] | <em>ndarray</em> | int, float, bool, bool, <em>Dict</em>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="simplemultiobsenv">
<h4>SimpleMultiObsEnv<a class="headerlink" href="#simplemultiobsenv" title="Permalink to this heading"></a></h4>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.envs.SimpleMultiObsEnv">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.envs.</span></span><span class="sig-name descname"><span class="pre">SimpleMultiObsEnv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_col</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_row</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">discrete_actions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_last</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/envs/multi_input_envs.html#SimpleMultiObsEnv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.envs.SimpleMultiObsEnv" title="Permalink to this definition"></a></dt>
<dd><p>Base class for GridWorld-based MultiObs Environments 4x4  grid world.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span> ____________
| 0  1  2   3|
| 4|¯5¯¯6¯| 7|
| 8|_9_10_|11|
|12 13  14 15|
¯¯¯¯¯¯¯¯¯¯¯¯¯¯
</pre></div>
</div>
<p>start is 0
states 5, 6, 9, and 10 are blocked
goal is 15
actions are = [left, down, right, up]</p>
<p>simple linear state env of 15 states but encoded with a vector and an image observation:
each column is represented by a random vector and each row is
represented by a random image, both sampled once at creation time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_col</strong> – Number of columns in the grid</p></li>
<li><p><strong>num_row</strong> – Number of rows in the grid</p></li>
<li><p><strong>random_start</strong> – If true, agent starts in random position</p></li>
<li><p><strong>channel_last</strong> – If true, the image will be channel last, else it will be channel first</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.envs.SimpleMultiObsEnv.get_state_mapping">
<span class="sig-name descname"><span class="pre">get_state_mapping</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/envs/multi_input_envs.html#SimpleMultiObsEnv.get_state_mapping"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.envs.SimpleMultiObsEnv.get_state_mapping" title="Permalink to this definition"></a></dt>
<dd><p>Uses the state to get the observation mapping.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>observation dict {‘vec’: …, ‘img’: …}</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Dict</em>[str, <em>ndarray</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.envs.SimpleMultiObsEnv.init_possible_transitions">
<span class="sig-name descname"><span class="pre">init_possible_transitions</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/envs/multi_input_envs.html#SimpleMultiObsEnv.init_possible_transitions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.envs.SimpleMultiObsEnv.init_possible_transitions" title="Permalink to this definition"></a></dt>
<dd><p>Initializes the transitions of the environment
The environment exploits the cardinal directions of the grid by noting that
they correspond to simple addition and subtraction from the cell id within the grid</p>
<ul class="simple">
<li><p>up =&gt; means moving up a row =&gt; means subtracting the length of a column</p></li>
<li><p>down =&gt; means moving down a row =&gt; means adding the length of a column</p></li>
<li><p>left =&gt; means moving left by one =&gt; means subtracting 1</p></li>
<li><p>right =&gt; means moving right by one =&gt; means adding 1</p></li>
</ul>
<p>Thus one only needs to specify in which states each action is possible
in order to define the transitions of the environment</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.envs.SimpleMultiObsEnv.init_state_mapping">
<span class="sig-name descname"><span class="pre">init_state_mapping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_col</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_row</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/envs/multi_input_envs.html#SimpleMultiObsEnv.init_state_mapping"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.envs.SimpleMultiObsEnv.init_state_mapping" title="Permalink to this definition"></a></dt>
<dd><p>Initializes the state_mapping array which holds the observation values for each state</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_col</strong> (<em>int</em>) – Number of columns.</p></li>
<li><p><strong>num_row</strong> (<em>int</em>) – Number of rows.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.envs.SimpleMultiObsEnv.render">
<span class="sig-name descname"><span class="pre">render</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'human'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/envs/multi_input_envs.html#SimpleMultiObsEnv.render"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.envs.SimpleMultiObsEnv.render" title="Permalink to this definition"></a></dt>
<dd><p>Prints the log of the environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mode</strong> (<em>str</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.envs.SimpleMultiObsEnv.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">options</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/envs/multi_input_envs.html#SimpleMultiObsEnv.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.envs.SimpleMultiObsEnv.reset" title="Permalink to this definition"></a></dt>
<dd><p>Resets the environment state and step count and returns reset observation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seed</strong> (<em>int</em><em> | </em><em>None</em>) – </p></li>
<li><p><strong>options</strong> (<em>Dict</em><em> | </em><em>None</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>observation dict {‘vec’: …, ‘img’: …}</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Dict</em>[str, <em>ndarray</em>], <em>Dict</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.envs.SimpleMultiObsEnv.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/envs/multi_input_envs.html#SimpleMultiObsEnv.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.envs.SimpleMultiObsEnv.step" title="Permalink to this definition"></a></dt>
<dd><p>Run one timestep of the environment’s dynamics. When end of
episode is reached, you are responsible for calling <cite>reset()</cite>
to reset this environment’s state.
Accepts an action and returns a tuple (observation, reward, terminated, truncated, info).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action</strong> (<em>int</em><em> | </em><em>ndarray</em>) – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>tuple (observation, reward, terminated, truncated, info).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tuple</em> | <em>Dict</em>[str, <em>Any</em>] | <em>ndarray</em> | int, float, bool, bool, <em>Dict</em>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
<span id="document-common/distributions"></span><section id="probability-distributions">
<span id="distributions"></span><h3>Probability Distributions<a class="headerlink" href="#probability-distributions" title="Permalink to this heading"></a></h3>
<p>Probability distributions used for the different action spaces:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">CategoricalDistribution</span></code> -&gt; Discrete</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DiagGaussianDistribution</span></code> -&gt; Box (continuous actions)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">StateDependentNoiseDistribution</span></code> -&gt; Box (continuous actions) when <code class="docutils literal notranslate"><span class="pre">use_sde=True</span></code></p></li>
</ul>
<p>The policy networks output parameters for the distributions (named <code class="docutils literal notranslate"><span class="pre">flat</span></code> in the methods).
Actions are then sampled from those distributions.</p>
<p>For instance, in the case of discrete actions. The policy network outputs probability
of taking each action. The <code class="docutils literal notranslate"><span class="pre">CategoricalDistribution</span></code> allows sampling from it,
computes the entropy, the log probability (<code class="docutils literal notranslate"><span class="pre">log_prob</span></code>) and backpropagate the gradient.</p>
<p>In the case of continuous actions, a Gaussian distribution is used. The policy network outputs
mean and (log) std of the distribution (assumed to be a <code class="docutils literal notranslate"><span class="pre">DiagGaussianDistribution</span></code>).</p>
<span class="target" id="module-stable_baselines3.common.distributions"></span><p>Probability distributions.</p>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.BernoulliDistribution">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.distributions.</span></span><span class="sig-name descname"><span class="pre">BernoulliDistribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_dims</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#BernoulliDistribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.BernoulliDistribution" title="Permalink to this definition"></a></dt>
<dd><p>Bernoulli distribution for MultiBinary action spaces.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>action_dim</strong> – Number of binary actions</p></li>
<li><p><strong>action_dims</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.BernoulliDistribution.actions_from_params">
<span class="sig-name descname"><span class="pre">actions_from_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_logits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#BernoulliDistribution.actions_from_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.BernoulliDistribution.actions_from_params" title="Permalink to this definition"></a></dt>
<dd><p>Returns samples from the probability distribution
given its parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>actions</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>action_logits</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.BernoulliDistribution.entropy">
<span class="sig-name descname"><span class="pre">entropy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#BernoulliDistribution.entropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.BernoulliDistribution.entropy" title="Permalink to this definition"></a></dt>
<dd><p>Returns Shannon’s entropy of the probability</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the entropy, or None if no analytical form is known</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.BernoulliDistribution.log_prob">
<span class="sig-name descname"><span class="pre">log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#BernoulliDistribution.log_prob"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.BernoulliDistribution.log_prob" title="Permalink to this definition"></a></dt>
<dd><p>Returns the log likelihood</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – the taken action</p></li>
<li><p><strong>actions</strong> (<em>Tensor</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The log likelihood of the distribution</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.BernoulliDistribution.log_prob_from_params">
<span class="sig-name descname"><span class="pre">log_prob_from_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_logits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#BernoulliDistribution.log_prob_from_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.BernoulliDistribution.log_prob_from_params" title="Permalink to this definition"></a></dt>
<dd><p>Returns samples and the associated log probabilities
from the probability distribution given its parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>actions and log prob</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>action_logits</strong> (<em>Tensor</em>) – </p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.BernoulliDistribution.mode">
<span class="sig-name descname"><span class="pre">mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#BernoulliDistribution.mode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.BernoulliDistribution.mode" title="Permalink to this definition"></a></dt>
<dd><p>Returns the most likely action (deterministic output)
from the probability distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the stochastic action</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.BernoulliDistribution.proba_distribution">
<span class="sig-name descname"><span class="pre">proba_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_logits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#BernoulliDistribution.proba_distribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.BernoulliDistribution.proba_distribution" title="Permalink to this definition"></a></dt>
<dd><p>Set parameters of the distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>self</strong> (<em>SelfBernoulliDistribution</em>) – </p></li>
<li><p><strong>action_logits</strong> (<em>Tensor</em>) – </p></li>
</ul>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfBernoulliDistribution</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.BernoulliDistribution.proba_distribution_net">
<span class="sig-name descname"><span class="pre">proba_distribution_net</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#BernoulliDistribution.proba_distribution_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.BernoulliDistribution.proba_distribution_net" title="Permalink to this definition"></a></dt>
<dd><p>Create the layer that represents the distribution:
it will be the logits of the Bernoulli distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>latent_dim</strong> (<em>int</em>) – Dimension of the last layer
of the policy network (before the action layer)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Module</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.BernoulliDistribution.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#BernoulliDistribution.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.BernoulliDistribution.sample" title="Permalink to this definition"></a></dt>
<dd><p>Returns a sample from the probability distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the stochastic action</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.CategoricalDistribution">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.distributions.</span></span><span class="sig-name descname"><span class="pre">CategoricalDistribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_dim</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#CategoricalDistribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.CategoricalDistribution" title="Permalink to this definition"></a></dt>
<dd><p>Categorical distribution for discrete actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_dim</strong> (<em>int</em>) – Number of discrete actions</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.CategoricalDistribution.actions_from_params">
<span class="sig-name descname"><span class="pre">actions_from_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_logits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#CategoricalDistribution.actions_from_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.CategoricalDistribution.actions_from_params" title="Permalink to this definition"></a></dt>
<dd><p>Returns samples from the probability distribution
given its parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>actions</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>action_logits</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.CategoricalDistribution.entropy">
<span class="sig-name descname"><span class="pre">entropy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#CategoricalDistribution.entropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.CategoricalDistribution.entropy" title="Permalink to this definition"></a></dt>
<dd><p>Returns Shannon’s entropy of the probability</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the entropy, or None if no analytical form is known</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.CategoricalDistribution.log_prob">
<span class="sig-name descname"><span class="pre">log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#CategoricalDistribution.log_prob"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.CategoricalDistribution.log_prob" title="Permalink to this definition"></a></dt>
<dd><p>Returns the log likelihood</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – the taken action</p></li>
<li><p><strong>actions</strong> (<em>Tensor</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The log likelihood of the distribution</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.CategoricalDistribution.log_prob_from_params">
<span class="sig-name descname"><span class="pre">log_prob_from_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_logits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#CategoricalDistribution.log_prob_from_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.CategoricalDistribution.log_prob_from_params" title="Permalink to this definition"></a></dt>
<dd><p>Returns samples and the associated log probabilities
from the probability distribution given its parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>actions and log prob</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>action_logits</strong> (<em>Tensor</em>) – </p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.CategoricalDistribution.mode">
<span class="sig-name descname"><span class="pre">mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#CategoricalDistribution.mode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.CategoricalDistribution.mode" title="Permalink to this definition"></a></dt>
<dd><p>Returns the most likely action (deterministic output)
from the probability distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the stochastic action</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.CategoricalDistribution.proba_distribution">
<span class="sig-name descname"><span class="pre">proba_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_logits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#CategoricalDistribution.proba_distribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.CategoricalDistribution.proba_distribution" title="Permalink to this definition"></a></dt>
<dd><p>Set parameters of the distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>self</strong> (<em>SelfCategoricalDistribution</em>) – </p></li>
<li><p><strong>action_logits</strong> (<em>Tensor</em>) – </p></li>
</ul>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfCategoricalDistribution</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.CategoricalDistribution.proba_distribution_net">
<span class="sig-name descname"><span class="pre">proba_distribution_net</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#CategoricalDistribution.proba_distribution_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.CategoricalDistribution.proba_distribution_net" title="Permalink to this definition"></a></dt>
<dd><p>Create the layer that represents the distribution:
it will be the logits of the Categorical distribution.
You can then get probabilities using a softmax.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>latent_dim</strong> (<em>int</em>) – Dimension of the last layer
of the policy network (before the action layer)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Module</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.CategoricalDistribution.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#CategoricalDistribution.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.CategoricalDistribution.sample" title="Permalink to this definition"></a></dt>
<dd><p>Returns a sample from the probability distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the stochastic action</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.DiagGaussianDistribution">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.distributions.</span></span><span class="sig-name descname"><span class="pre">DiagGaussianDistribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_dim</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#DiagGaussianDistribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.DiagGaussianDistribution" title="Permalink to this definition"></a></dt>
<dd><p>Gaussian distribution with diagonal covariance matrix, for continuous actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_dim</strong> (<em>int</em>) – Dimension of the action space.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.DiagGaussianDistribution.actions_from_params">
<span class="sig-name descname"><span class="pre">actions_from_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean_actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#DiagGaussianDistribution.actions_from_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.DiagGaussianDistribution.actions_from_params" title="Permalink to this definition"></a></dt>
<dd><p>Returns samples from the probability distribution
given its parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>actions</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>mean_actions</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>log_std</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.DiagGaussianDistribution.entropy">
<span class="sig-name descname"><span class="pre">entropy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#DiagGaussianDistribution.entropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.DiagGaussianDistribution.entropy" title="Permalink to this definition"></a></dt>
<dd><p>Returns Shannon’s entropy of the probability</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the entropy, or None if no analytical form is known</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.DiagGaussianDistribution.log_prob">
<span class="sig-name descname"><span class="pre">log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#DiagGaussianDistribution.log_prob"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.DiagGaussianDistribution.log_prob" title="Permalink to this definition"></a></dt>
<dd><p>Get the log probabilities of actions according to the distribution.
Note that you must first call the <code class="docutils literal notranslate"><span class="pre">proba_distribution()</span></code> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>actions</strong> (<em>Tensor</em>) – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.DiagGaussianDistribution.log_prob_from_params">
<span class="sig-name descname"><span class="pre">log_prob_from_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean_actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#DiagGaussianDistribution.log_prob_from_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.DiagGaussianDistribution.log_prob_from_params" title="Permalink to this definition"></a></dt>
<dd><p>Compute the log probability of taking an action
given the distribution parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mean_actions</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>log_std</strong> (<em>Tensor</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.DiagGaussianDistribution.mode">
<span class="sig-name descname"><span class="pre">mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#DiagGaussianDistribution.mode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.DiagGaussianDistribution.mode" title="Permalink to this definition"></a></dt>
<dd><p>Returns the most likely action (deterministic output)
from the probability distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the stochastic action</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.DiagGaussianDistribution.proba_distribution">
<span class="sig-name descname"><span class="pre">proba_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean_actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#DiagGaussianDistribution.proba_distribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.DiagGaussianDistribution.proba_distribution" title="Permalink to this definition"></a></dt>
<dd><p>Create the distribution given its parameters (mean, std)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mean_actions</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>log_std</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>self</strong> (<em>SelfDiagGaussianDistribution</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfDiagGaussianDistribution</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.DiagGaussianDistribution.proba_distribution_net">
<span class="sig-name descname"><span class="pre">proba_distribution_net</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#DiagGaussianDistribution.proba_distribution_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.DiagGaussianDistribution.proba_distribution_net" title="Permalink to this definition"></a></dt>
<dd><p>Create the layers and parameter that represent the distribution:
one output will be the mean of the Gaussian, the other parameter will be the
standard deviation (log std in fact to allow negative values)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>latent_dim</strong> (<em>int</em>) – Dimension of the last layer of the policy (before the action layer)</p></li>
<li><p><strong>log_std_init</strong> (<em>float</em>) – Initial value for the log standard deviation</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Module</em>, <em>Parameter</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.DiagGaussianDistribution.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#DiagGaussianDistribution.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.DiagGaussianDistribution.sample" title="Permalink to this definition"></a></dt>
<dd><p>Returns a sample from the probability distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the stochastic action</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.Distribution">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.distributions.</span></span><span class="sig-name descname"><span class="pre">Distribution</span></span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#Distribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.Distribution" title="Permalink to this definition"></a></dt>
<dd><p>Abstract base class for distributions.</p>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.Distribution.actions_from_params">
<em class="property"><span class="pre">abstract</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">actions_from_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#Distribution.actions_from_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.Distribution.actions_from_params" title="Permalink to this definition"></a></dt>
<dd><p>Returns samples from the probability distribution
given its parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>actions</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.Distribution.entropy">
<em class="property"><span class="pre">abstract</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">entropy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#Distribution.entropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.Distribution.entropy" title="Permalink to this definition"></a></dt>
<dd><p>Returns Shannon’s entropy of the probability</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the entropy, or None if no analytical form is known</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.Distribution.get_actions">
<span class="sig-name descname"><span class="pre">get_actions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#Distribution.get_actions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.Distribution.get_actions" title="Permalink to this definition"></a></dt>
<dd><p>Return actions according to the probability distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>deterministic</strong> (<em>bool</em>) – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.Distribution.log_prob">
<em class="property"><span class="pre">abstract</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#Distribution.log_prob"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.Distribution.log_prob" title="Permalink to this definition"></a></dt>
<dd><p>Returns the log likelihood</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – the taken action</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The log likelihood of the distribution</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.Distribution.log_prob_from_params">
<em class="property"><span class="pre">abstract</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">log_prob_from_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#Distribution.log_prob_from_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.Distribution.log_prob_from_params" title="Permalink to this definition"></a></dt>
<dd><p>Returns samples and the associated log probabilities
from the probability distribution given its parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>actions and log prob</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.Distribution.mode">
<em class="property"><span class="pre">abstract</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#Distribution.mode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.Distribution.mode" title="Permalink to this definition"></a></dt>
<dd><p>Returns the most likely action (deterministic output)
from the probability distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the stochastic action</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.Distribution.proba_distribution">
<em class="property"><span class="pre">abstract</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">proba_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#Distribution.proba_distribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.Distribution.proba_distribution" title="Permalink to this definition"></a></dt>
<dd><p>Set parameters of the distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>self</strong> (<em>SelfDistribution</em>) – </p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfDistribution</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.Distribution.proba_distribution_net">
<em class="property"><span class="pre">abstract</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">proba_distribution_net</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#Distribution.proba_distribution_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.Distribution.proba_distribution_net" title="Permalink to this definition"></a></dt>
<dd><p>Create the layers and parameters that represent the distribution.</p>
<p>Subclasses must define this, but the arguments and return type vary between
concrete classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Module</em> | <em>Tuple</em>[<em>Module</em>, <em>Parameter</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.Distribution.sample">
<em class="property"><span class="pre">abstract</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#Distribution.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.Distribution.sample" title="Permalink to this definition"></a></dt>
<dd><p>Returns a sample from the probability distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the stochastic action</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.MultiCategoricalDistribution">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.distributions.</span></span><span class="sig-name descname"><span class="pre">MultiCategoricalDistribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_dims</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#MultiCategoricalDistribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.MultiCategoricalDistribution" title="Permalink to this definition"></a></dt>
<dd><p>MultiCategorical distribution for multi discrete actions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action_dims</strong> (<em>List</em><em>[</em><em>int</em><em>]</em>) – List of sizes of discrete action spaces</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.MultiCategoricalDistribution.actions_from_params">
<span class="sig-name descname"><span class="pre">actions_from_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_logits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#MultiCategoricalDistribution.actions_from_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.MultiCategoricalDistribution.actions_from_params" title="Permalink to this definition"></a></dt>
<dd><p>Returns samples from the probability distribution
given its parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>actions</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>action_logits</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.MultiCategoricalDistribution.entropy">
<span class="sig-name descname"><span class="pre">entropy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#MultiCategoricalDistribution.entropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.MultiCategoricalDistribution.entropy" title="Permalink to this definition"></a></dt>
<dd><p>Returns Shannon’s entropy of the probability</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the entropy, or None if no analytical form is known</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.MultiCategoricalDistribution.log_prob">
<span class="sig-name descname"><span class="pre">log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#MultiCategoricalDistribution.log_prob"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.MultiCategoricalDistribution.log_prob" title="Permalink to this definition"></a></dt>
<dd><p>Returns the log likelihood</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – the taken action</p></li>
<li><p><strong>actions</strong> (<em>Tensor</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The log likelihood of the distribution</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.MultiCategoricalDistribution.log_prob_from_params">
<span class="sig-name descname"><span class="pre">log_prob_from_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_logits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#MultiCategoricalDistribution.log_prob_from_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.MultiCategoricalDistribution.log_prob_from_params" title="Permalink to this definition"></a></dt>
<dd><p>Returns samples and the associated log probabilities
from the probability distribution given its parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>actions and log prob</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>action_logits</strong> (<em>Tensor</em>) – </p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.MultiCategoricalDistribution.mode">
<span class="sig-name descname"><span class="pre">mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#MultiCategoricalDistribution.mode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.MultiCategoricalDistribution.mode" title="Permalink to this definition"></a></dt>
<dd><p>Returns the most likely action (deterministic output)
from the probability distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the stochastic action</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.MultiCategoricalDistribution.proba_distribution">
<span class="sig-name descname"><span class="pre">proba_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_logits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#MultiCategoricalDistribution.proba_distribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.MultiCategoricalDistribution.proba_distribution" title="Permalink to this definition"></a></dt>
<dd><p>Set parameters of the distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>self</strong> (<em>SelfMultiCategoricalDistribution</em>) – </p></li>
<li><p><strong>action_logits</strong> (<em>Tensor</em>) – </p></li>
</ul>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfMultiCategoricalDistribution</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.MultiCategoricalDistribution.proba_distribution_net">
<span class="sig-name descname"><span class="pre">proba_distribution_net</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#MultiCategoricalDistribution.proba_distribution_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.MultiCategoricalDistribution.proba_distribution_net" title="Permalink to this definition"></a></dt>
<dd><p>Create the layer that represents the distribution:
it will be the logits (flattened) of the MultiCategorical distribution.
You can then get probabilities using a softmax on each sub-space.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>latent_dim</strong> (<em>int</em>) – Dimension of the last layer
of the policy network (before the action layer)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Module</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.MultiCategoricalDistribution.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#MultiCategoricalDistribution.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.MultiCategoricalDistribution.sample" title="Permalink to this definition"></a></dt>
<dd><p>Returns a sample from the probability distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the stochastic action</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.SquashedDiagGaussianDistribution">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.distributions.</span></span><span class="sig-name descname"><span class="pre">SquashedDiagGaussianDistribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#SquashedDiagGaussianDistribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.SquashedDiagGaussianDistribution" title="Permalink to this definition"></a></dt>
<dd><p>Gaussian distribution with diagonal covariance matrix, followed by a squashing function (tanh) to ensure bounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>action_dim</strong> (<em>int</em>) – Dimension of the action space.</p></li>
<li><p><strong>epsilon</strong> (<em>float</em>) – small value to avoid NaN due to numerical imprecision.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.SquashedDiagGaussianDistribution.entropy">
<span class="sig-name descname"><span class="pre">entropy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#SquashedDiagGaussianDistribution.entropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.SquashedDiagGaussianDistribution.entropy" title="Permalink to this definition"></a></dt>
<dd><p>Returns Shannon’s entropy of the probability</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the entropy, or None if no analytical form is known</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.SquashedDiagGaussianDistribution.log_prob">
<span class="sig-name descname"><span class="pre">log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gaussian_actions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#SquashedDiagGaussianDistribution.log_prob"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.SquashedDiagGaussianDistribution.log_prob" title="Permalink to this definition"></a></dt>
<dd><p>Get the log probabilities of actions according to the distribution.
Note that you must first call the <code class="docutils literal notranslate"><span class="pre">proba_distribution()</span></code> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>actions</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>gaussian_actions</strong> (<em>Tensor</em><em> | </em><em>None</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.SquashedDiagGaussianDistribution.log_prob_from_params">
<span class="sig-name descname"><span class="pre">log_prob_from_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean_actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#SquashedDiagGaussianDistribution.log_prob_from_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.SquashedDiagGaussianDistribution.log_prob_from_params" title="Permalink to this definition"></a></dt>
<dd><p>Compute the log probability of taking an action
given the distribution parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mean_actions</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>log_std</strong> (<em>Tensor</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.SquashedDiagGaussianDistribution.mode">
<span class="sig-name descname"><span class="pre">mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#SquashedDiagGaussianDistribution.mode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.SquashedDiagGaussianDistribution.mode" title="Permalink to this definition"></a></dt>
<dd><p>Returns the most likely action (deterministic output)
from the probability distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the stochastic action</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.SquashedDiagGaussianDistribution.proba_distribution">
<span class="sig-name descname"><span class="pre">proba_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean_actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#SquashedDiagGaussianDistribution.proba_distribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.SquashedDiagGaussianDistribution.proba_distribution" title="Permalink to this definition"></a></dt>
<dd><p>Create the distribution given its parameters (mean, std)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mean_actions</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>log_std</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>self</strong> (<em>SelfSquashedDiagGaussianDistribution</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfSquashedDiagGaussianDistribution</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.SquashedDiagGaussianDistribution.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#SquashedDiagGaussianDistribution.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.SquashedDiagGaussianDistribution.sample" title="Permalink to this definition"></a></dt>
<dd><p>Returns a sample from the probability distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the stochastic action</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.StateDependentNoiseDistribution">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.distributions.</span></span><span class="sig-name descname"><span class="pre">StateDependentNoiseDistribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_expln</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">squash_output</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learn_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#StateDependentNoiseDistribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.StateDependentNoiseDistribution" title="Permalink to this definition"></a></dt>
<dd><p>Distribution class for using generalized State Dependent Exploration (gSDE).
Paper: <a class="reference external" href="https://arxiv.org/abs/2005.05719">https://arxiv.org/abs/2005.05719</a></p>
<p>It is used to create the noise exploration matrix and
compute the log probability of an action with that noise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>action_dim</strong> (<em>int</em>) – Dimension of the action space.</p></li>
<li><p><strong>full_std</strong> (<em>bool</em>) – Whether to use (n_features x n_actions) parameters
for the std instead of only (n_features,)</p></li>
<li><p><strong>use_expln</strong> (<em>bool</em>) – Use <code class="docutils literal notranslate"><span class="pre">expln()</span></code> function instead of <code class="docutils literal notranslate"><span class="pre">exp()</span></code> to ensure
a positive standard deviation (cf paper). It allows to keep variance
above zero and prevent it from growing too fast. In practice, <code class="docutils literal notranslate"><span class="pre">exp()</span></code> is usually enough.</p></li>
<li><p><strong>squash_output</strong> (<em>bool</em>) – Whether to squash the output using a tanh function,
this ensures bounds are satisfied.</p></li>
<li><p><strong>learn_features</strong> (<em>bool</em>) – Whether to learn features for gSDE or not.
This will enable gradients to be backpropagated through the features
<code class="docutils literal notranslate"><span class="pre">latent_sde</span></code> in the code.</p></li>
<li><p><strong>epsilon</strong> (<em>float</em>) – small value to avoid NaN due to numerical imprecision.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.StateDependentNoiseDistribution.actions_from_params">
<span class="sig-name descname"><span class="pre">actions_from_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean_actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_sde</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#StateDependentNoiseDistribution.actions_from_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.StateDependentNoiseDistribution.actions_from_params" title="Permalink to this definition"></a></dt>
<dd><p>Returns samples from the probability distribution
given its parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>actions</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>mean_actions</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>log_std</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>latent_sde</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.StateDependentNoiseDistribution.entropy">
<span class="sig-name descname"><span class="pre">entropy</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#StateDependentNoiseDistribution.entropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.StateDependentNoiseDistribution.entropy" title="Permalink to this definition"></a></dt>
<dd><p>Returns Shannon’s entropy of the probability</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the entropy, or None if no analytical form is known</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em> | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.StateDependentNoiseDistribution.get_std">
<span class="sig-name descname"><span class="pre">get_std</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_std</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#StateDependentNoiseDistribution.get_std"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.StateDependentNoiseDistribution.get_std" title="Permalink to this definition"></a></dt>
<dd><p>Get the standard deviation from the learned parameter
(log of it by default). This ensures that the std is positive.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>log_std</strong> (<em>Tensor</em>) – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.StateDependentNoiseDistribution.log_prob">
<span class="sig-name descname"><span class="pre">log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#StateDependentNoiseDistribution.log_prob"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.StateDependentNoiseDistribution.log_prob" title="Permalink to this definition"></a></dt>
<dd><p>Returns the log likelihood</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – the taken action</p></li>
<li><p><strong>actions</strong> (<em>Tensor</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The log likelihood of the distribution</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.StateDependentNoiseDistribution.log_prob_from_params">
<span class="sig-name descname"><span class="pre">log_prob_from_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean_actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_sde</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#StateDependentNoiseDistribution.log_prob_from_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.StateDependentNoiseDistribution.log_prob_from_params" title="Permalink to this definition"></a></dt>
<dd><p>Returns samples and the associated log probabilities
from the probability distribution given its parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>actions and log prob</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>mean_actions</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>log_std</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>latent_sde</strong> (<em>Tensor</em>) – </p></li>
</ul>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Tensor</em>, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.StateDependentNoiseDistribution.mode">
<span class="sig-name descname"><span class="pre">mode</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#StateDependentNoiseDistribution.mode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.StateDependentNoiseDistribution.mode" title="Permalink to this definition"></a></dt>
<dd><p>Returns the most likely action (deterministic output)
from the probability distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the stochastic action</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.StateDependentNoiseDistribution.proba_distribution">
<span class="sig-name descname"><span class="pre">proba_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean_actions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_sde</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#StateDependentNoiseDistribution.proba_distribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.StateDependentNoiseDistribution.proba_distribution" title="Permalink to this definition"></a></dt>
<dd><p>Create the distribution given its parameters (mean, std)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mean_actions</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>log_std</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>latent_sde</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>self</strong> (<em>SelfStateDependentNoiseDistribution</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>SelfStateDependentNoiseDistribution</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.StateDependentNoiseDistribution.proba_distribution_net">
<span class="sig-name descname"><span class="pre">proba_distribution_net</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_std_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_sde_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#StateDependentNoiseDistribution.proba_distribution_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.StateDependentNoiseDistribution.proba_distribution_net" title="Permalink to this definition"></a></dt>
<dd><p>Create the layers and parameter that represent the distribution:
one output will be the deterministic action, the other parameter will be the
standard deviation of the distribution that control the weights of the noise matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>latent_dim</strong> (<em>int</em>) – Dimension of the last layer of the policy (before the action layer)</p></li>
<li><p><strong>log_std_init</strong> (<em>float</em>) – Initial value for the log standard deviation</p></li>
<li><p><strong>latent_sde_dim</strong> (<em>int</em><em> | </em><em>None</em>) – Dimension of the last layer of the features extractor
for gSDE. By default, it is shared with the policy network.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Module</em>, <em>Parameter</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.StateDependentNoiseDistribution.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#StateDependentNoiseDistribution.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.StateDependentNoiseDistribution.sample" title="Permalink to this definition"></a></dt>
<dd><p>Returns a sample from the probability distribution</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the stochastic action</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.StateDependentNoiseDistribution.sample_weights">
<span class="sig-name descname"><span class="pre">sample_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_std</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#StateDependentNoiseDistribution.sample_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.StateDependentNoiseDistribution.sample_weights" title="Permalink to this definition"></a></dt>
<dd><p>Sample weights for the noise exploration matrix,
using a centered Gaussian distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_std</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.TanhBijector">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.distributions.</span></span><span class="sig-name descname"><span class="pre">TanhBijector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#TanhBijector"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.TanhBijector" title="Permalink to this definition"></a></dt>
<dd><p>Bijective transformation of a probability distribution
using a squashing function (tanh)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>epsilon</strong> (<em>float</em>) – small value to avoid NaN due to numerical imprecision.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.TanhBijector.atanh">
<em class="property"><span class="pre">static</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">atanh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#TanhBijector.atanh"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.TanhBijector.atanh" title="Permalink to this definition"></a></dt>
<dd><p>Inverse of Tanh</p>
<p>Taken from Pyro: <a class="reference external" href="https://github.com/pyro-ppl/pyro">https://github.com/pyro-ppl/pyro</a>
0.5 * torch.log((1 + x ) / (1 - x))</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.TanhBijector.inverse">
<em class="property"><span class="pre">static</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">inverse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#TanhBijector.inverse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.TanhBijector.inverse" title="Permalink to this definition"></a></dt>
<dd><p>Inverse tanh.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>y</strong> (<em>Tensor</em>) – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.kl_divergence">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.distributions.</span></span><span class="sig-name descname"><span class="pre">kl_divergence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dist_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dist_pred</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#kl_divergence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.kl_divergence" title="Permalink to this definition"></a></dt>
<dd><p>Wrapper for the PyTorch implementation of the full form KL Divergence</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dist_true</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.distributions.Distribution" title="stable_baselines3.common.distributions.Distribution"><em>Distribution</em></a>) – the p distribution</p></li>
<li><p><strong>dist_pred</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.distributions.Distribution" title="stable_baselines3.common.distributions.Distribution"><em>Distribution</em></a>) – the q distribution</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>KL(dist_true||dist_pred)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.make_proba_distribution">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.distributions.</span></span><span class="sig-name descname"><span class="pre">make_proba_distribution</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_sde</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dist_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#make_proba_distribution"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.make_proba_distribution" title="Permalink to this definition"></a></dt>
<dd><p>Return an instance of Distribution for the correct type of action space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>action_space</strong> (<em>Space</em>) – the input action space</p></li>
<li><p><strong>use_sde</strong> (<em>bool</em>) – Force the use of StateDependentNoiseDistribution
instead of DiagGaussianDistribution</p></li>
<li><p><strong>dist_kwargs</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>] </em><em>| </em><em>None</em>) – Keyword arguments to pass to the probability distribution</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the appropriate Distribution object</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="index.html#stable_baselines3.common.distributions.Distribution" title="stable_baselines3.common.distributions.Distribution"><em>Distribution</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.distributions.sum_independent_dims">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.distributions.</span></span><span class="sig-name descname"><span class="pre">sum_independent_dims</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/distributions.html#sum_independent_dims"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.distributions.sum_independent_dims" title="Permalink to this definition"></a></dt>
<dd><p>Continuous actions are usually considered to be independent,
so we can sum components of the <code class="docutils literal notranslate"><span class="pre">log_prob</span></code> or the entropy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>tensor</strong> (<em>Tensor</em>) – shape: (n_batch, n_actions) or (n_batch,)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>shape: (n_batch,)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</section>
<span id="document-common/evaluation"></span><section id="module-stable_baselines3.common.evaluation">
<span id="evaluation-helper"></span><span id="eval"></span><h3>Evaluation Helper<a class="headerlink" href="#module-stable_baselines3.common.evaluation" title="Permalink to this heading"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.evaluation.evaluate_policy">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.evaluation.</span></span><span class="sig-name descname"><span class="pre">evaluate_policy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_eval_episodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">deterministic</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">render</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_episode_rewards</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/evaluation.html#evaluate_policy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.evaluation.evaluate_policy" title="Permalink to this definition"></a></dt>
<dd><p>Runs policy for <code class="docutils literal notranslate"><span class="pre">n_eval_episodes</span></code> episodes and returns average reward.
If a vector env is passed in, this divides the episodes to evaluate onto the
different elements of the vector env. This static division of work is done to
remove bias. See <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/402">https://github.com/DLR-RM/stable-baselines3/issues/402</a> for more
details and discussion.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If environment has not been wrapped with <code class="docutils literal notranslate"><span class="pre">Monitor</span></code> wrapper, reward and
episode lengths are counted as it appears with <code class="docutils literal notranslate"><span class="pre">env.step</span></code> calls. If
the environment contains wrappers that modify rewards or episode lengths
(e.g. reward scaling, early episode reset), these will affect the evaluation
results as well. You can avoid this by wrapping environment with <code class="docutils literal notranslate"><span class="pre">Monitor</span></code>
wrapper before anything else.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>PolicyPredictor</em>) – The RL agent you want to evaluate. This can be any object
that implements a <cite>predict</cite> method, such as an RL algorithm (<code class="docutils literal notranslate"><span class="pre">BaseAlgorithm</span></code>)
or policy (<code class="docutils literal notranslate"><span class="pre">BasePolicy</span></code>).</p></li>
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.base_vec_env.VecEnv"><em>VecEnv</em></a>) – The gym environment or <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code> environment.</p></li>
<li><p><strong>n_eval_episodes</strong> (<em>int</em>) – Number of episode to evaluate the agent</p></li>
<li><p><strong>deterministic</strong> (<em>bool</em>) – Whether to use deterministic or stochastic actions</p></li>
<li><p><strong>render</strong> (<em>bool</em>) – Whether to render the environment or not</p></li>
<li><p><strong>callback</strong> (<em>Callable</em><em>[</em><em>[</em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>, </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em><em>]</em><em>, </em><em>None</em><em>] </em><em>| </em><em>None</em>) – callback function to do additional checks,
called after each step. Gets locals() and globals() passed as parameters.</p></li>
<li><p><strong>reward_threshold</strong> (<em>float</em><em> | </em><em>None</em>) – Minimum expected reward per episode,
this will raise an error if the performance is not met</p></li>
<li><p><strong>return_episode_rewards</strong> (<em>bool</em>) – If True, a list of rewards and episode lengths
per episode will be returned instead of the mean.</p></li>
<li><p><strong>warn</strong> (<em>bool</em>) – If True (default), warns user about lack of a Monitor wrapper in the
evaluation environment.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Mean reward per episode, std of reward per episode.
Returns ([float], [int]) when <code class="docutils literal notranslate"><span class="pre">return_episode_rewards</span></code> is True, first
list containing per-episode rewards and second containing per-episode lengths
(in number of steps).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[float, float] | <em>Tuple</em>[<em>List</em>[float], <em>List</em>[int]]</p>
</dd>
</dl>
</dd></dl>

</section>
<span id="document-common/env_checker"></span><section id="module-stable_baselines3.common.env_checker">
<span id="gym-environment-checker"></span><span id="env-checker"></span><h3>Gym Environment Checker<a class="headerlink" href="#module-stable_baselines3.common.env_checker" title="Permalink to this heading"></a></h3>
<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.env_checker.check_env">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.env_checker.</span></span><span class="sig-name descname"><span class="pre">check_env</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_render_check</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/env_checker.html#check_env"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.env_checker.check_env" title="Permalink to this definition"></a></dt>
<dd><p>Check that an environment follows Gym API.
This is particularly useful when using a custom environment.
Please take a look at <a class="reference external" href="https://gymnasium.farama.org/api/env/">https://gymnasium.farama.org/api/env/</a>
for more information about the API.</p>
<p>It also optionally check that the environment is compatible with Stable-Baselines.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<em>Env</em>) – The Gym environment that will be checked</p></li>
<li><p><strong>warn</strong> (<em>bool</em>) – Whether to output additional warnings
mainly related to the interaction with Stable Baselines</p></li>
<li><p><strong>skip_render_check</strong> (<em>bool</em>) – Whether to skip the checks for the render method.
True by default (useful for the CI)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</section>
<span id="document-common/monitor"></span><section id="module-stable_baselines3.common.monitor">
<span id="monitor-wrapper"></span><span id="monitor"></span><h3>Monitor Wrapper<a class="headerlink" href="#module-stable_baselines3.common.monitor" title="Permalink to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.monitor.Monitor">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.monitor.</span></span><span class="sig-name descname"><span class="pre">Monitor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">allow_early_resets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_keywords</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">info_keywords</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">override_existing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/monitor.html#Monitor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.monitor.Monitor" title="Permalink to this definition"></a></dt>
<dd><p>A monitor wrapper for Gym environments, it is used to know the episode reward, length, time and other data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> – The environment</p></li>
<li><p><strong>filename</strong> – the location to save a log file, can be None for no log</p></li>
<li><p><strong>allow_early_resets</strong> – allows the reset of the environment before it is done</p></li>
<li><p><strong>reset_keywords</strong> – extra keywords for the reset call,
if extra parameters are needed at reset</p></li>
<li><p><strong>info_keywords</strong> – extra information to log, from the information return of env.step()</p></li>
<li><p><strong>override_existing</strong> – appends to file if <code class="docutils literal notranslate"><span class="pre">filename</span></code> exists, otherwise
override existing files (default)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.monitor.Monitor.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/monitor.html#Monitor.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.monitor.Monitor.close" title="Permalink to this definition"></a></dt>
<dd><p>Closes the environment</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.monitor.Monitor.get_episode_lengths">
<span class="sig-name descname"><span class="pre">get_episode_lengths</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/monitor.html#Monitor.get_episode_lengths"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.monitor.Monitor.get_episode_lengths" title="Permalink to this definition"></a></dt>
<dd><p>Returns the number of timesteps of all the episodes</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>List</em>[int]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.monitor.Monitor.get_episode_rewards">
<span class="sig-name descname"><span class="pre">get_episode_rewards</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/monitor.html#Monitor.get_episode_rewards"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.monitor.Monitor.get_episode_rewards" title="Permalink to this definition"></a></dt>
<dd><p>Returns the rewards of all the episodes</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.monitor.Monitor.get_episode_times">
<span class="sig-name descname"><span class="pre">get_episode_times</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/monitor.html#Monitor.get_episode_times"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.monitor.Monitor.get_episode_times" title="Permalink to this definition"></a></dt>
<dd><p>Returns the runtime in seconds of all the episodes</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>List</em>[float]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.monitor.Monitor.get_total_steps">
<span class="sig-name descname"><span class="pre">get_total_steps</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/monitor.html#Monitor.get_total_steps"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.monitor.Monitor.get_total_steps" title="Permalink to this definition"></a></dt>
<dd><p>Returns the total number of timesteps</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.monitor.Monitor.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/monitor.html#Monitor.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.monitor.Monitor.reset" title="Permalink to this definition"></a></dt>
<dd><p>Calls the Gym environment reset. Can only be called if the environment is over, or if allow_early_resets is True</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>kwargs</strong> – Extra keywords saved for the next episode. only if defined by reset_keywords</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the first observation of the environment</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>ObsType</em>, <em>Dict</em>[str, <em>Any</em>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.monitor.Monitor.step">
<span class="sig-name descname"><span class="pre">step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/monitor.html#Monitor.step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.monitor.Monitor.step" title="Permalink to this definition"></a></dt>
<dd><p>Step the environment with the given action</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>action</strong> (<em>ActType</em>) – the action</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>observation, reward, terminated, truncated, information</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>ObsType</em>, <em>SupportsFloat</em>, bool, bool, <em>Dict</em>[str, <em>Any</em>]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.monitor.ResultsWriter">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.monitor.</span></span><span class="sig-name descname"><span class="pre">ResultsWriter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">header</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extra_keys</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">override_existing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/monitor.html#ResultsWriter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.monitor.ResultsWriter" title="Permalink to this definition"></a></dt>
<dd><p>A result writer that saves the data from the <cite>Monitor</cite> class</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> (<em>str</em>) – the location to save a log file. When it does not end in
the string <code class="docutils literal notranslate"><span class="pre">&quot;monitor.csv&quot;</span></code>, this suffix will be appended to it</p></li>
<li><p><strong>header</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em> | </em><em>str</em><em>] </em><em>| </em><em>None</em>) – the header dictionary object of the saved csv</p></li>
<li><p><strong>extra_keys</strong> (<em>Tuple</em><em>[</em><em>str</em><em>, </em><em>...</em><em>]</em>) – the extra information to log, typically is composed of
<code class="docutils literal notranslate"><span class="pre">reset_keywords</span></code> and <code class="docutils literal notranslate"><span class="pre">info_keywords</span></code></p></li>
<li><p><strong>override_existing</strong> (<em>bool</em>) – appends to file if <code class="docutils literal notranslate"><span class="pre">filename</span></code> exists, otherwise
override existing files (default)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.monitor.ResultsWriter.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/monitor.html#ResultsWriter.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.monitor.ResultsWriter.close" title="Permalink to this definition"></a></dt>
<dd><p>Close the file handler</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.monitor.ResultsWriter.write_row">
<span class="sig-name descname"><span class="pre">write_row</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epinfo</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/monitor.html#ResultsWriter.write_row"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.monitor.ResultsWriter.write_row" title="Permalink to this definition"></a></dt>
<dd><p>Write row of monitor data to csv log file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>epinfo</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>]</em>) – the information on episodic return, length, and time</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.monitor.get_monitor_files">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.monitor.</span></span><span class="sig-name descname"><span class="pre">get_monitor_files</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/monitor.html#get_monitor_files"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.monitor.get_monitor_files" title="Permalink to this definition"></a></dt>
<dd><p>get all the monitor files in the given path</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>path</strong> (<em>str</em>) – the logging folder</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the log files</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>List</em>[str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.monitor.load_results">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.monitor.</span></span><span class="sig-name descname"><span class="pre">load_results</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/monitor.html#load_results"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.monitor.load_results" title="Permalink to this definition"></a></dt>
<dd><p>Load all Monitor logs from a given directory path matching <code class="docutils literal notranslate"><span class="pre">*monitor.csv</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>path</strong> (<em>str</em>) – the directory path containing the log file(s)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the logged data</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>DataFrame</em></p>
</dd>
</dl>
</dd></dl>

</section>
<span id="document-common/logger"></span><section id="logger">
<span id="id1"></span><h3>Logger<a class="headerlink" href="#logger" title="Permalink to this heading"></a></h3>
<p>To overwrite the default logger, you can pass one to the algorithm.
Available formats are <code class="docutils literal notranslate"><span class="pre">[&quot;stdout&quot;,</span> <span class="pre">&quot;csv&quot;,</span> <span class="pre">&quot;log&quot;,</span> <span class="pre">&quot;tensorboard&quot;,</span> <span class="pre">&quot;json&quot;]</span></code>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When passing a custom logger object,
this will overwrite <code class="docutils literal notranslate"><span class="pre">tensorboard_log</span></code> and <code class="docutils literal notranslate"><span class="pre">verbose</span></code> settings
passed to the constructor.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3</span> <span class="kn">import</span> <span class="n">A2C</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.logger</span> <span class="kn">import</span> <span class="n">configure</span>

<span class="n">tmp_path</span> <span class="o">=</span> <span class="s2">&quot;/tmp/sb3_log/&quot;</span>
<span class="c1"># set up logger</span>
<span class="n">new_logger</span> <span class="o">=</span> <span class="n">configure</span><span class="p">(</span><span class="n">tmp_path</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;stdout&quot;</span><span class="p">,</span> <span class="s2">&quot;csv&quot;</span><span class="p">,</span> <span class="s2">&quot;tensorboard&quot;</span><span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">A2C</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="s2">&quot;CartPole-v1&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Set new logger</span>
<span class="n">model</span><span class="o">.</span><span class="n">set_logger</span><span class="p">(</span><span class="n">new_logger</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
</pre></div>
</div>
<section id="explanation-of-logger-output">
<h4>Explanation of logger output<a class="headerlink" href="#explanation-of-logger-output" title="Permalink to this heading"></a></h4>
<p>You can find below short explanations of the values logged in Stable-Baselines3 (SB3).
Depending on the algorithm used and of the wrappers/callbacks applied, SB3 only logs a subset of those keys during training.</p>
<p>Below you can find an example of the logger output when training a PPO agent:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>-----------------------------------------
<span class="p">|</span><span class="w"> </span>eval/<span class="w">                   </span><span class="p">|</span><span class="w">             </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>mean_ep_length<span class="w">       </span><span class="p">|</span><span class="w"> </span><span class="m">200</span><span class="w">         </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>mean_reward<span class="w">          </span><span class="p">|</span><span class="w"> </span>-157<span class="w">        </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>rollout/<span class="w">                </span><span class="p">|</span><span class="w">             </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>ep_len_mean<span class="w">          </span><span class="p">|</span><span class="w"> </span><span class="m">200</span><span class="w">         </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>ep_rew_mean<span class="w">          </span><span class="p">|</span><span class="w"> </span>-227<span class="w">        </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>time/<span class="w">                   </span><span class="p">|</span><span class="w">             </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>fps<span class="w">                  </span><span class="p">|</span><span class="w"> </span><span class="m">972</span><span class="w">         </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>iterations<span class="w">           </span><span class="p">|</span><span class="w"> </span><span class="m">19</span><span class="w">          </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>time_elapsed<span class="w">         </span><span class="p">|</span><span class="w"> </span><span class="m">80</span><span class="w">          </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>total_timesteps<span class="w">      </span><span class="p">|</span><span class="w"> </span><span class="m">77824</span><span class="w">       </span><span class="p">|</span>
<span class="p">|</span><span class="w"> </span>train/<span class="w">                  </span><span class="p">|</span><span class="w">             </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>approx_kl<span class="w">            </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.037781604<span class="w"> </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>clip_fraction<span class="w">        </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.243<span class="w">       </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>clip_range<span class="w">           </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.2<span class="w">         </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>entropy_loss<span class="w">         </span><span class="p">|</span><span class="w"> </span>-1.06<span class="w">       </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>explained_variance<span class="w">   </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.999<span class="w">       </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>learning_rate<span class="w">        </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.001<span class="w">       </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>loss<span class="w">                 </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.245<span class="w">       </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>n_updates<span class="w">            </span><span class="p">|</span><span class="w"> </span><span class="m">180</span><span class="w">         </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>policy_gradient_loss<span class="w"> </span><span class="p">|</span><span class="w"> </span>-0.00398<span class="w">    </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>std<span class="w">                  </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.205<span class="w">       </span><span class="p">|</span>
<span class="p">|</span><span class="w">    </span>value_loss<span class="w">           </span><span class="p">|</span><span class="w"> </span><span class="m">0</span>.226<span class="w">       </span><span class="p">|</span>
-----------------------------------------
</pre></div>
</div>
<section id="eval">
<h5>eval/<a class="headerlink" href="#eval" title="Permalink to this heading"></a></h5>
<p>All <code class="docutils literal notranslate"><span class="pre">eval/</span></code> values are computed by the <code class="docutils literal notranslate"><span class="pre">EvalCallback</span></code>.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mean_ep_length</span></code>: Mean episode length</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mean_reward</span></code>: Mean episodic reward (during evaluation)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">success_rate</span></code>: Mean success rate during evaluation (1.0 means 100% success), the environment info dict must contain an <code class="docutils literal notranslate"><span class="pre">is_success</span></code> key to compute that value</p></li>
</ul>
</section>
<section id="rollout">
<h5>rollout/<a class="headerlink" href="#rollout" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ep_len_mean</span></code>: Mean episode length (averaged over <code class="docutils literal notranslate"><span class="pre">stats_window_size</span></code> episodes, 100 by default)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ep_rew_mean</span></code>: Mean episodic training reward (averaged over <code class="docutils literal notranslate"><span class="pre">stats_window_size</span></code> episodes, 100 by default), a <code class="docutils literal notranslate"><span class="pre">Monitor</span></code> wrapper is required to compute that value (automatically added by <cite>make_vec_env</cite>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">exploration_rate</span></code>: Current value of the exploration rate when using DQN, it corresponds to the fraction of actions taken randomly (epsilon of the “epsilon-greedy” exploration)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">success_rate</span></code>: Mean success rate during training (averaged over <code class="docutils literal notranslate"><span class="pre">stats_window_size</span></code> episodes, 100 by default), you must pass an extra argument to the <code class="docutils literal notranslate"><span class="pre">Monitor</span></code> wrapper to log that value (<code class="docutils literal notranslate"><span class="pre">info_keywords=(&quot;is_success&quot;,)</span></code>) and provide <code class="docutils literal notranslate"><span class="pre">info[&quot;is_success&quot;]=True/False</span></code> on the final step of the episode</p></li>
</ul>
</section>
<section id="time">
<h5>time/<a class="headerlink" href="#time" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">episodes</span></code>: Total number of episodes</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fps</span></code>: Number of frames per seconds (includes time taken by gradient update)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iterations</span></code>: Number of iterations (data collection + policy update for A2C/PPO)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">time_elapsed</span></code>: Time in seconds since the beginning of training</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">total_timesteps</span></code>: Total number of timesteps (steps in the environments)</p></li>
</ul>
</section>
<section id="train">
<h5>train/<a class="headerlink" href="#train" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">actor_loss</span></code>: Current value for the actor loss for off-policy algorithms</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">approx_kl</span></code>: approximate mean KL divergence between old and new policy (for PPO), it is an estimation of how much changes happened in the update</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clip_fraction</span></code>: mean fraction of surrogate loss that was clipped (above <code class="docutils literal notranslate"><span class="pre">clip_range</span></code> threshold) for PPO.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clip_range</span></code>: Current value of the clipping factor for the surrogate loss of PPO</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">critic_loss</span></code>: Current value for the critic function loss for off-policy algorithms, usually error between value function output and TD(0), temporal difference estimate</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ent_coef</span></code>: Current value of the entropy coefficient (when using SAC)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ent_coef_loss</span></code>: Current value of the entropy coefficient loss (when using SAC)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entropy_loss</span></code>: Mean value of the entropy loss (negative of the average policy entropy)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">explained_variance</span></code>: Fraction of the return variance explained by the value function, see <a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html#explained-variance-score">https://scikit-learn.org/stable/modules/model_evaluation.html#explained-variance-score</a>
(ev=0 =&gt; might as well have predicted zero, ev=1 =&gt; perfect prediction, ev&lt;0 =&gt; worse than just predicting zero)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>: Current learning rate value</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">loss</span></code>: Current total loss value</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_updates</span></code>: Number of gradient updates applied so far</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">policy_gradient_loss</span></code>: Current value of the policy gradient loss (its value does not have much meaning)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">value_loss</span></code>: Current value for the value function loss for on-policy algorithms, usually error between value function output and Monte-Carlo estimate (or TD(lambda) estimate)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">std</span></code>: Current standard deviation of the noise when using generalized State-Dependent Exploration (gSDE)</p></li>
</ul>
<span class="target" id="module-stable_baselines3.common.logger"></span><dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.CSVOutputFormat">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.logger.</span></span><span class="sig-name descname"><span class="pre">CSVOutputFormat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#CSVOutputFormat"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.CSVOutputFormat" title="Permalink to this definition"></a></dt>
<dd><p>Log to a file, in a CSV format</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>filename</strong> (<em>str</em>) – the file to write the log to</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.CSVOutputFormat.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#CSVOutputFormat.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.CSVOutputFormat.close" title="Permalink to this definition"></a></dt>
<dd><p>closes the file</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.CSVOutputFormat.write">
<span class="sig-name descname"><span class="pre">write</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key_values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key_excluded</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#CSVOutputFormat.write"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.CSVOutputFormat.write" title="Permalink to this definition"></a></dt>
<dd><p>Write a dictionary to file</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key_values</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
<li><p><strong>key_excluded</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>str</em><em>, </em><em>...</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>step</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.Figure">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.logger.</span></span><span class="sig-name descname"><span class="pre">Figure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">figure</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">close</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#Figure"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.Figure" title="Permalink to this definition"></a></dt>
<dd><p>Figure data class storing a matplotlib figure and whether to close the figure after logging it</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>figure</strong> (<em>Figure</em>) – figure to log</p></li>
<li><p><strong>close</strong> (<em>bool</em>) – if true, close the figure after logging it</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py exception">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.FormatUnsupportedError">
<em class="property"><span class="pre">exception</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.logger.</span></span><span class="sig-name descname"><span class="pre">FormatUnsupportedError</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">unsupported_formats</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value_description</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#FormatUnsupportedError"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.FormatUnsupportedError" title="Permalink to this definition"></a></dt>
<dd><p>Custom error to display informative message when
a value is not supported by some formats.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>unsupported_formats</strong> (<em>Sequence</em><em>[</em><em>str</em><em>]</em>) – A sequence of unsupported formats,
for instance <code class="docutils literal notranslate"><span class="pre">[&quot;stdout&quot;]</span></code>.</p></li>
<li><p><strong>value_description</strong> (<em>str</em>) – Description of the value that cannot be logged by this format.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.HParam">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.logger.</span></span><span class="sig-name descname"><span class="pre">HParam</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hparam_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#HParam"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.HParam" title="Permalink to this definition"></a></dt>
<dd><p>Hyperparameter data class storing hyperparameters and metrics in dictionaries</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hparam_dict</strong> (<em>Mapping</em><em>[</em><em>str</em><em>, </em><em>bool</em><em> | </em><em>str</em><em> | </em><em>float</em><em> | </em><em>None</em><em>]</em>) – key-value pairs of hyperparameters to log</p></li>
<li><p><strong>metric_dict</strong> (<em>Mapping</em><em>[</em><em>str</em><em>, </em><em>float</em><em>]</em>) – key-value pairs of metrics to log
A non-empty metrics dict is required to display hyperparameters in the corresponding Tensorboard section.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.HumanOutputFormat">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.logger.</span></span><span class="sig-name descname"><span class="pre">HumanOutputFormat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename_or_file</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">36</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#HumanOutputFormat"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.HumanOutputFormat" title="Permalink to this definition"></a></dt>
<dd><p>A human-readable output format producing ASCII tables of key-value pairs.</p>
<p>Set attribute <code class="docutils literal notranslate"><span class="pre">max_length</span></code> to change the maximum length of keys and values
to write to output (or specify it when calling <code class="docutils literal notranslate"><span class="pre">__init__</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename_or_file</strong> (<em>str</em><em> | </em><em>TextIO</em>) – the file to write the log to</p></li>
<li><p><strong>max_length</strong> (<em>int</em>) – the maximum length of keys and values to write to output.
Outputs longer than this will be truncated. An error will be raised
if multiple keys are truncated to the same value. The maximum output
width will be <code class="docutils literal notranslate"><span class="pre">2*max_length</span> <span class="pre">+</span> <span class="pre">7</span></code>. The default of 36 produces output
no longer than 79 characters wide.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.HumanOutputFormat.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#HumanOutputFormat.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.HumanOutputFormat.close" title="Permalink to this definition"></a></dt>
<dd><p>closes the file</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.HumanOutputFormat.write">
<span class="sig-name descname"><span class="pre">write</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key_values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key_excluded</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#HumanOutputFormat.write"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.HumanOutputFormat.write" title="Permalink to this definition"></a></dt>
<dd><p>Write a dictionary to file</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key_values</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
<li><p><strong>key_excluded</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>str</em><em>, </em><em>...</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>step</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.HumanOutputFormat.write_sequence">
<span class="sig-name descname"><span class="pre">write_sequence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sequence</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#HumanOutputFormat.write_sequence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.HumanOutputFormat.write_sequence" title="Permalink to this definition"></a></dt>
<dd><p>write_sequence an array to file</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>sequence</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.Image">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.logger.</span></span><span class="sig-name descname"><span class="pre">Image</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataformats</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#Image"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.Image" title="Permalink to this definition"></a></dt>
<dd><p>Image data class storing an image and data format</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>Tensor</em><em> | </em><em>ndarray</em><em> | </em><em>str</em>) – image to log</p></li>
<li><p><strong>dataformats</strong> (<em>str</em>) – Image data format specification of the form NCHW, NHWC, CHW, HWC, HW, WH, etc.
More info in add_image method doc at <a class="reference external" href="https://pytorch.org/docs/stable/tensorboard.html">https://pytorch.org/docs/stable/tensorboard.html</a>
Gym envs normally use ‘HWC’ (channel last)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.JSONOutputFormat">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.logger.</span></span><span class="sig-name descname"><span class="pre">JSONOutputFormat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#JSONOutputFormat"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.JSONOutputFormat" title="Permalink to this definition"></a></dt>
<dd><p>Log to a file, in the JSON format</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>filename</strong> (<em>str</em>) – the file to write the log to</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.JSONOutputFormat.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#JSONOutputFormat.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.JSONOutputFormat.close" title="Permalink to this definition"></a></dt>
<dd><p>closes the file</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.JSONOutputFormat.write">
<span class="sig-name descname"><span class="pre">write</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key_values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key_excluded</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#JSONOutputFormat.write"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.JSONOutputFormat.write" title="Permalink to this definition"></a></dt>
<dd><p>Write a dictionary to file</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key_values</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
<li><p><strong>key_excluded</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>str</em><em>, </em><em>...</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>step</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.KVWriter">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.logger.</span></span><span class="sig-name descname"><span class="pre">KVWriter</span></span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#KVWriter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.KVWriter" title="Permalink to this definition"></a></dt>
<dd><p>Key Value writer</p>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.KVWriter.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#KVWriter.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.KVWriter.close" title="Permalink to this definition"></a></dt>
<dd><p>Close owned resources</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.KVWriter.write">
<span class="sig-name descname"><span class="pre">write</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key_values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key_excluded</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#KVWriter.write"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.KVWriter.write" title="Permalink to this definition"></a></dt>
<dd><p>Write a dictionary to file</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key_values</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
<li><p><strong>key_excluded</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>str</em><em>, </em><em>...</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>step</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.Logger">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.logger.</span></span><span class="sig-name descname"><span class="pre">Logger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">folder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_formats</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#Logger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.Logger" title="Permalink to this definition"></a></dt>
<dd><p>The logger class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>folder</strong> (<em>str</em><em> | </em><em>None</em>) – the logging location</p></li>
<li><p><strong>output_formats</strong> (<em>List</em><em>[</em><a class="reference internal" href="index.html#stable_baselines3.common.logger.KVWriter" title="stable_baselines3.common.logger.KVWriter"><em>KVWriter</em></a><em>]</em>) – the list of output formats</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.Logger.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#Logger.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.Logger.close" title="Permalink to this definition"></a></dt>
<dd><p>closes the file</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.Logger.debug">
<span class="sig-name descname"><span class="pre">debug</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#Logger.debug"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.Logger.debug" title="Permalink to this definition"></a></dt>
<dd><p>Write the sequence of args, with no separators,
to the console and output files (if you’ve configured an output file).
Using the DEBUG level.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>args</strong> – log the arguments</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.Logger.dump">
<span class="sig-name descname"><span class="pre">dump</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#Logger.dump"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.Logger.dump" title="Permalink to this definition"></a></dt>
<dd><p>Write all of the diagnostics from the current iteration</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>step</strong> (<em>int</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.Logger.error">
<span class="sig-name descname"><span class="pre">error</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#Logger.error"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.Logger.error" title="Permalink to this definition"></a></dt>
<dd><p>Write the sequence of args, with no separators,
to the console and output files (if you’ve configured an output file).
Using the ERROR level.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>args</strong> – log the arguments</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.Logger.get_dir">
<span class="sig-name descname"><span class="pre">get_dir</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#Logger.get_dir"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.Logger.get_dir" title="Permalink to this definition"></a></dt>
<dd><p>Get directory that log files are being written to.
will be None if there is no output directory (i.e., if you didn’t call start)</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>the logging directory</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>str | None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.Logger.info">
<span class="sig-name descname"><span class="pre">info</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#Logger.info"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.Logger.info" title="Permalink to this definition"></a></dt>
<dd><p>Write the sequence of args, with no separators,
to the console and output files (if you’ve configured an output file).
Using the INFO level.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>args</strong> – log the arguments</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.Logger.log">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#Logger.log"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.Logger.log" title="Permalink to this definition"></a></dt>
<dd><p>Write the sequence of args, with no separators,
to the console and output files (if you’ve configured an output file).</p>
<dl class="simple">
<dt>level: int. (see logger.py docs) If the global logger level is higher than</dt><dd><p>the level argument here, don’t print to stdout.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> – log the arguments</p></li>
<li><p><strong>level</strong> (<em>int</em>) – the logging level (can be DEBUG=10, INFO=20, WARN=30, ERROR=40, DISABLED=50)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.Logger.record">
<span class="sig-name descname"><span class="pre">record</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#Logger.record"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.Logger.record" title="Permalink to this definition"></a></dt>
<dd><p>Log a value of some diagnostic
Call this once for each diagnostic quantity, each iteration
If called many times, last value will be used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key</strong> (<em>str</em>) – save to log this key</p></li>
<li><p><strong>value</strong> (<em>Any</em>) – save to log this value</p></li>
<li><p><strong>exclude</strong> (<em>str</em><em> | </em><em>Tuple</em><em>[</em><em>str</em><em>, </em><em>...</em><em>] </em><em>| </em><em>None</em>) – outputs to be excluded</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.Logger.record_mean">
<span class="sig-name descname"><span class="pre">record_mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#Logger.record_mean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.Logger.record_mean" title="Permalink to this definition"></a></dt>
<dd><p>The same as record(), but if called many times, values averaged.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key</strong> (<em>str</em>) – save to log this key</p></li>
<li><p><strong>value</strong> (<em>float</em><em> | </em><em>None</em>) – save to log this value</p></li>
<li><p><strong>exclude</strong> (<em>str</em><em> | </em><em>Tuple</em><em>[</em><em>str</em><em>, </em><em>...</em><em>] </em><em>| </em><em>None</em>) – outputs to be excluded</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.Logger.set_level">
<span class="sig-name descname"><span class="pre">set_level</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">level</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#Logger.set_level"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.Logger.set_level" title="Permalink to this definition"></a></dt>
<dd><p>Set logging threshold on current logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>level</strong> (<em>int</em>) – the logging level (can be DEBUG=10, INFO=20, WARN=30, ERROR=40, DISABLED=50)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.Logger.to_tuple">
<em class="property"><span class="pre">static</span><span class="w">  </span></em><span class="sig-name descname"><span class="pre">to_tuple</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">string_or_tuple</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#Logger.to_tuple"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.Logger.to_tuple" title="Permalink to this definition"></a></dt>
<dd><p>Helper function to convert str to tuple of str.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>string_or_tuple</strong> (<em>str</em><em> | </em><em>Tuple</em><em>[</em><em>str</em><em>, </em><em>...</em><em>] </em><em>| </em><em>None</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tuple</em>[str, …]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.Logger.warn">
<span class="sig-name descname"><span class="pre">warn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#Logger.warn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.Logger.warn" title="Permalink to this definition"></a></dt>
<dd><p>Write the sequence of args, with no separators,
to the console and output files (if you’ve configured an output file).
Using the WARN level.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>args</strong> – log the arguments</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.SeqWriter">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.logger.</span></span><span class="sig-name descname"><span class="pre">SeqWriter</span></span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#SeqWriter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.SeqWriter" title="Permalink to this definition"></a></dt>
<dd><p>sequence writer</p>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.SeqWriter.write_sequence">
<span class="sig-name descname"><span class="pre">write_sequence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sequence</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#SeqWriter.write_sequence"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.SeqWriter.write_sequence" title="Permalink to this definition"></a></dt>
<dd><p>write_sequence an array to file</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>sequence</strong> (<em>List</em><em>[</em><em>str</em><em>]</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.TensorBoardOutputFormat">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.logger.</span></span><span class="sig-name descname"><span class="pre">TensorBoardOutputFormat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">folder</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#TensorBoardOutputFormat"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.TensorBoardOutputFormat" title="Permalink to this definition"></a></dt>
<dd><p>Dumps key/value pairs into TensorBoard’s numeric format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>folder</strong> (<em>str</em>) – the folder to write the log to</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.TensorBoardOutputFormat.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#TensorBoardOutputFormat.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.TensorBoardOutputFormat.close" title="Permalink to this definition"></a></dt>
<dd><p>closes the file</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.TensorBoardOutputFormat.write">
<span class="sig-name descname"><span class="pre">write</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key_values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key_excluded</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#TensorBoardOutputFormat.write"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.TensorBoardOutputFormat.write" title="Permalink to this definition"></a></dt>
<dd><p>Write a dictionary to file</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key_values</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – </p></li>
<li><p><strong>key_excluded</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>str</em><em>, </em><em>...</em><em>]</em><em>]</em>) – </p></li>
<li><p><strong>step</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.Video">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.logger.</span></span><span class="sig-name descname"><span class="pre">Video</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">frames</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fps</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#Video"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.Video" title="Permalink to this definition"></a></dt>
<dd><p>Video data class storing the video frames and the frame per seconds</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>frames</strong> (<em>Tensor</em>) – frames to create the video from</p></li>
<li><p><strong>fps</strong> (<em>float</em>) – frames per second</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.configure">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.logger.</span></span><span class="sig-name descname"><span class="pre">configure</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">folder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">format_strings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#configure"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.configure" title="Permalink to this definition"></a></dt>
<dd><p>Configure the current logger.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>folder</strong> (<em>str</em><em> | </em><em>None</em>) – the save location
(if None, $SB3_LOGDIR, if still None, tempdir/SB3-[date &amp; time])</p></li>
<li><p><strong>format_strings</strong> (<em>List</em><em>[</em><em>str</em><em>] </em><em>| </em><em>None</em>) – the output logging format
(if None, $SB3_LOG_FORMAT, if still None, [‘stdout’, ‘log’, ‘csv’])</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The logger object.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="index.html#stable_baselines3.common.logger.Logger" title="stable_baselines3.common.logger.Logger"><em>Logger</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.filter_excluded_keys">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.logger.</span></span><span class="sig-name descname"><span class="pre">filter_excluded_keys</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key_values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key_excluded</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_format</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#filter_excluded_keys"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.filter_excluded_keys" title="Permalink to this definition"></a></dt>
<dd><p>Filters the keys specified by <code class="docutils literal notranslate"><span class="pre">key_exclude</span></code> for the specified format</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key_values</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – log dictionary to be filtered</p></li>
<li><p><strong>key_excluded</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Tuple</em><em>[</em><em>str</em><em>, </em><em>...</em><em>]</em><em>]</em>) – keys to be excluded per format</p></li>
<li><p><strong>_format</strong> (<em>str</em>) – format for which this filter is run</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>dict without the excluded keys</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Dict</em>[str, <em>Any</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.make_output_format">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.logger.</span></span><span class="sig-name descname"><span class="pre">make_output_format</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_format</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_suffix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#make_output_format"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.make_output_format" title="Permalink to this definition"></a></dt>
<dd><p>return a logger for the requested format</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>_format</strong> (<em>str</em>) – the requested format to log to (‘stdout’, ‘log’, ‘json’ or ‘csv’ or ‘tensorboard’)</p></li>
<li><p><strong>log_dir</strong> (<em>str</em>) – the logging directory</p></li>
<li><p><strong>log_suffix</strong> (<em>str</em>) – the suffix for the log file</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the logger</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="index.html#stable_baselines3.common.logger.KVWriter" title="stable_baselines3.common.logger.KVWriter"><em>KVWriter</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.read_csv">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.logger.</span></span><span class="sig-name descname"><span class="pre">read_csv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#read_csv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.read_csv" title="Permalink to this definition"></a></dt>
<dd><p>read a csv file using pandas</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>filename</strong> (<em>str</em>) – the file path to read</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the data in the csv</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>DataFrame</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.logger.read_json">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.logger.</span></span><span class="sig-name descname"><span class="pre">read_json</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/logger.html#read_json"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.logger.read_json" title="Permalink to this definition"></a></dt>
<dd><p>read a json file using pandas</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>filename</strong> (<em>str</em>) – the file path to read</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the data in the json</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>DataFrame</em></p>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>
<span id="document-common/noise"></span><section id="module-stable_baselines3.common.noise">
<span id="action-noise"></span><span id="noise"></span><h3>Action Noise<a class="headerlink" href="#module-stable_baselines3.common.noise" title="Permalink to this heading"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.noise.ActionNoise">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.noise.</span></span><span class="sig-name descname"><span class="pre">ActionNoise</span></span><a class="reference internal" href="_modules/stable_baselines3/common/noise.html#ActionNoise"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.noise.ActionNoise" title="Permalink to this definition"></a></dt>
<dd><p>The action noise base class</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.noise.ActionNoise.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/noise.html#ActionNoise.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.noise.ActionNoise.reset" title="Permalink to this definition"></a></dt>
<dd><p>Call end of episode reset for the noise</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.noise.NormalActionNoise">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.noise.</span></span><span class="sig-name descname"><span class="pre">NormalActionNoise</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.float32'&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/noise.html#NormalActionNoise"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.noise.NormalActionNoise" title="Permalink to this definition"></a></dt>
<dd><p>A Gaussian action noise.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mean</strong> (<em>ndarray</em>) – Mean value of the noise</p></li>
<li><p><strong>sigma</strong> (<em>ndarray</em>) – Scale of the noise (std here)</p></li>
<li><p><strong>dtype</strong> (<em>dtype</em><em>[</em><em>Any</em><em>] </em><em>| </em><em>None</em><em> | </em><em>Type</em><em>[</em><em>Any</em><em>] </em><em>| </em><em>_SupportsDType</em><em>[</em><em>dtype</em><em>[</em><em>Any</em><em>]</em><em>] </em><em>| </em><em>str</em><em> | </em><em>Tuple</em><em>[</em><em>Any</em><em>, </em><em>int</em><em>] </em><em>| </em><em>Tuple</em><em>[</em><em>Any</em><em>, </em><em>SupportsIndex</em><em> | </em><em>Sequence</em><em>[</em><em>SupportsIndex</em><em>]</em><em>] </em><em>| </em><em>List</em><em>[</em><em>Any</em><em>] </em><em>| </em><em>_DTypeDict</em><em> | </em><em>Tuple</em><em>[</em><em>Any</em><em>, </em><em>Any</em><em>]</em>) – Type of the output noise</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.noise.OrnsteinUhlenbeckActionNoise">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.noise.</span></span><span class="sig-name descname"><span class="pre">OrnsteinUhlenbeckActionNoise</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">theta=0.15</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt=0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_noise=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.float32'&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/noise.html#OrnsteinUhlenbeckActionNoise"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.noise.OrnsteinUhlenbeckActionNoise" title="Permalink to this definition"></a></dt>
<dd><p>An Ornstein Uhlenbeck action noise, this is designed to approximate Brownian motion with friction.</p>
<p>Based on <a class="reference external" href="http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab">http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mean</strong> (<em>ndarray</em>) – Mean of the noise</p></li>
<li><p><strong>sigma</strong> (<em>ndarray</em>) – Scale of the noise</p></li>
<li><p><strong>theta</strong> (<em>float</em>) – Rate of mean reversion</p></li>
<li><p><strong>dt</strong> (<em>float</em>) – Timestep for the noise</p></li>
<li><p><strong>initial_noise</strong> (<em>ndarray</em><em> | </em><em>None</em>) – Initial value for the noise output, (if None: 0)</p></li>
<li><p><strong>dtype</strong> (<em>dtype</em><em>[</em><em>Any</em><em>] </em><em>| </em><em>None</em><em> | </em><em>Type</em><em>[</em><em>Any</em><em>] </em><em>| </em><em>_SupportsDType</em><em>[</em><em>dtype</em><em>[</em><em>Any</em><em>]</em><em>] </em><em>| </em><em>str</em><em> | </em><em>Tuple</em><em>[</em><em>Any</em><em>, </em><em>int</em><em>] </em><em>| </em><em>Tuple</em><em>[</em><em>Any</em><em>, </em><em>SupportsIndex</em><em> | </em><em>Sequence</em><em>[</em><em>SupportsIndex</em><em>]</em><em>] </em><em>| </em><em>List</em><em>[</em><em>Any</em><em>] </em><em>| </em><em>_DTypeDict</em><em> | </em><em>Tuple</em><em>[</em><em>Any</em><em>, </em><em>Any</em><em>]</em>) – Type of the output noise</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.noise.OrnsteinUhlenbeckActionNoise.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/noise.html#OrnsteinUhlenbeckActionNoise.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.noise.OrnsteinUhlenbeckActionNoise.reset" title="Permalink to this definition"></a></dt>
<dd><p>reset the Ornstein Uhlenbeck noise, to the initial position</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="stable_baselines3.common.noise.VectorizedActionNoise">
<em class="property"><span class="pre">class</span><span class="w">  </span></em><span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.noise.</span></span><span class="sig-name descname"><span class="pre">VectorizedActionNoise</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_noise</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_envs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/noise.html#VectorizedActionNoise"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.noise.VectorizedActionNoise" title="Permalink to this definition"></a></dt>
<dd><p>A Vectorized action noise for parallel environments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>base_noise</strong> (<a class="reference internal" href="index.html#stable_baselines3.common.noise.ActionNoise" title="stable_baselines3.common.noise.ActionNoise"><em>ActionNoise</em></a>) – Noise generator to use</p></li>
<li><p><strong>n_envs</strong> (<em>int</em>) – Number of parallel environments</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="stable_baselines3.common.noise.VectorizedActionNoise.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/noise.html#VectorizedActionNoise.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.noise.VectorizedActionNoise.reset" title="Permalink to this definition"></a></dt>
<dd><p>Reset all the noise processes, or those listed in indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>indices</strong> (<em>Iterable</em><em>[</em><em>int</em><em>] </em><em>| </em><em>None</em>) – The indices to reset. Default: None.
If the parameter is None, then all processes are reset to their initial position.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<span id="document-common/utils"></span><section id="utils">
<span id="id1"></span><h3>Utils<a class="headerlink" href="#utils" title="Permalink to this heading"></a></h3>
<span class="target" id="module-stable_baselines3.common.utils"></span><dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.check_for_correct_spaces">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">check_for_correct_spaces</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">env</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">action_space</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#check_for_correct_spaces"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.check_for_correct_spaces" title="Permalink to this definition"></a></dt>
<dd><p>Checks that the environment has same spaces as provided ones. Used by BaseAlgorithm to check if
spaces match after loading the model with given env.
Checked parameters:
- observation_space
- action_space</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>env</strong> (<em>Env</em><em> | </em><a class="reference internal" href="index.html#stable_baselines3.common.vec_env.VecEnv" title="stable_baselines3.common.vec_env.VecEnv"><em>VecEnv</em></a>) – Environment to check for valid spaces</p></li>
<li><p><strong>observation_space</strong> (<em>Space</em>) – Observation space to check against</p></li>
<li><p><strong>action_space</strong> (<em>Space</em>) – Action space to check against</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.check_shape_equal">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">check_shape_equal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">space1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">space2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#check_shape_equal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.check_shape_equal" title="Permalink to this definition"></a></dt>
<dd><p>If the spaces are Box, check that they have the same shape.</p>
<p>If the spaces are Dict, it recursively checks the subspaces.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>space1</strong> (<em>Space</em>) – Space</p></li>
<li><p><strong>space2</strong> (<em>Space</em>) – Other space</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.configure_logger">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">configure_logger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensorboard_log</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tb_log_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reset_num_timesteps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#configure_logger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.configure_logger" title="Permalink to this definition"></a></dt>
<dd><p>Configure the logger’s outputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>verbose</strong> (<em>int</em>) – Verbosity level: 0 for no output, 1 for the standard output to be part of the logger outputs</p></li>
<li><p><strong>tensorboard_log</strong> (<em>str</em><em> | </em><em>None</em>) – the log location for tensorboard (if None, no logging)</p></li>
<li><p><strong>tb_log_name</strong> (<em>str</em>) – tensorboard log</p></li>
<li><p><strong>reset_num_timesteps</strong> (<em>bool</em>) – Whether the <code class="docutils literal notranslate"><span class="pre">num_timesteps</span></code> attribute is reset or not.
It allows to continue a previous learning curve (<code class="docutils literal notranslate"><span class="pre">reset_num_timesteps=False</span></code>)
or start from t=0 (<code class="docutils literal notranslate"><span class="pre">reset_num_timesteps=True</span></code>, the default).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The logger object</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="index.html#stable_baselines3.common.logger.Logger" title="stable_baselines3.common.logger.Logger"><em>Logger</em></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.constant_fn">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">constant_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#constant_fn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.constant_fn" title="Permalink to this definition"></a></dt>
<dd><p>Create a function that returns a constant
It is useful for learning rate schedule (to avoid code duplication)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>val</strong> (<em>float</em>) – constant value</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Constant schedule function.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Callable</em>[[float], float]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.explained_variance">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">explained_variance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#explained_variance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.explained_variance" title="Permalink to this definition"></a></dt>
<dd><p>Computes fraction of variance that ypred explains about y.
Returns 1 - Var[y-ypred] / Var[y]</p>
<dl class="simple">
<dt>interpretation:</dt><dd><p>ev=0  =&gt;  might as well have predicted zero
ev=1  =&gt;  perfect prediction
ev&lt;0  =&gt;  worse than just predicting zero</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>y_pred</strong> (<em>ndarray</em>) – the prediction</p></li>
<li><p><strong>y_true</strong> (<em>ndarray</em>) – the expected value</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>explained variance of ypred and y</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>ndarray</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.get_device">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">get_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#get_device"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.get_device" title="Permalink to this definition"></a></dt>
<dd><p>Retrieve PyTorch device.
It checks that the requested device is available first.
For now, it supports only cpu and cuda.
By default, it tries to use the gpu.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> (<em>device</em><em> | </em><em>str</em>) – One for ‘auto’, ‘cuda’, ‘cpu’</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Supported Pytorch device</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>device</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.get_latest_run_id">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">get_latest_run_id</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#get_latest_run_id"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.get_latest_run_id" title="Permalink to this definition"></a></dt>
<dd><p>Returns the latest run number for the given log name and log path,
by finding the greatest number in the directories.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_path</strong> (<em>str</em>) – Path to the log folder containing several runs.</p></li>
<li><p><strong>log_name</strong> (<em>str</em>) – Name of the experiment. Each run is stored
in a folder named <code class="docutils literal notranslate"><span class="pre">log_name_1</span></code>, <code class="docutils literal notranslate"><span class="pre">log_name_2</span></code>, …</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>latest run number</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.get_linear_fn">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">get_linear_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">start</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_fraction</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#get_linear_fn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.get_linear_fn" title="Permalink to this definition"></a></dt>
<dd><p>Create a function that interpolates linearly between start and end
between <code class="docutils literal notranslate"><span class="pre">progress_remaining</span></code> = 1 and <code class="docutils literal notranslate"><span class="pre">progress_remaining</span></code> = <code class="docutils literal notranslate"><span class="pre">end_fraction</span></code>.
This is used in DQN for linearly annealing the exploration fraction
(epsilon for the epsilon-greedy strategy).</p>
<dl class="field-list simple">
<dt class="field-odd">Params start<span class="colon">:</span></dt>
<dd class="field-odd"><p>value to start with if <code class="docutils literal notranslate"><span class="pre">progress_remaining</span></code> = 1</p>
</dd>
<dt class="field-even">Params end<span class="colon">:</span></dt>
<dd class="field-even"><p>value to end with if <code class="docutils literal notranslate"><span class="pre">progress_remaining</span></code> = 0</p>
</dd>
<dt class="field-odd">Params end_fraction<span class="colon">:</span></dt>
<dd class="field-odd"><p>fraction of <code class="docutils literal notranslate"><span class="pre">progress_remaining</span></code>
where end is reached e.g 0.1 then end is reached after 10%
of the complete training process.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Linear schedule function.</p>
</dd>
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>start</strong> (<em>float</em>) – </p></li>
<li><p><strong>end</strong> (<em>float</em>) – </p></li>
<li><p><strong>end_fraction</strong> (<em>float</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Callable</em>[[float], float]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.get_parameters_by_name">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">get_parameters_by_name</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">included_names</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#get_parameters_by_name"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.get_parameters_by_name" title="Permalink to this definition"></a></dt>
<dd><p>Extract parameters from the state dict of <code class="docutils literal notranslate"><span class="pre">model</span></code>
if the name contains one of the strings in <code class="docutils literal notranslate"><span class="pre">included_names</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>Module</em>) – the model where the parameters come from.</p></li>
<li><p><strong>included_names</strong> (<em>Iterable</em><em>[</em><em>str</em><em>]</em>) – substrings of names to include.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>List of parameters values (Pytorch tensors)
that matches the queried names.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>List</em>[<em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.get_schedule_fn">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">get_schedule_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value_schedule</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#get_schedule_fn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.get_schedule_fn" title="Permalink to this definition"></a></dt>
<dd><p>Transform (if needed) learning rate and clip range (for PPO)
to callable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>value_schedule</strong> (<em>Callable</em><em>[</em><em>[</em><em>float</em><em>]</em><em>, </em><em>float</em><em>] </em><em>| </em><em>float</em>) – Constant value of schedule function</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Schedule function (can return constant value)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Callable</em>[[float], float]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.get_system_info">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">get_system_info</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">print_info</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#get_system_info"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.get_system_info" title="Permalink to this definition"></a></dt>
<dd><p>Retrieve system and python env info for the current system.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>print_info</strong> (<em>bool</em>) – Whether to print or not those infos</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary summing up the version for each relevant package
and a formatted string.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tuple</em>[<em>Dict</em>[str, str], str]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.is_vectorized_box_observation">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">is_vectorized_box_observation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#is_vectorized_box_observation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.is_vectorized_box_observation" title="Permalink to this definition"></a></dt>
<dd><p>For box observation type, detects and validates the shape,
then returns whether or not the observation is vectorized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation</strong> (<em>ndarray</em>) – the input observation to validate</p></li>
<li><p><strong>observation_space</strong> (<em>Box</em>) – the observation space</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>whether the given observation is vectorized or not</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.is_vectorized_dict_observation">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">is_vectorized_dict_observation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#is_vectorized_dict_observation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.is_vectorized_dict_observation" title="Permalink to this definition"></a></dt>
<dd><p>For dict observation type, detects and validates the shape,
then returns whether or not the observation is vectorized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation</strong> (<em>ndarray</em>) – the input observation to validate</p></li>
<li><p><strong>observation_space</strong> (<em>Dict</em>) – the observation space</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>whether the given observation is vectorized or not</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.is_vectorized_discrete_observation">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">is_vectorized_discrete_observation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#is_vectorized_discrete_observation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.is_vectorized_discrete_observation" title="Permalink to this definition"></a></dt>
<dd><p>For discrete observation type, detects and validates the shape,
then returns whether or not the observation is vectorized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation</strong> (<em>int</em><em> | </em><em>ndarray</em>) – the input observation to validate</p></li>
<li><p><strong>observation_space</strong> (<em>Discrete</em>) – the observation space</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>whether the given observation is vectorized or not</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.is_vectorized_multibinary_observation">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">is_vectorized_multibinary_observation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#is_vectorized_multibinary_observation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.is_vectorized_multibinary_observation" title="Permalink to this definition"></a></dt>
<dd><p>For multibinary observation type, detects and validates the shape,
then returns whether or not the observation is vectorized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation</strong> (<em>ndarray</em>) – the input observation to validate</p></li>
<li><p><strong>observation_space</strong> (<em>MultiBinary</em>) – the observation space</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>whether the given observation is vectorized or not</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.is_vectorized_multidiscrete_observation">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">is_vectorized_multidiscrete_observation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#is_vectorized_multidiscrete_observation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.is_vectorized_multidiscrete_observation" title="Permalink to this definition"></a></dt>
<dd><p>For multidiscrete observation type, detects and validates the shape,
then returns whether or not the observation is vectorized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation</strong> (<em>ndarray</em>) – the input observation to validate</p></li>
<li><p><strong>observation_space</strong> (<em>MultiDiscrete</em>) – the observation space</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>whether the given observation is vectorized or not</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.is_vectorized_observation">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">is_vectorized_observation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observation_space</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#is_vectorized_observation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.is_vectorized_observation" title="Permalink to this definition"></a></dt>
<dd><p>For every observation type, detects and validates the shape,
then returns whether or not the observation is vectorized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observation</strong> (<em>int</em><em> | </em><em>ndarray</em>) – the input observation to validate</p></li>
<li><p><strong>observation_space</strong> (<em>Space</em>) – the observation space</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>whether the given observation is vectorized or not</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.obs_as_tensor">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">obs_as_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#obs_as_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.obs_as_tensor" title="Permalink to this definition"></a></dt>
<dd><p>Moves the observation to the given device.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>obs</strong> (<em>ndarray</em><em> | </em><em>Dict</em><em>[</em><em>str</em><em>, </em><em>ndarray</em><em>]</em>) – </p></li>
<li><p><strong>device</strong> (<em>device</em>) – PyTorch device</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>PyTorch tensor of the observation on a desired device.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em> | <em>Dict</em>[str, <em>Tensor</em>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.polyak_update">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">polyak_update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#polyak_update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.polyak_update" title="Permalink to this definition"></a></dt>
<dd><p>Perform a Polyak average update on <code class="docutils literal notranslate"><span class="pre">target_params</span></code> using <code class="docutils literal notranslate"><span class="pre">params</span></code>:
target parameters are slowly updated towards the main parameters.
<code class="docutils literal notranslate"><span class="pre">tau</span></code>, the soft update coefficient controls the interpolation:
<code class="docutils literal notranslate"><span class="pre">tau=1</span></code> corresponds to copying the parameters to the target ones whereas nothing happens when <code class="docutils literal notranslate"><span class="pre">tau=0</span></code>.
The Polyak update is done in place, with <code class="docutils literal notranslate"><span class="pre">no_grad</span></code>, and therefore does not create intermediate tensors,
or a computation graph, reducing memory cost and improving performance.  We scale the target params
by <code class="docutils literal notranslate"><span class="pre">1-tau</span></code> (in-place), add the new weights, scaled by <code class="docutils literal notranslate"><span class="pre">tau</span></code> and store the result of the sum in the target
params (in place).
See <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/93">https://github.com/DLR-RM/stable-baselines3/issues/93</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> (<em>Iterable</em><em>[</em><em>Tensor</em><em>]</em>) – parameters to use to update the target params</p></li>
<li><p><strong>target_params</strong> (<em>Iterable</em><em>[</em><em>Tensor</em><em>]</em>) – parameters to update</p></li>
<li><p><strong>tau</strong> (<em>float</em>) – the soft update coefficient (“Polyak update”, between 0 and 1)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.safe_mean">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">safe_mean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arr</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#safe_mean"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.safe_mean" title="Permalink to this definition"></a></dt>
<dd><p>Compute the mean of an array if there is at least one element.
For empty array, return NaN. It is used for logging only.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>arr</strong> (<em>ndarray</em><em> | </em><em>list</em><em> | </em><em>deque</em>) – Numpy array or list of values</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.set_random_seed">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">set_random_seed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">using_cuda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#set_random_seed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.set_random_seed" title="Permalink to this definition"></a></dt>
<dd><p>Seed the different random generators.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seed</strong> (<em>int</em>) – </p></li>
<li><p><strong>using_cuda</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.should_collect_more_steps">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">should_collect_more_steps</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_freq</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_collected_steps</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_collected_episodes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#should_collect_more_steps"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.should_collect_more_steps" title="Permalink to this definition"></a></dt>
<dd><p>Helper used in <code class="docutils literal notranslate"><span class="pre">collect_rollouts()</span></code> of off-policy algorithms
to determine the termination condition.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_freq</strong> (<em>TrainFreq</em>) – How much experience should be collected before updating the policy.</p></li>
<li><p><strong>num_collected_steps</strong> (<em>int</em>) – The number of already collected steps.</p></li>
<li><p><strong>num_collected_episodes</strong> (<em>int</em>) – The number of already collected episodes.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Whether to continue or not collecting experience
by doing rollouts of the current policy.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.update_learning_rate">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">update_learning_rate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#update_learning_rate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.update_learning_rate" title="Permalink to this definition"></a></dt>
<dd><p>Update the learning rate for a given optimizer.
Useful when doing linear schedule.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<em>Optimizer</em>) – Pytorch optimizer</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em>) – New learning rate value</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="stable_baselines3.common.utils.zip_strict">
<span class="sig-prename descclassname"><span class="pre">stable_baselines3.common.utils.</span></span><span class="sig-name descname"><span class="pre">zip_strict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">iterables</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/stable_baselines3/common/utils.html#zip_strict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#stable_baselines3.common.utils.zip_strict" title="Permalink to this definition"></a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">zip()</span></code> function but enforces that iterables are of equal length.
Raises <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> if iterables not of equal length.
Code inspired by Stackoverflow answer for question #32954486.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>*iterables</strong> (<em>Iterable</em>) – iterables to <code class="docutils literal notranslate"><span class="pre">zip()</span></code></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Iterable</em></p>
</dd>
</dl>
</dd></dl>

</section>
</div>
<div class="toctree-wrapper compound">
<span id="document-misc/changelog"></span><section id="changelog">
<span id="id1"></span><h3>Changelog<a class="headerlink" href="#changelog" title="Permalink to this heading"></a></h3>
<section id="release-2-2-1-2023-11-17">
<h4>Release 2.2.1 (2023-11-17)<a class="headerlink" href="#release-2-2-1-2023-11-17" title="Permalink to this heading"></a></h4>
<p><strong>Support for options at reset, bug fixes and better error messages</strong></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>SB3 v2.2.0 was yanked after a breaking change was found in <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/1751">GH#1751</a>.
Please use SB3 v2.2.1 and not v2.2.0.</p>
</div>
<section id="breaking-changes">
<h5>Breaking Changes:<a class="headerlink" href="#breaking-changes" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Switched to <code class="docutils literal notranslate"><span class="pre">ruff</span></code> for sorting imports (isort is no longer needed), black and ruff version now require a minimum version</p></li>
<li><p>Dropped <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">is</span> <span class="pre">False</span></code> in favor of <code class="docutils literal notranslate"><span class="pre">not</span> <span class="pre">x</span></code>, which means that callbacks that wrongly returned None (instead of a boolean) will cause the training to stop (&#64;iwishiwasaneagle)</p></li>
</ul>
</section>
<section id="new-features">
<h5>New Features:<a class="headerlink" href="#new-features" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Improved error message of the <code class="docutils literal notranslate"><span class="pre">env_checker</span></code> for env wrongly detected as GoalEnv (<code class="docutils literal notranslate"><span class="pre">compute_reward()</span></code> is defined)</p></li>
<li><p>Improved error message when mixing Gym API with VecEnv API (see GH#1694)</p></li>
<li><p>Add support for setting <code class="docutils literal notranslate"><span class="pre">options</span></code> at reset with VecEnv via the <code class="docutils literal notranslate"><span class="pre">set_options()</span></code> method. Same as seeds logic, options are reset at the end of an episode (&#64;ReHoss)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">rollout_buffer_class</span></code> and <code class="docutils literal notranslate"><span class="pre">rollout_buffer_kwargs</span></code> arguments to on-policy algorithms (A2C and PPO)</p></li>
</ul>
</section>
<section id="bug-fixes">
<h5>Bug Fixes:<a class="headerlink" href="#bug-fixes" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Prevents using squash_output and not use_sde in ActorCritcPolicy (&#64;PatrickHelm)</p></li>
<li><p>Performs unscaling of actions in collect_rollout in OnPolicyAlgorithm (&#64;PatrickHelm)</p></li>
<li><p>Moves VectorizedActionNoise into <code class="docutils literal notranslate"><span class="pre">_setup_learn()</span></code> in OffPolicyAlgorithm (&#64;PatrickHelm)</p></li>
<li><p>Prevents out of bound error on Windows if no seed is passed (&#64;PatrickHelm)</p></li>
<li><p>Calls <code class="docutils literal notranslate"><span class="pre">callback.update_locals()</span></code> before <code class="docutils literal notranslate"><span class="pre">callback.on_rollout_end()</span></code> in OnPolicyAlgorithm (&#64;PatrickHelm)</p></li>
<li><p>Fixed replay buffer device after loading in OffPolicyAlgorithm (&#64;PatrickHelm)</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">render_mode</span></code> which was not properly loaded when using <code class="docutils literal notranslate"><span class="pre">VecNormalize.load()</span></code></p></li>
<li><p>Fixed success reward dtype in <code class="docutils literal notranslate"><span class="pre">SimpleMultiObsEnv</span></code> (&#64;NixGD)</p></li>
<li><p>Fixed check_env for Sequence observation space (&#64;corentinlger)</p></li>
<li><p>Prevents instantiating BitFlippingEnv with conflicting observation spaces (&#64;kylesayrs)</p></li>
<li><p>Fixed ResourceWarning when loading and saving models (files were not closed), please note that only path are closed automatically,
the behavior stay the same for tempfiles (they need to be closed manually),
the behavior is now consistent when loading/saving replay buffer</p></li>
</ul>
</section>
<section id="sb3-contrib">
<h5><a class="reference external" href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib">SB3-Contrib</a><a class="headerlink" href="#sb3-contrib" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added <code class="docutils literal notranslate"><span class="pre">set_options</span></code> for <code class="docutils literal notranslate"><span class="pre">AsyncEval</span></code></p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">rollout_buffer_class</span></code> and <code class="docutils literal notranslate"><span class="pre">rollout_buffer_kwargs</span></code> arguments to TRPO</p></li>
</ul>
</section>
<section id="rl-zoo">
<h5><a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">RL Zoo</a><a class="headerlink" href="#rl-zoo" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Removed <cite>gym</cite> dependency, the package is still required for some pretrained agents.</p></li>
<li><p>Added <cite>–eval-env-kwargs</cite> to <cite>train.py</cite> (&#64;Quentin18)</p></li>
<li><p>Added <cite>ppo_lstm</cite> to hyperparams_opt.py (&#64;technocrat13)</p></li>
<li><p>Upgraded to <cite>pybullet_envs_gymnasium&gt;=0.4.0</cite></p></li>
<li><p>Removed old hacks (for instance limiting offpolicy algorithms to one env at test time)</p></li>
<li><p>Updated docker image, removed support for X server</p></li>
<li><p>Replaced deprecated <cite>optuna.suggest_uniform(…)</cite> by <cite>optuna.suggest_float(…, low=…, high=…)</cite></p></li>
</ul>
</section>
<section id="sbx-sb3-jax">
<h5><a class="reference external" href="https://github.com/araffin/sbx">SBX</a> (SB3 + Jax)<a class="headerlink" href="#sbx-sb3-jax" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added <code class="docutils literal notranslate"><span class="pre">DDPG</span></code> and <code class="docutils literal notranslate"><span class="pre">TD3</span></code> algorithms</p></li>
</ul>
</section>
<section id="deprecations">
<h5>Deprecations:<a class="headerlink" href="#deprecations" title="Permalink to this heading"></a></h5>
</section>
<section id="others">
<h5>Others:<a class="headerlink" href="#others" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/callbacks.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/utils.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/vec_envs/vec_transpose.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/vec_env/vec_video_recorder.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/save_util.py</span></code> type hints</p></li>
<li><p>Updated docker images to  Ubuntu Jammy using micromamba 1.5</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/buffers.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/her/her_replay_buffer.py</span></code> type hints</p></li>
<li><p>Buffers do no call an additional <code class="docutils literal notranslate"><span class="pre">.copy()</span></code> when storing new transitions</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">ActorCriticPolicy.extract_features()</span></code> signature by adding an optional <code class="docutils literal notranslate"><span class="pre">features_extractor</span></code> argument</p></li>
<li><p>Update dependencies (accept newer Shimmy/Sphinx version and remove <code class="docutils literal notranslate"><span class="pre">sphinx_autodoc_typehints</span></code>)</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/off_policy_algorithm.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/distributions.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/vec_env/vec_normalize.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/vec_env/__init__.py</span></code> type hints</p></li>
<li><p>Switched to PyTorch 2.1.0 in the CI (fixes type annotations)</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/policies.py</span></code> type hints</p></li>
<li><p>Switched to <code class="docutils literal notranslate"><span class="pre">mypy</span></code> only for checking types</p></li>
<li><p>Added tests to check consistency when saving/loading files</p></li>
</ul>
</section>
<section id="documentation">
<h5>Documentation:<a class="headerlink" href="#documentation" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Updated RL Tips and Tricks (include recommendation for evaluation, added links to DroQ, ARS and SBX).</p></li>
<li><p>Fixed various typos and grammar mistakes</p></li>
<li><p>Added PokemonRedExperiments to the project page</p></li>
<li><p>Fixed an out-of-date command for installing Atari in examples</p></li>
</ul>
</section>
</section>
<section id="release-2-1-0-2023-08-17">
<h4>Release 2.1.0 (2023-08-17)<a class="headerlink" href="#release-2-1-0-2023-08-17" title="Permalink to this heading"></a></h4>
<p><strong>Float64 actions , Gymnasium 0.29 support and bug fixes</strong></p>
<section id="id2">
<h5>Breaking Changes:<a class="headerlink" href="#id2" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Removed Python 3.7 support</p></li>
<li><p>SB3 now requires PyTorch &gt;= 1.13</p></li>
</ul>
</section>
<section id="id3">
<h5>New Features:<a class="headerlink" href="#id3" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added Python 3.11 support</p></li>
<li><p>Added Gymnasium 0.29 support (&#64;pseudo-rnd-thoughts)</p></li>
</ul>
</section>
<section id="id4">
<h5><a class="reference external" href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib">SB3-Contrib</a><a class="headerlink" href="#id4" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed MaskablePPO ignoring <code class="docutils literal notranslate"><span class="pre">stats_window_size</span></code> argument</p></li>
<li><p>Added Python 3.11 support</p></li>
</ul>
</section>
<section id="id5">
<h5><a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">RL Zoo</a><a class="headerlink" href="#id5" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Upgraded to Huggingface-SB3 &gt;= 2.3</p></li>
<li><p>Added Python 3.11 support</p></li>
</ul>
</section>
<section id="id6">
<h5>Bug Fixes:<a class="headerlink" href="#id6" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Relaxed check in logger, that was causing issue on Windows with colorama</p></li>
<li><p>Fixed off-policy algorithms with continuous float64 actions (see #1145) (&#64;tobirohrer)</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">env_checker.py</span></code> warning messages for out of bounds in complex observation spaces (&#64;Gabo-Tor)</p></li>
</ul>
</section>
<section id="id7">
<h5>Deprecations:<a class="headerlink" href="#id7" title="Permalink to this heading"></a></h5>
</section>
<section id="id8">
<h5>Others:<a class="headerlink" href="#id8" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Updated GitHub issue templates</p></li>
<li><p>Fix typo in gym patch error message (&#64;lukashass)</p></li>
<li><p>Refactor <code class="docutils literal notranslate"><span class="pre">test_spaces.py</span></code> tests</p></li>
</ul>
</section>
<section id="id9">
<h5>Documentation:<a class="headerlink" href="#id9" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed callback example (&#64;BertrandDecoster)</p></li>
<li><p>Fixed policy network example (&#64;kyle-he)</p></li>
<li><p>Added mobile-env as new community project (&#64;stefanbschneider)</p></li>
<li><p>Added [DeepNetSlice](<a class="reference external" href="https://github.com/AlexPasqua/DeepNetSlice">https://github.com/AlexPasqua/DeepNetSlice</a>) to community projects (&#64;AlexPasqua)</p></li>
</ul>
</section>
</section>
<section id="release-2-0-0-2023-06-22">
<h4>Release 2.0.0 (2023-06-22)<a class="headerlink" href="#release-2-0-0-2023-06-22" title="Permalink to this heading"></a></h4>
<p><strong>Gymnasium support</strong></p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Stable-Baselines3 (SB3) v2.0 will be the last one supporting python 3.7 (end of life in June 2023).
We highly recommended you to upgrade to Python &gt;= 3.8.</p>
</div>
<section id="id10">
<h5>Breaking Changes:<a class="headerlink" href="#id10" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Switched to Gymnasium as primary backend, Gym 0.21 and 0.26 are still supported via the <code class="docutils literal notranslate"><span class="pre">shimmy</span></code> package (&#64;carlosluis, &#64;arjun-kg, &#64;tlpss)</p></li>
<li><p>The deprecated <code class="docutils literal notranslate"><span class="pre">online_sampling</span></code> argument of <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code> was removed</p></li>
<li><p>Removed deprecated <code class="docutils literal notranslate"><span class="pre">stack_observation_space</span></code> method of <code class="docutils literal notranslate"><span class="pre">StackedObservations</span></code></p></li>
<li><p>Renamed environment output observations in <code class="docutils literal notranslate"><span class="pre">evaluate_policy</span></code> to prevent shadowing the input observations during callbacks (&#64;npit)</p></li>
<li><p>Upgraded wrappers and custom environment to Gymnasium</p></li>
<li><p>Refined the <code class="docutils literal notranslate"><span class="pre">HumanOutputFormat</span></code> file check: now it verifies if the object is an instance of <code class="docutils literal notranslate"><span class="pre">io.TextIOBase</span></code> instead of only checking for the presence of a <code class="docutils literal notranslate"><span class="pre">write</span></code> method.</p></li>
<li><p>Because of new Gym API (0.26+), the random seed passed to <code class="docutils literal notranslate"><span class="pre">vec_env.seed(seed=seed)</span></code> will only be effective after then <code class="docutils literal notranslate"><span class="pre">env.reset()</span></code> call.</p></li>
</ul>
</section>
<section id="id11">
<h5>New Features:<a class="headerlink" href="#id11" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added Gymnasium support (Gym 0.21 and 0.26 are supported via the <code class="docutils literal notranslate"><span class="pre">shimmy</span></code> package)</p></li>
</ul>
</section>
<section id="id12">
<h5><a class="reference external" href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib">SB3-Contrib</a><a class="headerlink" href="#id12" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed QRDQN update interval for multi envs</p></li>
</ul>
</section>
<section id="id13">
<h5><a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">RL Zoo</a><a class="headerlink" href="#id13" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Gym 0.26+ patches to continue working with pybullet and TimeLimit wrapper</p></li>
<li><p>Renamed <cite>CarRacing-v1</cite> to <cite>CarRacing-v2</cite> in hyperparameters</p></li>
<li><p>Huggingface push to hub now accepts a <cite>–n-timesteps</cite> argument to adjust the length of the video</p></li>
<li><p>Fixed <cite>record_video</cite> steps (before it was stepping in a closed env)</p></li>
<li><p>Dropped Gym 0.21 support</p></li>
</ul>
</section>
<section id="id14">
<h5>Bug Fixes:<a class="headerlink" href="#id14" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">VecExtractDictObs</span></code> does not handle terminal observation (&#64;WeberSamuel)</p></li>
<li><p>Set NumPy version to <code class="docutils literal notranslate"><span class="pre">&gt;=1.20</span></code> due to use of <code class="docutils literal notranslate"><span class="pre">numpy.typing</span></code> (&#64;troiganto)</p></li>
<li><p>Fixed loading DQN changes <code class="docutils literal notranslate"><span class="pre">target_update_interval</span></code> (&#64;tobirohrer)</p></li>
<li><p>Fixed env checker to properly reset the env before calling <code class="docutils literal notranslate"><span class="pre">step()</span></code> when checking
for <code class="docutils literal notranslate"><span class="pre">Inf</span></code> and <code class="docutils literal notranslate"><span class="pre">NaN</span></code> (&#64;lutogniew)</p></li>
<li><p>Fixed HER <code class="docutils literal notranslate"><span class="pre">truncate_last_trajectory()</span></code> (&#64;lbergmann1)</p></li>
<li><p>Fixed HER desired and achieved goal order in reward computation (&#64;JonathanKuelz)</p></li>
</ul>
</section>
<section id="id15">
<h5>Deprecations:<a class="headerlink" href="#id15" title="Permalink to this heading"></a></h5>
</section>
<section id="id16">
<h5>Others:<a class="headerlink" href="#id16" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/a2c/*.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/ppo/*.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/sac/*.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/td3/*.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/base_class.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/logger.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/envs/*.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/vec_env/vec_monitor|vec_extract_dict_obs|util.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/vec_env/base_vec_env.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/vec_env/vec_frame_stack.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/vec_env/dummy_vec_env.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/vec_env/subproc_vec_env.py</span></code> type hints</p></li>
<li><p>Upgraded docker images to use mamba/micromamba and CUDA 11.7</p></li>
<li><p>Updated env checker to reflect what subset of Gymnasium is supported and improve GoalEnv checks</p></li>
<li><p>Improve type annotation of wrappers</p></li>
<li><p>Tests envs are now checked too</p></li>
<li><p>Added render test for <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code> and <code class="docutils literal notranslate"><span class="pre">VecEnvWrapper</span></code></p></li>
<li><p>Update issue templates and env info saved with the model</p></li>
<li><p>Changed <code class="docutils literal notranslate"><span class="pre">seed()</span></code> method return type from <code class="docutils literal notranslate"><span class="pre">List</span></code> to <code class="docutils literal notranslate"><span class="pre">Sequence</span></code></p></li>
<li><p>Updated env checker doc and requirements for tuple spaces/goal envs</p></li>
</ul>
</section>
<section id="id17">
<h5>Documentation:<a class="headerlink" href="#id17" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added Deep RL Course link to the Deep RL Resources page</p></li>
<li><p>Added documentation about <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code> API vs Gym API</p></li>
<li><p>Upgraded tutorials to Gymnasium API</p></li>
<li><p>Make it more explicit when using <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code> vs Gym env</p></li>
<li><p>Added UAV_Navigation_DRL_AirSim to the project page (&#64;heleidsn)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">EvalCallback</span></code> example (&#64;sidney-tio)</p></li>
<li><p>Update custom env documentation</p></li>
<li><p>Added <cite>pink-noise-rl</cite> to projects page</p></li>
<li><p>Fix custom policy example, <code class="docutils literal notranslate"><span class="pre">ortho_init</span></code> was ignored</p></li>
<li><p>Added SBX page</p></li>
</ul>
</section>
</section>
<section id="release-1-8-0-2023-04-07">
<h4>Release 1.8.0 (2023-04-07)<a class="headerlink" href="#release-1-8-0-2023-04-07" title="Permalink to this heading"></a></h4>
<p><strong>Multi-env HerReplayBuffer, Open RL Benchmark, Improved env checker</strong></p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Stable-Baselines3 (SB3) v1.8.0 will be the last one to use Gym as a backend.
Starting with v2.0.0, Gymnasium will be the default backend (though SB3 will have compatibility layers for Gym envs).
You can find a migration guide here: <a class="reference external" href="https://gymnasium.farama.org/content/migration-guide/">https://gymnasium.farama.org/content/migration-guide/</a>.
If you want to try the SB3 v2.0 alpha version, you can take a look at <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/pull/1327">PR #1327</a>.</p>
</div>
<section id="id18">
<h5>Breaking Changes:<a class="headerlink" href="#id18" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Removed shared layers in <code class="docutils literal notranslate"><span class="pre">mlp_extractor</span></code> (&#64;AlexPasqua)</p></li>
<li><p>Refactored <code class="docutils literal notranslate"><span class="pre">StackedObservations</span></code> (it now handles dict obs, <code class="docutils literal notranslate"><span class="pre">StackedDictObservations</span></code> was removed)</p></li>
<li><p>You must now explicitely pass a <code class="docutils literal notranslate"><span class="pre">features_extractor</span></code> parameter when calling <code class="docutils literal notranslate"><span class="pre">extract_features()</span></code></p></li>
<li><p>Dropped offline sampling for <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code></p></li>
<li><p>As <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code> was refactored to support multiprocessing, previous replay buffer are incompatible with this new version</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code> doesn’t require a <code class="docutils literal notranslate"><span class="pre">max_episode_length</span></code> anymore</p></li>
</ul>
</section>
<section id="id19">
<h5>New Features:<a class="headerlink" href="#id19" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added <code class="docutils literal notranslate"><span class="pre">repeat_action_probability</span></code> argument in <code class="docutils literal notranslate"><span class="pre">AtariWrapper</span></code>.</p></li>
<li><p>Only use <code class="docutils literal notranslate"><span class="pre">NoopResetEnv</span></code> and <code class="docutils literal notranslate"><span class="pre">MaxAndSkipEnv</span></code> when needed in <code class="docutils literal notranslate"><span class="pre">AtariWrapper</span></code></p></li>
<li><p>Added support for dict/tuple observations spaces for <code class="docutils literal notranslate"><span class="pre">VecCheckNan</span></code>, the check is now active in the <code class="docutils literal notranslate"><span class="pre">env_checker()</span></code> (&#64;DavyMorgan)</p></li>
<li><p>Added multiprocessing support for <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code> now supports all datatypes supported by <code class="docutils literal notranslate"><span class="pre">ReplayBuffer</span></code></p></li>
<li><p>Provide more helpful failure messages when validating the <code class="docutils literal notranslate"><span class="pre">observation_space</span></code> of custom gym environments using <code class="docutils literal notranslate"><span class="pre">check_env</span></code> (&#64;FieteO)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">stats_window_size</span></code> argument to control smoothing in rollout logging (&#64;jonasreiher)</p></li>
</ul>
</section>
<section id="id20">
<h5><a class="reference external" href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib">SB3-Contrib</a><a class="headerlink" href="#id20" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added warning about potential crashes caused by <code class="docutils literal notranslate"><span class="pre">check_env</span></code> in the <code class="docutils literal notranslate"><span class="pre">MaskablePPO</span></code> docs (&#64;AlexPasqua)</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">sb3_contrib/qrdqn/*.py</span></code> type hints</p></li>
<li><p>Removed shared layers in <code class="docutils literal notranslate"><span class="pre">mlp_extractor</span></code> (&#64;AlexPasqua)</p></li>
</ul>
</section>
<section id="id21">
<h5><a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">RL Zoo</a><a class="headerlink" href="#id21" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/openrlbenchmark/openrlbenchmark/issues/7">Open RL Benchmark</a></p></li>
<li><p>Upgraded to new <cite>HerReplayBuffer</cite> implementation that supports multiple envs</p></li>
<li><p>Removed <cite>TimeFeatureWrapper</cite> for Panda and Fetch envs, as the new replay buffer should handle timeout.</p></li>
<li><p>Tuned hyperparameters for RecurrentPPO on Swimmer</p></li>
<li><p>Documentation is now built using Sphinx and hosted on read the doc</p></li>
<li><p>Removed <cite>use_auth_token</cite> for push to hub util</p></li>
<li><p>Reverted from v3 to v2 for HumanoidStandup, Reacher, InvertedPendulum and InvertedDoublePendulum since they were not part of the mujoco refactoring (see <a class="reference external" href="https://github.com/openai/gym/pull/1304">https://github.com/openai/gym/pull/1304</a>)</p></li>
<li><p>Fixed <cite>gym-minigrid</cite> policy (from <cite>MlpPolicy</cite> to <cite>MultiInputPolicy</cite>)</p></li>
<li><p>Replaced deprecated <cite>optuna.suggest_loguniform(…)</cite> by <cite>optuna.suggest_float(…, log=True)</cite></p></li>
<li><p>Switched to <cite>ruff</cite> and <cite>pyproject.toml</cite></p></li>
<li><p>Removed <cite>online_sampling</cite> and <cite>max_episode_length</cite> argument when using <cite>HerReplayBuffer</cite></p></li>
</ul>
</section>
<section id="id22">
<h5>Bug Fixes:<a class="headerlink" href="#id22" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed Atari wrapper that missed the reset condition (&#64;luizapozzobon)</p></li>
<li><p>Added the argument <code class="docutils literal notranslate"><span class="pre">dtype</span></code> (default to <code class="docutils literal notranslate"><span class="pre">float32</span></code>) to the noise for consistency with gym action (&#64;sidney-tio)</p></li>
<li><p>Fixed PPO train/n_updates metric not accounting for early stopping (&#64;adamfrly)</p></li>
<li><p>Fixed loading of normalized image-based environments</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">DictRolloutBuffer.add</span></code> with multidimensional action space (&#64;younik)</p></li>
</ul>
</section>
<section id="id23">
<h5>Deprecations:<a class="headerlink" href="#id23" title="Permalink to this heading"></a></h5>
</section>
<section id="id24">
<h5>Others:<a class="headerlink" href="#id24" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">tests/test_tensorboard.py</span></code> type hint</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">tests/test_vec_normalize.py</span></code> type hint</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/monitor.py</span></code> type hint</p></li>
<li><p>Added tests for StackedObservations</p></li>
<li><p>Removed Gitlab CI file</p></li>
<li><p>Moved from <code class="docutils literal notranslate"><span class="pre">setup.cg</span></code> to <code class="docutils literal notranslate"><span class="pre">pyproject.toml</span></code> configuration file</p></li>
<li><p>Switched from <code class="docutils literal notranslate"><span class="pre">flake8</span></code> to <code class="docutils literal notranslate"><span class="pre">ruff</span></code></p></li>
<li><p>Upgraded AutoROM to latest version</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/dqn/*.py</span></code> type hints</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">extra_no_roms</span></code> option for package installation without Atari Roms</p></li>
</ul>
</section>
<section id="id25">
<h5>Documentation:<a class="headerlink" href="#id25" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Renamed <code class="docutils literal notranslate"><span class="pre">load_parameters</span></code> to <code class="docutils literal notranslate"><span class="pre">set_parameters</span></code> (&#64;DavyMorgan)</p></li>
<li><p>Clarified documentation about subproc multiprocessing for A2C (&#64;Bonifatius94)</p></li>
<li><p>Fixed typo in <code class="docutils literal notranslate"><span class="pre">A2C</span></code> docstring (&#64;AlexPasqua)</p></li>
<li><p>Renamed timesteps to episodes for <code class="docutils literal notranslate"><span class="pre">log_interval</span></code> description (&#64;theSquaredError)</p></li>
<li><p>Removed note about gif creation for Atari games (&#64;harveybellini)</p></li>
<li><p>Added information about default network architecture</p></li>
<li><p>Update information about Gymnasium support</p></li>
</ul>
</section>
</section>
<section id="release-1-7-0-2023-01-10">
<h4>Release 1.7.0 (2023-01-10)<a class="headerlink" href="#release-1-7-0-2023-01-10" title="Permalink to this heading"></a></h4>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Shared layers in MLP policy (<code class="docutils literal notranslate"><span class="pre">mlp_extractor</span></code>) are now deprecated for PPO, A2C and TRPO.
This feature will be removed in SB3 v1.8.0 and the behavior of <code class="docutils literal notranslate"><span class="pre">net_arch=[64,</span> <span class="pre">64]</span></code>
will create <strong>separate</strong> networks with the same architecture, to be consistent with the off-policy algorithms.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A2C and PPO saved with SB3 &lt; 1.7.0 will show a warning about
missing keys in the state dict when loaded with SB3 &gt;= 1.7.0.
To suppress the warning, simply save the model again.
You can find more info in <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues/1233">issue #1233</a></p>
</div>
<section id="id26">
<h5>Breaking Changes:<a class="headerlink" href="#id26" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Removed deprecated <code class="docutils literal notranslate"><span class="pre">create_eval_env</span></code>, <code class="docutils literal notranslate"><span class="pre">eval_env</span></code>, <code class="docutils literal notranslate"><span class="pre">eval_log_path</span></code>, <code class="docutils literal notranslate"><span class="pre">n_eval_episodes</span></code> and <code class="docutils literal notranslate"><span class="pre">eval_freq</span></code> parameters,
please use an <code class="docutils literal notranslate"><span class="pre">EvalCallback</span></code> instead</p></li>
<li><p>Removed deprecated <code class="docutils literal notranslate"><span class="pre">sde_net_arch</span></code> parameter</p></li>
<li><p>Removed <code class="docutils literal notranslate"><span class="pre">ret</span></code> attributes in <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code>, please use <code class="docutils literal notranslate"><span class="pre">returns</span></code> instead</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> now updates the observation space when normalizing images</p></li>
</ul>
</section>
<section id="id27">
<h5>New Features:<a class="headerlink" href="#id27" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Introduced mypy type checking</p></li>
<li><p>Added option to have non-shared features extractor between actor and critic in on-policy algorithms (&#64;AlexPasqua)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">with_bias</span></code> argument to <code class="docutils literal notranslate"><span class="pre">create_mlp</span></code></p></li>
<li><p>Added support for multidimensional <code class="docutils literal notranslate"><span class="pre">spaces.MultiBinary</span></code> observations</p></li>
<li><p>Features extractors now properly support unnormalized image-like observations (3D tensor)
when passing <code class="docutils literal notranslate"><span class="pre">normalize_images=False</span></code></p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">normalized_image</span></code> parameter to <code class="docutils literal notranslate"><span class="pre">NatureCNN</span></code> and <code class="docutils literal notranslate"><span class="pre">CombinedExtractor</span></code></p></li>
<li><p>Added support for Python 3.10</p></li>
</ul>
</section>
<section id="id28">
<h5><a class="reference external" href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib">SB3-Contrib</a><a class="headerlink" href="#id28" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed a bug in <code class="docutils literal notranslate"><span class="pre">RecurrentPPO</span></code> where the lstm states where incorrectly reshaped for <code class="docutils literal notranslate"><span class="pre">n_lstm_layers</span> <span class="pre">&gt;</span> <span class="pre">1</span></code> (thanks &#64;kolbytn)</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">RuntimeError:</span> <span class="pre">rnn:</span> <span class="pre">hx</span> <span class="pre">is</span> <span class="pre">not</span> <span class="pre">contiguous</span></code> while predicting terminal values for <code class="docutils literal notranslate"><span class="pre">RecurrentPPO</span></code> when <code class="docutils literal notranslate"><span class="pre">n_lstm_layers</span> <span class="pre">&gt;</span> <span class="pre">1</span></code></p></li>
</ul>
</section>
<section id="id29">
<h5><a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">RL Zoo</a><a class="headerlink" href="#id29" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added support for python file for configuration</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">monitor_kwargs</span></code> parameter</p></li>
</ul>
</section>
<section id="id30">
<h5>Bug Fixes:<a class="headerlink" href="#id30" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">ProgressBarCallback</span></code> under-reporting (&#64;dominicgkerr)</p></li>
<li><p>Fixed return type of <code class="docutils literal notranslate"><span class="pre">evaluate_actions</span></code> in <code class="docutils literal notranslate"><span class="pre">ActorCritcPolicy</span></code> to reflect that entropy is an optional tensor (&#64;Rocamonde)</p></li>
<li><p>Fixed type annotation of <code class="docutils literal notranslate"><span class="pre">policy</span></code> in <code class="docutils literal notranslate"><span class="pre">BaseAlgorithm</span></code> and <code class="docutils literal notranslate"><span class="pre">OffPolicyAlgorithm</span></code></p></li>
<li><p>Allowed model trained with Python 3.7 to be loaded with Python 3.8+ without the <code class="docutils literal notranslate"><span class="pre">custom_objects</span></code> workaround</p></li>
<li><p>Raise an error when the same gym environment instance is passed as separate environments when creating a vectorized environment with more than one environment. (&#64;Rocamonde)</p></li>
<li><p>Fix type annotation of <code class="docutils literal notranslate"><span class="pre">model</span></code> in <code class="docutils literal notranslate"><span class="pre">evaluate_policy</span></code></p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">Self</span></code> return type using <code class="docutils literal notranslate"><span class="pre">TypeVar</span></code></p></li>
<li><p>Fixed the env checker, the key was not passed when checking images from Dict observation space</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">normalize_images</span></code> which was not passed to parent class in some cases</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">load_from_vector</span></code> that was broken with newer PyTorch version when passing PyTorch tensor</p></li>
</ul>
</section>
<section id="id31">
<h5>Deprecations:<a class="headerlink" href="#id31" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>You should now explicitely pass a <code class="docutils literal notranslate"><span class="pre">features_extractor</span></code> parameter when calling <code class="docutils literal notranslate"><span class="pre">extract_features()</span></code></p></li>
<li><p>Deprecated shared layers in <code class="docutils literal notranslate"><span class="pre">MlpExtractor</span></code> (&#64;AlexPasqua)</p></li>
</ul>
</section>
<section id="id32">
<h5>Others:<a class="headerlink" href="#id32" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Used issue forms instead of issue templates</p></li>
<li><p>Updated the PR template to associate each PR with its peer in RL-Zoo3 and SB3-Contrib</p></li>
<li><p>Fixed flake8 config to be compatible with flake8 6+</p></li>
<li><p>Goal-conditioned environments are now characterized by the availability of the <code class="docutils literal notranslate"><span class="pre">compute_reward</span></code> method, rather than by their inheritance to <code class="docutils literal notranslate"><span class="pre">gym.GoalEnv</span></code></p></li>
<li><p>Replaced <code class="docutils literal notranslate"><span class="pre">CartPole-v0</span></code> by <code class="docutils literal notranslate"><span class="pre">CartPole-v1</span></code> is tests</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">tests/test_distributions.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/type_aliases.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/torch_layers.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/env_util.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/preprocessing.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/atari_wrappers.py</span></code> type hints</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">stable_baselines3/common/vec_env/vec_check_nan.py</span></code> type hints</p></li>
<li><p>Exposed modules in <code class="docutils literal notranslate"><span class="pre">__init__.py</span></code> with the <code class="docutils literal notranslate"><span class="pre">__all__</span></code> attribute (&#64;ZikangXiong)</p></li>
<li><p>Upgraded GitHub CI/setup-python to v4 and checkout to v3</p></li>
<li><p>Set tensors construction directly on the device (~8% speed boost on GPU)</p></li>
<li><p>Monkey-patched <code class="docutils literal notranslate"><span class="pre">np.bool</span> <span class="pre">=</span> <span class="pre">bool</span></code> so gym 0.21 is compatible with NumPy 1.24+</p></li>
<li><p>Standardized the use of <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">gym</span> <span class="pre">import</span> <span class="pre">spaces</span></code></p></li>
<li><p>Modified <code class="docutils literal notranslate"><span class="pre">get_system_info</span></code> to avoid issue linked to copy-pasting on GitHub issue</p></li>
</ul>
</section>
<section id="id33">
<h5>Documentation:<a class="headerlink" href="#id33" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Updated Hugging Face Integration page (&#64;simoninithomas)</p></li>
<li><p>Changed <code class="docutils literal notranslate"><span class="pre">env</span></code> to <code class="docutils literal notranslate"><span class="pre">vec_env</span></code> when environment is vectorized</p></li>
<li><p>Updated custom policy docs to better explain the <code class="docutils literal notranslate"><span class="pre">mlp_extractor</span></code>’s dimensions (&#64;AlexPasqua)</p></li>
<li><p>Updated custom policy documentation (&#64;athatheo)</p></li>
<li><p>Improved tensorboard callback doc</p></li>
<li><p>Clarify doc when using image-like input</p></li>
<li><p>Added RLeXplore to the project page (&#64;yuanmingqi)</p></li>
</ul>
</section>
</section>
<section id="release-1-6-2-2022-10-10">
<h4>Release 1.6.2 (2022-10-10)<a class="headerlink" href="#release-1-6-2-2022-10-10" title="Permalink to this heading"></a></h4>
<p><strong>Progress bar in the learn() method, RL Zoo3 is now a package</strong></p>
<section id="id34">
<h5>Breaking Changes:<a class="headerlink" href="#id34" title="Permalink to this heading"></a></h5>
</section>
<section id="id35">
<h5>New Features:<a class="headerlink" href="#id35" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added <code class="docutils literal notranslate"><span class="pre">progress_bar</span></code> argument in the <code class="docutils literal notranslate"><span class="pre">learn()</span></code> method, displayed using TQDM and rich packages</p></li>
<li><p>Added progress bar callback</p></li>
<li><p>The <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">RL Zoo</a> can now be installed as a package (<code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">rl_zoo3</span></code>)</p></li>
</ul>
</section>
<section id="id37">
<h5><a class="reference external" href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib">SB3-Contrib</a><a class="headerlink" href="#id37" title="Permalink to this heading"></a></h5>
</section>
<section id="id38">
<h5><a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">RL Zoo</a><a class="headerlink" href="#id38" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>RL Zoo is now a python package and can be installed using <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">rl_zoo3</span></code></p></li>
</ul>
</section>
<section id="id39">
<h5>Bug Fixes:<a class="headerlink" href="#id39" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">self.num_timesteps</span></code> was initialized properly only after the first call to <code class="docutils literal notranslate"><span class="pre">on_step()</span></code> for callbacks</p></li>
<li><p>Set importlib-metadata version to <code class="docutils literal notranslate"><span class="pre">~=4.13</span></code> to be compatible with <code class="docutils literal notranslate"><span class="pre">gym=0.21</span></code></p></li>
</ul>
</section>
<section id="id40">
<h5>Deprecations:<a class="headerlink" href="#id40" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added deprecation warning if parameters <code class="docutils literal notranslate"><span class="pre">eval_env</span></code>, <code class="docutils literal notranslate"><span class="pre">eval_freq</span></code> or <code class="docutils literal notranslate"><span class="pre">create_eval_env</span></code> are used (see #925) (&#64;tobirohrer)</p></li>
</ul>
</section>
<section id="id41">
<h5>Others:<a class="headerlink" href="#id41" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed type hint of the <code class="docutils literal notranslate"><span class="pre">env_id</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">make_vec_env</span></code> and <code class="docutils literal notranslate"><span class="pre">make_atari_env</span></code> (&#64;AlexPasqua)</p></li>
</ul>
</section>
<section id="id42">
<h5>Documentation:<a class="headerlink" href="#id42" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Extended docstring of the <code class="docutils literal notranslate"><span class="pre">wrapper_class</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">make_vec_env</span></code> (&#64;AlexPasqua)</p></li>
</ul>
</section>
</section>
<section id="release-1-6-1-2022-09-29">
<h4>Release 1.6.1 (2022-09-29)<a class="headerlink" href="#release-1-6-1-2022-09-29" title="Permalink to this heading"></a></h4>
<p><strong>Bug fix release</strong></p>
<section id="id43">
<h5>Breaking Changes:<a class="headerlink" href="#id43" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Switched minimum tensorboard version to 2.9.1</p></li>
</ul>
</section>
<section id="id44">
<h5>New Features:<a class="headerlink" href="#id44" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Support logging hyperparameters to tensorboard (&#64;timothe-chaumont)</p></li>
<li><p>Added checkpoints for replay buffer and <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> statistics (&#64;anand-bala)</p></li>
<li><p>Added option for <code class="docutils literal notranslate"><span class="pre">Monitor</span></code> to append to existing file instead of overriding (&#64;sidney-tio)</p></li>
<li><p>The env checker now raises an error when using dict observation spaces and observation keys don’t match observation space keys</p></li>
</ul>
</section>
<section id="id45">
<h5><a class="reference external" href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib">SB3-Contrib</a><a class="headerlink" href="#id45" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed the issue of wrongly passing policy arguments when using <code class="docutils literal notranslate"><span class="pre">CnnLstmPolicy</span></code> or <code class="docutils literal notranslate"><span class="pre">MultiInputLstmPolicy</span></code> with <code class="docutils literal notranslate"><span class="pre">RecurrentPPO</span></code> (&#64;mlodel)</p></li>
</ul>
</section>
<section id="id46">
<h5>Bug Fixes:<a class="headerlink" href="#id46" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed issue where <code class="docutils literal notranslate"><span class="pre">PPO</span></code> gives NaN if rollout buffer provides a batch of size 1 (&#64;hughperkins)</p></li>
<li><p>Fixed the issue that <code class="docutils literal notranslate"><span class="pre">predict</span></code> does not always return action as <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> (&#64;qgallouedec)</p></li>
<li><p>Fixed division by zero error when computing FPS when a small number of time has elapsed in operating systems with low-precision timers.</p></li>
<li><p>Added multidimensional action space support (&#64;qgallouedec)</p></li>
<li><p>Fixed missing verbose parameter passing in the <code class="docutils literal notranslate"><span class="pre">EvalCallback</span></code> constructor (&#64;burakdmb)</p></li>
<li><p>Fixed the issue that when updating the target network in DQN, SAC, TD3, the <code class="docutils literal notranslate"><span class="pre">running_mean</span></code> and <code class="docutils literal notranslate"><span class="pre">running_var</span></code> properties of batch norm layers are not updated (&#64;honglu2875)</p></li>
<li><p>Fixed incorrect type annotation of the replay_buffer_class argument in <code class="docutils literal notranslate"><span class="pre">common.OffPolicyAlgorithm</span></code> initializer, where an instance instead of a class was required (&#64;Rocamonde)</p></li>
<li><p>Fixed loading saved model with different number of environments</p></li>
<li><p>Removed <code class="docutils literal notranslate"><span class="pre">forward()</span></code> abstract method declaration from <code class="docutils literal notranslate"><span class="pre">common.policies.BaseModel</span></code> (already defined in <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>) to fix type errors in subclasses (&#64;Rocamonde)</p></li>
<li><p>Fixed the return type of <code class="docutils literal notranslate"><span class="pre">.load()</span></code> and <code class="docutils literal notranslate"><span class="pre">.learn()</span></code> methods in <code class="docutils literal notranslate"><span class="pre">BaseAlgorithm</span></code> so that they now use <code class="docutils literal notranslate"><span class="pre">TypeVar</span></code> (&#64;Rocamonde)</p></li>
<li><p>Fixed an issue where keys with different tags but the same key raised an error in <code class="docutils literal notranslate"><span class="pre">common.logger.HumanOutputFormat</span></code> (&#64;Rocamonde and &#64;AdamGleave)</p></li>
<li><p>Set importlib-metadata version to <cite>~=4.13</cite></p></li>
</ul>
</section>
<section id="id47">
<h5>Deprecations:<a class="headerlink" href="#id47" title="Permalink to this heading"></a></h5>
</section>
<section id="id48">
<h5>Others:<a class="headerlink" href="#id48" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">DictReplayBuffer.next_observations</span></code> typing (&#64;qgallouedec)</p></li>
<li><p>Added support for <code class="docutils literal notranslate"><span class="pre">device=&quot;auto&quot;</span></code> in buffers and made it default (&#64;qgallouedec)</p></li>
<li><p>Updated <code class="docutils literal notranslate"><span class="pre">ResultsWriter</span></code> (used internally by <code class="docutils literal notranslate"><span class="pre">Monitor</span></code> wrapper) to automatically create missing directories when <code class="docutils literal notranslate"><span class="pre">filename</span></code> is a path (&#64;dominicgkerr)</p></li>
</ul>
</section>
<section id="id49">
<h5>Documentation:<a class="headerlink" href="#id49" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added an example of callback that logs hyperparameters to tensorboard. (&#64;timothe-chaumont)</p></li>
<li><p>Fixed typo in docstring “nature” -&gt; “Nature” (&#64;Melanol)</p></li>
<li><p>Added info on split tensorboard logs into (&#64;Melanol)</p></li>
<li><p>Fixed typo in ppo doc (&#64;francescoluciano)</p></li>
<li><p>Fixed typo in install doc(&#64;jlp-ue)</p></li>
<li><p>Clarified and standardized verbosity documentation</p></li>
<li><p>Added link to a GitHub issue in the custom policy documentation (&#64;AlexPasqua)</p></li>
<li><p>Update doc on exporting models (fixes and added torch jit)</p></li>
<li><p>Fixed typos (&#64;Akhilez)</p></li>
<li><p>Standardized the use of <code class="docutils literal notranslate"><span class="pre">&quot;</span></code> for string representation in documentation</p></li>
</ul>
</section>
</section>
<section id="release-1-6-0-2022-07-11">
<h4>Release 1.6.0 (2022-07-11)<a class="headerlink" href="#release-1-6-0-2022-07-11" title="Permalink to this heading"></a></h4>
<p><strong>Recurrent PPO (PPO LSTM), better defaults for learning from pixels with SAC/TD3</strong></p>
<section id="id50">
<h5>Breaking Changes:<a class="headerlink" href="#id50" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Changed the way policy “aliases” are handled (“MlpPolicy”, “CnnPolicy”, …), removing the former
<code class="docutils literal notranslate"><span class="pre">register_policy</span></code> helper, <code class="docutils literal notranslate"><span class="pre">policy_base</span></code> parameter and using <code class="docutils literal notranslate"><span class="pre">policy_aliases</span></code> static attributes instead (&#64;Gregwar)</p></li>
<li><p>SB3 now requires PyTorch &gt;= 1.11</p></li>
<li><p>Changed the default network architecture when using <code class="docutils literal notranslate"><span class="pre">CnnPolicy</span></code> or <code class="docutils literal notranslate"><span class="pre">MultiInputPolicy</span></code> with SAC or DDPG/TD3,
<code class="docutils literal notranslate"><span class="pre">share_features_extractor</span></code> is now set to False by default and the <code class="docutils literal notranslate"><span class="pre">net_arch=[256,</span> <span class="pre">256]</span></code> (instead of <code class="docutils literal notranslate"><span class="pre">net_arch=[]</span></code> that was before)</p></li>
</ul>
</section>
<section id="id51">
<h5>New Features:<a class="headerlink" href="#id51" title="Permalink to this heading"></a></h5>
</section>
<section id="id52">
<h5><a class="reference external" href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib">SB3-Contrib</a><a class="headerlink" href="#id52" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added Recurrent PPO (PPO LSTM). See <a class="reference external" href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib/pull/53">https://github.com/Stable-Baselines-Team/stable-baselines3-contrib/pull/53</a></p></li>
</ul>
</section>
<section id="id53">
<h5>Bug Fixes:<a class="headerlink" href="#id53" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed saving and loading large policies greater than 2GB (&#64;jkterry1, &#64;ycheng517)</p></li>
<li><p>Fixed final goal selection strategy that did not sample the final achieved goal (&#64;qgallouedec)</p></li>
<li><p>Fixed a bug with special characters in the tensorboard log name (&#64;quantitative-technologies)</p></li>
<li><p>Fixed a bug in <code class="docutils literal notranslate"><span class="pre">DummyVecEnv</span></code>’s and <code class="docutils literal notranslate"><span class="pre">SubprocVecEnv</span></code>’s seeding function. None value was unchecked (&#64;ScheiklP)</p></li>
<li><p>Fixed a bug where <code class="docutils literal notranslate"><span class="pre">EvalCallback</span></code> would crash when trying to synchronize <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> stats when observation normalization was disabled</p></li>
<li><p>Added a check for unbounded actions</p></li>
<li><p>Fixed issues due to newer version of protobuf (tensorboard) and sphinx</p></li>
<li><p>Fix exception causes all over the codebase (&#64;cool-RR)</p></li>
<li><p>Prohibit simultaneous use of optimize_memory_usage and handle_timeout_termination due to a bug (&#64;MWeltevrede)</p></li>
<li><p>Fixed a bug in <code class="docutils literal notranslate"><span class="pre">kl_divergence</span></code> check that would fail when using numpy arrays with MultiCategorical distribution</p></li>
</ul>
</section>
<section id="id54">
<h5>Deprecations:<a class="headerlink" href="#id54" title="Permalink to this heading"></a></h5>
</section>
<section id="id55">
<h5>Others:<a class="headerlink" href="#id55" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Upgraded to Python 3.7+ syntax using <code class="docutils literal notranslate"><span class="pre">pyupgrade</span></code></p></li>
<li><p>Removed redundant double-check for nested observations from <code class="docutils literal notranslate"><span class="pre">BaseAlgorithm._wrap_env</span></code> (&#64;TibiGG)</p></li>
</ul>
</section>
<section id="id56">
<h5>Documentation:<a class="headerlink" href="#id56" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added link to gym doc and gym env checker</p></li>
<li><p>Fix typo in PPO doc (&#64;bcollazo)</p></li>
<li><p>Added link to PPO ICLR blog post</p></li>
<li><p>Added remark about breaking Markov assumption and timeout handling</p></li>
<li><p>Added doc about MLFlow integration via custom logger (&#64;git-thor)</p></li>
<li><p>Updated Huggingface integration doc</p></li>
<li><p>Added copy button for code snippets</p></li>
<li><p>Added doc about EnvPool and Isaac Gym support</p></li>
</ul>
</section>
</section>
<section id="release-1-5-0-2022-03-25">
<h4>Release 1.5.0 (2022-03-25)<a class="headerlink" href="#release-1-5-0-2022-03-25" title="Permalink to this heading"></a></h4>
<p><strong>Bug fixes, early stopping callback</strong></p>
<section id="id57">
<h5>Breaking Changes:<a class="headerlink" href="#id57" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Switched minimum Gym version to 0.21.0</p></li>
</ul>
</section>
<section id="id58">
<h5>New Features:<a class="headerlink" href="#id58" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added <code class="docutils literal notranslate"><span class="pre">StopTrainingOnNoModelImprovement</span></code> to callback collection (&#64;caburu)</p></li>
<li><p>Makes the length of keys and values in <code class="docutils literal notranslate"><span class="pre">HumanOutputFormat</span></code> configurable,
depending on desired maximum width of output.</p></li>
<li><p>Allow PPO to turn of advantage normalization (see <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/pull/763">PR #763</a>) &#64;vwxyzjn</p></li>
</ul>
</section>
<section id="id59">
<h5><a class="reference external" href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib">SB3-Contrib</a><a class="headerlink" href="#id59" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>coming soon: Cross Entropy Method, see <a class="reference external" href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib/pull/62">https://github.com/Stable-Baselines-Team/stable-baselines3-contrib/pull/62</a></p></li>
</ul>
</section>
<section id="id60">
<h5>Bug Fixes:<a class="headerlink" href="#id60" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed a bug in <code class="docutils literal notranslate"><span class="pre">VecMonitor</span></code>. The monitor did not consider the <code class="docutils literal notranslate"><span class="pre">info_keywords</span></code> during stepping (&#64;ScheiklP)</p></li>
<li><p>Fixed a bug in <code class="docutils literal notranslate"><span class="pre">HumanOutputFormat</span></code>. Distinct keys truncated to the same prefix would overwrite each others value,
resulting in only one being output. This now raises an error (this should only affect a small fraction of use cases
with very long keys.)</p></li>
<li><p>Routing all the <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> calls through implicit rather than explict forward as per pytorch guidelines (&#64;manuel-delverme)</p></li>
<li><p>Fixed a bug in <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> where error occurs when <code class="docutils literal notranslate"><span class="pre">norm_obs</span></code> is set to False for environment with dictionary observation  (&#64;buoyancy99)</p></li>
<li><p>Set default <code class="docutils literal notranslate"><span class="pre">env</span></code> argument to <code class="docutils literal notranslate"><span class="pre">None</span></code> in <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer.sample</span></code> (&#64;qgallouedec)</p></li>
<li><p>Fix <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> typing in <code class="docutils literal notranslate"><span class="pre">DQN</span></code> (&#64;qgallouedec)</p></li>
<li><p>Fixed sample normalization in <code class="docutils literal notranslate"><span class="pre">DictReplayBuffer</span></code> (&#64;qgallouedec)</p></li>
</ul>
</section>
<section id="id61">
<h5>Deprecations:<a class="headerlink" href="#id61" title="Permalink to this heading"></a></h5>
</section>
<section id="id62">
<h5>Others:<a class="headerlink" href="#id62" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed pytest warnings</p></li>
<li><p>Removed parameter <code class="docutils literal notranslate"><span class="pre">remove_time_limit_termination</span></code> in off policy algorithms since it was dead code (&#64;Gregwar)</p></li>
</ul>
</section>
<section id="id63">
<h5>Documentation:<a class="headerlink" href="#id63" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added doc on Hugging Face integration (&#64;simoninithomas)</p></li>
<li><p>Added furuta pendulum project to project list (&#64;armandpl)</p></li>
<li><p>Fix indentation 2 spaces to 4 spaces in custom env documentation example (&#64;Gautam-J)</p></li>
<li><p>Update MlpExtractor docstring (&#64;gianlucadecola)</p></li>
<li><p>Added explanation of the logger output</p></li>
<li><p>Update <code class="docutils literal notranslate"><span class="pre">Directly</span> <span class="pre">Accessing</span> <span class="pre">The</span> <span class="pre">Summary</span> <span class="pre">Writer</span></code> in tensorboard integration (&#64;xy9485)</p></li>
</ul>
</section>
</section>
<section id="release-1-4-0-2022-01-18">
<h4>Release 1.4.0 (2022-01-18)<a class="headerlink" href="#release-1-4-0-2022-01-18" title="Permalink to this heading"></a></h4>
<p><em>TRPO, ARS and multi env training for off-policy algorithms</em></p>
<section id="id64">
<h5>Breaking Changes:<a class="headerlink" href="#id64" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Dropped python 3.6 support (as announced in previous release)</p></li>
<li><p>Renamed <code class="docutils literal notranslate"><span class="pre">mask</span></code> argument of the <code class="docutils literal notranslate"><span class="pre">predict()</span></code> method to <code class="docutils literal notranslate"><span class="pre">episode_start</span></code> (used with RNN policies only)</p></li>
<li><p>local variables <code class="docutils literal notranslate"><span class="pre">action</span></code>, <code class="docutils literal notranslate"><span class="pre">done</span></code> and <code class="docutils literal notranslate"><span class="pre">reward</span></code> were renamed to their plural form for offpolicy algorithms (<code class="docutils literal notranslate"><span class="pre">actions</span></code>, <code class="docutils literal notranslate"><span class="pre">dones</span></code>, <code class="docutils literal notranslate"><span class="pre">rewards</span></code>),
this may affect custom callbacks.</p></li>
<li><p>Removed <code class="docutils literal notranslate"><span class="pre">episode_reward</span></code> field from <code class="docutils literal notranslate"><span class="pre">RolloutReturn()</span></code> type</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>An update to the <code class="docutils literal notranslate"><span class="pre">HER</span></code> algorithm is planned to support multi-env training and remove the max episode length constrain.
(see <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/pull/704">PR #704</a>)
This will be a backward incompatible change (model trained with previous version of <code class="docutils literal notranslate"><span class="pre">HER</span></code> won’t work with the new version).</p>
</div>
</section>
<section id="id65">
<h5>New Features:<a class="headerlink" href="#id65" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added <code class="docutils literal notranslate"><span class="pre">norm_obs_keys</span></code> param for <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> wrapper to configure which observation keys to normalize (&#64;kachayev)</p></li>
<li><p>Added experimental support to train off-policy algorithms with multiple envs (note: <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code> currently not supported)</p></li>
<li><p>Handle timeout termination properly for on-policy algorithms (when using <code class="docutils literal notranslate"><span class="pre">TimeLimit</span></code>)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">skip</span></code> option to <code class="docutils literal notranslate"><span class="pre">VecTransposeImage</span></code> to skip transforming the channel order when the heuristic is wrong</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">copy()</span></code> and <code class="docutils literal notranslate"><span class="pre">combine()</span></code> methods to <code class="docutils literal notranslate"><span class="pre">RunningMeanStd</span></code></p></li>
</ul>
</section>
<section id="id66">
<h5><a class="reference external" href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib">SB3-Contrib</a><a class="headerlink" href="#id66" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added Trust Region Policy Optimization (TRPO) (&#64;cyprienc)</p></li>
<li><p>Added Augmented Random Search (ARS) (&#64;sgillen)</p></li>
<li><p>Coming soon: PPO LSTM, see <a class="reference external" href="https://github.com/Stable-Baselines-Team/stable-baselines3-contrib/pull/53">https://github.com/Stable-Baselines-Team/stable-baselines3-contrib/pull/53</a></p></li>
</ul>
</section>
<section id="id67">
<h5>Bug Fixes:<a class="headerlink" href="#id67" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed a bug where <code class="docutils literal notranslate"><span class="pre">set_env()</span></code> with <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> would result in an error with off-policy algorithms (thanks &#64;cleversonahum)</p></li>
<li><p>FPS calculation is now performed based on number of steps performed during last <code class="docutils literal notranslate"><span class="pre">learn</span></code> call, even when <code class="docutils literal notranslate"><span class="pre">reset_num_timesteps</span></code> is set to <code class="docutils literal notranslate"><span class="pre">False</span></code> (&#64;kachayev)</p></li>
<li><p>Fixed evaluation script for recurrent policies (experimental feature in SB3 contrib)</p></li>
<li><p>Fixed a bug where the observation would be incorrectly detected as non-vectorized instead of throwing an error</p></li>
<li><p>The env checker now properly checks and warns about potential issues for continuous action spaces when the boundaries are too small or when the dtype is not float32</p></li>
<li><p>Fixed a bug in <code class="docutils literal notranslate"><span class="pre">VecFrameStack</span></code> with channel first image envs, where the terminal observation would be wrongly created.</p></li>
</ul>
</section>
<section id="id68">
<h5>Deprecations:<a class="headerlink" href="#id68" title="Permalink to this heading"></a></h5>
</section>
<section id="id69">
<h5>Others:<a class="headerlink" href="#id69" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added a warning in the env checker when not using <code class="docutils literal notranslate"><span class="pre">np.float32</span></code> for continuous actions</p></li>
<li><p>Improved test coverage and error message when checking shape of observation</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">newline=&quot;\n&quot;</span></code> when opening CSV monitor files so that each line ends with <code class="docutils literal notranslate"><span class="pre">\r\n</span></code> instead of <code class="docutils literal notranslate"><span class="pre">\r\r\n</span></code> on Windows while Linux environments are not affected (&#64;hsuehch)</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">device</span></code> argument inconsistency (&#64;qgallouedec)</p></li>
</ul>
</section>
<section id="id70">
<h5>Documentation:<a class="headerlink" href="#id70" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Add drivergym to projects page (&#64;theDebugger811)</p></li>
<li><p>Add highway-env to projects page (&#64;eleurent)</p></li>
<li><p>Add tactile-gym to projects page (&#64;ac-93)</p></li>
<li><p>Fix indentation in the RL tips page (&#64;cove9988)</p></li>
<li><p>Update GAE computation docstring</p></li>
<li><p>Add documentation on exporting to TFLite/Coral</p></li>
<li><p>Added JMLR paper and updated citation</p></li>
<li><p>Added link to RL Tips and Tricks video</p></li>
<li><p>Updated <code class="docutils literal notranslate"><span class="pre">BaseAlgorithm.load</span></code> docstring (&#64;Demetrio92)</p></li>
<li><p>Added a note on <code class="docutils literal notranslate"><span class="pre">load</span></code> behavior in the examples (&#64;Demetrio92)</p></li>
<li><p>Updated SB3 Contrib doc</p></li>
<li><p>Fixed A2C and migration guide guidance on how to set epsilon with RMSpropTFLike (&#64;thomasgubler)</p></li>
<li><p>Fixed custom policy documentation (&#64;IperGiove)</p></li>
<li><p>Added doc on Weights &amp; Biases integration</p></li>
</ul>
</section>
</section>
<section id="release-1-3-0-2021-10-23">
<h4>Release 1.3.0 (2021-10-23)<a class="headerlink" href="#release-1-3-0-2021-10-23" title="Permalink to this heading"></a></h4>
<p><em>Bug fixes and improvements for the user</em></p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This version will be the last one supporting Python 3.6 (end of life in Dec 2021).
We highly recommended you to upgrade to Python &gt;= 3.7.</p>
</div>
<section id="id71">
<h5>Breaking Changes:<a class="headerlink" href="#id71" title="Permalink to this heading"></a></h5>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sde_net_arch</span></code> argument in policies is deprecated and will be removed in a future version.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">_get_latent</span></code> (<code class="docutils literal notranslate"><span class="pre">ActorCriticPolicy</span></code>) was removed</p></li>
<li><p>All logging keys now use underscores instead of spaces (&#64;timokau). Concretely this changes:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">time/total</span> <span class="pre">timesteps</span></code> to <code class="docutils literal notranslate"><span class="pre">time/total_timesteps</span></code> for off-policy algorithms (PPO and A2C) and the eval callback (on-policy algorithms already used the underscored version),</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rollout/exploration</span> <span class="pre">rate</span></code> to <code class="docutils literal notranslate"><span class="pre">rollout/exploration_rate</span></code> and</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rollout/success</span> <span class="pre">rate</span></code> to <code class="docutils literal notranslate"><span class="pre">rollout/success_rate</span></code>.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</section>
<section id="id72">
<h5>New Features:<a class="headerlink" href="#id72" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added methods <code class="docutils literal notranslate"><span class="pre">get_distribution</span></code> and <code class="docutils literal notranslate"><span class="pre">predict_values</span></code> for <code class="docutils literal notranslate"><span class="pre">ActorCriticPolicy</span></code> for A2C/PPO/TRPO (&#64;cyprienc)</p></li>
<li><p>Added methods <code class="docutils literal notranslate"><span class="pre">forward_actor</span></code> and <code class="docutils literal notranslate"><span class="pre">forward_critic</span></code> for <code class="docutils literal notranslate"><span class="pre">MlpExtractor</span></code></p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">sb3.get_system_info()</span></code> helper function to gather version information relevant to SB3 (e.g., Python and PyTorch version)</p></li>
<li><p>Saved models now store system information where agent was trained, and load functions have <code class="docutils literal notranslate"><span class="pre">print_system_info</span></code> parameter to help debugging load issues</p></li>
</ul>
</section>
<section id="id73">
<h5>Bug Fixes:<a class="headerlink" href="#id73" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">dtype</span></code> of observations for <code class="docutils literal notranslate"><span class="pre">SimpleMultiObsEnv</span></code></p></li>
<li><p>Allow <cite>VecNormalize</cite> to wrap discrete-observation environments to normalize reward
when observation normalization is disabled</p></li>
<li><p>Fixed a bug where <code class="docutils literal notranslate"><span class="pre">DQN</span></code> would throw an error when using <code class="docutils literal notranslate"><span class="pre">Discrete</span></code> observation and stochastic actions</p></li>
<li><p>Fixed a bug where sub-classed observation spaces could not be used</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">force_reset</span></code> argument to <code class="docutils literal notranslate"><span class="pre">load()</span></code> and <code class="docutils literal notranslate"><span class="pre">set_env()</span></code> in order to be able to call <code class="docutils literal notranslate"><span class="pre">learn(reset_num_timesteps=False)</span></code> with a new environment</p></li>
</ul>
</section>
<section id="id74">
<h5>Deprecations:<a class="headerlink" href="#id74" title="Permalink to this heading"></a></h5>
</section>
<section id="id75">
<h5>Others:<a class="headerlink" href="#id75" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Cap gym max version to 0.19 to avoid issues with atari-py and other breaking changes</p></li>
<li><p>Improved error message when using dict observation with the wrong policy</p></li>
<li><p>Improved error message when using <code class="docutils literal notranslate"><span class="pre">EvalCallback</span></code> with two envs not wrapped the same way.</p></li>
<li><p>Added additional infos about supported python version for PyPi in <code class="docutils literal notranslate"><span class="pre">setup.py</span></code></p></li>
</ul>
</section>
<section id="id76">
<h5>Documentation:<a class="headerlink" href="#id76" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Add Rocket League Gym to list of supported projects (&#64;AechPro)</p></li>
<li><p>Added gym-electric-motor to project page (&#64;wkirgsn)</p></li>
<li><p>Added policy-distillation-baselines to project page (&#64;CUN-bjy)</p></li>
<li><p>Added ONNX export instructions (&#64;batu)</p></li>
<li><p>Update read the doc env (fixed <code class="docutils literal notranslate"><span class="pre">docutils</span></code> issue)</p></li>
<li><p>Fix PPO environment name (&#64;IljaAvadiev)</p></li>
<li><p>Fix custom env doc and add env registration example</p></li>
<li><p>Update algorithms from SB3 Contrib</p></li>
<li><p>Use underscores for numeric literals in examples to improve clarity</p></li>
</ul>
</section>
</section>
<section id="release-1-2-0-2021-09-03">
<h4>Release 1.2.0 (2021-09-03)<a class="headerlink" href="#release-1-2-0-2021-09-03" title="Permalink to this heading"></a></h4>
<p><strong>Hotfix for VecNormalize, training/eval mode support</strong></p>
<section id="id77">
<h5>Breaking Changes:<a class="headerlink" href="#id77" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>SB3 now requires PyTorch &gt;= 1.8.1</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> <code class="docutils literal notranslate"><span class="pre">ret</span></code> attribute was renamed to <code class="docutils literal notranslate"><span class="pre">returns</span></code></p></li>
</ul>
</section>
<section id="id78">
<h5>New Features:<a class="headerlink" href="#id78" title="Permalink to this heading"></a></h5>
</section>
<section id="id79">
<h5>Bug Fixes:<a class="headerlink" href="#id79" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Hotfix for <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> where the observation filter was not updated at reset (thanks &#64;vwxyzjn)</p></li>
<li><p>Fixed model predictions when using batch normalization and dropout layers by calling <code class="docutils literal notranslate"><span class="pre">train()</span></code> and <code class="docutils literal notranslate"><span class="pre">eval()</span></code> (&#64;davidblom603)</p></li>
<li><p>Fixed model training for DQN, TD3 and SAC so that their target nets always remain in evaluation mode (&#64;ayeright)</p></li>
<li><p>Passing <code class="docutils literal notranslate"><span class="pre">gradient_steps=0</span></code> to an off-policy algorithm will result in no gradient steps being taken (vs as many gradient steps as steps done in the environment
during the rollout in previous versions)</p></li>
</ul>
</section>
<section id="id80">
<h5>Deprecations:<a class="headerlink" href="#id80" title="Permalink to this heading"></a></h5>
</section>
<section id="id81">
<h5>Others:<a class="headerlink" href="#id81" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Enabled Python 3.9 in GitHub CI</p></li>
<li><p>Fixed type annotations</p></li>
<li><p>Refactored <code class="docutils literal notranslate"><span class="pre">predict()</span></code> by moving the preprocessing to <code class="docutils literal notranslate"><span class="pre">obs_to_tensor()</span></code> method</p></li>
</ul>
</section>
<section id="id82">
<h5>Documentation:<a class="headerlink" href="#id82" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Updated multiprocessing example</p></li>
<li><p>Added example of <code class="docutils literal notranslate"><span class="pre">VecEnvWrapper</span></code></p></li>
<li><p>Added a note about logging to tensorboard more often</p></li>
<li><p>Added warning about simplicity of examples and link to RL zoo (&#64;MihaiAnca13)</p></li>
</ul>
</section>
</section>
<section id="release-1-1-0-2021-07-01">
<h4>Release 1.1.0 (2021-07-01)<a class="headerlink" href="#release-1-1-0-2021-07-01" title="Permalink to this heading"></a></h4>
<p><strong>Dict observation support, timeout handling and refactored HER buffer</strong></p>
<section id="id83">
<h5>Breaking Changes:<a class="headerlink" href="#id83" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>All customs environments (e.g. the <code class="docutils literal notranslate"><span class="pre">BitFlippingEnv</span></code> or <code class="docutils literal notranslate"><span class="pre">IdentityEnv</span></code>) were moved to <code class="docutils literal notranslate"><span class="pre">stable_baselines3.common.envs</span></code> folder</p></li>
<li><p>Refactored <code class="docutils literal notranslate"><span class="pre">HER</span></code> which is now the <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code> class that can be passed to any off-policy algorithm</p></li>
<li><p>Handle timeout termination properly for off-policy algorithms (when using <code class="docutils literal notranslate"><span class="pre">TimeLimit</span></code>)</p></li>
<li><p>Renamed <code class="docutils literal notranslate"><span class="pre">_last_dones</span></code> and <code class="docutils literal notranslate"><span class="pre">dones</span></code> to <code class="docutils literal notranslate"><span class="pre">_last_episode_starts</span></code> and <code class="docutils literal notranslate"><span class="pre">episode_starts</span></code> in <code class="docutils literal notranslate"><span class="pre">RolloutBuffer</span></code>.</p></li>
<li><p>Removed <code class="docutils literal notranslate"><span class="pre">ObsDictWrapper</span></code> as <code class="docutils literal notranslate"><span class="pre">Dict</span></code> observation spaces are now supported</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">her_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_sampled_goal</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">goal_selection_strategy</span><span class="o">=</span><span class="s2">&quot;future&quot;</span><span class="p">,</span> <span class="n">online_sampling</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># SB3 &lt; 1.1.0</span>
<span class="c1"># model = HER(&quot;MlpPolicy&quot;, env, model_class=SAC, **her_kwargs)</span>
<span class="c1"># SB3 &gt;= 1.1.0:</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span><span class="s2">&quot;MultiInputPolicy&quot;</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">replay_buffer_class</span><span class="o">=</span><span class="n">HerReplayBuffer</span><span class="p">,</span> <span class="n">replay_buffer_kwargs</span><span class="o">=</span><span class="n">her_kwargs</span><span class="p">)</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Updated the KL Divergence estimator in the PPO algorithm to be positive definite and have lower variance (&#64;09tangriro)</p></li>
<li><p>Updated the KL Divergence check in the PPO algorithm to be before the gradient update step rather than after end of epoch (&#64;09tangriro)</p></li>
<li><p>Removed parameter <code class="docutils literal notranslate"><span class="pre">channels_last</span></code> from <code class="docutils literal notranslate"><span class="pre">is_image_space</span></code> as it can be inferred.</p></li>
<li><p>The logger object is now an attribute <code class="docutils literal notranslate"><span class="pre">model.logger</span></code> that be set by the user using <code class="docutils literal notranslate"><span class="pre">model.set_logger()</span></code></p></li>
<li><p>Changed the signature of <code class="docutils literal notranslate"><span class="pre">logger.configure</span></code> and <code class="docutils literal notranslate"><span class="pre">utils.configure_logger</span></code>, they now return a <code class="docutils literal notranslate"><span class="pre">Logger</span></code> object</p></li>
<li><p>Removed <code class="docutils literal notranslate"><span class="pre">Logger.CURRENT</span></code> and <code class="docutils literal notranslate"><span class="pre">Logger.DEFAULT</span></code></p></li>
<li><p>Moved <code class="docutils literal notranslate"><span class="pre">warn(),</span> <span class="pre">debug(),</span> <span class="pre">log(),</span> <span class="pre">info(),</span> <span class="pre">dump()</span></code> methods to the <code class="docutils literal notranslate"><span class="pre">Logger</span></code> class</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.learn()</span></code> now throws an import error when the user tries to log to tensorboard but the package is not installed</p></li>
</ul>
</section>
<section id="id84">
<h5>New Features:<a class="headerlink" href="#id84" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added support for single-level <code class="docutils literal notranslate"><span class="pre">Dict</span></code> observation space (&#64;JadenTravnik)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">DictRolloutBuffer</span></code> <code class="docutils literal notranslate"><span class="pre">DictReplayBuffer</span></code> to support dictionary observations (&#64;JadenTravnik)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">StackedObservations</span></code> and <code class="docutils literal notranslate"><span class="pre">StackedDictObservations</span></code> that are used within <code class="docutils literal notranslate"><span class="pre">VecFrameStack</span></code></p></li>
<li><p>Added simple 4x4 room Dict test environments</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code> now supports <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> when <code class="docutils literal notranslate"><span class="pre">online_sampling=False</span></code></p></li>
<li><p>Added <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/blob/master/stable_baselines3/common/vec_env/vec_monitor.py">VecMonitor</a> and
<a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/blob/master/stable_baselines3/common/vec_env/vec_extract_dict_obs.py">VecExtractDictObs</a> wrappers
to handle gym3-style vectorized environments (&#64;vwxyzjn)</p></li>
<li><p>Ignored the terminal observation if the it is not provided by the environment
such as the gym3-style vectorized environments. (&#64;vwxyzjn)</p></li>
<li><p>Added policy_base as input to the OnPolicyAlgorithm for more flexibility (&#64;09tangriro)</p></li>
<li><p>Added support for image observation when using <code class="docutils literal notranslate"><span class="pre">HER</span></code></p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">replay_buffer_class</span></code> and <code class="docutils literal notranslate"><span class="pre">replay_buffer_kwargs</span></code> arguments to off-policy algorithms</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">kl_divergence</span></code> helper for <code class="docutils literal notranslate"><span class="pre">Distribution</span></code> classes (&#64;09tangriro)</p></li>
<li><p>Added support for vector environments with <code class="docutils literal notranslate"><span class="pre">num_envs</span> <span class="pre">&gt;</span> <span class="pre">1</span></code> (&#64;benblack769)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">wrapper_kwargs</span></code> argument to <code class="docutils literal notranslate"><span class="pre">make_vec_env</span></code> (&#64;amy12xx)</p></li>
</ul>
</section>
<section id="id85">
<h5>Bug Fixes:<a class="headerlink" href="#id85" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed potential issue when calling off-policy algorithms with default arguments multiple times (the size of the replay buffer would be the same)</p></li>
<li><p>Fixed loading of <code class="docutils literal notranslate"><span class="pre">ent_coef</span></code> for <code class="docutils literal notranslate"><span class="pre">SAC</span></code> and <code class="docutils literal notranslate"><span class="pre">TQC</span></code>, it was not optimized anymore (thanks &#64;Atlis)</p></li>
<li><p>Fixed saving of <code class="docutils literal notranslate"><span class="pre">A2C</span></code> and <code class="docutils literal notranslate"><span class="pre">PPO</span></code> policy when using gSDE (thanks &#64;liusida)</p></li>
<li><p>Fixed a bug where no output would be shown even if <code class="docutils literal notranslate"><span class="pre">verbose&gt;=1</span></code> after passing <code class="docutils literal notranslate"><span class="pre">verbose=0</span></code> once</p></li>
<li><p>Fixed observation buffers dtype in DictReplayBuffer (&#64;c-rizz)</p></li>
<li><p>Fixed EvalCallback tensorboard logs being logged with the incorrect timestep. They are now written with the timestep at which they were recorded. (&#64;skandermoalla)</p></li>
</ul>
</section>
<section id="id86">
<h5>Deprecations:<a class="headerlink" href="#id86" title="Permalink to this heading"></a></h5>
</section>
<section id="id87">
<h5>Others:<a class="headerlink" href="#id87" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added <code class="docutils literal notranslate"><span class="pre">flake8-bugbear</span></code> to tests dependencies to find likely bugs</p></li>
<li><p>Updated <code class="docutils literal notranslate"><span class="pre">env_checker</span></code> to reflect support of dict observation spaces</p></li>
<li><p>Added Code of Conduct</p></li>
<li><p>Added tests for GAE and lambda return computation</p></li>
<li><p>Updated distribution entropy test (thanks &#64;09tangriro)</p></li>
<li><p>Added sanity check <code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">&gt;</span> <span class="pre">1</span></code> in PPO to avoid NaN in advantage normalization</p></li>
</ul>
</section>
<section id="id88">
<h5>Documentation:<a class="headerlink" href="#id88" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added gym pybullet drones project (&#64;JacopoPan)</p></li>
<li><p>Added link to SuperSuit in projects (&#64;justinkterry)</p></li>
<li><p>Fixed DQN example (thanks &#64;ltbd78)</p></li>
<li><p>Clarified channel-first/channel-last recommendation</p></li>
<li><p>Update sphinx environment installation instructions (&#64;tom-doerr)</p></li>
<li><p>Clarified pip installation in Zsh (&#64;tom-doerr)</p></li>
<li><p>Clarified return computation for on-policy algorithms (TD(lambda) estimate was used)</p></li>
<li><p>Added example for using <code class="docutils literal notranslate"><span class="pre">ProcgenEnv</span></code></p></li>
<li><p>Added note about advanced custom policy example for off-policy algorithms</p></li>
<li><p>Fixed DQN unicode checkmarks</p></li>
<li><p>Updated migration guide (&#64;juancroldan)</p></li>
<li><p>Pinned <code class="docutils literal notranslate"><span class="pre">docutils==0.16</span></code> to avoid issue with rtd theme</p></li>
<li><p>Clarified callback <code class="docutils literal notranslate"><span class="pre">save_freq</span></code> definition</p></li>
<li><p>Added doc on how to pass a custom logger</p></li>
<li><p>Remove recurrent policies from <code class="docutils literal notranslate"><span class="pre">A2C</span></code> docs (&#64;bstee615)</p></li>
</ul>
</section>
</section>
<section id="release-1-0-2021-03-15">
<h4>Release 1.0 (2021-03-15)<a class="headerlink" href="#release-1-0-2021-03-15" title="Permalink to this heading"></a></h4>
<p><strong>First Major Version</strong></p>
<section id="id89">
<h5>Breaking Changes:<a class="headerlink" href="#id89" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Removed <code class="docutils literal notranslate"><span class="pre">stable_baselines3.common.cmd_util</span></code> (already deprecated), please use <code class="docutils literal notranslate"><span class="pre">env_util</span></code> instead</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>A refactoring of the <code class="docutils literal notranslate"><span class="pre">HER</span></code> algorithm is planned together with support for dictionary observations
(see <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/pull/243">PR #243</a> and <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/pull/351">#351</a>)
This will be a backward incompatible change (model trained with previous version of <code class="docutils literal notranslate"><span class="pre">HER</span></code> won’t work with the new version).</p>
</div>
</section>
<section id="id91">
<h5>New Features:<a class="headerlink" href="#id91" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added support for <code class="docutils literal notranslate"><span class="pre">custom_objects</span></code> when loading models</p></li>
</ul>
</section>
<section id="id92">
<h5>Bug Fixes:<a class="headerlink" href="#id92" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed a bug with <code class="docutils literal notranslate"><span class="pre">DQN</span></code> predict method when using <code class="docutils literal notranslate"><span class="pre">deterministic=False</span></code> with image space</p></li>
</ul>
</section>
<section id="id93">
<h5>Documentation:<a class="headerlink" href="#id93" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed examples</p></li>
<li><p>Added new project using SB3: rl_reach (&#64;PierreExeter)</p></li>
<li><p>Added note about slow-down when switching to PyTorch</p></li>
<li><p>Add a note on continual learning and resetting environment</p></li>
</ul>
</section>
<section id="id94">
<h5>Others:<a class="headerlink" href="#id94" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Updated RL-Zoo to reflect the fact that is it more than a collection of trained agents</p></li>
<li><p>Added images to illustrate the training loop and custom policies (created with <a class="reference external" href="https://excalidraw.com/">https://excalidraw.com/</a>)</p></li>
<li><p>Updated the custom policy section</p></li>
</ul>
</section>
</section>
<section id="pre-release-0-11-1-2021-02-27">
<h4>Pre-Release 0.11.1 (2021-02-27)<a class="headerlink" href="#pre-release-0-11-1-2021-02-27" title="Permalink to this heading"></a></h4>
<section id="id95">
<h5>Bug Fixes:<a class="headerlink" href="#id95" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed a bug where <code class="docutils literal notranslate"><span class="pre">train_freq</span></code> was not properly converted when loading a saved model</p></li>
</ul>
</section>
</section>
<section id="pre-release-0-11-0-2021-02-27">
<h4>Pre-Release 0.11.0 (2021-02-27)<a class="headerlink" href="#pre-release-0-11-0-2021-02-27" title="Permalink to this heading"></a></h4>
<section id="id96">
<h5>Breaking Changes:<a class="headerlink" href="#id96" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">evaluate_policy</span></code> now returns rewards/episode lengths from a <code class="docutils literal notranslate"><span class="pre">Monitor</span></code> wrapper if one is present,
this allows to return the unnormalized reward in the case of Atari games for instance.</p></li>
<li><p>Renamed <code class="docutils literal notranslate"><span class="pre">common.vec_env.is_wrapped</span></code> to <code class="docutils literal notranslate"><span class="pre">common.vec_env.is_vecenv_wrapped</span></code> to avoid confusion
with the new <code class="docutils literal notranslate"><span class="pre">is_wrapped()</span></code> helper</p></li>
<li><p>Renamed <code class="docutils literal notranslate"><span class="pre">_get_data()</span></code> to <code class="docutils literal notranslate"><span class="pre">_get_constructor_parameters()</span></code> for policies (this affects independent saving/loading of policies)</p></li>
<li><p>Removed <code class="docutils literal notranslate"><span class="pre">n_episodes_rollout</span></code> and merged it with <code class="docutils literal notranslate"><span class="pre">train_freq</span></code>, which now accepts a tuple <code class="docutils literal notranslate"><span class="pre">(frequency,</span> <span class="pre">unit)</span></code>:</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">replay_buffer</span></code> in <code class="docutils literal notranslate"><span class="pre">collect_rollout</span></code> is no more optional</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># SB3 &lt; 0.11.0</span>
<span class="c1"># model = SAC(&quot;MlpPolicy&quot;, env, n_episodes_rollout=1, train_freq=-1)</span>
<span class="c1"># SB3 &gt;= 0.11.0:</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SAC</span><span class="p">(</span><span class="s2">&quot;MlpPolicy&quot;</span><span class="p">,</span> <span class="n">env</span><span class="p">,</span> <span class="n">train_freq</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;episode&quot;</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="id97">
<h5>New Features:<a class="headerlink" href="#id97" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Add support for <code class="docutils literal notranslate"><span class="pre">VecFrameStack</span></code> to stack on first or last observation dimension, along with
automatic check for image spaces.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">VecFrameStack</span></code> now has a <code class="docutils literal notranslate"><span class="pre">channels_order</span></code> argument to tell if observations should be stacked
on the first or last observation dimension (originally always stacked on last).</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">common.env_util.is_wrapped</span></code> and <code class="docutils literal notranslate"><span class="pre">common.env_util.unwrap_wrapper</span></code> functions for checking/unwrapping
an environment for specific wrapper.</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">env_is_wrapped()</span></code> method for <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code> to check if its environments are wrapped
with given Gym wrappers.</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">monitor_kwargs</span></code> parameter to <code class="docutils literal notranslate"><span class="pre">make_vec_env</span></code> and <code class="docutils literal notranslate"><span class="pre">make_atari_env</span></code></p></li>
<li><p>Wrap the environments automatically with a <code class="docutils literal notranslate"><span class="pre">Monitor</span></code> wrapper when possible.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">EvalCallback</span></code> now logs the success rate when available (<code class="docutils literal notranslate"><span class="pre">is_success</span></code> must be present in the info dict)</p></li>
<li><p>Added new wrappers to log images and matplotlib figures to tensorboard. (&#64;zampanteymedio)</p></li>
<li><p>Add support for text records to <code class="docutils literal notranslate"><span class="pre">Logger</span></code>. (&#64;lorenz-h)</p></li>
</ul>
</section>
<section id="id98">
<h5>Bug Fixes:<a class="headerlink" href="#id98" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed bug where code added VecTranspose on channel-first image environments (thanks &#64;qxcv)</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">DQN</span></code> predict method when using single <code class="docutils literal notranslate"><span class="pre">gym.Env</span></code> with <code class="docutils literal notranslate"><span class="pre">deterministic=False</span></code></p></li>
<li><p>Fixed bug that the arguments order of <code class="docutils literal notranslate"><span class="pre">explained_variance()</span></code> in <code class="docutils literal notranslate"><span class="pre">ppo.py</span></code> and <code class="docutils literal notranslate"><span class="pre">a2c.py</span></code> is not correct (&#64;thisray)</p></li>
<li><p>Fixed bug where full <code class="docutils literal notranslate"><span class="pre">HerReplayBuffer</span></code> leads to an index error. (&#64;megan-klaiber)</p></li>
<li><p>Fixed bug where replay buffer could not be saved if it was too big (&gt; 4 Gb) for python&lt;3.8 (thanks &#64;hn2)</p></li>
<li><p>Added informative <code class="docutils literal notranslate"><span class="pre">PPO</span></code> construction error in edge-case scenario where <code class="docutils literal notranslate"><span class="pre">n_steps</span> <span class="pre">*</span> <span class="pre">n_envs</span> <span class="pre">=</span> <span class="pre">1</span></code> (size of rollout buffer),
which otherwise causes downstream breaking errors in training (&#64;decodyng)</p></li>
<li><p>Fixed discrete observation space support when using multiple envs with A2C/PPO (thanks &#64;ardabbour)</p></li>
<li><p>Fixed a bug for TD3 delayed update (the update was off-by-one and not delayed when <code class="docutils literal notranslate"><span class="pre">train_freq=1</span></code>)</p></li>
<li><p>Fixed numpy warning (replaced <code class="docutils literal notranslate"><span class="pre">np.bool</span></code> with <code class="docutils literal notranslate"><span class="pre">bool</span></code>)</p></li>
<li><p>Fixed a bug where <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> was not normalizing the terminal observation</p></li>
<li><p>Fixed a bug where <code class="docutils literal notranslate"><span class="pre">VecTranspose</span></code> was not transposing the terminal observation</p></li>
<li><p>Fixed a bug where the terminal observation stored in the replay buffer was not the right one for off-policy algorithms</p></li>
<li><p>Fixed a bug where <code class="docutils literal notranslate"><span class="pre">action_noise</span></code> was not used when using <code class="docutils literal notranslate"><span class="pre">HER</span></code> (thanks &#64;ShangqunYu)</p></li>
</ul>
</section>
<section id="id99">
<h5>Deprecations:<a class="headerlink" href="#id99" title="Permalink to this heading"></a></h5>
</section>
<section id="id100">
<h5>Others:<a class="headerlink" href="#id100" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Add more issue templates</p></li>
<li><p>Add signatures to callable type annotations (&#64;ernestum)</p></li>
<li><p>Improve error message in <code class="docutils literal notranslate"><span class="pre">NatureCNN</span></code></p></li>
<li><p>Added checks for supported action spaces to improve clarity of error messages for the user</p></li>
<li><p>Renamed variables in the <code class="docutils literal notranslate"><span class="pre">train()</span></code> method of <code class="docutils literal notranslate"><span class="pre">SAC</span></code>, <code class="docutils literal notranslate"><span class="pre">TD3</span></code> and <code class="docutils literal notranslate"><span class="pre">DQN</span></code> to match SB3-Contrib.</p></li>
<li><p>Updated docker base image to Ubuntu 18.04</p></li>
<li><p>Set tensorboard min version to 2.2.0 (earlier version are apparently not working with PyTorch)</p></li>
<li><p>Added warning for <code class="docutils literal notranslate"><span class="pre">PPO</span></code> when <code class="docutils literal notranslate"><span class="pre">n_steps</span> <span class="pre">*</span> <span class="pre">n_envs</span></code> is not a multiple of <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> (last mini-batch truncated) (&#64;decodyng)</p></li>
<li><p>Removed some warnings in the tests</p></li>
</ul>
</section>
<section id="id101">
<h5>Documentation:<a class="headerlink" href="#id101" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Updated algorithm table</p></li>
<li><p>Minor docstring improvements regarding rollout (&#64;stheid)</p></li>
<li><p>Fix migration doc for <code class="docutils literal notranslate"><span class="pre">A2C</span></code> (epsilon parameter)</p></li>
<li><p>Fix <code class="docutils literal notranslate"><span class="pre">clip_range</span></code> docstring</p></li>
<li><p>Fix duplicated parameter in <code class="docutils literal notranslate"><span class="pre">EvalCallback</span></code> docstring (thanks &#64;tfederico)</p></li>
<li><p>Added example of learning rate schedule</p></li>
<li><p>Added SUMO-RL as example project (&#64;LucasAlegre)</p></li>
<li><p>Fix docstring of classes in atari_wrappers.py which were inside the constructor (&#64;LucasAlegre)</p></li>
<li><p>Added SB3-Contrib page</p></li>
<li><p>Fix bug in the example code of DQN (&#64;AptX395)</p></li>
<li><p>Add example on how to access the tensorboard summary writer directly. (&#64;lorenz-h)</p></li>
<li><p>Updated migration guide</p></li>
<li><p>Updated custom policy doc (separate policy architecture recommended)</p></li>
<li><p>Added a note about OpenCV headless version</p></li>
<li><p>Corrected typo on documentation (&#64;mschweizer)</p></li>
<li><p>Provide the environment when loading the model in the examples (&#64;lorepieri8)</p></li>
</ul>
</section>
</section>
<section id="pre-release-0-10-0-2020-10-28">
<h4>Pre-Release 0.10.0 (2020-10-28)<a class="headerlink" href="#pre-release-0-10-0-2020-10-28" title="Permalink to this heading"></a></h4>
<p><strong>HER with online and offline sampling, bug fixes for features extraction</strong></p>
<section id="id102">
<h5>Breaking Changes:<a class="headerlink" href="#id102" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p><strong>Warning:</strong> Renamed <code class="docutils literal notranslate"><span class="pre">common.cmd_util</span></code> to <code class="docutils literal notranslate"><span class="pre">common.env_util</span></code> for clarity (affects <code class="docutils literal notranslate"><span class="pre">make_vec_env</span></code> and <code class="docutils literal notranslate"><span class="pre">make_atari_env</span></code> functions)</p></li>
</ul>
</section>
<section id="id103">
<h5>New Features:<a class="headerlink" href="#id103" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Allow custom actor/critic network architectures using <code class="docutils literal notranslate"><span class="pre">net_arch=dict(qf=[400,</span> <span class="pre">300],</span> <span class="pre">pi=[64,</span> <span class="pre">64])</span></code> for off-policy algorithms (SAC, TD3, DDPG)</p></li>
<li><p>Added Hindsight Experience Replay <code class="docutils literal notranslate"><span class="pre">HER</span></code>. (&#64;megan-klaiber)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> now supports <code class="docutils literal notranslate"><span class="pre">gym.spaces.Dict</span></code> observation spaces</p></li>
<li><p>Support logging videos to Tensorboard (&#64;SwamyDev)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">share_features_extractor</span></code> argument to <code class="docutils literal notranslate"><span class="pre">SAC</span></code> and <code class="docutils literal notranslate"><span class="pre">TD3</span></code> policies</p></li>
</ul>
</section>
<section id="id104">
<h5>Bug Fixes:<a class="headerlink" href="#id104" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fix GAE computation for on-policy algorithms (off-by one for the last value) (thanks &#64;Wovchena)</p></li>
<li><p>Fixed potential issue when loading a different environment</p></li>
<li><p>Fix ignoring the exclude parameter when recording logs using json, csv or log as logging format (&#64;SwamyDev)</p></li>
<li><p>Make <code class="docutils literal notranslate"><span class="pre">make_vec_env</span></code> support the <code class="docutils literal notranslate"><span class="pre">env_kwargs</span></code> argument when using an env ID str (&#64;ManifoldFR)</p></li>
<li><p>Fix model creation initializing CUDA even when <cite>device=”cpu”</cite> is provided</p></li>
<li><p>Fix <code class="docutils literal notranslate"><span class="pre">check_env</span></code> not checking if the env has a Dict actionspace before calling <code class="docutils literal notranslate"><span class="pre">_check_nan</span></code> (&#64;wmmc88)</p></li>
<li><p>Update the check for spaces unsupported by Stable Baselines 3 to include checks on the action space (&#64;wmmc88)</p></li>
<li><p>Fixed features extractor bug for target network where the same net was shared instead
of being separate. This bug affects <code class="docutils literal notranslate"><span class="pre">SAC</span></code>, <code class="docutils literal notranslate"><span class="pre">DDPG</span></code> and <code class="docutils literal notranslate"><span class="pre">TD3</span></code> when using <code class="docutils literal notranslate"><span class="pre">CnnPolicy</span></code> (or custom features extractor)</p></li>
<li><p>Fixed a bug when passing an environment when loading a saved model with a <code class="docutils literal notranslate"><span class="pre">CnnPolicy</span></code>, the passed env was not wrapped properly
(the bug was introduced when implementing <code class="docutils literal notranslate"><span class="pre">HER</span></code> so it should not be present in previous versions)</p></li>
</ul>
</section>
<section id="id105">
<h5>Deprecations:<a class="headerlink" href="#id105" title="Permalink to this heading"></a></h5>
</section>
<section id="id106">
<h5>Others:<a class="headerlink" href="#id106" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Improved typing coverage</p></li>
<li><p>Improved error messages for unsupported spaces</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">.vscode</span></code> to the gitignore</p></li>
</ul>
</section>
<section id="id107">
<h5>Documentation:<a class="headerlink" href="#id107" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added first draft of migration guide</p></li>
<li><p>Added intro to <a class="reference external" href="https://github.com/HumanCompatibleAI/imitation">imitation</a> library (&#64;shwang)</p></li>
<li><p>Enabled doc for <code class="docutils literal notranslate"><span class="pre">CnnPolicies</span></code></p></li>
<li><p>Added advanced saving and loading example</p></li>
<li><p>Added base doc for exporting models</p></li>
<li><p>Added example for getting and setting model parameters</p></li>
</ul>
</section>
</section>
<section id="pre-release-0-9-0-2020-10-03">
<h4>Pre-Release 0.9.0 (2020-10-03)<a class="headerlink" href="#pre-release-0-9-0-2020-10-03" title="Permalink to this heading"></a></h4>
<p><strong>Bug fixes, get/set parameters  and improved docs</strong></p>
<section id="id108">
<h5>Breaking Changes:<a class="headerlink" href="#id108" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Removed <code class="docutils literal notranslate"><span class="pre">device</span></code> keyword argument of policies; use <code class="docutils literal notranslate"><span class="pre">policy.to(device)</span></code> instead. (&#64;qxcv)</p></li>
<li><p>Rename <code class="docutils literal notranslate"><span class="pre">BaseClass.get_torch_variables</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">BaseClass._get_torch_save_params</span></code> and <code class="docutils literal notranslate"><span class="pre">BaseClass.excluded_save_params</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">BaseClass._excluded_save_params</span></code></p></li>
<li><p>Renamed saved items <code class="docutils literal notranslate"><span class="pre">tensors</span></code> to <code class="docutils literal notranslate"><span class="pre">pytorch_variables</span></code> for clarity</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">make_atari_env</span></code>, <code class="docutils literal notranslate"><span class="pre">make_vec_env</span></code> and <code class="docutils literal notranslate"><span class="pre">set_random_seed</span></code> must be imported with (and not directly from <code class="docutils literal notranslate"><span class="pre">stable_baselines3.common</span></code>):</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">stable_baselines3.common.cmd_util</span> <span class="kn">import</span> <span class="n">make_atari_env</span><span class="p">,</span> <span class="n">make_vec_env</span>
<span class="kn">from</span> <span class="nn">stable_baselines3.common.utils</span> <span class="kn">import</span> <span class="n">set_random_seed</span>
</pre></div>
</div>
</section>
<section id="id109">
<h5>New Features:<a class="headerlink" href="#id109" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added <code class="docutils literal notranslate"><span class="pre">unwrap_vec_wrapper()</span></code> to <code class="docutils literal notranslate"><span class="pre">common.vec_env</span></code> to extract <code class="docutils literal notranslate"><span class="pre">VecEnvWrapper</span></code> if needed</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">StopTrainingOnMaxEpisodes</span></code> to callback collection (&#64;xicocaio)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">device</span></code> keyword argument to <code class="docutils literal notranslate"><span class="pre">BaseAlgorithm.load()</span></code> (&#64;liorcohen5)</p></li>
<li><p>Callbacks have access to rollout collection locals as in SB2. (&#64;PartiallyTyped)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">get_parameters</span></code> and <code class="docutils literal notranslate"><span class="pre">set_parameters</span></code> for accessing/setting parameters of the agent</p></li>
<li><p>Added actor/critic loss logging for TD3. (&#64;mloo3)</p></li>
</ul>
</section>
<section id="id110">
<h5>Bug Fixes:<a class="headerlink" href="#id110" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added <code class="docutils literal notranslate"><span class="pre">unwrap_vec_wrapper()</span></code> to <code class="docutils literal notranslate"><span class="pre">common.vec_env</span></code> to extract <code class="docutils literal notranslate"><span class="pre">VecEnvWrapper</span></code> if needed</p></li>
<li><p>Fixed a bug where the environment was reset twice when using <code class="docutils literal notranslate"><span class="pre">evaluate_policy</span></code></p></li>
<li><p>Fix logging of <code class="docutils literal notranslate"><span class="pre">clip_fraction</span></code> in PPO (&#64;diditforlulz273)</p></li>
<li><p>Fixed a bug where cuda support was wrongly checked when passing the GPU index, e.g., <code class="docutils literal notranslate"><span class="pre">device=&quot;cuda:0&quot;</span></code> (&#64;liorcohen5)</p></li>
<li><p>Fixed a bug when the random seed was not properly set on cuda when passing the GPU index</p></li>
</ul>
</section>
<section id="id111">
<h5>Deprecations:<a class="headerlink" href="#id111" title="Permalink to this heading"></a></h5>
</section>
<section id="id112">
<h5>Others:<a class="headerlink" href="#id112" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Improve typing coverage of the <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code></p></li>
<li><p>Fix type annotation of <code class="docutils literal notranslate"><span class="pre">make_vec_env</span></code> (&#64;ManifoldFR)</p></li>
<li><p>Removed <code class="docutils literal notranslate"><span class="pre">AlreadySteppingError</span></code> and <code class="docutils literal notranslate"><span class="pre">NotSteppingError</span></code> that were not used</p></li>
<li><p>Fixed typos in SAC and TD3</p></li>
<li><p>Reorganized functions for clarity in <code class="docutils literal notranslate"><span class="pre">BaseClass</span></code> (save/load functions close to each other, private
functions at top)</p></li>
<li><p>Clarified docstrings on what is saved and loaded to/from files</p></li>
<li><p>Simplified <code class="docutils literal notranslate"><span class="pre">save_to_zip_file</span></code> function by removing duplicate code</p></li>
<li><p>Store library version along with the saved models</p></li>
<li><p>DQN loss is now logged</p></li>
</ul>
</section>
<section id="id113">
<h5>Documentation:<a class="headerlink" href="#id113" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added <code class="docutils literal notranslate"><span class="pre">StopTrainingOnMaxEpisodes</span></code> details and example (&#64;xicocaio)</p></li>
<li><p>Updated custom policy section (added custom features extractor example)</p></li>
<li><p>Re-enable <code class="docutils literal notranslate"><span class="pre">sphinx_autodoc_typehints</span></code></p></li>
<li><p>Updated doc style for type hints and remove duplicated type hints</p></li>
</ul>
</section>
</section>
<section id="pre-release-0-8-0-2020-08-03">
<h4>Pre-Release 0.8.0 (2020-08-03)<a class="headerlink" href="#pre-release-0-8-0-2020-08-03" title="Permalink to this heading"></a></h4>
<p><strong>DQN, DDPG, bug fixes and performance matching for Atari games</strong></p>
<section id="id114">
<h5>Breaking Changes:<a class="headerlink" href="#id114" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">AtariWrapper</span></code> and other Atari wrappers were updated to match SB2 ones</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">save_replay_buffer</span></code> now receives as argument the file path instead of the folder path (&#64;tirafesi)</p></li>
<li><p>Refactored <code class="docutils literal notranslate"><span class="pre">Critic</span></code> class for <code class="docutils literal notranslate"><span class="pre">TD3</span></code> and <code class="docutils literal notranslate"><span class="pre">SAC</span></code>, it is now called <code class="docutils literal notranslate"><span class="pre">ContinuousCritic</span></code>
and has an additional parameter <code class="docutils literal notranslate"><span class="pre">n_critics</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SAC</span></code> and <code class="docutils literal notranslate"><span class="pre">TD3</span></code> now accept an arbitrary number of critics (e.g. <code class="docutils literal notranslate"><span class="pre">policy_kwargs=dict(n_critics=3)</span></code>)
instead of only 2 previously</p></li>
</ul>
</section>
<section id="id115">
<h5>New Features:<a class="headerlink" href="#id115" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added <code class="docutils literal notranslate"><span class="pre">DQN</span></code> Algorithm (&#64;Artemis-Skade)</p></li>
<li><p>Buffer dtype is now set according to action and observation spaces for <code class="docutils literal notranslate"><span class="pre">ReplayBuffer</span></code></p></li>
<li><p>Added warning when allocation of a buffer may exceed the available memory of the system
when <code class="docutils literal notranslate"><span class="pre">psutil</span></code> is available</p></li>
<li><p>Saving models now automatically creates the necessary folders and raises appropriate warnings (&#64;PartiallyTyped)</p></li>
<li><p>Refactored opening paths for saving and loading to use strings, pathlib or io.BufferedIOBase (&#64;PartiallyTyped)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">DDPG</span></code> algorithm as a special case of <code class="docutils literal notranslate"><span class="pre">TD3</span></code>.</p></li>
<li><p>Introduced <code class="docutils literal notranslate"><span class="pre">BaseModel</span></code> abstract parent for <code class="docutils literal notranslate"><span class="pre">BasePolicy</span></code>, which critics inherit from.</p></li>
</ul>
</section>
<section id="id116">
<h5>Bug Fixes:<a class="headerlink" href="#id116" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed a bug in the <code class="docutils literal notranslate"><span class="pre">close()</span></code> method of <code class="docutils literal notranslate"><span class="pre">SubprocVecEnv</span></code>, causing wrappers further down in the wrapper stack to not be closed. (&#64;NeoExtended)</p></li>
<li><p>Fix target for updating q values in SAC: the entropy term was not conditioned by terminals states</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">cloudpickle.load</span></code> instead of <code class="docutils literal notranslate"><span class="pre">pickle.load</span></code> in <code class="docutils literal notranslate"><span class="pre">CloudpickleWrapper</span></code>. (&#64;shwang)</p></li>
<li><p>Fixed a bug with orthogonal initialization when <cite>bias=False</cite> in custom policy (&#64;rk37)</p></li>
<li><p>Fixed approximate entropy calculation in PPO and A2C. (&#64;andyshih12)</p></li>
<li><p>Fixed DQN target network sharing features extractor with the main network.</p></li>
<li><p>Fixed storing correct <code class="docutils literal notranslate"><span class="pre">dones</span></code> in on-policy algorithm rollout collection. (&#64;andyshih12)</p></li>
<li><p>Fixed number of filters in final convolutional layer in NatureCNN to match original implementation.</p></li>
</ul>
</section>
<section id="id117">
<h5>Deprecations:<a class="headerlink" href="#id117" title="Permalink to this heading"></a></h5>
</section>
<section id="id118">
<h5>Others:<a class="headerlink" href="#id118" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Refactored off-policy algorithm to share the same <code class="docutils literal notranslate"><span class="pre">.learn()</span></code> method</p></li>
<li><p>Split the <code class="docutils literal notranslate"><span class="pre">collect_rollout()</span></code> method for off-policy algorithms</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">_on_step()</span></code> for off-policy base class</p></li>
<li><p>Optimized replay buffer size by removing the need of <code class="docutils literal notranslate"><span class="pre">next_observations</span></code> numpy array</p></li>
<li><p>Optimized polyak updates (1.5-1.95 speedup) through inplace operations (&#64;PartiallyTyped)</p></li>
<li><p>Switch to <code class="docutils literal notranslate"><span class="pre">black</span></code> codestyle and added <code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">format</span></code>, <code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">check-codestyle</span></code> and <code class="docutils literal notranslate"><span class="pre">commit-checks</span></code></p></li>
<li><p>Ignored errors from newer pytype version</p></li>
<li><p>Added a check when using <code class="docutils literal notranslate"><span class="pre">gSDE</span></code></p></li>
<li><p>Removed codacy dependency from Dockerfile</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">common.sb2_compat.RMSpropTFLike</span></code> optimizer, which corresponds closer to the implementation of RMSprop from Tensorflow.</p></li>
</ul>
</section>
<section id="id119">
<h5>Documentation:<a class="headerlink" href="#id119" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Updated notebook links</p></li>
<li><p>Fixed a typo in the section of Enjoy a Trained Agent, in RL Baselines3 Zoo README. (&#64;blurLake)</p></li>
<li><p>Added Unity reacher to the projects page (&#64;koulakis)</p></li>
<li><p>Added PyBullet colab notebook</p></li>
<li><p>Fixed typo in PPO example code (&#64;joeljosephjin)</p></li>
<li><p>Fixed typo in custom policy doc (&#64;RaphaelWag)</p></li>
</ul>
</section>
</section>
<section id="pre-release-0-7-0-2020-06-10">
<h4>Pre-Release 0.7.0 (2020-06-10)<a class="headerlink" href="#pre-release-0-7-0-2020-06-10" title="Permalink to this heading"></a></h4>
<p><strong>Hotfix for PPO/A2C + gSDE, internal refactoring and bug fixes</strong></p>
<section id="id120">
<h5>Breaking Changes:<a class="headerlink" href="#id120" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">render()</span></code> method of <code class="docutils literal notranslate"><span class="pre">VecEnvs</span></code> now only accept one argument: <code class="docutils literal notranslate"><span class="pre">mode</span></code></p></li>
<li><p>Created new file common/torch_layers.py, similar to SB refactoring</p>
<ul>
<li><p>Contains all PyTorch network layer definitions and features extractors: <code class="docutils literal notranslate"><span class="pre">MlpExtractor</span></code>, <code class="docutils literal notranslate"><span class="pre">create_mlp</span></code>, <code class="docutils literal notranslate"><span class="pre">NatureCNN</span></code></p></li>
</ul>
</li>
<li><p>Renamed <code class="docutils literal notranslate"><span class="pre">BaseRLModel</span></code> to <code class="docutils literal notranslate"><span class="pre">BaseAlgorithm</span></code> (along with offpolicy and onpolicy variants)</p></li>
<li><p>Moved on-policy and off-policy base algorithms to <code class="docutils literal notranslate"><span class="pre">common/on_policy_algorithm.py</span></code> and <code class="docutils literal notranslate"><span class="pre">common/off_policy_algorithm.py</span></code>, respectively.</p></li>
<li><p>Moved <code class="docutils literal notranslate"><span class="pre">PPOPolicy</span></code> to <code class="docutils literal notranslate"><span class="pre">ActorCriticPolicy</span></code> in common/policies.py</p></li>
<li><p>Moved <code class="docutils literal notranslate"><span class="pre">PPO</span></code> (algorithm class) into <code class="docutils literal notranslate"><span class="pre">OnPolicyAlgorithm</span></code> (<code class="docutils literal notranslate"><span class="pre">common/on_policy_algorithm.py</span></code>), to be shared with A2C</p></li>
<li><p>Moved following functions from <code class="docutils literal notranslate"><span class="pre">BaseAlgorithm</span></code>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">_load_from_file</span></code> to <code class="docutils literal notranslate"><span class="pre">load_from_zip_file</span></code> (save_util.py)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">_save_to_file_zip</span></code> to <code class="docutils literal notranslate"><span class="pre">save_to_zip_file</span></code> (save_util.py)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">safe_mean</span></code> to <code class="docutils literal notranslate"><span class="pre">safe_mean</span></code> (utils.py)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">check_env</span></code> to <code class="docutils literal notranslate"><span class="pre">check_for_correct_spaces</span></code> (utils.py. Renamed to avoid confusion with environment checker tools)</p></li>
</ul>
</li>
<li><p>Moved static function <code class="docutils literal notranslate"><span class="pre">_is_vectorized_observation</span></code> from common/policies.py to common/utils.py under name <code class="docutils literal notranslate"><span class="pre">is_vectorized_observation</span></code>.</p></li>
<li><p>Removed <code class="docutils literal notranslate"><span class="pre">{save,load}_running_average</span></code> functions of <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> in favor of <code class="docutils literal notranslate"><span class="pre">load/save</span></code>.</p></li>
<li><p>Removed <code class="docutils literal notranslate"><span class="pre">use_gae</span></code> parameter from <code class="docutils literal notranslate"><span class="pre">RolloutBuffer.compute_returns_and_advantage</span></code>.</p></li>
</ul>
</section>
<section id="id121">
<h5>New Features:<a class="headerlink" href="#id121" title="Permalink to this heading"></a></h5>
</section>
<section id="id122">
<h5>Bug Fixes:<a class="headerlink" href="#id122" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">render()</span></code> method for <code class="docutils literal notranslate"><span class="pre">VecEnvs</span></code></p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">seed()</span></code> method for <code class="docutils literal notranslate"><span class="pre">SubprocVecEnv</span></code></p></li>
<li><p>Fixed loading on GPU for testing when using gSDE and <code class="docutils literal notranslate"><span class="pre">deterministic=False</span></code></p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">register_policy</span></code> to allow re-registering same policy for same sub-class (i.e. assign same value to same key).</p></li>
<li><p>Fixed a bug where the gradient was passed when using <code class="docutils literal notranslate"><span class="pre">gSDE</span></code> with <code class="docutils literal notranslate"><span class="pre">PPO</span></code>/<code class="docutils literal notranslate"><span class="pre">A2C</span></code>, this does not affect <code class="docutils literal notranslate"><span class="pre">SAC</span></code></p></li>
</ul>
</section>
<section id="id123">
<h5>Deprecations:<a class="headerlink" href="#id123" title="Permalink to this heading"></a></h5>
</section>
<section id="id124">
<h5>Others:<a class="headerlink" href="#id124" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Re-enable unsafe <code class="docutils literal notranslate"><span class="pre">fork</span></code> start method in the tests (was causing a deadlock with tensorflow)</p></li>
<li><p>Added a test for seeding <code class="docutils literal notranslate"><span class="pre">SubprocVecEnv</span></code> and rendering</p></li>
<li><p>Fixed reference in NatureCNN (pointed to older version with different network architecture)</p></li>
<li><p>Fixed comments saying “CxWxH” instead of “CxHxW” (same style as in torch docs / commonly used)</p></li>
<li><p>Added bit further comments on register/getting policies (“MlpPolicy”, “CnnPolicy”).</p></li>
<li><p>Renamed <code class="docutils literal notranslate"><span class="pre">progress</span></code> (value from 1 in start of training to 0 in end) to <code class="docutils literal notranslate"><span class="pre">progress_remaining</span></code>.</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">policies.py</span></code> files for A2C/PPO, which define MlpPolicy/CnnPolicy (renamed ActorCriticPolicies).</p></li>
<li><p>Added some missing tests for <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code>, <code class="docutils literal notranslate"><span class="pre">VecCheckNan</span></code> and <code class="docutils literal notranslate"><span class="pre">PPO</span></code>.</p></li>
</ul>
</section>
<section id="id125">
<h5>Documentation:<a class="headerlink" href="#id125" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added a paragraph on “MlpPolicy”/”CnnPolicy” and policy naming scheme under “Developer Guide”</p></li>
<li><p>Fixed second-level listing in changelog</p></li>
</ul>
</section>
</section>
<section id="pre-release-0-6-0-2020-06-01">
<h4>Pre-Release 0.6.0 (2020-06-01)<a class="headerlink" href="#pre-release-0-6-0-2020-06-01" title="Permalink to this heading"></a></h4>
<p><strong>Tensorboard support, refactored logger</strong></p>
<section id="id126">
<h5>Breaking Changes:<a class="headerlink" href="#id126" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Remove State-Dependent Exploration (SDE) support for <code class="docutils literal notranslate"><span class="pre">TD3</span></code></p></li>
<li><p>Methods were renamed in the logger:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">logkv</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">record</span></code>, <code class="docutils literal notranslate"><span class="pre">writekvs</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">write</span></code>, <code class="docutils literal notranslate"><span class="pre">writeseq</span></code> -&gt;  <code class="docutils literal notranslate"><span class="pre">write_sequence</span></code>,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">logkvs</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">record_dict</span></code>, <code class="docutils literal notranslate"><span class="pre">dumpkvs</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">dump</span></code>,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">getkvs</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">get_log_dict</span></code>, <code class="docutils literal notranslate"><span class="pre">logkv_mean</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">record_mean</span></code>,</p></li>
</ul>
</li>
</ul>
</section>
<section id="id127">
<h5>New Features:<a class="headerlink" href="#id127" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added env checker (Sync with Stable Baselines)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">VecCheckNan</span></code> and <code class="docutils literal notranslate"><span class="pre">VecVideoRecorder</span></code> (Sync with Stable Baselines)</p></li>
<li><p>Added determinism tests</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">cmd_util</span></code> and <code class="docutils literal notranslate"><span class="pre">atari_wrappers</span></code></p></li>
<li><p>Added support for <code class="docutils literal notranslate"><span class="pre">MultiDiscrete</span></code> and <code class="docutils literal notranslate"><span class="pre">MultiBinary</span></code> observation spaces (&#64;rolandgvc)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">MultiCategorical</span></code> and <code class="docutils literal notranslate"><span class="pre">Bernoulli</span></code> distributions for PPO/A2C (&#64;rolandgvc)</p></li>
<li><p>Added support for logging to tensorboard (&#64;rolandgvc)</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">VectorizedActionNoise</span></code> for continuous vectorized environments (&#64;PartiallyTyped)</p></li>
<li><p>Log evaluation in the <code class="docutils literal notranslate"><span class="pre">EvalCallback</span></code> using the logger</p></li>
</ul>
</section>
<section id="id128">
<h5>Bug Fixes:<a class="headerlink" href="#id128" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed a bug that prevented model trained on cpu to be loaded on gpu</p></li>
<li><p>Fixed version number that had a new line included</p></li>
<li><p>Fixed weird seg fault in docker image due to FakeImageEnv by reducing screen size</p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">sde_sample_freq</span></code> that was not taken into account for SAC</p></li>
<li><p>Pass logger module to <code class="docutils literal notranslate"><span class="pre">BaseCallback</span></code> otherwise they cannot write in the one used by the algorithms</p></li>
</ul>
</section>
<section id="id129">
<h5>Deprecations:<a class="headerlink" href="#id129" title="Permalink to this heading"></a></h5>
</section>
<section id="id130">
<h5>Others:<a class="headerlink" href="#id130" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Renamed to Stable-Baseline3</p></li>
<li><p>Added Dockerfile</p></li>
<li><p>Sync <code class="docutils literal notranslate"><span class="pre">VecEnvs</span></code> with Stable-Baselines</p></li>
<li><p>Update requirement: <code class="docutils literal notranslate"><span class="pre">gym&gt;=0.17</span></code></p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">.readthedoc.yml</span></code> file</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">flake8</span></code> and <code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">lint</span></code> command</p></li>
<li><p>Added Github workflow</p></li>
<li><p>Added warning when passing both <code class="docutils literal notranslate"><span class="pre">train_freq</span></code> and <code class="docutils literal notranslate"><span class="pre">n_episodes_rollout</span></code> to Off-Policy Algorithms</p></li>
</ul>
</section>
<section id="id131">
<h5>Documentation:<a class="headerlink" href="#id131" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added most documentation (adapted from Stable-Baselines)</p></li>
<li><p>Added link to CONTRIBUTING.md in the README (&#64;kinalmehta)</p></li>
<li><p>Added gSDE project and update docstrings accordingly</p></li>
<li><p>Fix <code class="docutils literal notranslate"><span class="pre">TD3</span></code> example code block</p></li>
</ul>
</section>
</section>
<section id="pre-release-0-5-0-2020-05-05">
<h4>Pre-Release 0.5.0 (2020-05-05)<a class="headerlink" href="#pre-release-0-5-0-2020-05-05" title="Permalink to this heading"></a></h4>
<p><strong>CnnPolicy support for image observations, complete saving/loading for policies</strong></p>
<section id="id132">
<h5>Breaking Changes:<a class="headerlink" href="#id132" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Previous loading of policy weights is broken and replace by the new saving/loading for policy</p></li>
</ul>
</section>
<section id="id133">
<h5>New Features:<a class="headerlink" href="#id133" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Added <code class="docutils literal notranslate"><span class="pre">optimizer_class</span></code> and <code class="docutils literal notranslate"><span class="pre">optimizer_kwargs</span></code> to <code class="docutils literal notranslate"><span class="pre">policy_kwargs</span></code> in order to easily
customizer optimizers</p></li>
<li><p>Complete independent save/load for policies</p></li>
<li><p>Add <code class="docutils literal notranslate"><span class="pre">CnnPolicy</span></code> and <code class="docutils literal notranslate"><span class="pre">VecTransposeImage</span></code> to support images as input</p></li>
</ul>
</section>
<section id="id134">
<h5>Bug Fixes:<a class="headerlink" href="#id134" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">reset_num_timesteps</span></code> behavior, so <code class="docutils literal notranslate"><span class="pre">env.reset()</span></code> is not called if <code class="docutils literal notranslate"><span class="pre">reset_num_timesteps=True</span></code></p></li>
<li><p>Fixed <code class="docutils literal notranslate"><span class="pre">squashed_output</span></code> that was not pass to policy constructor for <code class="docutils literal notranslate"><span class="pre">SAC</span></code> and <code class="docutils literal notranslate"><span class="pre">TD3</span></code> (would result in scaled actions for unscaled action spaces)</p></li>
</ul>
</section>
<section id="id135">
<h5>Deprecations:<a class="headerlink" href="#id135" title="Permalink to this heading"></a></h5>
</section>
<section id="id136">
<h5>Others:<a class="headerlink" href="#id136" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Cleanup rollout return</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">get_device</span></code> util to manage PyTorch devices</p></li>
<li><p>Added type hints to logger + use f-strings</p></li>
</ul>
</section>
<section id="id137">
<h5>Documentation:<a class="headerlink" href="#id137" title="Permalink to this heading"></a></h5>
</section>
</section>
<section id="pre-release-0-4-0-2020-02-14">
<h4>Pre-Release 0.4.0 (2020-02-14)<a class="headerlink" href="#pre-release-0-4-0-2020-02-14" title="Permalink to this heading"></a></h4>
<p><strong>Proper pre-processing, independent save/load for policies</strong></p>
<section id="id138">
<h5>Breaking Changes:<a class="headerlink" href="#id138" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Removed CEMRL</p></li>
<li><p>Model saved with previous versions cannot be loaded (because of the pre-preprocessing)</p></li>
</ul>
</section>
<section id="id139">
<h5>New Features:<a class="headerlink" href="#id139" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Add support for <code class="docutils literal notranslate"><span class="pre">Discrete</span></code> observation spaces</p></li>
<li><p>Add saving/loading for policy weights, so the policy can be used without the model</p></li>
</ul>
</section>
<section id="id140">
<h5>Bug Fixes:<a class="headerlink" href="#id140" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fix type hint for activation functions</p></li>
</ul>
</section>
<section id="id141">
<h5>Deprecations:<a class="headerlink" href="#id141" title="Permalink to this heading"></a></h5>
</section>
<section id="id142">
<h5>Others:<a class="headerlink" href="#id142" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Refactor handling of observation and action spaces</p></li>
<li><p>Refactored features extraction to have proper preprocessing</p></li>
<li><p>Refactored action distributions</p></li>
</ul>
</section>
</section>
<section id="pre-release-0-3-0-2020-02-14">
<h4>Pre-Release 0.3.0 (2020-02-14)<a class="headerlink" href="#pre-release-0-3-0-2020-02-14" title="Permalink to this heading"></a></h4>
<p><strong>Bug fixes, sync with Stable-Baselines, code cleanup</strong></p>
<section id="id143">
<h5>Breaking Changes:<a class="headerlink" href="#id143" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Removed default seed</p></li>
<li><p>Bump dependencies (PyTorch and Gym)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">predict()</span></code> now returns a tuple to match Stable-Baselines behavior</p></li>
</ul>
</section>
<section id="id144">
<h5>New Features:<a class="headerlink" href="#id144" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Better logging for <code class="docutils literal notranslate"><span class="pre">SAC</span></code> and <code class="docutils literal notranslate"><span class="pre">PPO</span></code></p></li>
</ul>
</section>
<section id="id145">
<h5>Bug Fixes:<a class="headerlink" href="#id145" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Synced callbacks with Stable-Baselines</p></li>
<li><p>Fixed colors in <code class="docutils literal notranslate"><span class="pre">results_plotter</span></code></p></li>
<li><p>Fix entropy computation (now summed over action dim)</p></li>
</ul>
</section>
<section id="id146">
<h5>Others:<a class="headerlink" href="#id146" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>SAC with SDE now sample only one matrix</p></li>
<li><p>Added <code class="docutils literal notranslate"><span class="pre">clip_mean</span></code> parameter to SAC policy</p></li>
<li><p>Buffers now return <code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code></p></li>
<li><p>More typing</p></li>
<li><p>Add test for <code class="docutils literal notranslate"><span class="pre">expln</span></code></p></li>
<li><p>Renamed <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> to <code class="docutils literal notranslate"><span class="pre">lr_schedule</span></code></p></li>
<li><p>Add <code class="docutils literal notranslate"><span class="pre">version.txt</span></code></p></li>
<li><p>Add more tests for distribution</p></li>
</ul>
</section>
<section id="id147">
<h5>Documentation:<a class="headerlink" href="#id147" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Deactivated <code class="docutils literal notranslate"><span class="pre">sphinx_autodoc_typehints</span></code> extension</p></li>
</ul>
</section>
</section>
<section id="pre-release-0-2-0-2020-02-14">
<h4>Pre-Release 0.2.0 (2020-02-14)<a class="headerlink" href="#pre-release-0-2-0-2020-02-14" title="Permalink to this heading"></a></h4>
<p><strong>Python 3.6+ required, type checking, callbacks, doc build</strong></p>
<section id="id148">
<h5>Breaking Changes:<a class="headerlink" href="#id148" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Python 2 support was dropped, Stable Baselines3 now requires Python 3.6 or above</p></li>
<li><p>Return type of <code class="docutils literal notranslate"><span class="pre">evaluation.evaluate_policy()</span></code> has been changed</p></li>
<li><p>Refactored the replay buffer to avoid transformation between PyTorch and NumPy</p></li>
<li><p>Created <cite>OffPolicyRLModel</cite> base class</p></li>
<li><p>Remove deprecated JSON format for <cite>Monitor</cite></p></li>
</ul>
</section>
<section id="id149">
<h5>New Features:<a class="headerlink" href="#id149" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Add <code class="docutils literal notranslate"><span class="pre">seed()</span></code> method to <code class="docutils literal notranslate"><span class="pre">VecEnv</span></code> class</p></li>
<li><p>Add support for Callback (cf <a class="reference external" href="https://github.com/hill-a/stable-baselines/pull/644">https://github.com/hill-a/stable-baselines/pull/644</a>)</p></li>
<li><p>Add methods for saving and loading replay buffer</p></li>
<li><p>Add <code class="docutils literal notranslate"><span class="pre">extend()</span></code> method to the buffers</p></li>
<li><p>Add <code class="docutils literal notranslate"><span class="pre">get_vec_normalize_env()</span></code> to <code class="docutils literal notranslate"><span class="pre">BaseRLModel</span></code> to retrieve <code class="docutils literal notranslate"><span class="pre">VecNormalize</span></code> wrapper when it exists</p></li>
<li><p>Add <code class="docutils literal notranslate"><span class="pre">results_plotter</span></code> from Stable Baselines</p></li>
<li><p>Improve <code class="docutils literal notranslate"><span class="pre">predict()</span></code> method to handle different type of observations (single, vectorized, …)</p></li>
</ul>
</section>
<section id="id150">
<h5>Bug Fixes:<a class="headerlink" href="#id150" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Fix loading model on CPU that were trained on GPU</p></li>
<li><p>Fix <code class="docutils literal notranslate"><span class="pre">reset_num_timesteps</span></code> that was not used</p></li>
<li><p>Fix entropy computation for squashed Gaussian (approximate it now)</p></li>
<li><p>Fix seeding when using multiple environments (different seed per env)</p></li>
</ul>
</section>
<section id="id151">
<h5>Others:<a class="headerlink" href="#id151" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Add type check</p></li>
<li><p>Converted all format string to f-strings</p></li>
<li><p>Add test for <code class="docutils literal notranslate"><span class="pre">OrnsteinUhlenbeckActionNoise</span></code></p></li>
<li><p>Add type aliases in <code class="docutils literal notranslate"><span class="pre">common.type_aliases</span></code></p></li>
</ul>
</section>
<section id="id152">
<h5>Documentation:<a class="headerlink" href="#id152" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>fix documentation build</p></li>
</ul>
</section>
</section>
<section id="pre-release-0-1-0-2020-01-20">
<h4>Pre-Release 0.1.0 (2020-01-20)<a class="headerlink" href="#pre-release-0-1-0-2020-01-20" title="Permalink to this heading"></a></h4>
<p><strong>First Release: base algorithms and state-dependent exploration</strong></p>
<section id="id153">
<h5>New Features:<a class="headerlink" href="#id153" title="Permalink to this heading"></a></h5>
<ul class="simple">
<li><p>Initial release of A2C, CEM-RL, PPO, SAC and TD3, working only with <code class="docutils literal notranslate"><span class="pre">Box</span></code> input space</p></li>
<li><p>State-Dependent Exploration (SDE) for A2C, PPO, SAC and TD3</p></li>
</ul>
</section>
</section>
<section id="maintainers">
<h4>Maintainers<a class="headerlink" href="#maintainers" title="Permalink to this heading"></a></h4>
<p>Stable-Baselines3 is currently maintained by <a class="reference external" href="https://araffin.github.io/">Antonin Raffin</a> (aka <a class="reference external" href="https://github.com/araffin">&#64;araffin</a>), <a class="reference external" href="https://github.com/hill-a">Ashley Hill</a> (aka &#64;hill-a),
<a class="reference external" href="https://github.com/ernestum">Maximilian Ernestus</a> (aka &#64;ernestum), <a class="reference external" href="https://gleave.me/">Adam Gleave</a> (<a class="reference external" href="https://github.com/adamgleave">&#64;AdamGleave</a>), <a class="reference external" href="https://github.com/Miffyli">Anssi Kanervisto</a> (aka <a class="reference external" href="https://github.com/Miffyli">&#64;Miffyli</a>)
and <a class="reference external" href="https://gallouedec.com/">Quentin Gallouédec</a> (aka &#64;qgallouedec).</p>
</section>
<section id="contributors">
<h4>Contributors:<a class="headerlink" href="#contributors" title="Permalink to this heading"></a></h4>
<p>In random order…</p>
<p>Thanks to the maintainers of V2: &#64;hill-a &#64;enerijunior &#64;AdamGleave &#64;Miffyli</p>
<p>And all the contributors:
&#64;taymuur &#64;bjmuld &#64;iambenzo &#64;iandanforth &#64;r7vme &#64;brendenpetersen &#64;huvar &#64;abhiskk &#64;JohannesAck
&#64;EliasHasle &#64;mrakgr &#64;Bleyddyn &#64;antoine-galataud &#64;junhyeokahn &#64;AdamGleave &#64;keshaviyengar &#64;tperol
&#64;XMaster96 &#64;kantneel &#64;Pastafarianist &#64;GerardMaggiolino &#64;PatrickWalter214 &#64;yutingsz &#64;sc420 &#64;Aaahh &#64;billtubbs
&#64;Miffyli &#64;dwiel &#64;miguelrass &#64;qxcv &#64;jaberkow &#64;eavelardev &#64;ruifeng96150 &#64;pedrohbtp &#64;srivatsankrishnan &#64;evilsocket
&#64;MarvineGothic &#64;jdossgollin &#64;stheid &#64;SyllogismRXS &#64;rusu24edward &#64;jbulow &#64;Antymon &#64;seheevic &#64;justinkterry &#64;edbeeching
&#64;flodorner &#64;KuKuXia &#64;NeoExtended &#64;PartiallyTyped &#64;mmcenta &#64;richardwu &#64;kinalmehta &#64;rolandgvc &#64;tkelestemur &#64;mloo3
&#64;tirafesi &#64;blurLake &#64;koulakis &#64;joeljosephjin &#64;shwang &#64;rk37 &#64;andyshih12 &#64;RaphaelWag &#64;xicocaio
&#64;diditforlulz273 &#64;liorcohen5 &#64;ManifoldFR &#64;mloo3 &#64;SwamyDev &#64;wmmc88 &#64;megan-klaiber &#64;thisray
&#64;tfederico &#64;hn2 &#64;LucasAlegre &#64;AptX395 &#64;zampanteymedio &#64;JadenTravnik &#64;decodyng &#64;ardabbour &#64;lorenz-h &#64;mschweizer &#64;lorepieri8 &#64;vwxyzjn
&#64;ShangqunYu &#64;PierreExeter &#64;JacopoPan &#64;ltbd78 &#64;tom-doerr &#64;Atlis &#64;liusida &#64;09tangriro &#64;amy12xx &#64;juancroldan
&#64;benblack769 &#64;bstee615 &#64;c-rizz &#64;skandermoalla &#64;MihaiAnca13 &#64;davidblom603 &#64;ayeright &#64;cyprienc
&#64;wkirgsn &#64;AechPro &#64;CUN-bjy &#64;batu &#64;IljaAvadiev &#64;timokau &#64;kachayev &#64;cleversonahum
&#64;eleurent &#64;ac-93 &#64;cove9988 &#64;theDebugger811 &#64;hsuehch &#64;Demetrio92 &#64;thomasgubler &#64;IperGiove &#64;ScheiklP
&#64;simoninithomas &#64;armandpl &#64;manuel-delverme &#64;Gautam-J &#64;gianlucadecola &#64;buoyancy99 &#64;caburu &#64;xy9485
&#64;Gregwar &#64;ycheng517 &#64;quantitative-technologies &#64;bcollazo &#64;git-thor &#64;TibiGG &#64;cool-RR &#64;MWeltevrede
&#64;carlosluis &#64;arjun-kg &#64;tlpss &#64;JonathanKuelz &#64;Gabo-Tor &#64;iwishiwasaneagle
&#64;Melanol &#64;qgallouedec &#64;francescoluciano &#64;jlp-ue &#64;burakdmb &#64;timothe-chaumont &#64;honglu2875
&#64;anand-bala &#64;hughperkins &#64;sidney-tio &#64;AlexPasqua &#64;dominicgkerr &#64;Akhilez &#64;Rocamonde &#64;tobirohrer &#64;ZikangXiong &#64;ReHoss
&#64;DavyMorgan &#64;luizapozzobon &#64;Bonifatius94 &#64;theSquaredError &#64;harveybellini &#64;DavyMorgan &#64;FieteO &#64;jonasreiher &#64;npit &#64;WeberSamuel &#64;troiganto
&#64;lutogniew &#64;lbergmann1 &#64;lukashass &#64;BertrandDecoster &#64;pseudo-rnd-thoughts &#64;stefanbschneider &#64;kyle-he &#64;PatrickHelm &#64;corentinlger</p>
</section>
</section>
<span id="document-misc/projects"></span><section id="projects">
<span id="id1"></span><h3>Projects<a class="headerlink" href="#projects" title="Permalink to this heading"></a></h3>
<p>This is a list of projects using stable-baselines3.
Please tell us, if you want your project to appear on this page ;)</p>
<section id="drivergym">
<h4>DriverGym<a class="headerlink" href="#drivergym" title="Permalink to this heading"></a></h4>
<p>An open-source Gym-compatible environment specifically tailored for developing RL algorithms for autonomous driving. DriverGym provides access to more than 1000 hours of expert logged data and also supports reactive and data-driven agent behavior. The performance of an RL policy can be easily validated using an extensive and flexible closed-loop evaluation protocol. We also provide behavior cloning baselines using supervised learning and RL, trained in DriverGym.</p>
<div class="line-block">
<div class="line">Authors: Parth Kothari, Christian Perone, Luca Bergamini, Alexandre Alahi, Peter Ondruska</div>
<div class="line">Github: <a class="reference external" href="https://github.com/lyft/l5kit">https://github.com/lyft/l5kit</a></div>
<div class="line">Paper: <a class="reference external" href="https://arxiv.org/abs/2111.06889">https://arxiv.org/abs/2111.06889</a></div>
</div>
</section>
<section id="rl-reach">
<h4>RL Reach<a class="headerlink" href="#rl-reach" title="Permalink to this heading"></a></h4>
<p>A platform for running reproducible reinforcement learning experiments for customizable robotic reaching tasks. This self-contained and straightforward toolbox allows its users to quickly investigate and identify optimal training configurations.</p>
<div class="line-block">
<div class="line">Authors: Pierre Aumjaud, David McAuliffe, Francisco Javier Rodríguez Lera, Philip Cardiff</div>
<div class="line">Github: <a class="reference external" href="https://github.com/PierreExeter/rl_reach">https://github.com/PierreExeter/rl_reach</a></div>
<div class="line">Paper: <a class="reference external" href="https://arxiv.org/abs/2102.04916">https://arxiv.org/abs/2102.04916</a></div>
</div>
</section>
<section id="generalized-state-dependent-exploration-for-deep-reinforcement-learning-in-robotics">
<h4>Generalized State Dependent Exploration for Deep Reinforcement Learning in Robotics<a class="headerlink" href="#generalized-state-dependent-exploration-for-deep-reinforcement-learning-in-robotics" title="Permalink to this heading"></a></h4>
<p>An exploration method to train RL agent directly on real robots.
It was the starting point of Stable-Baselines3.</p>
<div class="line-block">
<div class="line">Author: Antonin Raffin, Freek Stulp</div>
<div class="line">Github: <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/tree/sde">https://github.com/DLR-RM/stable-baselines3/tree/sde</a></div>
<div class="line">Paper: <a class="reference external" href="https://arxiv.org/abs/2005.05719">https://arxiv.org/abs/2005.05719</a></div>
</div>
</section>
<section id="furuta-pendulum-robot">
<h4>Furuta Pendulum Robot<a class="headerlink" href="#furuta-pendulum-robot" title="Permalink to this heading"></a></h4>
<p>Everything you need to build and train a rotary inverted pendulum, also known as a furuta pendulum! This makes use of gSDE listed above.
The Github repository contains code, CAD files and a bill of materials for you to build the robot. You can watch <a class="reference external" href="https://www.youtube.com/watch?v=Y6FVBbqjR40">a video overview of the project here</a>.</p>
<div class="line-block">
<div class="line">Authors: Armand du Parc Locmaria, Pierre Fabre</div>
<div class="line">Github: <a class="reference external" href="https://github.com/Armandpl/furuta">https://github.com/Armandpl/furuta</a></div>
</div>
</section>
<section id="reacher">
<h4>Reacher<a class="headerlink" href="#reacher" title="Permalink to this heading"></a></h4>
<p>A solution to the second project of the Udacity deep reinforcement learning course.
It is an example of:</p>
<ul class="simple">
<li><p>wrapping single and multi-agent Unity environments to make them usable in Stable-Baselines3</p></li>
<li><p>creating experimentation scripts which train and run A2C, PPO, TD3 and SAC models (a better choice for this one is <a class="reference external" href="https://github.com/DLR-RM/rl-baselines3-zoo">https://github.com/DLR-RM/rl-baselines3-zoo</a>)</p></li>
<li><p>generating several pre-trained models which solve the reacher environment</p></li>
</ul>
<div class="line-block">
<div class="line">Author: Marios Koulakis</div>
<div class="line">Github: <a class="reference external" href="https://github.com/koulakis/reacher-deep-reinforcement-learning">https://github.com/koulakis/reacher-deep-reinforcement-learning</a></div>
</div>
</section>
<section id="sumo-rl">
<h4>SUMO-RL<a class="headerlink" href="#sumo-rl" title="Permalink to this heading"></a></h4>
<p>A simple interface to instantiate RL environments with SUMO for Traffic Signal Control.</p>
<ul class="simple">
<li><p>Supports Multiagent RL</p></li>
<li><p>Compatibility with gym.Env and popular RL libraries such as stable-baselines3 and RLlib</p></li>
<li><p>Easy customization: state and reward definitions are easily modifiable</p></li>
</ul>
<div class="line-block">
<div class="line">Author: Lucas Alegre</div>
<div class="line">Github: <a class="reference external" href="https://github.com/LucasAlegre/sumo-rl">https://github.com/LucasAlegre/sumo-rl</a></div>
</div>
</section>
<section id="gym-pybullet-drones">
<h4>gym-pybullet-drones<a class="headerlink" href="#gym-pybullet-drones" title="Permalink to this heading"></a></h4>
<p>PyBullet Gym environments for single and multi-agent reinforcement learning of quadcopter control.</p>
<ul class="simple">
<li><p>Physics-based simulation for the development and test of quadcopter control.</p></li>
<li><p>Compatibility with <code class="docutils literal notranslate"><span class="pre">gym.Env</span></code>, RLlib’s MultiAgentEnv.</p></li>
<li><p>Learning and testing script templates for stable-baselines3 and RLlib.</p></li>
</ul>
<div class="line-block">
<div class="line">Author: Jacopo Panerati</div>
<div class="line">Github: <a class="reference external" href="https://github.com/utiasDSL/gym-pybullet-drones/">https://github.com/utiasDSL/gym-pybullet-drones/</a></div>
<div class="line">Paper: <a class="reference external" href="https://arxiv.org/abs/2103.02142">https://arxiv.org/abs/2103.02142</a></div>
</div>
</section>
<section id="supersuit">
<h4>SuperSuit<a class="headerlink" href="#supersuit" title="Permalink to this heading"></a></h4>
<p>SuperSuit contains easy to use wrappers for Gym (and multi-agent PettingZoo) environments to do all forms of common preprocessing (frame stacking, converting graphical observations to greyscale, max-and-skip for Atari, etc.). It also notably includes:</p>
<p>-Wrappers that apply lambda functions to observations, actions, or rewards with a single line of code.
-All wrappers can be used natively on vector environments, wrappers exist to Gym environments to vectorized environments and concatenate multiple vector environments together
-A wrapper is included that allows for using regular single agent RL libraries (e.g. stable baselines) to learn simple multi-agent PettingZoo environments, explained in this tutorial:</p>
<div class="line-block">
<div class="line">Author: Justin Terry</div>
<div class="line">GitHub: <a class="reference external" href="https://github.com/PettingZoo-Team/SuperSuit">https://github.com/PettingZoo-Team/SuperSuit</a></div>
<div class="line">Tutorial on multi-agent support in stable baselines: <a class="reference external" href="https://towardsdatascience.com/multi-agent-deep-reinforcement-learning-in-15-lines-of-code-using-pettingzoo-e0b963c0820b">https://towardsdatascience.com/multi-agent-deep-reinforcement-learning-in-15-lines-of-code-using-pettingzoo-e0b963c0820b</a></div>
</div>
</section>
<section id="rocket-league-gym">
<h4>Rocket League Gym<a class="headerlink" href="#rocket-league-gym" title="Permalink to this heading"></a></h4>
<p>A fully custom python API and C++ DLL to treat the popular game Rocket League like an OpenAI Gym environment.</p>
<ul class="simple">
<li><p>Dramatically increases the rate at which the game runs.</p></li>
<li><p>Supports full configuration of initial states, observations, rewards, and terminal states.</p></li>
<li><p>Supports multiple simultaneous game clients.</p></li>
<li><p>Supports multi-agent training and self-play.</p></li>
<li><p>Provides custom wrappers for easy use with stable-baselines3.</p></li>
</ul>
<div class="line-block">
<div class="line">Authors: Lucas Emery, Matthew Allen</div>
<div class="line">GitHub: <a class="reference external" href="https://github.com/lucas-emery/rocket-league-gym">https://github.com/lucas-emery/rocket-league-gym</a></div>
<div class="line">Website: <a class="reference external" href="https://rlgym.github.io">https://rlgym.github.io</a></div>
</div>
</section>
<section id="gym-electric-motor">
<h4>gym-electric-motor<a class="headerlink" href="#gym-electric-motor" title="Permalink to this heading"></a></h4>
<p>An OpenAI gym environment for the simulation and control of electric drive trains.
Think of Matlab/Simulink for electric motors, inverters, and load profiles, but non-graphical and open-source in Python.</p>
<p><cite>gym-electric-motor</cite> offers a rich interface for customization, including
- plug-and-play of different control algorithms ranging from classical controllers (like field-oriented control) up to any RL agent you can find,
- reward shaping,
- load profiling,
- finite-set or continuous-set control,
- one-phase and three-phase motors such as induction machines and permanent magnet synchronous motors, among others.</p>
<p>SB3 is used as an example in one of many tutorials showcasing the easy usage of <cite>gym-electric-motor</cite>.</p>
<div class="line-block">
<div class="line">Author: <a class="reference external" href="https://github.com/upb-lea">Paderborn University, LEA department</a></div>
<div class="line">GitHub: <a class="reference external" href="https://github.com/upb-lea/gym-electric-motor">https://github.com/upb-lea/gym-electric-motor</a></div>
<div class="line">SB3 Tutorial: <a class="reference external" href="https://colab.research.google.com/github/upb-lea/gym-electric-motor/blob/master/examples/reinforcement_learning_controllers/stable_baselines3_dqn_disc_pmsm_example.ipynb">Colab Link</a></div>
<div class="line">Paper: <a class="reference external" href="https://joss.theoj.org/papers/10.21105/joss.02498">JOSS</a>, <a class="reference external" href="https://ieeexplore.ieee.org/document/9241851">TNNLS</a>, <a class="reference external" href="https://arxiv.org/abs/1910.09434">ArXiv</a></div>
</div>
</section>
<section id="policy-distillation-baselines">
<h4>policy-distillation-baselines<a class="headerlink" href="#policy-distillation-baselines" title="Permalink to this heading"></a></h4>
<p>A PyTorch implementation of Policy Distillation for control, which has well-trained teachers via Stable Baselines3.</p>
<ul class="simple">
<li><p><cite>policy-distillation-baselines</cite> provides some good examples for policy distillation in various environment and using reliable algorithms.</p></li>
<li><p>All well-trained models and algorithms are compatible with Stable Baselines3.</p></li>
</ul>
<div class="line-block">
<div class="line">Authors: Junyeob Baek</div>
<div class="line">GitHub: <a class="reference external" href="https://github.com/CUN-bjy/policy-distillation-baselines">https://github.com/CUN-bjy/policy-distillation-baselines</a></div>
<div class="line">Demo: <a class="reference external" href="https://github.com/CUN-bjy/policy-distillation-baselines/issues/3#issuecomment-817730173">link</a></div>
</div>
</section>
<section id="highway-env">
<h4>highway-env<a class="headerlink" href="#highway-env" title="Permalink to this heading"></a></h4>
<p>A minimalist environment for decision-making in Autonomous Driving.</p>
<p>Driving policies can be trained in different scenarios, and several notebooks using SB3 are provided as examples.</p>
<div class="line-block">
<div class="line">Author: <a class="reference external" href="https://edouardleurent.com">Edouard Leurent</a></div>
<div class="line">GitHub: <a class="reference external" href="https://github.com/eleurent/highway-env">https://github.com/eleurent/highway-env</a></div>
<div class="line">Examples: <a class="reference external" href="https://github.com/eleurent/highway-env/tree/master/scripts#using-stable-baselines3">Colab Links</a></div>
</div>
</section>
<section id="tactile-gym">
<h4>tactile-gym<a class="headerlink" href="#tactile-gym" title="Permalink to this heading"></a></h4>
<p>Suite of RL environments focused on using a simulated tactile sensor as the primary source of observations. Sim-to-Real results across 4 out of 5 proposed envs.</p>
<div class="line-block">
<div class="line">Author: Alex Church</div>
<div class="line">GitHub: <a class="reference external" href="https://github.com/ac-93/tactile_gym">https://github.com/ac-93/tactile_gym</a></div>
<div class="line">Paper: <a class="reference external" href="https://arxiv.org/abs/2106.08796">https://arxiv.org/abs/2106.08796</a></div>
<div class="line">Website: <a class="reference external" href="https://sites.google.com/my.bristol.ac.uk/tactile-gym-sim2real/home">tactile-gym website</a></div>
</div>
</section>
<section id="rlexplore">
<h4>RLeXplore<a class="headerlink" href="#rlexplore" title="Permalink to this heading"></a></h4>
<p>RLeXplore is a set of implementations of intrinsic reward driven-exploration approaches in reinforcement learning using PyTorch, which can be deployed in arbitrary algorithms in a plug-and-play manner. In particular, RLeXplore is designed to be well compatible with Stable-Baselines3, providing more stable exploration benchmarks.</p>
<ul class="simple">
<li><p>Support arbitrary RL algorithms;</p></li>
<li><p>Highly modular and high expansibility;</p></li>
<li><p>Keep up with the latest research progress.</p></li>
</ul>
<div class="line-block">
<div class="line">Author: Mingqi Yuan</div>
<div class="line">GitHub: <a class="reference external" href="https://github.com/yuanmingqi/rl-exploration-baselines">https://github.com/yuanmingqi/rl-exploration-baselines</a></div>
</div>
</section>
<section id="uav-navigation-drl-airsim">
<h4>UAV_Navigation_DRL_AirSim<a class="headerlink" href="#uav-navigation-drl-airsim" title="Permalink to this heading"></a></h4>
<p>A platform for training UAV navigation policies in complex unknown environments.</p>
<ul class="simple">
<li><p>Based on AirSim and SB3.</p></li>
<li><p>An Open AI Gym env is created including kinematic models for both multirotor and fixed-wing UAVs.</p></li>
<li><p>Some UE4 environments are provided to train and test the navigation policy.</p></li>
</ul>
<p>Try to train your own autonomous flight policy and even transfer it to real UAVs! Have fun ^_^!</p>
<div class="line-block">
<div class="line">Author: Lei He</div>
<div class="line">Github: <a class="reference external" href="https://github.com/heleidsn/UAV_Navigation_DRL_AirSim">https://github.com/heleidsn/UAV_Navigation_DRL_AirSim</a></div>
</div>
</section>
<section id="pink-noise-exploration">
<h4>Pink Noise Exploration<a class="headerlink" href="#pink-noise-exploration" title="Permalink to this heading"></a></h4>
<p>A simple library for pink noise exploration with deterministic (DDPG / TD3) and stochastic (SAC) off-policy algorithms. Pink noise has been shown to work better than uncorrelated Gaussian noise (the default choice) and Ornstein-Uhlenbeck noise on a range of continuous control benchmark tasks. This library is designed to work with Stable Baselines3.</p>
<div class="line-block">
<div class="line">Authors: Onno Eberhard, Jakob Hollenstein, Cristina Pinneri, Georg Martius</div>
<div class="line">Github: <a class="reference external" href="https://github.com/martius-lab/pink-noise-rl">https://github.com/martius-lab/pink-noise-rl</a></div>
<div class="line">Paper: <a class="reference external" href="https://openreview.net/forum?id=hQ9V5QN27eS">https://openreview.net/forum?id=hQ9V5QN27eS</a> (Oral at ICLR 2023)</div>
</div>
</section>
<section id="mobile-env">
<h4>mobile-env<a class="headerlink" href="#mobile-env" title="Permalink to this heading"></a></h4>
<p>An open, minimalist Gymnasium environment for autonomous coordination in wireless mobile networks.
It allows simulating various scenarios with moving users in a cellular network with multiple base stations.</p>
<ul class="simple">
<li><p>Written in pure Python, easy to modify and extend, and can be installed directly via PyPI.</p></li>
<li><p>Implements the standard Gymnasium interface such that it can be used with all common frameworks for reinforcement learning.</p></li>
<li><p>There are examples for both single-agent and multi-agent RL using either <cite>stable-baselines3</cite> or Ray RLlib.</p></li>
</ul>
<div class="line-block">
<div class="line">Authors: Stefan Schneider, Stefan Werner</div>
<div class="line">Github: <a class="reference external" href="https://github.com/stefanbschneider/mobile-env">https://github.com/stefanbschneider/mobile-env</a></div>
<div class="line">Paper: <a class="reference external" href="https://ris.uni-paderborn.de/download/30236/30237">https://ris.uni-paderborn.de/download/30236/30237</a> (2022 IEEE/IFIP Network Operations and Management Symposium (NOMS))</div>
</div>
</section>
<section id="deepnetslice">
<h4>DeepNetSlice<a class="headerlink" href="#deepnetslice" title="Permalink to this heading"></a></h4>
<p>A Deep Reinforcement Learning Open-Source Toolkit for Network Slice Placement (NSP).</p>
<p>NSP is the problem of deciding which physical servers in a network should host the virtual network functions (VNFs) that make up a network slice, as well as managing the mapping of the virtual links between the VNFs onto the physical infrastructure.
It is a complex optimization problem, as it involves considering the requirements of the network slice and the available resources on the physical network.
The goal is generally to maximize the utilization of the physical resources while ensuring that the network slices meet their performance requirements.</p>
<p>The toolkit includes a customizable simulation environments, as well as some ready-to-use demos for training
intelligent agents to perform network slice placement.</p>
<div class="line-block">
<div class="line">Author: Alex Pasquali</div>
<div class="line">Github: <a class="reference external" href="https://github.com/AlexPasqua/DeepNetSlice">https://github.com/AlexPasqua/DeepNetSlice</a></div>
<div class="line">Paper: <strong>under review</strong> (citation instructions on the project’s README.md) -&gt; see this Master’s Thesis for the moment: <a class="reference external" href="https://etd.adm.unipi.it/theses/available/etd-01182023-110038/unrestricted/Tesi_magistrale_Pasquali_Alex.pdf">https://etd.adm.unipi.it/theses/available/etd-01182023-110038/unrestricted/Tesi_magistrale_Pasquali_Alex.pdf</a></div>
</div>
</section>
<section id="pokemonredexperiments">
<h4>PokemonRedExperiments<a class="headerlink" href="#pokemonredexperiments" title="Permalink to this heading"></a></h4>
<p>Playing Pokemon Red with Reinforcement Learning.</p>
<div class="line-block">
<div class="line">Author: Peter Whidden</div>
<div class="line">Github: <a class="reference external" href="https://github.com/PWhiddy/PokemonRedExperiments">https://github.com/PWhiddy/PokemonRedExperiments</a></div>
<div class="line">Video: <a class="reference external" href="https://www.youtube.com/watch?v=DcYLT37ImBY">https://www.youtube.com/watch?v=DcYLT37ImBY</a></div>
</div>
</section>
</section>
</div>
</section>
<section id="citing-stable-baselines3">
<h2>Citing Stable Baselines3<a class="headerlink" href="#citing-stable-baselines3" title="Permalink to this heading"></a></h2>
<p>To cite this project in publications:</p>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">stable-baselines3</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="w">  </span><span class="p">=</span><span class="w"> </span><span class="s">{Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann}</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="w">   </span><span class="p">=</span><span class="w"> </span><span class="s">{Stable-Baselines3: Reliable Reinforcement Learning Implementations}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Journal of Machine Learning Research}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="w">    </span><span class="p">=</span><span class="w"> </span><span class="s">{2021}</span><span class="p">,</span>
<span class="w">  </span><span class="na">volume</span><span class="w">  </span><span class="p">=</span><span class="w"> </span><span class="s">{22}</span><span class="p">,</span>
<span class="w">  </span><span class="na">number</span><span class="w">  </span><span class="p">=</span><span class="w"> </span><span class="s">{268}</span><span class="p">,</span>
<span class="w">  </span><span class="na">pages</span><span class="w">   </span><span class="p">=</span><span class="w"> </span><span class="s">{1-8}</span><span class="p">,</span>
<span class="w">  </span><span class="na">url</span><span class="w">     </span><span class="p">=</span><span class="w"> </span><span class="s">{http://jmlr.org/papers/v22/20-1364.html}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="contributing">
<h2>Contributing<a class="headerlink" href="#contributing" title="Permalink to this heading"></a></h2>
<p>To any interested in making the rl baselines better, there are still some improvements
that need to be done.
You can check issues in the <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/issues">repo</a>.</p>
<p>If you want to contribute, please read <a class="reference external" href="https://github.com/DLR-RM/stable-baselines3/blob/master/CONTRIBUTING.md">CONTRIBUTING.md</a> first.</p>
</section>
<section id="indices-and-tables">
<h2>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></p></li>
<li><p><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></p></li>
<li><p><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021-2023, Stable Baselines3.
      <span class="commit">Revision <code>373166d6</code>.
      </span></p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="Versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: master
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Versions</dt>
        
          <dd><a href="/en/master/">master</a></dd>
        
          <dd><a href="/en/v2.2.1/">v2.2.1</a></dd>
        
          <dd><a href="/en/v2.1.0_a/">v2.1.0_a</a></dd>
        
          <dd><a href="/en/v2.1.0/">v2.1.0</a></dd>
        
          <dd><a href="/en/v2.0.0/">v2.0.0</a></dd>
        
          <dd><a href="/en/v1.8.0/">v1.8.0</a></dd>
        
          <dd><a href="/en/v1.7.0/">v1.7.0</a></dd>
        
          <dd><a href="/en/v1.6.2/">v1.6.2</a></dd>
        
          <dd><a href="/en/v1.5.0/">v1.5.0</a></dd>
        
          <dd><a href="/en/v1.4.0/">v1.4.0</a></dd>
        
          <dd><a href="/en/v1.0/">v1.0</a></dd>
        
          <dd><a href="/en/v0.11.1/">v0.11.1</a></dd>
        
          <dd><a href="/en/sde/">sde</a></dd>
        
          <dd><a href="/en/feat-gymnasium-support/">feat-gymnasium-support</a></dd>
        
          <dd><a href="/en/chores-update-deps/">chores-update-deps</a></dd>
        
      </dl>
      <dl>
        <dt>Downloads</dt>
        
          <dd><a href="//stable-baselines3.readthedocs.io/_/downloads/en/master/pdf/">pdf</a></dd>
        
          <dd><a href="//stable-baselines3.readthedocs.io/_/downloads/en/master/htmlzip/">html</a></dd>
        
          <dd><a href="//stable-baselines3.readthedocs.io/_/downloads/en/master/epub/">epub</a></dd>
        
      </dl>
      <dl>
        
        <dt>On Read the Docs</dt>
          <dd>
            <a href="//readthedocs.org/projects/stable-baselines3/?fromdocs=stable-baselines3">Project Home</a>
          </dd>
          <dd>
            <a href="//readthedocs.org/builds/stable-baselines3/?fromdocs=stable-baselines3">Builds</a>
          </dd>
      </dl>
    </div>
  </div>
<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>